["Chapter 1\nVectors in R\ud835\udc5b\n1.1\nIntroduction\nLinear algebra is used widely in the social sciences, business, science, and engineering.\nVectors are used in the sciences for displacement, velocity, acceleration, force, and many\nother important physical concepts. Informally, a vector is an object that has both magnitude\nand direction. For instance, the velocity of a boat on a river can be represented by a vector\nthat encodes both its magnitude (speed) and its direction of travel.\nIn mathematics, a vector is represented by a column of numbers, as in the following defini-\ntion.\nDefinition 1.1.1\nR\ud835\udc5b, Vector in R\ud835\udc5b\nThe set R\ud835\udc5b is defined as\n\u23a7\n\u23aa\n\u23a8\n\u23aa\n\u23a9\n#\u00bb\ud835\udc65 =\n\u23a1\n\u23a2\u23a3\n\ud835\udc651\n...\n\ud835\udc65\ud835\udc5b\n\u23a4\n\u23a5\u23a6 : \ud835\udc651, . . . , \ud835\udc65\ud835\udc5b \u2208 R\n\u23ab\n\u23aa\n\u23ac\n\u23aa\n\u23ad\n.\nA vector is an element #\u00bb\ud835\udc65 =\n\u23a1\n\u23a2\u23a3\n\ud835\udc651\n...\n\ud835\udc65\ud835\udc5b\n\u23a4\n\u23a5\u23a6 of R\ud835\udc5b.\nREMARK\nIn these notes, a vector is indicated by an accented right arrow: #\u00bb\ud835\udc63 .\nOther texts use different notation for vectors, such as v or \ud835\udc63.\nExample 1.1.2\nThe following are vectors: #\u00bb\ud835\udc64 =\n[\ufe022\n3\n]\ufe02\n\u2208 R2,\n#\u00bb\ud835\udc63 =\n\u23a1\n\u23a3\n\u22123\n1\n\u22125\n\u23a4\n\u23a6 \u2208 R3, and #\u00bb\ud835\udc62 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc621\n\ud835\udc622\n...\n\ud835\udc62100\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 \u2208 R100.\n56\nChapter 1\nVectors in R\ud835\udc5b\nWe will usually write vectors in column notation. It can be more convenient and compact\nto write a vector in row notation, which includes the superscript \u201c\ud835\udc47\u201d (short for transpose)\nand clearly separates the components of the vectors with spaces, as follows.\nDefinition 1.1.3\nRow Notation for a\nVector\nThe row notation for the vector #\u00bb\ud835\udc63 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc631\n\ud835\udc632\n...\n\ud835\udc63\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 is #\u00bb\ud835\udc63 =\n[\ufe00\n\ud835\udc631 \ud835\udc632 \u00b7 \u00b7 \u00b7 \ud835\udc63\ud835\udc5b\n]\ufe00\ud835\udc47 .\nREMARK\nMany texts do not distinguish between\n[\ufe00\n\ud835\udc631 \ud835\udc632 \u00b7 \u00b7 \u00b7 \ud835\udc63\ud835\udc5b\n]\ufe00\nand\n[\ufe00\n\ud835\udc631 \ud835\udc632 \u00b7 \u00b7 \u00b7 \ud835\udc63\ud835\udc5b\n]\ufe00\ud835\udc47 .\nFor our purposes, this distinction is important, i.e.\n[\ufe00\n\ud835\udc631 \ud835\udc632 . . . \ud835\udc63\ud835\udc5b\n]\ufe00\n\u0338=\n[\ufe00\n\ud835\udc631 \ud835\udc632 . . . \ud835\udc63\ud835\udc5b\n]\ufe00\ud835\udc47 .\n1.2", "Algebraic and Geometric Representation of Vectors\nA vector\u2019s algebraic representation consists of a column of numbers, e.g. #\u00bb\ud835\udc63 =\n[\ufe022\n3\n]\ufe02\n.\nA vector\u2019s geometric representation consists of a directed line segment in R\ud835\udc5b.\nVectors are not localized; that is, if two vectors have the same magnitude and direction,\nbut different starting points, we consider those vectors to be equal. For convenience, we\noften choose the starting point of a vector to be the origin, \ud835\udc42.\nFigure 1.2.1: Vectors and the Origin\nRelationship between Geometric and Algebraic Representations\nConsider the geometric representation for a vector #\u00bb\ud835\udc63 in R\ud835\udc5b, which is a directed line segment.\nWe typically consider the initial point of #\u00bb\ud835\udc63 to be the origin \ud835\udc42 and call its terminal point V\n(i.e., we use the same letter as the vector). If the point V has coordinates (\ud835\udc631, \ud835\udc632, . . . , \ud835\udc63\ud835\udc5b),\nthen we write the vector #\u00bb\ud835\udc63 as\n#\u00bb\ud835\udc63 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc631\n\ud835\udc632\n...\n\ud835\udc63\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6\nThis \ud835\udc5b-tuple is the algebraic representation of #\u00bb\ud835\udc63 .Section 1.3", "Operations on Vectors\n7\nOn the other hand, if the algebraic representation of a vector #\u00bb\ud835\udc63 in R\ud835\udc5b is\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc631\n\ud835\udc632\n...\n\ud835\udc63\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6, then its\ngeometric interpretation is a directed line segment from the initial point, \ud835\udc42, to the terminal\npoint, V, with co-ordinates (\ud835\udc631, \ud835\udc632, . . . , \ud835\udc63\ud835\udc5b).\nFigure 1.2.2: The geometric representation of #\u00bb\ud835\udc63 =\n[\ufe02\ud835\udc631\n\ud835\udc632\n]\ufe02\nin R2\nWe are free to move the vector #\u00bb\ud835\udc63 around, as long as we maintain its magnitude and direction;\nhowever, moving it will change both the initial and terminal points. We say that the point\n\ud835\udc49 is the terminal point associated with the vector #\u00bb\ud835\udc63 (using the initial point as \ud835\udc42), or more\nsimply, we say that \ud835\udc49 is the point associated with the vector #\u00bb\ud835\udc63 .\nExample 1.2.1\nThe point \ud835\udc49 = (2, \u22124, 9) is the terminal point associated with the vector #\u00bb\ud835\udc63 =\n\u23a1\n\u23a3\n2\n\u22124\n9\n\u23a4\n\u23a6 in R3.\n1.3\nOperations on Vectors\nDefinition 1.3.1\nEquality of Vectors\nin R\ud835\udc5b\nWe say that vectors #\u00bb\ud835\udc62 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc621\n\ud835\udc622\n...\n\ud835\udc62\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 and #\u00bb\ud835\udc63 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc631\n\ud835\udc632\n...\n\ud835\udc63\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 in R\ud835\udc5b are equal if \ud835\udc62\ud835\udc56 = \ud835\udc63\ud835\udc56 for all \ud835\udc56 = 1, . . . , \ud835\udc5b.\nWe denote this by writing #\u00bb\ud835\udc62 = #\u00bb\ud835\udc63 .\nThe vector equation #\u00bb\ud835\udc62 = #\u00bb\ud835\udc63 is therefore equivalent to a system of \ud835\udc5b equations, one for each\ncomponent.\nExample 1.3.2\nIf #\u00bb\ud835\udc62 =\n\u23a1\n\u23a3\n1\n2\n3\n\u23a4\n\u23a6 and #\u00bb\ud835\udc63 =\n\u23a1\n\u23a3\n1\n2\n4\n\u23a4\n\u23a6, then #\u00bb\ud835\udc62 \u0338= #\u00bb\ud835\udc63 because \ud835\udc623 \u0338= \ud835\udc633.8\nChapter 1\nVectors in R\ud835\udc5b\nGeometrically, two vectors #\u00bb\ud835\udc62 and #\u00bb\ud835\udc63 are said to be equal if they have the same magnitude\nand the same direction.\nDefinition 1.3.3\nAddition in R\ud835\udc5b\nLet #\u00bb\ud835\udc62 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc621\n\ud835\udc622\n...\n\ud835\udc62\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 , #\u00bb\ud835\udc63 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc631\n\ud835\udc632\n...\n\ud835\udc63\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 \u2208 R\ud835\udc5b. Then #\u00bb\ud835\udc62 + #\u00bb\ud835\udc63 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc621\n\ud835\udc622\n...\n\ud835\udc62\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 +\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc631\n\ud835\udc632\n...\n\ud835\udc63\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc621 + \ud835\udc631\n\ud835\udc622 + \ud835\udc632\n...\n\ud835\udc62\ud835\udc5b + \ud835\udc63\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6.\nExample 1.3.4\nWe have\n\u23a1\n\u23a3\n2\n4\n6\n\u23a4\n\u23a6 +\n\u23a1\n\u23a3\n3\n\u22125\n7\n\u23a4\n\u23a6 =\n\u23a1\n\u23a3\n2 + 3\n4 \u2212 5\n6 + 7\n\u23a4\n\u23a6 =\n\u23a1\n\u23a3\n5\n\u22121\n13\n\u23a4\n\u23a6 .\nGeometrically, the vector #\u00bb\ud835\udc64 = #\u00bb\ud835\udc62 + #\u00bb\ud835\udc63 follows the Parallelogram Law, illustrated in the\nfollowing example with #\u00bb\ud835\udc63 moved so that its initial point is the terminal point of #\u00bb\ud835\udc62.\nExample 1.3.5\nAdd #\u00bb\ud835\udc62 =\n[\ufe02\u22122\n3\n]\ufe02\nto #\u00bb\ud835\udc63 =\n[\ufe025\n1\n]\ufe02\nin R2. Show the result geometrically.\nSolution: #\u00bb\ud835\udc62 + #\u00bb\ud835\udc63 =\n[\ufe02\u22122\n3\n]\ufe02\n+\n[\ufe025\n1\n]\ufe02\n=\n[\ufe023\n4\n]\ufe02\n.\nREMARK\nIn this course, most of the time we will be labelling axes in R2 as \ud835\udc651, \ud835\udc652 instead of \ud835\udc65, \ud835\udc66.\nSimilarly, in R3 we will be labelling axes as \ud835\udc651, \ud835\udc652, \ud835\udc653 instead of \ud835\udc65, \ud835\udc66, \ud835\udc67. We recommend you\nto follow that practice as well.\nExample 1.3.6\nSuppose a boat is moving with a velocity of #\u00bb\ud835\udc62 and a person on the boat walks with velocity\n#\u00bb\ud835\udc63 on (relative to) the boat. An observer on the shore sees the person move with velocity\n#\u00bb\ud835\udc64 = #\u00bb\ud835\udc62 + #\u00bb\ud835\udc63 , and thus sees the combined velocity of the person and the boat.\nThe following rules of vector addition follow from the properties of addition of real numbers.Section 1.3\nOperations on Vectors\n9\nProposition 1.3.7\n(Properties of Vector Addition)\nLet #\u00bb\ud835\udc62, #\u00bb\ud835\udc63 , #\u00bb\ud835\udc64 \u2208 R\ud835\udc5b.\n(a) #\u00bb\ud835\udc62 + #\u00bb\ud835\udc63 = #\u00bb\ud835\udc63 + #\u00bb\ud835\udc62\n(symmetry)\n(b) #\u00bb\ud835\udc62 + #\u00bb\ud835\udc63 + #\u00bb\ud835\udc64 = #\u00bb\ud835\udc62 + (#\u00bb\ud835\udc63 + #\u00bb\ud835\udc64) = (#\u00bb\ud835\udc62 + #\u00bb\ud835\udc63 ) + #\u00bb\ud835\udc64\n(associativity)\n(c) There is a zero vector, #\u00bb0 =\n[\ufe00\n0 0 \u00b7 \u00b7 \u00b7 0\n]\ufe00\ud835\udc47 in R\ud835\udc5b, with the property that\n#\u00bb\ud835\udc63 + #\u00bb0 = #\u00bb0 + #\u00bb\ud835\udc63 = #\u00bb\ud835\udc63 .\nEXERCISE\nProve Proposition 1.3.7 (Properties of Vector Addition).\nFor many of the results in this chapter, the proof is left as an exercise for you.\nDefinition 1.3.8\nAdditive Inverse\nLet #\u00bb\ud835\udc62 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc621\n\ud835\udc622\n...\n\ud835\udc62\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 \u2208 R\ud835\udc5b. The additive inverse of #\u00bb\ud835\udc62, denoted \u2212#\u00bb\ud835\udc62, is defined as\n\u2212#\u00bb\ud835\udc62 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\u2212\ud835\udc621\n\u2212\ud835\udc622\n...\n\u2212\ud835\udc62\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 .\nExample 1.3.9\nIf #\u00bb\ud835\udc62 =\n\u23a1\n\u23a3\n1\n\u22124\n2\n\u23a4\n\u23a6, then \u2212#\u00bb\ud835\udc62 =\n\u23a1\n\u23a3\n\u22121\n4\n\u22122\n\u23a4\n\u23a6.\nWe now notice the key property of the additive inverse.\nProposition 1.3.10\n(Additive Inverse Property)\nIf #\u00bb\ud835\udc62 \u2208 R\ud835\udc5b, we have\n#\u00bb\ud835\udc62 \u2212 #\u00bb\ud835\udc62 = #\u00bb\ud835\udc62 + (\u2212#\u00bb\ud835\udc62) = (\u2212#\u00bb\ud835\udc62) + #\u00bb\ud835\udc62 = #\u00bb0 .\nThus \u2212#\u00bb\ud835\udc62 has the effect of \u201ccancelling\u201d the vector #\u00bb\ud835\udc62 when addition is performed (hence the\nterm additive inverse).10\nChapter 1\nVectors in R\ud835\udc5b\nREMARK\nThe vector \u2212#\u00bb\ud835\udc62 has the same magnitude as #\u00bb\ud835\udc62, but the opposite direction.\nDefinition 1.3.11\nSubtraction in R\ud835\udc5b\nLet #\u00bb\ud835\udc63 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc631\n\ud835\udc632\n...\n\ud835\udc63\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6, #\u00bb\ud835\udc62 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc621\n\ud835\udc622\n...\n\ud835\udc62\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 and \u2212#\u00bb\ud835\udc62 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\u2212\ud835\udc621\n\u2212\ud835\udc622\n...\n\u2212\ud835\udc62\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 be vectors in R\ud835\udc5b. We define\n#\u00bb\ud835\udc63 \u2212 #\u00bb\ud835\udc62 = #\u00bb\ud835\udc63 + (\u2212#\u00bb\ud835\udc62) =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc631 \u2212 \ud835\udc621\n\ud835\udc632 \u2212 \ud835\udc622\n...\n\ud835\udc63\ud835\udc5b \u2212 \ud835\udc62\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 .\nFigure 1.3.3: General geometric interpretation of #\u00bb\ud835\udc63 \u2212 #\u00bb\ud835\udc62\nExample 1.3.12\nWe have\n\u23a1\n\u23a3\n2\n4\n6\n\u23a4\n\u23a6 \u2212\n\u23a1\n\u23a3\n3\n\u22125\n7\n\u23a4\n\u23a6 =\n\u23a1\n\u23a3\n2 \u2212 3\n4 + 5\n6 \u2212 7\n\u23a4\n\u23a6 =\n\u23a1\n\u23a3\n\u22121\n9\n\u22121\n\u23a4\n\u23a6 .\nFor vectors in R\ud835\udc5b with \ud835\udc5b > 1, we do not define a component-wise \u201cvector multiplication\u201d,\nas we did for addition and subtraction, since such an operation turns out to be of little use\nin linear algebra. There are different types of \u201cvector products\u201d that we do define, however.\nThese will be discussed later in this chapter.\nIn the meantime, we will define the scalar multiplication of a vector by a real number \ud835\udc50.\nDefinition 1.3.13\nScalar\nMultiplication\nLet \ud835\udc50 \u2208 R and #\u00bb\ud835\udc63 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc631\n\ud835\udc632\n...\n\ud835\udc63\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 \u2208 R\ud835\udc5b. We define \ud835\udc50#\u00bb\ud835\udc63 = \ud835\udc50\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc631\n\ud835\udc632\n...\n\ud835\udc63\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc50\ud835\udc631\n\ud835\udc50\ud835\udc632\n...\n\ud835\udc50\ud835\udc63\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6.\nWe say that the vector #\u00bb\ud835\udc63 is scaled by \ud835\udc50.\nFor this reason, real numbers are often referred to as scalars.Section 1.3\nOperations on Vectors\n11\nFigure 1.3.4: Scalar multiplication of #\u00bb\ud835\udc63\nREMARKS\n\u2022 When \ud835\udc50 > 0, the vector \ud835\udc50#\u00bb\ud835\udc63 points in the direction of #\u00bb\ud835\udc63 and is \ud835\udc50 times as long.\n\u2022 When \ud835\udc50 < 0, then \ud835\udc50#\u00bb\ud835\udc63 points in the opposite direction to #\u00bb\ud835\udc63 and is |\ud835\udc50| times as long.\n\u2022 The vector (\u22121)#\u00bb\ud835\udc63 = \u2212#\u00bb\ud835\udc63 has the same length as #\u00bb\ud835\udc63 but points in the opposite direction.\nProposition 1.3.14\n(Properties of Scalar Multiplication)\nLet \ud835\udc50, \ud835\udc51 \u2208 R and #\u00bb\ud835\udc62, #\u00bb\ud835\udc63 \u2208 R\ud835\udc5b.\n(a) (\ud835\udc50 + \ud835\udc51)#\u00bb\ud835\udc63 = \ud835\udc50#\u00bb\ud835\udc63 + \ud835\udc51#\u00bb\ud835\udc63 .\n(b) (\ud835\udc50\ud835\udc51)#\u00bb\ud835\udc63 = \ud835\udc50(\ud835\udc51#\u00bb\ud835\udc63 ).\n(c) \ud835\udc50(#\u00bb\ud835\udc62 + #\u00bb\ud835\udc63 ) = \ud835\udc50#\u00bb\ud835\udc62 + \ud835\udc50#\u00bb\ud835\udc63 .\n(d) 0#\u00bb\ud835\udc63 = #\u00bb0 .\n(e) If \ud835\udc50#\u00bb\ud835\udc63 = #\u00bb0 , then \ud835\udc50 = 0 or #\u00bb\ud835\udc63 = #\u00bb0 .\n(cancellation law)\nProperty (e) may look especially familiar, because the following result is often used in\nmathematics when dealing with real numbers:\nFor all \ud835\udc4e, \ud835\udc4f \u2208 R, if \ud835\udc4e\ud835\udc4f = 0, then \ud835\udc4e = 0 or \ud835\udc4f = 0.\nDefinition 1.3.15\nStandard Basis for\nR\ud835\udc5b\nIn R\ud835\udc5b, let #\u00bb\n\ud835\udc52\ud835\udc56 be the vector whose \ud835\udc56\ud835\udc61\u210e component is 1 with all other components 0. The set\n\u2130 = {#\u00bb\n\ud835\udc521, #\u00bb\n\ud835\udc522, . . . , #\u00bb\n\ud835\udc52\ud835\udc5b} is called the standard basis for R\ud835\udc5b.\nExample 1.3.16\nThe standard basis for R3 is {#\u00bb\n\ud835\udc521, #\u00bb\n\ud835\udc522, #\u00bb\n\ud835\udc523} =\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n1\n0\n0\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n0\n1\n0\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n0\n0\n1\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad.\nDefinition 1.3.17\nComponents\nIf #\u00bb\ud835\udc63 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc631\n\ud835\udc632\n...\n\ud835\udc63\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 = \ud835\udc631 #\u00bb\n\ud835\udc521 + \ud835\udc632 #\u00bb\n\ud835\udc522 + ... + \ud835\udc63\ud835\udc5b #\u00bb\n\ud835\udc52\ud835\udc5b, then we call \ud835\udc631, \ud835\udc632, ..., \ud835\udc63\ud835\udc5b the components of #\u00bb\ud835\udc63 .12\nChapter 1\nVectors in R\ud835\udc5b\nExample 1.3.18\nIn R2, #\u00bb\ud835\udc63 =\n[\ufe022\n3\n]\ufe02\n= 2#\u00bb\n\ud835\udc521 + 3#\u00bb\n\ud835\udc522 = 2\n[\ufe021\n0\n]\ufe02\n+ 3\n[\ufe020\n1\n]\ufe02\n.\nExample 1.3.19\nIf #\u00bb\ud835\udc63 =\n\u23a1\n\u23a3\n5\n3\n\u22124\n\u23a4\n\u23a6 \u2208 R3, then #\u00bb\ud835\udc63 = 5\n\u23a1\n\u23a3\n1\n0\n0\n\u23a4\n\u23a6 + 3\n\u23a1\n\u23a3\n0\n1\n0\n\u23a4\n\u23a6 \u2212 4\n\u23a1\n\u23a3\n0\n0\n1\n\u23a4\n\u23a6 = 5#\u00bb\n\ud835\udc521 + 3#\u00bb\n\ud835\udc522 \u2212 4#\u00bb\n\ud835\udc523.\nThe components of #\u00bb\ud835\udc63 are 5, 3 and \u22124.\n1.4", "Vectors in C\ud835\udc5b\nVectors are also defined in C\ud835\udc5b, where each component is a complex number.\nEquality,\naddition, subtraction, scalar multiplication, and the cancellation law in C\ud835\udc5b are all defined\nas in the previous propositions, replacing R with C.\nDefinition 1.4.1\nC\ud835\udc5b, Vector in C\ud835\udc5b\nThe set C\ud835\udc5b is defined as\n\u23a7\n\u23aa\n\u23a8\n\u23aa\n\u23a9\n#\u00bb\ud835\udc67 =\n\u23a1\n\u23a2\u23a3\n\ud835\udc671\n...\n\ud835\udc67\ud835\udc5b\n\u23a4\n\u23a5\u23a6 : \ud835\udc671, . . . , \ud835\udc67\ud835\udc5b \u2208 C\n\u23ab\n\u23aa\n\u23ac\n\u23aa\n\u23ad\n.\nA vector is an element #\u00bb\ud835\udc67 =\n\u23a1\n\u23a2\u23a3\n\ud835\udc671\n...\n\ud835\udc67\ud835\udc5b\n\u23a4\n\u23a5\u23a6 of C\ud835\udc5b.\nExample 1.4.2\nWe have #\u00bb\ud835\udc64 =\n[\ufe021 \u2212 2\ud835\udc56\n7\n]\ufe02\n\u2208 C2 and #\u00bb\ud835\udc67 =\n\u23a1\n\u23a3\n1 + \ud835\udc56\n2 \u2212 3\ud835\udc56\n\u22124 + 5\ud835\udc56\n\u23a4\n\u23a6 \u2208 C3.\nAddition, subtraction, and scalar multiplication in C\ud835\udc5b are defined as in R\ud835\udc5b.\nExample 1.4.3\nThe expression 3\n[\ufe021 + \ud835\udc56\n2 + \ud835\udc56\n]\ufe02\n\u2212 2\n[\ufe022 \u2212 \ud835\udc56\n4 + \ud835\udc56\n]\ufe02\nevaluates to\n3\n[\ufe021 + \ud835\udc56\n2 + \ud835\udc56\n]\ufe02\n\u2212 2\n[\ufe022 \u2212 \ud835\udc56\n4 + \ud835\udc56\n]\ufe02\n=\n[\ufe023 + 3\ud835\udc56\n6 + 3\ud835\udc56\n]\ufe02\n\u2212\n[\ufe024 \u2212 2\ud835\udc56\n8 + 2\ud835\udc56\n]\ufe02\n=\n[\ufe02\u22121 + 5\ud835\udc56\n\u22122 + \ud835\udc56\n]\ufe02\n.Section 1.5", "Dot Product in R\ud835\udc5b\n13\nExample 1.4.4\nIf \ud835\udc50 \u2208 C and #\u00bb\ud835\udc67 , #\u00bb\ud835\udc64 \u2208 C\ud835\udc5b and (\ud835\udc50 \u2212 4 \u2212 \ud835\udc56)(#\u00bb\ud835\udc67 \u2212 #\u00bb\ud835\udc64) = #\u00bb0 , then \ud835\udc50 = 4 + \ud835\udc56 or #\u00bb\ud835\udc67 = #\u00bb\ud835\udc64.\nThe standard basis {#\u00bb\n\ud835\udc521, #\u00bb\n\ud835\udc522, ..., #\u00bb\n\ud835\udc52\ud835\udc5b} for C\ud835\udc5b is the same as the standard basis for R\ud835\udc5b.\nDefinition 1.4.5\nStandard Basis for\nC\ud835\udc5b\nIn C\ud835\udc5b, let #\u00bb\n\ud835\udc52\ud835\udc56 represent the vector whose \ud835\udc56\ud835\udc61\u210e component is 1 with all other components 0.\nThe set {#\u00bb\n\ud835\udc521, #\u00bb\n\ud835\udc522, ..., #\u00bb\n\ud835\udc52\ud835\udc5b} is called the standard basis for C\ud835\udc5b.\nExample 1.4.6\nThe standard basis for C4 is {#\u00bb\n\ud835\udc521, #\u00bb\n\ud835\udc522, #\u00bb\n\ud835\udc523, #\u00bb\n\ud835\udc524} =\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n1\n0\n0\n0\n\u23a4\n\u23a5\u23a5\u23a6 ,\n\u23a1\n\u23a2\u23a2\u23a3\n0\n1\n0\n0\n\u23a4\n\u23a5\u23a5\u23a6 ,\n\u23a1\n\u23a2\u23a2\u23a3\n0\n0\n1\n0\n\u23a4\n\u23a5\u23a5\u23a6 ,\n\u23a1\n\u23a2\u23a2\u23a3\n0\n0\n0\n1\n\u23a4\n\u23a5\u23a5\u23a6\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n.\nDefinition 1.4.7\nComponents\nIf #\u00bb\ud835\udc63 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc631\n\ud835\udc632\n...\n\ud835\udc63\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 = \ud835\udc631 #\u00bb\n\ud835\udc521 + \ud835\udc632 #\u00bb\n\ud835\udc522 + ... + \ud835\udc63\ud835\udc5b #\u00bb\n\ud835\udc52\ud835\udc5b, then we refer to \ud835\udc631, \ud835\udc632, ..., \ud835\udc63\ud835\udc5b as the components\nof #\u00bb\ud835\udc63 .\nExample 1.4.8\nIf #\u00bb\ud835\udc63 =\n\u23a1\n\u23a3\n5 + \ud835\udc56\n3\ud835\udc56\n\u22124\n\u23a4\n\u23a6 \u2208 C3, then #\u00bb\ud835\udc63 = (5 + \ud835\udc56)\n\u23a1\n\u23a3\n1\n0\n0\n\u23a4\n\u23a6 + 3\ud835\udc56\n\u23a1\n\u23a3\n0\n1\n0\n\u23a4\n\u23a6 \u2212 4\n\u23a1\n\u23a3\n0\n0\n1\n\u23a4\n\u23a6 = (5 + \ud835\udc56)#\u00bb\n\ud835\udc521 + 3\ud835\udc56 #\u00bb\n\ud835\udc522 \u2212 4#\u00bb\n\ud835\udc523.\nThe components of #\u00bb\ud835\udc63 are 5 + \ud835\udc56, 3\ud835\udc56 and \u22124.\n1.5\nDot Product in R\ud835\udc5b\nThe dot product is a function that takes as input two vectors in R\ud835\udc5b and returns a real\nnumber. (Later, we will adapt this idea to vectors in C\ud835\udc5b using a different operation.)\nDefinition 1.5.1\nDot Product\nLet #\u00bb\ud835\udc62 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc621\n\ud835\udc622\n...\n\ud835\udc62\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 and #\u00bb\ud835\udc63 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc631\n\ud835\udc632\n...\n\ud835\udc63\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 be vectors in R\ud835\udc5b. We define their dot product by\n#\u00bb\ud835\udc62 \u00b7 #\u00bb\ud835\udc63 = \ud835\udc621\ud835\udc631 + \ud835\udc622\ud835\udc632 + \u00b7 \u00b7 \u00b7 + \ud835\udc62\ud835\udc5b\ud835\udc63\ud835\udc5b.\nExample 1.5.2\nWe have\n[\ufe022\n3\n]\ufe02\n\u00b7\n[\ufe025\n7\n]\ufe02\n= 2(5)+3(7) = 31 and\n\u23a1\n\u23a3\n3\n\u22125\n2\n\u23a4\n\u23a6\u00b7\n\u23a1\n\u23a3\n\u22124\n4\n\u22122\n\u23a4\n\u23a6 = 3(\u22124)+(\u22125)(4)+2(\u22122) = \u221236.14\nChapter 1\nVectors in R\ud835\udc5b\nProposition 1.5.3\n(Properties of the Dot Product)\nIf \ud835\udc50 \u2208 R and #\u00bb\ud835\udc62, #\u00bb\ud835\udc63 , #\u00bb\ud835\udc64 are vectors in R\ud835\udc5b, then:\n(a) #\u00bb\ud835\udc62 \u00b7 #\u00bb\ud835\udc63 = #\u00bb\ud835\udc63 \u00b7 #\u00bb\ud835\udc62\n(symmetry)\n(b) (#\u00bb\ud835\udc62 + #\u00bb\ud835\udc63 ) \u00b7 #\u00bb\ud835\udc64 = #\u00bb\ud835\udc62 \u00b7 #\u00bb\ud835\udc64 + #\u00bb\ud835\udc63 \u00b7 #\u00bb\ud835\udc64\n(c) (\ud835\udc50#\u00bb\ud835\udc62) \u00b7 #\u00bb\ud835\udc63 = \ud835\udc50(#\u00bb\ud835\udc62 \u00b7 #\u00bb\ud835\udc63 )\n}\ufe03\n(collectively known as linearity)\n(d) #\u00bb\ud835\udc63 \u00b7 #\u00bb\ud835\udc63 \u2265 0, with #\u00bb\ud835\udc63 \u00b7 #\u00bb\ud835\udc63 = 0 if and only if #\u00bb\ud835\udc63 = #\u00bb0 .\n(non-negativity)\nAn important use of the dot product is determining the length of a vector.\nDefinition 1.5.4\nLength in R\ud835\udc5b,\nNorm in R\ud835\udc5b\nThe length (or norm or magnitude) of the vector #\u00bb\ud835\udc63 \u2208 R\ud835\udc5b is \u2016#\u00bb\ud835\udc63 \u2016 =\n\u221a#\u00bb\ud835\udc63 \u00b7 #\u00bb\ud835\udc63 .\nExample 1.5.5\nWe have\n\u20e6\u20e6\u20e6\u20e6\n[\ufe022\n4\n]\ufe02\u20e6\u20e6\u20e6\u20e6 =\n\u221a\ufe03[\ufe022\n4\n]\ufe02\n\u00b7\n[\ufe022\n4\n]\ufe02\n=\n\u221a\ufe00\n2(2) + 4(4) =\n\u221a\n20 = 2\n\u221a\n5.\nExample 1.5.6\nWe have\n\u20e6\u20e6\u20e6\u20e6\u20e6\u20e6\n\u23a1\n\u23a3\n2\n\u22123\n4\n\u23a4\n\u23a6\n\u20e6\u20e6\u20e6\u20e6\u20e6\u20e6\n=\n\u23af\n\u23b8\n\u23b8\n\u23b8\n\u23b7\n\u23a1\n\u23a3\n2\n\u22123\n4\n\u23a4\n\u23a6 \u00b7\n\u23a1\n\u23a3\n2\n\u22123\n4\n\u23a4\n\u23a6 =\n\u221a\ufe00\n2(2) + (\u22123)(\u22123) + 4(4) =\n\u221a\n29.\nREMARKS\nThe notation \u201c\u2016\u201d is used in order to distinguish from the notation for the absolute value of\na real number, \u201c|\u201d.\nRecall that when we take the square root, we mean the positive square root, so that\n\u221a\n4 = 2\n(not \u00b12). Notice that it follows from Property (d) of Proposition 1.5.3 (Properties of the\nDot Product) that every non-zero vector has length greater than zero, and the zero vector\n#\u00bb0 has a length of zero.\nProposition 1.5.7\nIf \ud835\udc50 \u2208 R and #\u00bb\ud835\udc63 \u2208 R\ud835\udc5b, then \u2016\ud835\udc50#\u00bb\ud835\udc63 \u2016 = |\ud835\udc50| \u2016#\u00bb\ud835\udc63 \u2016.\nExample 1.5.8\nWe have\n\u20e6\u20e6\u20e6\u20e6\n[\ufe02\u22123\n\u22126\n]\ufe02\u20e6\u20e6\u20e6\u20e6 =\n\u20e6\u20e6\u20e6\u20e6\u22123\n[\ufe021\n2\n]\ufe02\u20e6\u20e6\u20e6\u20e6 = | \u2212 3|\n\u20e6\u20e6\u20e6\u20e6\n[\ufe021\n2\n]\ufe02\u20e6\u20e6\u20e6\u20e6 = 3\n\u221a\ufe00\n1(1) + 2(2) = 3\n\u221a\n5.\nExample 1.5.9\nWe have\n\u20e6\u20e6\u20e6\u20e6\u20e6\u20e6\n\u23a1\n\u23a3\n\u22122\n\u22126\n4\n\u23a4\n\u23a6\n\u20e6\u20e6\u20e6\u20e6\u20e6\u20e6\n=\n\u20e6\u20e6\u20e6\u20e6\u20e6\u20e6\n\u22122\n\u23a1\n\u23a3\n1\n3\n\u22122\n\u23a4\n\u23a6\n\u20e6\u20e6\u20e6\u20e6\u20e6\u20e6\n= | \u2212 2|\n\u20e6\u20e6\u20e6\u20e6\u20e6\u20e6\n\u23a1\n\u23a3\n1\n3\n\u22122\n\u23a4\n\u23a6\n\u20e6\u20e6\u20e6\u20e6\u20e6\u20e6\n= 2\n\u221a\ufe00\n12 + 32 + (\u22122)2 = 2\n\u221a\n14.Section 1.5\nDot Product in R\ud835\udc5b\n15\nDefinition 1.5.10\nUnit Vector\nWe say that #\u00bb\ud835\udc63 \u2208 R\ud835\udc5b is a unit vector if \u2016#\u00bb\ud835\udc63 \u2016 = 1.\nExample 1.5.11\nIf #\u00bb\ud835\udc62 =\n[\ufe022\n3\n]\ufe02\n, then \u2016#\u00bb\ud835\udc62\u2016 =\n\u221a\n13, so #\u00bb\ud835\udc62 is not a unit vector.\nExample 1.5.12\nIf #\u00bb\ud835\udc63 =\n[\ufe02 1\n\u221a\n6\n1\n\u221a\n6\n2\n\u221a\n6\n]\ufe02\ud835\udc47\n=\n1\n\u221a\n6\n\u23a1\n\u23a3\n1\n1\n2\n\u23a4\n\u23a6, then \u2016#\u00bb\ud835\udc63 \u2016 =\n1\n\u221a\n6\n\u221a\n12 + 12 + 22 = 1, so #\u00bb\ud835\udc63 is a unit\nvector.\nDefinition 1.5.13\nNormalization\nWhen #\u00bb\ud835\udc63 \u2208 R\ud835\udc5b is a non-zero vector, we can produce a unit vector\n^\ud835\udc63 =\n#\u00bb\ud835\udc63\n\u2016#\u00bb\ud835\udc63 \u2016\nin the direction of #\u00bb\ud835\udc63 by scaling #\u00bb\ud835\udc63 . This process is called normalization.\nREMARKS\nThe vector ^\ud835\udc63 has the same direction as the vector #\u00bb\ud835\udc63 , since ^\ud835\udc63 =\n#\u00bb\ud835\udc63\n\u2016 #\u00bb\ud835\udc63 \u2016 =\n1\n\u2016 #\u00bb\ud835\udc63 \u2016 #\u00bb\ud835\udc63 .\nThe vector ^\ud835\udc63 is a unit vector, since \u2016^\ud835\udc63\u2016 =\n\u20e6\u20e6\u20e6\n1\n\u2016 #\u00bb\ud835\udc63 \u2016 #\u00bb\ud835\udc63\n\u20e6\u20e6\u20e6 =\n\u20d2\u20d2\u20d2\n1\n\u2016 #\u00bb\ud835\udc63 \u2016\n\u20d2\u20d2\u20d2 \u2016#\u00bb\ud835\udc63 \u2016 = 1.\nExample 1.5.14\nThe unit vector in the direction of #\u00bb\ud835\udc63 =\n\u23a1\n\u23a3\n2\n\u22124\n\u22121\n\u23a4\n\u23a6 is the vector ^\ud835\udc63 =\n#\u00bb\ud835\udc63\n\u2016#\u00bb\ud835\udc63 \u2016 =\n1\n\u221a\n21\n\u23a1\n\u23a3\n2\n\u22124\n\u22121\n\u23a4\n\u23a6 .\nThe dot product can also be used to determine the angle between two vectors. In R2 this\ncan be seen as follows.\nFigure 1.5.5: The angle \ud835\udf03 between #\u00bb\ud835\udc62 and #\u00bb\ud835\udc63 in R216\nChapter 1\nVectors in R\ud835\udc5b\nIf \ud835\udf03 is the angle between #\u00bb\ud835\udc62, #\u00bb\ud835\udc63 \u2208 R2, then the law of cosines says that\n\u2016#\u00bb\ud835\udc62 \u2212 #\u00bb\ud835\udc63 \u20162 = \u2016#\u00bb\ud835\udc62\u20162 + \u2016#\u00bb\ud835\udc63 \u20162 \u2212 2\u2016#\u00bb\ud835\udc62\u2016\u2016#\u00bb\ud835\udc63 \u2016 cos \ud835\udf03.\nOn the other hand, recalling the definition of the length \u2016 \u00b7 \u2016 in terms of the dot product,\nwe have\n\u2016#\u00bb\ud835\udc62 \u2212 #\u00bb\ud835\udc63 \u20162 = (#\u00bb\ud835\udc62 \u2212 #\u00bb\ud835\udc63 ) \u00b7 (#\u00bb\ud835\udc62 \u2212 #\u00bb\ud835\udc63 )\n= #\u00bb\ud835\udc62 \u00b7 #\u00bb\ud835\udc62 \u2212 #\u00bb\ud835\udc62 \u00b7 #\u00bb\ud835\udc63 \u2212 #\u00bb\ud835\udc63 \u00b7 #\u00bb\ud835\udc62 + #\u00bb\ud835\udc63 \u00b7 #\u00bb\ud835\udc63\n= \u2016#\u00bb\ud835\udc62\u20162 \u2212 2#\u00bb\ud835\udc63 \u00b7 #\u00bb\ud835\udc62 + \u2016#\u00bb\ud835\udc63 \u20162.\nIf we combine the above two equations, we arrive at\n#\u00bb\ud835\udc62 \u00b7 #\u00bb\ud835\udc63 = \u2016#\u00bb\ud835\udc62\u2016\u2016#\u00bb\ud835\udc63 \u2016 cos \ud835\udf03.\nThis gives us a relationship between the angle \ud835\udf03 between the vectors #\u00bb\ud835\udc62, #\u00bb\ud835\udc63 \u2208 R2 and their\ndot product. This motivates the following definition.\nDefinition 1.5.15\nAngle Between\nVectors\nLet #\u00bb\ud835\udc62 and #\u00bb\ud835\udc63 be non-zero vectors in R\ud835\udc5b. The angle \ud835\udf03, in radians (0 \u2264 \ud835\udf03 \u2264 \ud835\udf0b), between #\u00bb\ud835\udc62\nand #\u00bb\ud835\udc63 is such that\n#\u00bb\ud835\udc62 \u00b7 #\u00bb\ud835\udc63 = \u2016#\u00bb\ud835\udc62\u2016\u2016#\u00bb\ud835\udc63 \u2016 cos \ud835\udf03, that is, \ud835\udf03 = arccos\n(\ufe02\n#\u00bb\ud835\udc62 \u00b7 #\u00bb\ud835\udc63\n\u2016#\u00bb\ud835\udc62\u2016\u2016#\u00bb\ud835\udc63 \u2016\n)\ufe02\n.\nFigure 1.5.6: The angle \ud835\udf03 between #\u00bb\ud835\udc63 and #\u00bb\n\ud835\udc64 is between 0 and \ud835\udf0b\nREMARK\nIn order for the above definition to be well-defined, we need to know that\n#\u00bb\ud835\udc62 \u00b7 #\u00bb\ud835\udc63\n\u2016 #\u00bb\ud835\udc62 \u2016\u2016 #\u00bb\ud835\udc63 \u2016 lies in in\nthe domain of arccos\u2014otherwise arccos\n(\ufe01\n#\u00bb\ud835\udc62 \u00b7 #\u00bb\ud835\udc63\n\u2016 #\u00bb\ud835\udc62 \u2016\u2016 #\u00bb\ud835\udc63 \u2016\n)\ufe01\nis undefined. That is, we need to know\nthat\n#\u00bb\ud835\udc62 \u00b7 #\u00bb\ud835\udc63\n\u2016#\u00bb\ud835\udc62\u2016\u2016#\u00bb\ud835\udc63 \u2016 \u2208 [\u22121, 1],\nor, equivalently, that\n|#\u00bb\ud835\udc62 \u00b7 #\u00bb\ud835\udc63 | \u2264 \u2016#\u00bb\ud835\udc62\u2016#\u00bb\ud835\udc63 \u2016 for all #\u00bb\ud835\udc62, #\u00bb\ud835\udc63 \u2208 R\ud835\udc5b.\nThis inequality is true and is known as the Cauchy\u2013Schwarz Inequality. We will take its\nvalidity for granted in these notes, and will not provide a proof.Section 1.5\nDot Product in R\ud835\udc5b\n17\nExample 1.5.16\nDetermine the angle \ud835\udf03 between\n[\ufe021\n4\n]\ufe02\nand\n[\ufe02\u22122\n3\n]\ufe02\nin R2, rounding your answer to three decimal\nplaces throughout.\nSolution: \ud835\udf03 = arccos\n\u239b\n\u239c\n\u239c\n\u239d\n[\ufe021\n4\n]\ufe02\n\u00b7\n[\ufe02\u22122\n3\n]\ufe02\n\u20e6\u20e6\u20e6\u20e6\n[\ufe021\n4\n]\ufe02\u20e6\u20e6\u20e6\u20e6\n\u20e6\u20e6\u20e6\u20e6\n[\ufe02\u22122\n3\n]\ufe02\u20e6\u20e6\u20e6\u20e6\n\u239e\n\u239f\n\u239f\n\u23a0 = arccos\n(\ufe02\n10\n\u221a\n17\n\u221a\n13\n)\ufe02\n\u2248 0.833.\nExample 1.5.17\nDetermine the angle, \ud835\udf03, between\n\u23a1\n\u23a3\n1\n3\n5\n\u23a4\n\u23a6 and\n\u23a1\n\u23a3\n2\n\u22124\n3\n\u23a4\n\u23a6 in R3, rounding your answer to three\ndecimal places throughout.\nSolution: \ud835\udf03 = arccos\n\u239b\n\u239c\n\u239c\n\u239c\n\u239c\n\u239c\n\u239c\n\u239c\n\u239d\n\u23a1\n\u23a3\n1\n3\n5\n\u23a4\n\u23a6 \u00b7\n\u23a1\n\u23a3\n2\n\u22124\n3\n\u23a4\n\u23a6\n\u20e6\u20e6\u20e6\u20e6\u20e6\u20e6\n\u23a1\n\u23a3\n1\n3\n5\n\u23a4\n\u23a6\n\u20e6\u20e6\u20e6\u20e6\u20e6\u20e6\n\u20e6\u20e6\u20e6\u20e6\u20e6\u20e6\n\u23a1\n\u23a3\n2\n\u22124\n3\n\u23a4\n\u23a6\n\u20e6\u20e6\u20e6\u20e6\u20e6\u20e6\n\u239e\n\u239f\n\u239f\n\u239f\n\u239f\n\u239f\n\u239f\n\u239f\n\u23a0\n= arccos\n(\ufe02\n5\n\u221a\n35\n\u221a\n29\n)\ufe02\n\u2248 1.413.\nDefinition 1.5.18\nOrthogonal in R\ud835\udc5b\nWe say that the two vectors #\u00bb\ud835\udc62 and #\u00bb\ud835\udc63 in R\ud835\udc5b are orthogonal (or perpendicular) if #\u00bb\ud835\udc62\u00b7#\u00bb\ud835\udc63 = 0.\nREMARK\nOur definition of the angle between two vectors, Definition 1.5.15, is consistent with our\ndefinition of orthogonality. Examining our new dot product formula,\n#\u00bb\ud835\udc63 \u00b7 #\u00bb\ud835\udc64 = \u2016#\u00bb\ud835\udc63 \u2016\u2016#\u00bb\ud835\udc64\u2016 cos \ud835\udf03,\nwe see that if two vectors are orthogonal, then their dot product is zero, and thus conclude\nthat the angle \ud835\udf03 between them is \ud835\udf0b\n2 , since cos \ud835\udf0b\n2 = 0 and 0 \u2264 \ud835\udf03 \u2264 \ud835\udf0b.\nExample 1.5.19\nThe vectors #\u00bb\ud835\udc62 =\n\u23a1\n\u23a3\n1\n5\n\u22123\n\u23a4\n\u23a6 and #\u00bb\ud835\udc63 =\n\u23a1\n\u23a3\n1\n1\n2\n\u23a4\n\u23a6 are orthogonal, since #\u00bb\ud835\udc62 \u00b7 #\u00bb\ud835\udc63 =\n\u23a1\n\u23a3\n1\n5\n\u22123\n\u23a4\n\u23a6 \u00b7\n\u23a1\n\u23a3\n1\n1\n2\n\u23a4\n\u23a6 = 0.\nExample 1.5.20\nThe vectors #\u00bb\ud835\udc64 =\n\u23a1\n\u23a3\n1\n\u22123\n5\n\u23a4\n\u23a6 and #\u00bb\ud835\udc65 =\n\u23a1\n\u23a3\n2\n2\n1\n\u23a4\n\u23a6 are not orthogonal, since #\u00bb\ud835\udc64 \u00b7 #\u00bb\ud835\udc65 =\n\u23a1\n\u23a3\n1\n\u22123\n5\n\u23a4\n\u23a6 \u00b7\n\u23a1\n\u23a3\n2\n2\n1\n\u23a4\n\u23a6 =\n1 \u0338= 0.18\nChapter 1\nVectors in R\ud835\udc5b\nREMARK\nEvery vector #\u00bb\ud835\udc63 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc631\n\ud835\udc632\n...\n\ud835\udc63\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 \u2208 R\ud835\udc5b is orthogonal to #\u00bb0 , as #\u00bb0 \u00b7 #\u00bb\ud835\udc63 = 0\ud835\udc631 + 0\ud835\udc632 + \u00b7 \u00b7 \u00b7 + 0\ud835\udc63\ud835\udc5b = 0.\nGiven a vector #\u00bb\ud835\udc63 , there are many ways to produce a non-trivial vector that is orthogonal\nto #\u00bb\ud835\udc63 .\nExample 1.5.21\nA vector orthogonal to\n[\ufe02\ud835\udc4e\n\ud835\udc4f\n]\ufe02\nin R2 is\n[\ufe02\u2212\ud835\udc4f\n\ud835\udc4e\n]\ufe02\n, since\n[\ufe02\u2212\ud835\udc4f\n\ud835\udc4e\n]\ufe02\n\u00b7\n[\ufe02\ud835\udc4e\n\ud835\udc4f\n]\ufe02\n= 0.\nExample 1.5.22\nA vector orthogonal to\n\u23a1\n\u23a3\n\ud835\udc4e\n\ud835\udc4f\n\ud835\udc50\n\u23a4\n\u23a6 in R3 is\n\u23a1\n\u23a3\n\u2212\ud835\udc4f\n\ud835\udc4e\n0\n\u23a4\n\u23a6, since\n\u23a1\n\u23a3\n\u2212\ud835\udc4f\n\ud835\udc4e\n0\n\u23a4\n\u23a6 \u00b7\n\u23a1\n\u23a3\n\ud835\udc4e\n\ud835\udc4f\n\ud835\udc50\n\u23a4\n\u23a6 = 0.\nEXERCISE\nProduce two different vectors that are orthogonal to\n\u23a1\n\u23a3\n\ud835\udc4e\n\ud835\udc4f\n\ud835\udc50\n\u23a4\n\u23a6.\nExample 1.5.23\nDetermine a vector #\u00bb\ud835\udc62 that is orthogonal to both #\u00bb\ud835\udc63 =\n\u23a1\n\u23a3\n1\n\u22121\n0\n\u23a4\n\u23a6 and #\u00bb\ud835\udc64 =\n\u23a1\n\u23a3\n1\n2\n3\n\u23a4\n\u23a6.\nSolution: Let #\u00bb\ud835\udc62 =\n\u23a1\n\u23a3\n\ud835\udc621\n\ud835\udc622\n\ud835\udc623\n\u23a4\n\u23a6 be such a vector. Then\n#\u00bb\ud835\udc62 \u00b7 #\u00bb\ud835\udc63 = 0\nand\n#\u00bb\ud835\udc62 \u00b7 #\u00bb\ud835\udc64 = 0\n\u23a1\n\u23a3\n\ud835\udc621\n\ud835\udc622\n\ud835\udc623\n\u23a4\n\u23a6 \u00b7\n\u23a1\n\u23a3\n1\n\u22121\n0\n\u23a4\n\u23a6 = 0\n\u23a1\n\u23a3\n\ud835\udc621\n\ud835\udc622\n\ud835\udc623\n\u23a4\n\u23a6 \u00b7\n\u23a1\n\u23a3\n1\n2\n3\n\u23a4\n\u23a6 = 0\n\ud835\udc621 \u2212 \ud835\udc622 = 0\n\ud835\udc621 + 2\ud835\udc622 + 3\ud835\udc623 = 0\n\ud835\udc621 = \ud835\udc622 (*)\n3\ud835\udc621 + 3\ud835\udc623 = 0\nsubstitute from (*)\n\ud835\udc623 = \u2212\ud835\udc621 (**)\nFrom (*) and (**) we have #\u00bb\ud835\udc62 =\n\u23a1\n\u23a3\n\ud835\udc621\n\ud835\udc621\n\u2212\ud835\udc621\n\u23a4\n\u23a6. For any choice of \ud835\udc621 \u2208 R, the vector\n\u23a1\n\u23a3\n\ud835\udc621\n\ud835\udc621\n\u2212\ud835\udc621\n\u23a4\n\u23a6 will\nbe orthogonal to both #\u00bb\ud835\udc63 and #\u00bb\ud835\udc64. This is because by choosing different values of \ud835\udc621, weSection 1.6", "Projection, Components and Perpendicular\n19\nchange the length of #\u00bb\ud835\udc62, but the line through the origin which contains #\u00bb\ud835\udc62 remains fixed.\nFor example, with \ud835\udc621 = 4 we get #\u00bb\ud835\udc62 =\n\u23a1\n\u23a3\n4\n4\n\u22124\n\u23a4\n\u23a6, in which case\n#\u00bb\ud835\udc62 \u00b7 #\u00bb\ud835\udc63 =\n\u23a1\n\u23a3\n4\n4\n\u22124\n\u23a4\n\u23a6 \u00b7\n\u23a1\n\u23a3\n1\n\u22121\n0\n\u23a4\n\u23a6 = 4 \u2212 4 = 0 and #\u00bb\ud835\udc62 \u00b7 #\u00bb\ud835\udc64 =\n\u23a1\n\u23a3\n4\n4\n\u22124\n\u23a4\n\u23a6 \u00b7\n\u23a1\n\u23a3\n1\n2\n3\n\u23a4\n\u23a6 = 4 + 8 \u2212 12 = 0.\nEXERCISE\nWith #\u00bb\ud835\udc62 =\n\u23a1\n\u23a3\n\ud835\udc621\n\ud835\udc621\n\u2212\ud835\udc621\n\u23a4\n\u23a6 from Example 1.5.23, choose different values of \ud835\udc621 \u2208 R and convince\nyourself that the resulting #\u00bb\ud835\udc62 is still orthogonal to both #\u00bb\ud835\udc63 =\n\u23a1\n\u23a3\n1\n2\n3\n\u23a4\n\u23a6 and #\u00bb\ud835\udc64 =\n\u23a1\n\u23a3\n1\n\u22121\n0\n\u23a4\n\u23a6.\nShow that for any choice of \ud835\udc621 \u2208 R, the resulting #\u00bb\ud835\udc62 is still orthogonal to both #\u00bb\ud835\udc63 and #\u00bb\ud835\udc64.\n1.6\nProjection, Components and Perpendicular\nDefinition 1.6.1\nProjection of #\u00bb\ud835\udc63\nOnto #\u00bb\n\ud835\udc64\nLet #\u00bb\ud835\udc63 , #\u00bb\ud835\udc64 \u2208 R\ud835\udc5b with #\u00bb\ud835\udc64 \u0338= #\u00bb0 . The projection of #\u00bb\ud835\udc63 onto #\u00bb\ud835\udc64 is defined by\nproj #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 ) = (#\u00bb\ud835\udc63 \u00b7 #\u00bb\ud835\udc64)\n\u2016#\u00bb\ud835\udc64\u20162\n#\u00bb\ud835\udc64 = (#\u00bb\ud835\udc63 \u00b7 #\u00bb\ud835\udc64)\n#\u00bb\ud835\udc64 \u00b7 #\u00bb\ud835\udc64\n#\u00bb\ud835\udc64.\nWe also refer to this as the projection of #\u00bb\ud835\udc63 in the #\u00bb\ud835\udc64 direction.\nFigure 1.6.7: proj #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 )20\nChapter 1\nVectors in R\ud835\udc5b\nExample 1.6.2\nFind the projection of #\u00bb\ud835\udc63 =\n[\ufe02 4\n\u22128\n]\ufe02\nonto #\u00bb\ud835\udc64 =\n[\ufe027\n1\n]\ufe02\n.\nSolution:\nproj #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 )\n=\n(#\u00bb\ud835\udc63 \u00b7 #\u00bb\ud835\udc64)\n\u2016#\u00bb\ud835\udc64\u20162\n#\u00bb\ud835\udc64\n=\n[\ufe02 4\n\u22128\n]\ufe02\n\u00b7\n[\ufe027\n1\n]\ufe02\n\u20e6\u20e6\u20e6\u20e6\n[\ufe027\n1\n]\ufe02\u20e6\u20e6\u20e6\u20e6\n2\n[\ufe027\n1\n]\ufe02\n=\n20\n50\n[\ufe027\n1\n]\ufe02\n=\n2\n5\n#\u00bb\ud835\udc64.\nExample 1.6.3\nFind the projection of #\u00bb\ud835\udc63 =\n\u23a1\n\u23a3\n3\n\u22124\n5\n\u23a4\n\u23a6 onto #\u00bb\ud835\udc64 =\n\u23a1\n\u23a3\n1\n2\n3\n\u23a4\n\u23a6.\nSolution:\nproj #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 ) = (#\u00bb\ud835\udc63 \u00b7 #\u00bb\ud835\udc64)\n\u2016#\u00bb\ud835\udc64\u20162\n#\u00bb\ud835\udc64 =\n\u23a1\n\u23a3\n3\n\u22124\n5\n\u23a4\n\u23a6 \u00b7\n\u23a1\n\u23a3\n1\n2\n3\n\u23a4\n\u23a6\n\u20e6\u20e6\u20e6\u20e6\u20e6\u20e6\n\u23a1\n\u23a3\n1\n2\n3\n\u23a4\n\u23a6\n\u20e6\u20e6\u20e6\u20e6\u20e6\u20e6\n2\n\u23a1\n\u23a3\n1\n2\n3\n\u23a4\n\u23a6 = 10\n14\n\u23a1\n\u23a3\n1\n2\n3\n\u23a4\n\u23a6 = 5\n7\n\u23a1\n\u23a3\n1\n2\n3\n\u23a4\n\u23a6 .\nREMARKS\n1. We can write the projection as follows:\nproj #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 ) = (#\u00bb\ud835\udc63 \u00b7 #\u00bb\ud835\udc64)\n\u2016#\u00bb\ud835\udc64\u20162\n#\u00bb\ud835\udc64 =\n(\ufe02\n#\u00bb\ud835\udc63 \u00b7\n#\u00bb\ud835\udc64\n\u2016#\u00bb\ud835\udc64\u2016\n)\ufe02\n#\u00bb\ud835\udc64\n\u2016#\u00bb\ud835\udc64\u2016 = (#\u00bb\ud835\udc63 \u00b7 ^\ud835\udc64) ^\ud835\udc64.\nThus, the magnitude of #\u00bb\ud835\udc64 is not relevant to the projection, but the direction of #\u00bb\ud835\udc64 is.\n2. Recall from Definition 1.5.15 that the angle \ud835\udf03 between #\u00bb\ud835\udc63 and #\u00bb\ud835\udc64 is given by #\u00bb\ud835\udc63 \u00b7 #\u00bb\ud835\udc64 =\n\u2016#\u00bb\ud835\udc63 \u2016\u2016#\u00bb\ud835\udc64\u2016 cos \ud835\udf03, giving:\nproj #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 ) = \u2016#\u00bb\ud835\udc63 \u2016\u2016#\u00bb\ud835\udc64\u2016 cos \ud835\udf03\n\u2016#\u00bb\ud835\udc64\u20162\n#\u00bb\ud835\udc64 = (\u2016#\u00bb\ud835\udc63 \u2016 cos \ud835\udf03) ^\ud835\udc64.\nYou can think of the projection of #\u00bb\ud835\udc63 onto #\u00bb\ud835\udc64 as giving that part of the vector #\u00bb\ud835\udc63 that\nlies in the #\u00bb\ud835\udc64 direction.Section 1.6\nProjection, Components and Perpendicular\n21\nDefinition 1.6.4\nComponent\nLet #\u00bb\ud835\udc63 , #\u00bb\ud835\udc64 \u2208 R\ud835\udc5b with #\u00bb\ud835\udc64 \u0338= #\u00bb0 . We refer to the quantity\n\u2016#\u00bb\ud835\udc63 \u2016 cos \ud835\udf03 = #\u00bb\ud835\udc63 \u00b7 ^\ud835\udc64\nas the component (or scalar component) of #\u00bb\ud835\udc63 along #\u00bb\ud835\udc64.\nIf the scalar component is negative, then the projection of #\u00bb\ud835\udc63 along #\u00bb\ud835\udc64 will be in the direction\nof the vector \u2212#\u00bb\ud835\udc64; we can still think of this projection vector as being in the #\u00bb\ud835\udc64 direction.\nExample 1.6.5\nDetermine the component of #\u00bb\ud835\udc63 =\n\u23a1\n\u23a3\n3\n\u22124\n5\n\u23a4\n\u23a6 along #\u00bb\ud835\udc64 =\n\u23a1\n\u23a3\n1\n2\n3\n\u23a4\n\u23a6.\nSolution: Note that \u2016#\u00bb\ud835\udc64\u2016 =\n\u221a\n14, so ^\ud835\udc64 =\n1\n\u221a\n14\n\u23a1\n\u23a3\n1\n2\n3\n\u23a4\n\u23a6.\nThe component of #\u00bb\ud835\udc63 along #\u00bb\ud835\udc64 is #\u00bb\ud835\udc63 \u00b7 ^\ud835\udc64 =\n\u23a1\n\u23a3\n3\n\u22124\n5\n\u23a4\n\u23a6 \u00b7\n1\n\u221a\n14\n\u23a1\n\u23a3\n1\n2\n3\n\u23a4\n\u23a6 =\n10\n\u221a\n14.\nDefinition 1.6.6\nPerpendicular\nLet #\u00bb\ud835\udc63 , #\u00bb\ud835\udc64 \u2208 R\ud835\udc5b with #\u00bb\ud835\udc64 \u0338= #\u00bb0 . The perpendicular of #\u00bb\ud835\udc63 onto #\u00bb\ud835\udc64 is defined by\nperp #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 ) = #\u00bb\ud835\udc63 \u2212 proj #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 ).\nFigure 1.6.8: perp #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 )\nExample 1.6.7\nDetermine the perpendicular of #\u00bb\ud835\udc63 =\n[\ufe02 4\n\u22128\n]\ufe02\nonto #\u00bb\ud835\udc64 =\n[\ufe027\n1\n]\ufe02\n.\nThen calculate proj #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 ) \u00b7 perp #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 ).\nSolution:22\nChapter 1\nVectors in R\ud835\udc5b\nFrom [Example 1.6.2], we have proj #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 ) = 2\n5\n[\ufe027\n1\n]\ufe02\n, so\nperp #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 )\n=\n#\u00bb\ud835\udc63 \u2212 proj #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 )\n=\n[\ufe02 4\n\u22128\n]\ufe02\n\u2212 2\n5\n[\ufe027\n1\n]\ufe02\n=\n6\n5\n[\ufe02 1\n\u22127\n]\ufe02\nproj #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 ) \u00b7 perp #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 )\n=\n(\ufe022\n5\n[\ufe027\n1\n]\ufe02)\ufe02\n\u00b7\n(\ufe026\n5\n[\ufe02 1\n\u22127\n]\ufe02)\ufe02\n=\n12\n25(7(1) + 1(\u22127))\n=\n0.\nExample 1.6.8\nDetermine the perpendicular of #\u00bb\ud835\udc63 =\n\u23a1\n\u23a3\n3\n\u22124\n5\n\u23a4\n\u23a6 onto #\u00bb\ud835\udc64 =\n\u23a1\n\u23a3\n1\n2\n3\n\u23a4\n\u23a6.\nSolution: From Example 1.6.3, we have proj #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 ) = 5\n7\n\u23a1\n\u23a3\n1\n2\n3\n\u23a4\n\u23a6, so\nperp #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 ) = #\u00bb\ud835\udc63 \u2212 proj #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 ) =\n\u23a1\n\u23a3\n3\n\u22124\n5\n\u23a4\n\u23a6 \u2212 5\n7\n\u23a1\n\u23a3\n1\n2\n3\n\u23a4\n\u23a6 = 1\n7\n\u23a1\n\u23a3\n16\n\u221238\n20\n\u23a4\n\u23a6 .\nProposition 1.6.9\nThe projection and the perpendicular of a vector #\u00bb\ud835\udc63 onto #\u00bb\ud835\udc64 \u0338= #\u00bb0 are orthogonal; that is\nperp #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 ) \u00b7 proj #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 ) = 0.\nProof: First, perp #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 ) is orthogonal to #\u00bb\ud835\udc64, since\nperp #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 ) \u00b7 #\u00bb\ud835\udc64 = (#\u00bb\ud835\udc63 \u2212 proj #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 )) \u00b7 #\u00bb\ud835\udc64\n= #\u00bb\ud835\udc63 \u00b7 #\u00bb\ud835\udc64 \u2212 (proj #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 )) \u00b7 #\u00bb\ud835\udc64\n= #\u00bb\ud835\udc63 \u00b7 #\u00bb\ud835\udc64 \u2212\n(\ufe02(#\u00bb\ud835\udc63 \u00b7 #\u00bb\ud835\udc64)\n\u2016#\u00bb\ud835\udc64\u20162\n#\u00bb\ud835\udc64\n)\ufe02\n\u00b7 #\u00bb\ud835\udc64\n= #\u00bb\ud835\udc63 \u00b7 #\u00bb\ud835\udc64 \u2212\n(\ufe02(#\u00bb\ud835\udc63 \u00b7 #\u00bb\ud835\udc64)\n\u2016#\u00bb\ud835\udc64\u20162\n)\ufe02\n\u2016#\u00bb\ud835\udc64\u20162\n= #\u00bb\ud835\udc63 \u00b7 #\u00bb\ud835\udc64 \u2212 #\u00bb\ud835\udc63 \u00b7 #\u00bb\ud835\udc64\n= 0.\nSince perp #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 ) is orthogonal to #\u00bb\ud835\udc64, it is also orthogonal to proj#\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 ).Section 1.7", "Standard Inner Product in C\ud835\udc5b\n23\n1.7\nStandard Inner Product in C\ud835\udc5b\nRecall the different ways used to find the magnitude of a real number and the magnitude\nof a complex number.\nIf \ud835\udc65 \u2208 R, then the magnitude (absolute value) of \ud835\udc65 is |\ud835\udc65| =\n\u221a\ufe00\n\ud835\udc65(\ud835\udc65).\nIf \ud835\udc67 \u2208 C, then the magnitude (modulus) of \ud835\udc67 is |\ud835\udc67| =\n\u221a\ufe00\n\ud835\udc67(\u00af\ud835\udc67).\nExample 1.7.1\nDetermine the magnitude of \ud835\udc67 = 2 \u2212 3\ud835\udc56.\nSolution: The magnitude of \ud835\udc67 is\n|\ud835\udc67| = |2 \u2212 3\ud835\udc56| =\n\u221a\ufe01\n(2 \u2212 3\ud835\udc56)(2 \u2212 3\ud835\udc56) =\n\u221a\ufe00\n22 + (\u22123)2 =\n\u221a\n13.\nOne of the most important uses of the dot product on R\ud835\udc5b is in finding the lengths of vectors.\nWhen we extend this concept to C\ud835\udc5b, we will need to use complex conjugates.\nDefinition 1.7.2\nStandard Inner\nProduct on C\ud835\udc5b\nThe standard inner product of #\u00bb\ud835\udc63 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc631\n\ud835\udc632\n...\n\ud835\udc63\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 , #\u00bb\ud835\udc64 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc641\n\ud835\udc642\n...\n\ud835\udc64\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 \u2208 C\ud835\udc5b is\n\u27e8#\u00bb\ud835\udc63 , #\u00bb\ud835\udc64\u27e9 = \ud835\udc631\ud835\udc641 + \ud835\udc632\ud835\udc642 + \u00b7 \u00b7 \u00b7 + \ud835\udc63\ud835\udc5b\ud835\udc64\ud835\udc5b.\nNotice that this operation is similar to the dot product, in that we multiply components\ntogether and add them up. An important difference is the fact that we take the complex\nconjugate of all of the components that come from the second vector #\u00bb\ud835\udc64.\nExample 1.7.3\nLet #\u00bb\ud835\udc63 =\n[\ufe02 1 + \ud835\udc56\n1 + 2\ud835\udc56\n]\ufe02\n, #\u00bb\ud835\udc64 =\n[\ufe022 + \ud835\udc56\n1 + \ud835\udc56\n]\ufe02\n. Evaluate \u27e8#\u00bb\ud835\udc63 , #\u00bb\ud835\udc64\u27e9.\nSolution:\n\u27e8#\u00bb\ud835\udc63 , #\u00bb\ud835\udc64\u27e9 = (1 + \ud835\udc56)(2 + \ud835\udc56) + (1 + 2\ud835\udc56)(1 + \ud835\udc56)\n= (2 \u2212 \ud835\udc56 + 2\ud835\udc56 + 1) + (1 \u2212 \ud835\udc56 + 2\ud835\udc56 + 2)\n= (3 + \ud835\udc56) + (3 + \ud835\udc56)\n= 6 + 2\ud835\udc56.\nExample 1.7.4\nEvaluate\n\u27e8[\ufe022 \u2212 3\ud835\udc56\n1 \u2212 2\ud835\udc56\n]\ufe02\n,\n[\ufe02\u22123 + 4\ud835\udc56\n3 + 5\ud835\udc56\n]\ufe02\u27e9\n.24\nChapter 1\nVectors in R\ud835\udc5b\nSolution:\n\u27e8[\ufe02 2 \u2212 3\ud835\udc56\n1 \u2212 2\ud835\udc56\n]\ufe02\n,\n[\ufe02 \u22123 + 4\ud835\udc56\n3 + 5\ud835\udc56\n]\ufe02\u27e9\n= (2 \u2212 3\ud835\udc56)(\u22123 + 4\ud835\udc56) + (1 \u2212 2\ud835\udc56)(3 + 5\ud835\udc56)\n= (2 \u2212 3\ud835\udc56) (\u22123 \u2212 4\ud835\udc56) + (1 \u2212 2\ud835\udc56)(3 \u2212 5\ud835\udc56)\n= (\u22126 \u2212 8\ud835\udc56 + 9\ud835\udc56 \u2212 12) + (3 \u2212 5\ud835\udc56 \u2212 6\ud835\udc56 \u2212 10)\n= \u221225 \u2212 10\ud835\udc56.\nProposition 1.7.5\n(Properties of the Standard Inner Product)\nIf \ud835\udc50 \u2208 C and #\u00bb\ud835\udc62, #\u00bb\ud835\udc63 and #\u00bb\ud835\udc64 are vectors in C\ud835\udc5b, then\n(a) \u27e8#\u00bb\ud835\udc62, #\u00bb\ud835\udc63 \u27e9 = \u27e8#\u00bb\ud835\udc63 , #\u00bb\ud835\udc62\u27e9\n(conjugate symmetry)\n(b) \u27e8#\u00bb\ud835\udc62 + #\u00bb\ud835\udc63 , #\u00bb\ud835\udc64\u27e9 = \u27e8#\u00bb\ud835\udc62, #\u00bb\ud835\udc64\u27e9 + \u27e8#\u00bb\ud835\udc63 , #\u00bb\ud835\udc64\u27e9\n(c) \u27e8\ud835\udc50#\u00bb\ud835\udc62, #\u00bb\ud835\udc63 \u27e9 = \ud835\udc50 \u27e8#\u00bb\ud835\udc62, #\u00bb\ud835\udc63 \u27e9\n}\ufe03\n(\ufe02 collectively known as\nlinearity in the first argument.\n)\ufe02\n(d) \u27e8#\u00bb\ud835\udc63 , #\u00bb\ud835\udc63 \u27e9 \u2265 0, with \u27e8#\u00bb\ud835\udc63 , #\u00bb\ud835\udc63 \u27e9 = 0 if and only if #\u00bb\ud835\udc63 = #\u00bb0 .\n(non-negativity).\nAs in R\ud835\udc5b, we can use Property (d) to calculate lengths of vectors in C\ud835\udc5b.\nDefinition 1.7.6\nLength in C\ud835\udc5b,\nNorm in C\ud835\udc5b\nThe length (or norm or magnitude) of the vector #\u00bb\ud835\udc63 \u2208 C\ud835\udc5b is \u2016#\u00bb\ud835\udc63 \u2016 =\n\u221a\ufe00\n\u27e8#\u00bb\ud835\udc63 , #\u00bb\ud835\udc63 \u27e9.\nExample 1.7.7\nDetermine the length of the vector #\u00bb\ud835\udc63 =\n\u23a1\n\u23a3\n2 \u2212 \ud835\udc56\n\u22123 + 2\ud835\udc56\n\u22124 \u2212 5\ud835\udc56\n\u23a4\n\u23a6.\nSolution:\n\u27e8#\u00bb\ud835\udc63 , #\u00bb\ud835\udc63 \u27e9\n=\n\u27e8\u23a1\n\u23a3\n2 \u2212 \ud835\udc56\n\u22123 + 2\ud835\udc56\n\u22124 \u2212 5\ud835\udc56\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n2 \u2212 \ud835\udc56\n\u22123 + 2\ud835\udc56\n\u22124 \u2212 5\ud835\udc56\n\u23a4\n\u23a6\n\u27e9\n=\n(2 \u2212 \ud835\udc56)(2 \u2212 \ud835\udc56) + (\u22123 + 2\ud835\udc56)(\u22123 + 2\ud835\udc56) + (\u22124 \u2212 5\ud835\udc56)(\u22124 \u2212 5\ud835\udc56)\n=\n22 + 12 + 32 + 22 + 42 + 52\n=\n59\n\u2016#\u00bb\ud835\udc63 \u2016\n=\n\u221a\ufe00\n\u27e8#\u00bb\ud835\udc63 , #\u00bb\ud835\udc63 \u27e9 =\n\u221a\n59.\nNote that \u27e8#\u00bb\ud835\udc63 , #\u00bb\ud835\udc63 \u27e9 = \u2016#\u00bb\ud835\udc63 \u20162 = |2 \u2212 \ud835\udc56|2 + | \u2212 3 + 2\ud835\udc56|2 + | \u2212 4 \u2212 5\ud835\udc56|2.\nProposition 1.7.8\n(Properties of the Length)\nLet \ud835\udc50 \u2208 C and #\u00bb\ud835\udc63 \u2208 C\ud835\udc5b. Then\n(a) \u2016\ud835\udc50#\u00bb\ud835\udc63 \u2016 = |\ud835\udc50| \u2016#\u00bb\ud835\udc63 \u2016Section 1.7\nStandard Inner Product in C\ud835\udc5b\n25\n(b) \u2016#\u00bb\ud835\udc63 \u2016 \u2265 0, and \u2016#\u00bb\ud835\udc63 \u2016 = 0 if and only if #\u00bb\ud835\udc63 = 0.\nExample 1.7.9\nDetermine\n\u20e6\u20e6\u20e6\u20e6\u20e6\u20e6\n(\u22121 + 2\ud835\udc56)\n\u23a1\n\u23a3\n2 \u2212 \ud835\udc56\n\u22123 + 2\ud835\udc56\n\u22124 \u2212 5\ud835\udc56\n\u23a4\n\u23a6\n\u20e6\u20e6\u20e6\u20e6\u20e6\u20e6\n.\nSolution: Using Property (a) in the above Proposition and Example 1.7.7,\n\u20e6\u20e6\u20e6\u20e6\u20e6\u20e6\n(\u22121 + 2\ud835\udc56)\n\u23a1\n\u23a3\n2 \u2212 \ud835\udc56\n\u22123 + 2\ud835\udc56\n\u22124 \u2212 5\ud835\udc56\n\u23a4\n\u23a6\n\u20e6\u20e6\u20e6\u20e6\u20e6\u20e6\n= | \u2212 1 + 2\ud835\udc56|\n\u20e6\u20e6\u20e6\u20e6\u20e6\u20e6\n\u23a1\n\u23a3\n2 \u2212 \ud835\udc56\n\u22123 + 2\ud835\udc56\n\u22124 \u2212 5\ud835\udc56\n\u23a4\n\u23a6\n\u20e6\u20e6\u20e6\u20e6\u20e6\u20e6\n=\n\u221a\n5\n\u221a\n59 =\n\u221a\n295.\nDefinition 1.7.10\nOrthogonal in C\ud835\udc5b\nWe say that the two vectors #\u00bb\ud835\udc62 and #\u00bb\ud835\udc63 in C\ud835\udc5b are orthogonal if \u27e8#\u00bb\ud835\udc62, #\u00bb\ud835\udc63 \u27e9 = 0.\nExample 1.7.11\nIs #\u00bb\ud835\udc63 =\n[\ufe02 1 + \ud835\udc56\n1 + 2\ud835\udc56\n]\ufe02\northogonal to #\u00bb\ud835\udc64 =\n[\ufe02 2 + \ud835\udc56\n\u22121 \u2212 \ud835\udc56\n]\ufe02\n?\nSolution: Let\u2019s calculate the standard inner product of #\u00bb\ud835\udc63 and #\u00bb\ud835\udc64:\n\u27e8#\u00bb\ud835\udc63 , #\u00bb\ud835\udc64\u27e9 = (1 + \ud835\udc56)(2 + \ud835\udc56) + (1 + 2\ud835\udc56)(\u22121 \u2212 \ud835\udc56)\n= 2 \u2212 \ud835\udc56 + 2\ud835\udc56 + 1 \u2212 1 + \ud835\udc56 \u2212 2\ud835\udc56 \u2212 2\n= 0.\nSince \u27e8#\u00bb\ud835\udc63 , #\u00bb\ud835\udc64\u27e9 = 0, #\u00bb\ud835\udc63 and #\u00bb\ud835\udc64 are orthogonal.\nExample 1.7.12\n(a) Find a non-zero vector that is orthogonal to #\u00bb\ud835\udc64 =\n[\ufe022 + \ud835\udc56\n1 + \ud835\udc56\n]\ufe02\n.\n(b) Find a unit vector that is orthogonal to #\u00bb\ud835\udc64 =\n[\ufe022 + \ud835\udc56\n1 + \ud835\udc56\n]\ufe02\n.\nSolution:\n(a) Let #\u00bb\ud835\udc63 =\n[\ufe02\ud835\udc631\n\ud835\udc632\n]\ufe02\nbe orthogonal to #\u00bb\ud835\udc64. Then\n\u27e8#\u00bb\ud835\udc63 , #\u00bb\ud835\udc64\u27e9 = 0\n\ud835\udc631(2 \u2212 \ud835\udc56) + \ud835\udc632(1 \u2212 \ud835\udc56) = 0\n\ud835\udc632(1 \u2212 \ud835\udc56) = \ud835\udc631(\ud835\udc56 \u2212 2)\n\ud835\udc632(1 \u2212 \ud835\udc56)(1 + \ud835\udc56) = \ud835\udc631(\ud835\udc56 \u2212 2)(1 + \ud835\udc56)\n(\ufe00\nmultiply by 1 \u2212 \ud835\udc56\n)\ufe00\n2\ud835\udc632 = \ud835\udc631(\u22123 \u2212 \ud835\udc56)\n\ud835\udc632 = \u22123 \u2212 \ud835\udc56\n2\n\ud835\udc631.\n(*)\nBy Proposition 1.7.5 (Properties of the Standard Inner Product), if \u27e8#\u00bb\ud835\udc63 , #\u00bb\ud835\udc64\u27e9 = 0, then\n\u27e8\ud835\udc50#\u00bb\ud835\udc63 , #\u00bb\ud835\udc64\u27e9 = \ud835\udc50 \u27e8#\u00bb\ud835\udc63 , #\u00bb\ud835\udc64\u27e9 = \ud835\udc50(0) = 0; that is, if #\u00bb\ud835\udc63 is orthogonal to #\u00bb\ud835\udc64, then any scalar multiple \ud835\udc50#\u00bb\ud835\udc63\nis also orthogonal to #\u00bb\ud835\udc64.26\nChapter 1\nVectors in R\ud835\udc5b\nAccordingly, by choosing any non-zero value for \ud835\udc631, we can use (*) to determine a corre-\nsponding value for \ud835\udc632, so that the resulting vector\n[\ufe02\ud835\udc631\n\ud835\udc632\n]\ufe02\nis orthogonal to #\u00bb\ud835\udc64.\nFor example, choosing \ud835\udc631 = 2 gives \ud835\udc632 = \u22123 \u2212 \ud835\udc56\n2\n(2) = \u22123 \u2212 \ud835\udc56.\nSince \u27e8#\u00bb\ud835\udc63 , #\u00bb\ud835\udc64\u27e9\n=\n\u27e8[\ufe02\n2\n\u22123 \u2212 \ud835\udc56\n]\ufe02\n,\n[\ufe022 + \ud835\udc56\n1 + \ud835\udc56\n]\ufe02\u27e9\n=\n2(2 + \ud835\udc56) + (\u22123 \u2212 \ud835\udc56)(1 + \ud835\udc56)\n=\n2(2 \u2212 \ud835\udc56) + (\u22123 \u2212 \ud835\udc56)(1 \u2212 \ud835\udc56)\n=\n4 \u2212 2\ud835\udc56 \u2212 3 \u2212 \ud835\udc56 + 3\ud835\udc56 \u2212 1 = 0,\nwe know that #\u00bb\ud835\udc63 =\n[\ufe02\n2\n\u22123 \u2212 \ud835\udc56\n]\ufe02\nis orthogonal to #\u00bb\ud835\udc64 =\n[\ufe022 + \ud835\udc56\n1 + \ud835\udc56\n]\ufe02\n.\n(b) A unit vector in the same direction as #\u00bb\ud835\udc63 =\n[\ufe02\n2\n\u22123 \u2212 \ud835\udc56\n]\ufe02\nis ^\ud835\udc63 =\n1\n\u2016#\u00bb\ud835\udc63 \u2016\n#\u00bb\ud835\udc63 .\n\u2016#\u00bb\ud835\udc63 \u2016 =\n\u221a\ufe00\n\u27e8#\u00bb\ud835\udc63 , #\u00bb\ud835\udc63 \u27e9\n=\n\u221a\ufe01\n2(2) + (\u22123 \u2212 \ud835\udc56)(\u22123 \u2212 \ud835\udc56)\n=\n\u221a\n4 + 9 + 1\n=\n\u221a\n14\nThus, ^\ud835\udc63 =\n1\n\u2016#\u00bb\ud835\udc63 \u2016\n#\u00bb\ud835\udc63 =\n1\n\u221a\n14\n[\ufe02\n2\n\u22123 \u2212 \ud835\udc56\n]\ufe02\nis a unit vector that is orthogonal to #\u00bb\ud835\udc64.\nEXERCISE\nIn (a) of the previous Example, choose a different non-zero value for \ud835\udc631 and use (*) to\ndetermine a value for \ud835\udc632.\nVerify that your resulting vector\n[\ufe02\ud835\udc631\n\ud835\udc632\n]\ufe02\nis orthogonal to #\u00bb\ud835\udc64 =\n[\ufe022 + \ud835\udc56\n1 + \ud835\udc56\n]\ufe02\n.\nDefinition 1.7.13\nProjection of #\u00bb\ud835\udc63\nOnto #\u00bb\n\ud835\udc64\nLet #\u00bb\ud835\udc63 , #\u00bb\ud835\udc64 \u2208 C\ud835\udc5b, with #\u00bb\ud835\udc64 \u0338= #\u00bb0 . The projection of #\u00bb\ud835\udc63 onto #\u00bb\ud835\udc64 is defined by\nproj #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 ) = \u27e8#\u00bb\ud835\udc63 , #\u00bb\ud835\udc64\u27e9\n\u2016#\u00bb\ud835\udc64\u20162\n#\u00bb\ud835\udc64 = \u27e8#\u00bb\ud835\udc63 , ^\ud835\udc64\u27e9 ^\ud835\udc64.\nExample 1.7.14\nFind the projection of #\u00bb\ud835\udc63 =\n\u23a1\n\u23a3\n1\n\ud835\udc56\n1 + \ud835\udc56\n\u23a4\n\u23a6 onto #\u00bb\ud835\udc64 =\n\u23a1\n\u23a3\n1 \u2212 \ud835\udc56\n2 \u2212 \ud835\udc56\n3 + \ud835\udc56\n\u23a4\n\u23a6 .\nSolution:Section 1.8", "Fields\n27\n\u27e8#\u00bb\ud835\udc63 , #\u00bb\ud835\udc64\u27e9\n=\n1(1 \u2212 \ud835\udc56) + \ud835\udc56(2 \u2212 \ud835\udc56) + (1 + \ud835\udc56)(3 + \ud835\udc56)\n=\n1(1 + \ud835\udc56) + \ud835\udc56(2 + \ud835\udc56) + (1 + \ud835\udc56)(3 \u2212 \ud835\udc56)\n=\n1 + \ud835\udc56 + 2\ud835\udc56 \u2212 1 + 3 \u2212 \ud835\udc56 + 3\ud835\udc56 + 1\n=\n4 + 5\ud835\udc56\n\u2016#\u00bb\ud835\udc64\u20162\n=\n|1 \u2212 \ud835\udc56|2 + |2 \u2212 \ud835\udc56|2 + |3 + \ud835\udc56|2\n=\n1 + 1 + 4 + 1 + 9 + 1\n=\n17\nThus, proj #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 )\n=\n\u27e8#\u00bb\ud835\udc63 , #\u00bb\ud835\udc64\u27e9\n\u2016#\u00bb\ud835\udc64\u20162\n#\u00bb\ud835\udc64 = 4 + 5\ud835\udc56\n17\n\u23a1\n\u23a3\n1 \u2212 \ud835\udc56\n2 \u2212 \ud835\udc56\n3 + \ud835\udc56\n\u23a4\n\u23a6 .\n1.8\nFields\nSo far, we have used the sets R and C to choose the components of vectors, but they will\nplay other roles as well. These sets are examples of a field.\nWe will not see any other fields in this course beyond R and C, but for the interested\nstudent, we can give some feel for what a field \u201cis\u201d.\nLoosely speaking, a field is a set where we can add, subtract, multiply and divide. So,\nthe set of integers, Z, is not a field, since although 2 and 3 are both integers, the quotient\n2/3 is not. The set of positive real numbers R+ is not a field since although 2 and 3 are\npositive real numbers, the difference 2 \u2212 3 is not. It turns out (and this is not supposed to\nbe obvious) that the ability to add, subtract, multiply and divide are exactly the properties\nwe need of our scalars in order to do the type of algebra that we want.\nIn much of what we do, there is no need to make an explicit distinction between R and C,\nand so we will refer to our universal set as the field F, with the understanding that F will\neither be R or C, so we will assume that F \u2286 C. Most of the time, the choice of F will not\nmatter. There are however a few occasions where we need to be explicit about which field\nwe are using.\nFor example, if we attempt to solve 2\ud835\udc65 = 5 over F, the solution is \ud835\udc65 = 5\n2, whether F is R or\nC. However, if we try to solve \ud835\udc652 = \u22121 over F, then the field matters. If F = R, then this\nequation has no solutions, but if F = C, then there are two solutions: \ud835\udc65 = \u00b1\ud835\udc56.\nWe previously saw the definition of the standard inner product in C\ud835\udc5b. It will be useful to\nextend this definition to F\ud835\udc5b.\nDefinition 1.8.1\nStandard Inner\nProduct on F\ud835\udc5b\nThe standard inner product of #\u00bb\ud835\udc63 , #\u00bb\ud835\udc64 \u2208 F\ud835\udc5b is\n\u27e8#\u00bb\ud835\udc63 , #\u00bb\ud835\udc64\u27e9 = \ud835\udc631\ud835\udc641 + \ud835\udc632\ud835\udc642 + \u00b7 \u00b7 \u00b7 + \ud835\udc63\ud835\udc5b\ud835\udc64\ud835\udc5b.28\nChapter 1\nVectors in R\ud835\udc5b\nREMARK\n\u2022 If F = C, then this is exactly the standard inner product on C\ud835\udc5b, from Definition 1.7.2.\n\u2022 If F = R, since each \ud835\udc64\ud835\udc56 \u2208 R, then \ud835\udc64\ud835\udc56 = \ud835\udc64\ud835\udc56, and this is just the dot product on R\ud835\udc5b, as\nin Definition 1.5.1.\n1.9", "The Cross Product in R3\nGiven two vectors #\u00bb\ud835\udc62, #\u00bb\ud835\udc63 \u2208 R3, the cross product returns a vector in R3 that is orthogonal\nto both #\u00bb\ud835\udc62 and #\u00bb\ud835\udc63 .\nDefinition 1.9.1\nCross Product\nLet #\u00bb\ud835\udc62 =\n\u23a1\n\u23a3\n\ud835\udc621\n\ud835\udc622\n\ud835\udc623\n\u23a4\n\u23a6 , #\u00bb\ud835\udc63 =\n\u23a1\n\u23a3\n\ud835\udc631\n\ud835\udc632\n\ud835\udc633\n\u23a4\n\u23a6 \u2208 R3. The cross product of #\u00bb\ud835\udc62 and #\u00bb\ud835\udc63 is defined to be the\nvector in R3 given by\n#\u00bb\ud835\udc62 \u00d7 #\u00bb\ud835\udc63 =\n\u23a1\n\u23a3\n\ud835\udc622\ud835\udc633 \u2212 \ud835\udc623\ud835\udc632\n\u2212(\ud835\udc621\ud835\udc633 \u2212 \ud835\udc623\ud835\udc631)\n\ud835\udc621\ud835\udc632 \u2212 \ud835\udc622\ud835\udc631\n\u23a4\n\u23a6 .\nExample 1.9.2\nWe have\n\u23a1\n\u23a3\n2\n\u22123\n5\n\u23a4\n\u23a6 \u00d7\n\u23a1\n\u23a3\n\u22122\n1\n4\n\u23a4\n\u23a6 =\n\u23a1\n\u23a3\n(\u22123)(4) \u2212 (5)(1)\n\u2212((2)(4) \u2212 (5)(\u22122))\n(2)(1) \u2212 (\u22123)(\u22122)\n\u23a4\n\u23a6 =\n\u23a1\n\u23a3\n\u221217\n\u221218\n\u22124\n\u23a4\n\u23a6 .\nREMARK\nA useful trick for remembering the definition of the cross product will be given in Section\n6.6.\nProposition 1.9.3\n(Properties of the Cross Product)\nLet #\u00bb\ud835\udc62, #\u00bb\ud835\udc63 \u2208 R3 and let #\u00bb\ud835\udc67 = #\u00bb\ud835\udc62 \u00d7 #\u00bb\ud835\udc63 . Then\n(a) #\u00bb\ud835\udc67 \u00b7 #\u00bb\ud835\udc62 = 0 and #\u00bb\ud835\udc67 \u00b7 #\u00bb\ud835\udc63 = 0\n(#\u00bb\ud835\udc67 is orthogonal to both #\u00bb\ud835\udc62 and #\u00bb\ud835\udc63 )\n(b) #\u00bb\ud835\udc63 \u00d7 #\u00bb\ud835\udc62 = \u2212#\u00bb\ud835\udc67 = \u2212#\u00bb\ud835\udc62 \u00d7 #\u00bb\ud835\udc63\n(skew-symmetric)\n(c) If #\u00bb\ud835\udc62 \u0338= #\u00bb0 and #\u00bb\ud835\udc63 \u0338= #\u00bb0 , then \u2016#\u00bb\ud835\udc62 \u00d7 #\u00bb\ud835\udc63 \u2016 = \u2016#\u00bb\ud835\udc62\u2016\u2016#\u00bb\ud835\udc63 \u2016 sin \ud835\udf03, where \ud835\udf03 is the angle between #\u00bb\ud835\udc62\nand #\u00bb\ud835\udc63 .Section 1.9\nThe Cross Product in R3\n29\nREMARK (Right-Hand Rule)\nIf #\u00bb\ud835\udc67 is orthogonal to both #\u00bb\ud835\udc62 and #\u00bb\ud835\udc63 , then \u2212#\u00bb\ud835\udc67 will\nalso be orthogonal to both #\u00bb\ud835\udc62 and #\u00bb\ud835\udc63 , and \u2212#\u00bb\ud835\udc67 has\nopposite direction to #\u00bb\ud835\udc67 .\nThe Right-Hand Rule is a convention used to\ndetermine which of these directions #\u00bb\ud835\udc62 \u00d7 #\u00bb\ud835\udc63 should\nhave.\nIf the pointer finger of your right hand points in\nthe direction of #\u00bb\ud835\udc62, and the middle finger of your\nright hand points in the direction of #\u00bb\ud835\udc63 , then your\nthumb points in the direction of #\u00bb\ud835\udc62 \u00d7 #\u00bb\ud835\udc63 .\nIf you consider #\u00bb\ud835\udc63 \u00d7 #\u00bb\ud835\udc62 instead, you would have to\nturn your hand upside-down, which helps demon-\nstrate the skew-symmetric property above!\nREMARK (Parallelogram Area via Cross Product)\nConsider the parallelogram defined by #\u00bb\ud835\udc62 and #\u00bb\ud835\udc63 ; its height is \u210e = \u2016#\u00bb\ud835\udc63 \u2016 sin \ud835\udf03.\nAs a result of Property (c) of the above Proposition, its area is\n\u2016#\u00bb\ud835\udc62\u2016\u210e = \u2016#\u00bb\ud835\udc62\u2016\u2016#\u00bb\ud835\udc63 \u2016 sin \ud835\udf03 = \u2016#\u00bb\ud835\udc62 \u00d7 #\u00bb\ud835\udc63 \u2016.\nExample 1.9.4\nWith #\u00bb\ud835\udc62 =\n\u23a1\n\u23a3\n2\n\u22123\n5\n\u23a4\n\u23a6 and #\u00bb\ud835\udc63 =\n\u23a1\n\u23a3\n\u22122\n1\n4\n\u23a4\n\u23a6, verify Proposition 1.9.3 (Properties of the Cross Prod-\nuct).\nSolution: From Example 1.9.2, #\u00bb\ud835\udc67 = #\u00bb\ud835\udc62 \u00d7 #\u00bb\ud835\udc63 =\n\u23a1\n\u23a3\n\u221217\n\u221218\n\u22124\n\u23a4\n\u23a6.\n(a) #\u00bb\ud835\udc67 \u00b7 #\u00bb\ud835\udc62 =\n\u23a1\n\u23a3\n\u221217\n\u221218\n\u22124\n\u23a4\n\u23a6 \u00b7\n\u23a1\n\u23a3\n2\n\u22123\n5\n\u23a4\n\u23a6 = \u221217(2) \u2212 18(\u22123) \u2212 4(5) = 0.\n#\u00bb\ud835\udc67 \u00b7 #\u00bb\ud835\udc63 =\n\u23a1\n\u23a3\n\u221217\n\u221218\n\u22124\n\u23a4\n\u23a6 \u00b7\n\u23a1\n\u23a3\n\u22122\n1\n4\n\u23a4\n\u23a6 = \u221217(\u22122) \u2212 18(1) \u2212 4(4) = 0.30\nChapter 1\nVectors in R\ud835\udc5b\n(b) #\u00bb\ud835\udc63 \u00d7 #\u00bb\ud835\udc62 =\n\u23a1\n\u23a3\n\u22122\n1\n4\n\u23a4\n\u23a6 \u00d7\n\u23a1\n\u23a3\n2\n\u22123\n5\n\u23a4\n\u23a6 =\n\u23a1\n\u23a3\n(1)(5) \u2212 (4)(\u22123)\n\u2212((\u22122)(5) \u2212 (4)(2))\n(\u22122)(\u22123) \u2212 (1)(2)\n\u23a4\n\u23a6 =\n\u23a1\n\u23a3\n17\n18\n4\n\u23a4\n\u23a6 = \u2212#\u00bb\ud835\udc62 \u00d7 #\u00bb\ud835\udc63 .\n(c) Let \ud835\udf03 be the angle between #\u00bb\ud835\udc62 and #\u00bb\ud835\udc63 . Working to three decimal places throughout,\n#\u00bb\ud835\udc62 \u00b7 #\u00bb\ud835\udc63 can be used to evaluate \ud835\udf03.\n\ud835\udf03 = arccos\n(\ufe02\n#\u00bb\ud835\udc62 \u00b7 #\u00bb\ud835\udc63\n\u2016#\u00bb\ud835\udc62\u2016\u2016#\u00bb\ud835\udc63 \u2016\n)\ufe02\n= arccos\n\u239b\n\u239c\n\u239c\n\u239c\n\u239c\n\u239c\n\u239c\n\u239c\n\u239d\n\u23a1\n\u23a3\n2\n\u22123\n5\n\u23a4\n\u23a6 \u00b7\n\u23a1\n\u23a3\n\u22122\n1\n4\n\u23a4\n\u23a6\n\u20e6\u20e6\u20e6\u20e6\u20e6\u20e6\n\u23a1\n\u23a3\n2\n\u22123\n5\n\u23a4\n\u23a6\n\u20e6\u20e6\u20e6\u20e6\u20e6\u20e6\n\u20e6\u20e6\u20e6\u20e6\u20e6\u20e6\n\u23a1\n\u23a3\n\u22122\n1\n4\n\u23a4\n\u23a6\n\u20e6\u20e6\u20e6\u20e6\u20e6\u20e6\n\u239e\n\u239f\n\u239f\n\u239f\n\u239f\n\u239f\n\u239f\n\u239f\n\u23a0\n= arccos\n(\ufe02 13\n\u221a\n798\n)\ufe02\n\u2248 1.093.\nThus \u2016#\u00bb\ud835\udc62\u2016\u2016#\u00bb\ud835\udc63 \u2016 sin \ud835\udf03 =\n\u20e6\u20e6\u20e6\u20e6\u20e6\u20e6\n\u23a1\n\u23a3\n2\n\u22123\n5\n\u23a4\n\u23a6\n\u20e6\u20e6\u20e6\u20e6\u20e6\u20e6\n\u20e6\u20e6\u20e6\u20e6\u20e6\u20e6\n\u23a1\n\u23a3\n\u22122\n1\n4\n\u23a4\n\u23a6\n\u20e6\u20e6\u20e6\u20e6\u20e6\u20e6\nsin \ud835\udf03 \u2248\n\u221a\n798(0.888) \u2248 25.080.\nSince #\u00bb\ud835\udc62 \u00d7 #\u00bb\ud835\udc63 =\n\u23a1\n\u23a3\n\u221217\n\u221218\n\u22124\n\u23a4\n\u23a6, thus\n\u2016#\u00bb\ud835\udc62 \u00d7 #\u00bb\ud835\udc63 \u2016 =\n\u221a\n172 + 182 + 42 =\n\u221a\n629 = 25.080 \u2248 \u2016#\u00bb\ud835\udc62\u2016\u2016#\u00bb\ud835\udc63 \u2016 sin \ud835\udf03.\nProposition 1.9.5\n(Linearity of the Cross Product)\nIf \ud835\udc50 \u2208 R and #\u00bb\ud835\udc62, #\u00bb\ud835\udc63 , #\u00bb\ud835\udc64 \u2208 R3, then\n(\ud835\udc4e)\n(#\u00bb\ud835\udc62 + #\u00bb\ud835\udc63 ) \u00d7 #\u00bb\ud835\udc64 = (#\u00bb\ud835\udc62 \u00d7 #\u00bb\ud835\udc64) + (#\u00bb\ud835\udc63 \u00d7 #\u00bb\ud835\udc64)\n(\ud835\udc4f)\n(\ud835\udc50#\u00bb\ud835\udc62) \u00d7 #\u00bb\ud835\udc63 = \ud835\udc50(#\u00bb\ud835\udc62 \u00d7 #\u00bb\ud835\udc63 )\n}\ufe03\nlinearity in the first argument\n(\ud835\udc50)\n#\u00bb\ud835\udc62 \u00d7 (#\u00bb\ud835\udc63 + #\u00bb\ud835\udc64) = (#\u00bb\ud835\udc62 \u00d7 #\u00bb\ud835\udc63 ) + (#\u00bb\ud835\udc62 \u00d7 #\u00bb\ud835\udc64)\n(\ud835\udc51)\n#\u00bb\ud835\udc62 \u00d7 (\ud835\udc50#\u00bb\ud835\udc63 ) = \ud835\udc50(#\u00bb\ud835\udc62 \u00d7 #\u00bb\ud835\udc63 )\n}\ufe03\nlinearity in the second argument\nProof: We will prove linearity in the second argument; the proof of linearity in the first\nargument follows by using the skew-symmetry of the cross product.\n(c) We have\n#\u00bb\ud835\udc62 \u00d7 (#\u00bb\ud835\udc63 + #\u00bb\ud835\udc64) =\n\u23a1\n\u23a3\n\ud835\udc622(\ud835\udc633 + \ud835\udc643) \u2212 \ud835\udc623(\ud835\udc632 + \ud835\udc642)\n\u2212[\ud835\udc621(\ud835\udc633 + \ud835\udc643) \u2212 \ud835\udc623(\ud835\udc631 + \ud835\udc641)]\n\ud835\udc621(\ud835\udc632 + \ud835\udc642) \u2212 \ud835\udc622(\ud835\udc631 + \ud835\udc641)\n\u23a4\n\u23a6\n=\n\u23a1\n\u23a3\n\ud835\udc622\ud835\udc633 \u2212 \ud835\udc623\ud835\udc632\n\u2212[\ud835\udc621\ud835\udc633 \u2212 \ud835\udc623\ud835\udc631]\n\ud835\udc621\ud835\udc632 \u2212 \ud835\udc622\ud835\udc631\n\u23a4\n\u23a6 +\n\u23a1\n\u23a3\n\ud835\udc622\ud835\udc643 \u2212 \ud835\udc623\ud835\udc642\n\u2212[\ud835\udc621\ud835\udc643 \u2212 \ud835\udc623\ud835\udc641]\n\ud835\udc621\ud835\udc642 \u2212 \ud835\udc622\ud835\udc641\n\u23a4\n\u23a6\n= (#\u00bb\ud835\udc62 \u00d7 #\u00bb\ud835\udc63 ) + (#\u00bb\ud835\udc62 \u00d7 #\u00bb\ud835\udc64).Section 1.9\nThe Cross Product in R3\n31\n(d) We have\n#\u00bb\ud835\udc62 \u00d7 (\ud835\udc50#\u00bb\ud835\udc63 ) =\n\u23a1\n\u23a3\n\ud835\udc622(\ud835\udc50\ud835\udc633) \u2212 \ud835\udc623(\ud835\udc50\ud835\udc632)\n\u2212[\ud835\udc621(\ud835\udc50\ud835\udc633) \u2212 \ud835\udc623(\ud835\udc50\ud835\udc631)]\n\ud835\udc621(\ud835\udc50\ud835\udc632) \u2212 \ud835\udc622(\ud835\udc50\ud835\udc631)\n\u23a4\n\u23a6\n= \ud835\udc50\n\u23a1\n\u23a3\n\ud835\udc622\ud835\udc633 \u2212 \ud835\udc623\ud835\udc632\n\u2212[\ud835\udc621\ud835\udc633 \u2212 \ud835\udc623\ud835\udc631]\n\ud835\udc621\ud835\udc632 \u2212 \ud835\udc622\ud835\udc631\n\u23a4\n\u23a6\n= \ud835\udc50(#\u00bb\ud835\udc62 \u00d7 #\u00bb\ud835\udc63 ).\nREMARK (Why is #\u00bb\ud835\udc62 \u00d7 #\u00bb\ud835\udc63 only defined for R3?)\nGiven two non-parallel vectors #\u00bb\ud835\udc62, #\u00bb\ud835\udc63 \u2208 R\ud835\udc5b for \ud835\udc5b = 3, we can notice that there is always\nexactly one line through the origin that is orthogonal to both #\u00bb\ud835\udc62 and #\u00bb\ud835\udc63 . A cross product\nallows us to compute one non-zero vector on this line. It turns out that any other vector\nthat is orthogonal to both #\u00bb\ud835\udc62 and #\u00bb\ud835\udc63 will always lie on this line, and hence will be a multiple\nof #\u00bb\ud835\udc62 \u00d7 #\u00bb\ud835\udc63 . Notice that, when \ud835\udc5b \u0338= 3, this does not happen.\n\u2022 In R2, if #\u00bb\ud835\udc62 =\n[\ufe021\n0\n]\ufe02\nand #\u00bb\ud835\udc63 =\n[\ufe020\n1\n]\ufe02\n, then the only vector that is orthogonal to both #\u00bb\ud835\udc62\nand #\u00bb\ud835\udc63 is #\u00bb0 , which we can consider a trivial choice.\n\u2022 For vectors #\u00bb\ud835\udc62, #\u00bb\ud835\udc63 \u2208 R\ud835\udc5b with \ud835\udc5b \u2265 4, there are many different lines through the origin\nthat are orthogonal to both #\u00bb\ud835\udc62 and #\u00bb\ud835\udc63 , making it difficult to choose one line out of\nmany.\nFor example, in R4, if #\u00bb\ud835\udc62 =\n\u23a1\n\u23a2\u23a2\u23a3\n1\n0\n0\n0\n\u23a4\n\u23a5\u23a5\u23a6 and #\u00bb\ud835\udc63 =\n\u23a1\n\u23a2\u23a2\u23a3\n0\n1\n0\n0\n\u23a4\n\u23a5\u23a5\u23a6, then #\u00bb\ud835\udc66 =\n\u23a1\n\u23a2\u23a2\u23a3\n0\n0\n1\n0\n\u23a4\n\u23a5\u23a5\u23a6 and #\u00bb\ud835\udc67 =\n\u23a1\n\u23a2\u23a2\u23a3\n0\n0\n0\n1\n\u23a4\n\u23a5\u23a5\u23a6 are\neach orthogonal to both #\u00bb\ud835\udc62 and #\u00bb\ud835\udc63 , but #\u00bb\ud835\udc66 and #\u00bb\ud835\udc67 lie on different lines through the\norigin.Chapter 2\nSpan, Lines and Planes\n2.1", "Linear Combinations and Span\nDefinition 2.1.1\nLinear\nCombination\nLet \ud835\udc501, \ud835\udc502, . . . , \ud835\udc50\ud835\udc58 \u2208 F and let #\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . #\u00bb\n\ud835\udc63\ud835\udc58 be vectors in F\ud835\udc5b. We refer to any vector of the\nform \ud835\udc501 #\u00bb\n\ud835\udc631 + \ud835\udc502 #\u00bb\n\ud835\udc632 + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc58 #\u00bb\n\ud835\udc63\ud835\udc58 as a linear combination of #\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . #\u00bb\n\ud835\udc63\ud835\udc58.\nExample 2.1.2\nSince 2\n\u23a1\n\u23a3\n2\n0\n5\n\u23a4\n\u23a6 \u2212 5\n\u23a1\n\u23a3\n\u22121\n1\n3\n\u23a4\n\u23a6 =\n\u23a1\n\u23a3\n9\n\u22125\n\u22125\n\u23a4\n\u23a6,\n\u23a1\n\u23a3\n9\n\u22125\n\u22125\n\u23a4\n\u23a6 is a linear combination of vectors\n\u23a1\n\u23a3\n2\n0\n5\n\u23a4\n\u23a6 and\n\u23a1\n\u23a3\n\u22121\n1\n3\n\u23a4\n\u23a6\nin R3.\nExample 2.1.3\nSince 3\ud835\udc56\n[\ufe02 \ud835\udc56\n0\n]\ufe02\n+ 4\n[\ufe021 + \ud835\udc56\n\u22124\ud835\udc56\n]\ufe02\n=\n[\ufe021 + 4\ud835\udc56\n\u221216\ud835\udc56\n]\ufe02\n,\n[\ufe021 + 4\ud835\udc56\n\u221216\ud835\udc56\n]\ufe02\nis a linear combination of\n[\ufe02 \ud835\udc56\n0\n]\ufe02\nand\n[\ufe021 + \ud835\udc56\n\u22124\ud835\udc56\n]\ufe02\nin C2.\nExample 2.1.4\nThe vector\n\u23a1\n\u23a2\u23a2\u23a3\n\u221231\n54\n\u221210\n23\n\u23a4\n\u23a5\u23a5\u23a6 = 2\n\u23a1\n\u23a2\u23a2\u23a3\n1\n0\n2\n0\n\u23a4\n\u23a5\u23a5\u23a6 \u2212 5\n\u23a1\n\u23a2\u23a2\u23a3\n0\n0\n\u22121\n1\n\u23a4\n\u23a5\u23a5\u23a6 + 7\n\u23a1\n\u23a2\u23a2\u23a3\n1\n2\n3\n4\n\u23a4\n\u23a5\u23a5\u23a6 \u2212 4\n\u23a1\n\u23a2\u23a2\u23a3\n10\n\u221210\n10\n0\n\u23a4\n\u23a5\u23a5\u23a6 is a linear combination of the\nfour vectors\n[\ufe00\n1 0 2 0\n]\ufe00\ud835\udc47 ,\n[\ufe00\n0 0 \u22121 1\n]\ufe00\ud835\udc47 ,\n[\ufe00\n1 2 3 4\n]\ufe00\ud835\udc47 ,\n[\ufe00\n10 \u221210 10 0\n]\ufe00\ud835\udc47\nin R4.\nExample 2.1.5\nFor any #\u00bb\ud835\udc63 , #\u00bb\ud835\udc64 \u2208 F\ud835\udc5b, the zero vector #\u00bb0 = 0#\u00bb\ud835\udc63 + 0#\u00bb\ud835\udc64 is a linear combination of #\u00bb\ud835\udc63 and #\u00bb\ud835\udc64.\nDefinition 2.1.6\nSpan\nLet #\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58 be vectors in F\ud835\udc5b. We define the span of {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58} to be the set of\nall linear combinations of #\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58. That is,\nSpan{#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58} = {\ud835\udc501 #\u00bb\n\ud835\udc631 + \ud835\udc502 #\u00bb\n\ud835\udc632 + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc58 #\u00bb\n\ud835\udc63\ud835\udc58 : \ud835\udc501, \ud835\udc502, . . . , \ud835\udc50\ud835\udc58 \u2208 F}.\n32Section 2.1\nLinear Combinations and Span\n33\nWe refer to {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58} as a spanning set for Span{#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58}. We also say that\nSpan{#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58} is spanned by {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58}.\nExample 2.1.7\nConsider the vectors #\u00bb\n\ud835\udc631 =\n\u23a1\n\u23a3\n2\ud835\udc56\n3\n\ud835\udc56\n\u23a4\n\u23a6 , #\u00bb\n\ud835\udc632 =\n\u23a1\n\u23a3\n2 + \ud835\udc56\n\u22125 + 2\ud835\udc56\n6\ud835\udc56\n\u23a4\n\u23a6 in C3. Then\nSpan\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n2\ud835\udc56\n3\n\ud835\udc56\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n2 + \ud835\udc56\n\u22125 + 2\ud835\udc56\n6\ud835\udc56\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad =\n\u23a7\n\u23a8\n\u23a9\ud835\udc501\n\u23a1\n\u23a3\n2\ud835\udc56\n3\n\ud835\udc56\n\u23a4\n\u23a6 + \ud835\udc502\n\u23a1\n\u23a3\n2 + \ud835\udc56\n\u22125 + 2\ud835\udc56\n6\ud835\udc56\n\u23a4\n\u23a6 : \ud835\udc501, \ud835\udc502 \u2208 C\n\u23ab\n\u23ac\n\u23ad .\nExample 2.1.8\nConsider the vectors #\u00bb\n\ud835\udc631 =\n\u23a1\n\u23a3\n1\n3\n7\n\u23a4\n\u23a6 , #\u00bb\n\ud835\udc632 =\n\u23a1\n\u23a3\n2\n5\n7\n\u23a4\n\u23a6 , #\u00bb\n\ud835\udc633 =\n\u23a1\n\u23a3\n2\n\u22128\n6\n\u23a4\n\u23a6 , #\u00bb\n\ud835\udc634 =\n\u23a1\n\u23a3\n5\n7\n\u22124\n\u23a4\n\u23a6 in F3. Then\nSpan {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, #\u00bb\n\ud835\udc633, #\u00bb\n\ud835\udc634} =\n\u23a7\n\u23a8\n\u23a9\ud835\udc501\n\u23a1\n\u23a3\n1\n3\n7\n\u23a4\n\u23a6 + \ud835\udc502\n\u23a1\n\u23a3\n2\n5\n7\n\u23a4\n\u23a6 + \ud835\udc503\n\u23a1\n\u23a3\n2\n\u22128\n6\n\u23a4\n\u23a6 + \ud835\udc504\n\u23a1\n\u23a3\n5\n7\n\u22124\n\u23a4\n\u23a6 : \ud835\udc501, \ud835\udc502, \ud835\udc503, \ud835\udc504 \u2208 F\n\u23ab\n\u23ac\n\u23ad .\nREMARK\nIn the above example, F could be either R or C.\nIf F = R, then we would choose\n\ud835\udc501, \ud835\udc502, \ud835\udc503, \ud835\udc504 \u2208 R.\nHowever, if F = C, then we would choose \ud835\udc501, \ud835\udc502, \ud835\udc503, \ud835\udc504 \u2208 C, resulting\nin more vectors being in Span {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, #\u00bb\n\ud835\udc633, #\u00bb\n\ud835\udc634}.\nExample 2.1.9\nDetermine whether the vector\n\u23a1\n\u23a3\n\u22123\n9\n2\n\u23a4\n\u23a6 is an element of Span\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n1\n2\n1\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n1\n\u22121\n0\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad.\nSolution:\nSince\n\u23a1\n\u23a3\n\u22123\n9\n2\n\u23a4\n\u23a6 = 2\n\u23a1\n\u23a3\n1\n2\n1\n\u23a4\n\u23a6 \u2212 5\n\u23a1\n\u23a3\n1\n\u22121\n0\n\u23a4\n\u23a6, we see that\n\u23a1\n\u23a3\n\u22123\n9\n2\n\u23a4\n\u23a6 \u2208 Span\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n1\n2\n1\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n1\n\u22121\n0\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad.\nExample 2.1.10\nDetermine whether\n\u23a1\n\u23a3\n0\n1\n0\n\u23a4\n\u23a6 is in Span\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n2\n0\n5\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n\u22121\n0\n3\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad.\nSolution:\nEvery vector in Span\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n2\n0\n5\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n\u22121\n0\n3\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad has the form \ud835\udc501\n\u23a1\n\u23a3\n2\n0\n5\n\u23a4\n\u23a6 + \ud835\udc502\n\u23a1\n\u23a3\n\u22121\n0\n3\n\u23a4\n\u23a6 =\n\u23a1\n\u23a3\n2\ud835\udc501 \u2212 \ud835\udc502\n0\n5\ud835\udc501 + 3\ud835\udc502\n\u23a4\n\u23a634\nChapter 2\nSpan, Lines and Planes\nfor some \ud835\udc501, \ud835\udc502 \u2208 F. Since the equation\n\u23a1\n\u23a3\n0\n1\n0\n\u23a4\n\u23a6 =\n\u23a1\n\u23a3\n2\ud835\udc501 \u2212 \ud835\udc502\n0\n5\ud835\udc501 + 3\ud835\udc502\n\u23a4\n\u23a6 has no solutions in \ud835\udc501, \ud835\udc502 \u2208 F,\nwe conclude that\n\u23a1\n\u23a3\n0\n1\n0\n\u23a4\n\u23a6 \u0338\u2208 Span\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n2\n0\n5\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n\u22121\n0\n3\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad.\n2.2", "Lines in R2\nThere is a nice way to write down the equation of a line in R\ud835\udc5b making use of vectors. We\nbegin with R2 (otherwise known as the \ud835\udc65\ud835\udc66-plane) before generalizing to R\ud835\udc5b.\nWe consider the line \u2112 with points (\ud835\udc651, \ud835\udc661) and (\ud835\udc652, \ud835\udc662), \ud835\udc66-intercept at (0, \ud835\udc4f), with slope\n\ud835\udc5a = \ud835\udc5d\n\ud835\udc5e where \ud835\udc5e \u0338= 0. We visualize all of this information below.\nFigure 2.2.1: Characteristics of a line \u2112 in R2\nThe table below includes four different forms of equation(s) for \u2112 in the \ud835\udc65\ud835\udc66-plane, based on\ngiven information.\nGiven Information\nEquation of Line\nSlope \ud835\udc5a and \ud835\udc66-intercept \ud835\udc4f\n\ud835\udc66 = \ud835\udc5a\ud835\udc65 + \ud835\udc4f\nTwo points (\ud835\udc651, \ud835\udc661) and (\ud835\udc652, \ud835\udc662)\n\ud835\udc66 \u2212 \ud835\udc661\n\ud835\udc662 \u2212 \ud835\udc661\n= \ud835\udc65 \u2212 \ud835\udc651\n\ud835\udc652 \u2212 \ud835\udc651\nPoint (\ud835\udc651, \ud835\udc661) and slope \ud835\udc5a\n\ud835\udc66 \u2212 \ud835\udc661 = \ud835\udc5a(\ud835\udc65 \u2212 \ud835\udc651)\nPoint (\ud835\udc651, \ud835\udc661) and slope \ud835\udc5d\n\ud835\udc5e (\ud835\udc5e \u0338= 0)\n\ud835\udc65 = \ud835\udc651 + \ud835\udc5e\ud835\udc61\n\ud835\udc66 = \ud835\udc661 + \ud835\udc5d\ud835\udc61 ,\n\ud835\udc61 \u2208 R\nIn the first 3 forms above, we input a particular value for \ud835\udc65 to obtain the value of \ud835\udc66 for the\ncorresponding point on the line.\nIn the last form above, the variable \ud835\udc61 is called a parameter. We input a particular value\nfor \ud835\udc61 to obtain the value of the \ud835\udc65- and \ud835\udc66-coordinates for the corresponding point on the line.\nDefinition 2.2.1\nParametric\nEquations of a Line\nin R2\nLet \ud835\udc5d, \ud835\udc5e be fixed real numbers and \ud835\udc5e \u0338= 0. Then parametric equations of a line in R2\nthrough the point (\ud835\udc651, \ud835\udc661) with slope \ud835\udc5d\n\ud835\udc5e are\n\ud835\udc65 = \ud835\udc651 + \ud835\udc5e\ud835\udc61\n\ud835\udc66 = \ud835\udc661 + \ud835\udc5d\ud835\udc61 ,\n\ud835\udc61 \u2208 R.Section 2.2\nLines in R2\n35\nEach value of \ud835\udc61 gives a different point on the line. For instance,\n\u2022 \ud835\udc61 = 0 gives the point (\ud835\udc65, \ud835\udc66) = (\ud835\udc651, \ud835\udc661)\n\u2022 \ud835\udc61 = 2 gives the point (\ud835\udc65, \ud835\udc66) = (\ud835\udc651 + 2\ud835\udc5e, \ud835\udc661 + 2\ud835\udc5d)\n\u2022 \ud835\udc61 = \u22125 gives the point (\ud835\udc65, \ud835\udc66) = (\ud835\udc651 \u2212 5\ud835\udc5e, \ud835\udc661 \u2212 5\ud835\udc5d).\nAs \ud835\udc61 varies over all real numbers, we generate all the points on the line.\nREMARK\nSince \ud835\udc5e \u0338= 0, the expression \ud835\udc5d\n\ud835\udc5e is always defined. Putting \ud835\udc5e = 0 into the parametric equations\nof the line gives us \ud835\udc65 = \ud835\udc651 and \ud835\udc66 = \ud835\udc661 + \ud835\udc5d\ud835\udc61, a vertical line with undefined slope (we can\nthink of this informally as \u201cinfinite slope\u201d).\nDefinition 2.2.2\nVector Equation of\na Line in R2\nLet\n[\ufe02\ud835\udc5e\n\ud835\udc5d\n]\ufe02\nbe a non-zero vector in R2. The expression\n#\u00bb\u2113 =\n[\ufe02\ud835\udc65\n\ud835\udc66\n]\ufe02\n=\n[\ufe02\ud835\udc651\n\ud835\udc661\n]\ufe02\n+ \ud835\udc61\n[\ufe02\ud835\udc5e\n\ud835\udc5d\n]\ufe02\n, \ud835\udc61 \u2208 R\nis a vector equation of the line \u2112 in R2 through\n[\ufe02\ud835\udc651\n\ud835\udc661\n]\ufe02\nwith direction\n[\ufe02\ud835\udc5e\n\ud835\udc5d\n]\ufe02\n.\nFor any value of \ud835\udc61 \u2208 R, the expression\n[\ufe02\ud835\udc651\n\ud835\udc661\n]\ufe02\n+\ud835\udc61\n[\ufe02\ud835\udc5e\n\ud835\udc5d\n]\ufe02\nproduces a vector in R2 whose terminal\npoint has coordinates \ud835\udc3f = (\ud835\udc651 + \ud835\udc61\ud835\udc5e, \ud835\udc661 + \ud835\udc61\ud835\udc5d) and is on \u2112.\nREMARKS\nIf we let #\u00bb\ud835\udc62 =\n[\ufe02\ud835\udc651\n\ud835\udc661\n]\ufe02\nand #\u00bb\ud835\udc63 =\n[\ufe02\ud835\udc5e\n\ud835\udc5d\n]\ufe02\n, we can write a vector equation of line \u2112 in R2 as\n#\u00bb\u2113 = #\u00bb\ud835\udc62 + \ud835\udc61#\u00bb\ud835\udc63 , for \ud835\udc61 \u2208 R.\n\u2022 Letting \ud835\udc61 = 0 gives us that the vector #\u00bb\ud835\udc62 is on the line.\n\u2022 The line passes through the terminal point \ud835\udc48 associated with #\u00bb\ud835\udc62. The other points on\nthe line move from \ud835\udc48 in the #\u00bb\ud835\udc63 direction by scalar multiples of #\u00bb\ud835\udc63 .\n\u2022 We say that #\u00bb\ud835\udc63 is parallel to the line and that #\u00bb\ud835\udc63 is a direction vector to the line.\n\u2022 The vector #\u00bb\ud835\udc63 is parallel to the line. However, the terminal point \ud835\udc49 associated with\n#\u00bb\ud835\udc63 is not usually a point on the line; in fact, \ud835\udc49 is a point on the line if and only if the\nvector #\u00bb\ud835\udc63 is a scalar multiple of the vector #\u00bb\ud835\udc62.36\nChapter 2\nSpan, Lines and Planes\nDefinition 2.2.3\nLine in R2\nLet #\u00bb\ud835\udc62, #\u00bb\ud835\udc63 \u2208 R2 with #\u00bb\ud835\udc63 \u0338= #\u00bb0 . We refer to the set of vectors\n\u2112 = {#\u00bb\ud835\udc62 + \ud835\udc61#\u00bb\ud835\udc63 : \ud835\udc61 \u2208 R}\nas a line \u2112 in R2 through #\u00bb\ud835\udc62 with direction #\u00bb\ud835\udc63 .\nFigure 2.2.2: Line in R2 through #\u00bb\ud835\udc62 with direction #\u00bb\ud835\udc63\nExample 2.2.4\nLet \ud835\udc48 = (2, 3) and \ud835\udc49 = (1, 4) be two points on a line \u2112 in R2. Find a vector equation of \u2112.\nSolution:\nWe can find a vector parallel to the line by taking the difference #\u00bb\ud835\udc63 \u2212 #\u00bb\ud835\udc62, where #\u00bb\ud835\udc62 and #\u00bb\ud835\udc63 are\nthe vector representations of points \ud835\udc48 and \ud835\udc49 , respectively. This gives\n[\ufe021\n4\n]\ufe02\n\u2212\n[\ufe022\n3\n]\ufe02\n=\n[\ufe02\u22121\n1\n]\ufe02\n,\nand a vector equation of the line is therefore #\u00bb\u2113 = #\u00bb\ud835\udc62 + \ud835\udc61(#\u00bb\ud835\udc63 \u2212 #\u00bb\ud835\udc62) =\n[\ufe022\n3\n]\ufe02\n+ \ud835\udc61\n[\ufe02\u22121\n1\n]\ufe02\nfor \ud835\udc61 \u2208 R.\n2.3", "Lines in R\ud835\udc5b\nWe now consider lines in R\ud835\udc5b. Lines in R\ud835\udc5b can be described using the same vector equations\nas lines in R2. The only major differences in describing these lines arise from the implicit\nnumber of components in the vectors, which in turn affects the number of parametric\nequations associated with these lines.\nDefinition 2.3.1\nVector Equation of\na Line in R\ud835\udc5b\nLet #\u00bb\ud835\udc62, #\u00bb\ud835\udc63 \u2208 R\ud835\udc5b with #\u00bb\ud835\udc63 \u0338= #\u00bb0 . The expression\n#\u00bb\u2113 = #\u00bb\ud835\udc62 + \ud835\udc61#\u00bb\ud835\udc63 ,\n\ud835\udc61 \u2208 R\nis a vector equation of the line \u2112 in R\ud835\udc5b through #\u00bb\ud835\udc62 with direction #\u00bb\ud835\udc63 .\nIf #\u00bb\u2113 1 and #\u00bb\u2113 2 are lines with direction #\u00bb\ud835\udc63 1 and #\u00bb\ud835\udc63 2, respectively, we say that they have the\nsame direction if \ud835\udc50#\u00bb\ud835\udc63 1 = #\u00bb\ud835\udc63 2 for some non-zero \ud835\udc50 \u2208 R.Section 2.3\nLines in R\ud835\udc5b\n37\nFor any value of \ud835\udc61 \u2208 R, the expression\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc621\n\ud835\udc622\n...\n\ud835\udc62\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 + \ud835\udc61\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc631\n\ud835\udc632\n...\n\ud835\udc63\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 produces a vector in R\ud835\udc5b whose\nterminal point has coordinates \ud835\udc3f = (\ud835\udc621 + \ud835\udc61\ud835\udc631, \ud835\udc622 + \ud835\udc61\ud835\udc632, ..., \ud835\udc62\ud835\udc5b + \ud835\udc61\ud835\udc63\ud835\udc5b) and is on line \u2112.\nFigure 2.3.3: In R\ud835\udc5b, the line #\u00bb\u2113 = #\u00bb\ud835\udc62 + \ud835\udc61#\u00bb\ud835\udc63 ,\n\ud835\udc61 \u2208 R.\nREMARKS\n\u2022 Letting \ud835\udc61 = 0 gives us that the vector #\u00bb\ud835\udc62 is on the line.\n\u2022 The line passes through the terminal point \ud835\udc48 associated with #\u00bb\ud835\udc62. The other points on\nthe line move from \ud835\udc48 in the #\u00bb\ud835\udc63 direction by scalar multiples of #\u00bb\ud835\udc63 .\n\u2022 We say that #\u00bb\ud835\udc63 is parallel to the line, and that #\u00bb\ud835\udc63 is a direction vector to the line.\n\u2022 The vector #\u00bb\ud835\udc63 is parallel to the line, however the terminal point \ud835\udc49 associated with the\nvector #\u00bb\ud835\udc63 , is not usually a point on the line. In fact, \ud835\udc49 is a point on the line if and\nonly if the vector #\u00bb\ud835\udc63 is a multiple of the vector #\u00bb\ud835\udc62.\n\u2022 There are many different vector equations that could be used to describe the same\nline \u2112. We\u2019ll see this in Example 2.3.5\nDefinition 2.3.2\nParametric\nEquations of a Line\nin R\ud835\udc5b\nLet #\u00bb\ud835\udc62, #\u00bb\ud835\udc63 \u2208 R\ud835\udc5b with #\u00bb\ud835\udc63 \u0338= #\u00bb0 . Consider the vector equation of the line \u2112 in R\ud835\udc5b given by\n#\u00bb\u2113 = #\u00bb\ud835\udc62 + \ud835\udc61#\u00bb\ud835\udc63 ,\n\ud835\udc61 \u2208 R.\nThe parametric equations of the line \u2112 in R\ud835\udc5b through #\u00bb\ud835\udc62 with direction #\u00bb\ud835\udc63 are\n\u21131 = \ud835\udc621 + \ud835\udc61\ud835\udc631\n\u21132 = \ud835\udc622 + \ud835\udc61\ud835\udc632\n...\n\u2113\ud835\udc5b = \ud835\udc62\ud835\udc5b + \ud835\udc61\ud835\udc63\ud835\udc5b\n,\n\ud835\udc61 \u2208 R.\nExample 2.3.3\nGive a vector equation and a set of parametric equations of the line through\n\ud835\udc48 = (4, \u22123, 5) and in the direction of the vector #\u00bb\ud835\udc63 =\n\u23a1\n\u23a3\n\u22122\n4\n1\n\u23a4\n\u23a6.38\nChapter 2\nSpan, Lines and Planes\nSolution: A vector equation of the line is\n#\u00bb\u2113 =\n\u23a1\n\u23a3\n4\n\u22123\n5\n\u23a4\n\u23a6 + \ud835\udc61\n\u23a1\n\u23a3\n\u22122\n4\n1\n\u23a4\n\u23a6 , \ud835\udc61 \u2208 R.\nThe corresponding parametric equations of the line are:\n\u21131 = 4 \u2212 2\ud835\udc61\n\u21132 = \u22123 + 4\ud835\udc61\n\u21133 = 5 + \ud835\udc61\n,\n\ud835\udc61 \u2208 R.\nDefinition 2.3.4\nLine in R\ud835\udc5b\nLet #\u00bb\ud835\udc62, #\u00bb\ud835\udc63 \u2208 R\ud835\udc5b with #\u00bb\ud835\udc63 \u0338= #\u00bb0 . We refer to the set of vectors\n\u2112 = {#\u00bb\ud835\udc62 + \ud835\udc61#\u00bb\ud835\udc63 : \ud835\udc61 \u2208 R}\nas a line \u2112 in R\ud835\udc5b through #\u00bb\ud835\udc62 with direction #\u00bb\ud835\udc63 .\nExample 2.3.5\nLet \u2112 =\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n4\n\u22123\n5\n\u23a4\n\u23a6 + \ud835\udc61\n\u23a1\n\u23a3\n\u22122\n4\n1\n\u23a4\n\u23a6 : \ud835\udc61 \u2208 R\n\u23ab\n\u23ac\n\u23ad, be the line from Example 2.3.3.\nShow that the line \u2133 =\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n0\n5\n7\n\u23a4\n\u23a6 + \ud835\udc60\n\u23a1\n\u23a3\n6\n\u221212\n\u22123\n\u23a4\n\u23a6 : \ud835\udc60 \u2208 R\n\u23ab\n\u23ac\n\u23ad is identical to \u2112.\nSolution: First, \u22123\n\u23a1\n\u23a3\n\u22122\n4\n1\n\u23a4\n\u23a6 =\n\u23a1\n\u23a3\n6\n\u221212\n\u22123\n\u23a4\n\u23a6, so\n\u23a1\n\u23a3\n\u22122\n4\n1\n\u23a4\n\u23a6 has the same direction as\n\u23a1\n\u23a3\n6\n\u221212\n\u22123\n\u23a4\n\u23a6.\nThus, \u2112 and \u2133 are parallel. Two parallel lines are the same if and only if they share a\ncommon point.\nTaking \ud835\udc60 = 0 shows that\n\u23a1\n\u23a3\n0\n5\n7\n\u23a4\n\u23a6 is on \u2133. Taking \ud835\udc61 = 2 shows that\n\u23a1\n\u23a3\n4\n\u22123\n5\n\u23a4\n\u23a6 + 2\n\u23a1\n\u23a3\n\u22122\n4\n1\n\u23a4\n\u23a6 =\n\u23a1\n\u23a3\n0\n5\n7\n\u23a4\n\u23a6\nis also on \u2112. Thus, lines \u2112 and \u2133 are identical.\nEXERCISE\nDetermine two different vector equations for the line #\u00bb\u2113 =\n\u23a1\n\u23a3\n1\n2\n2\n\u23a4\n\u23a6 + \ud835\udc61\n\u23a1\n\u23a3\n0\n1\n1\n\u23a4\n\u23a6 , \ud835\udc61 \u2208 R.\nSuppose that we are given two distinct points, \ud835\udc48 and \ud835\udc44, on a line in R\ud835\udc5b, with associated\nvectors, #\u00bb\ud835\udc62 and #\u00bb\ud835\udc5e , respectively. We can define #\u00bb\ud835\udc63 = #\u00bb\ud835\udc5e \u2212 #\u00bb\ud835\udc62, and this vector gives the direction\nof the line. Thus, we can still use Definition 2.3.1 for the vector equation of the line:\n#\u00bb\u2113 = #\u00bb\ud835\udc62 + \ud835\udc61(#\u00bb\ud835\udc5e \u2212 #\u00bb\ud835\udc62),\n\ud835\udc61 \u2208 R.Section 2.4\nLines in R\ud835\udc5b\n39\nFigure 2.3.4: Line in R\ud835\udc5b with direction #\u00bb\ud835\udc63 = #\u00bb\ud835\udc5e \u2212 #\u00bb\ud835\udc62\nExample 2.3.6\nDetermine a vector equation of the line through \ud835\udc48 = (2, \u22123, 5) and \ud835\udc44 = (4, \u22122, 6).\nSolution: A vector equation of the line through the given points is\n#\u00bb\u2113 =\n\u23a1\n\u23a3\n2\n\u22123\n5\n\u23a4\n\u23a6 + \ud835\udc61\n\u239b\n\u239d\n\u23a1\n\u23a3\n4\n\u22122\n6\n\u23a4\n\u23a6 \u2212\n\u23a1\n\u23a3\n2\n\u22123\n5\n\u23a4\n\u23a6\n\u239e\n\u23a0 =\n\u23a1\n\u23a3\n2\n\u22123\n5\n\u23a4\n\u23a6 + \ud835\udc61\n\u23a1\n\u23a3\n2\n1\n1\n\u23a4\n\u23a6 , \ud835\udc61 \u2208 R.\nWe can describe lines through the origin as the span of a single vector. If #\u00bb\ud835\udc63 \u2208 R\ud835\udc5b, with\n#\u00bb\ud835\udc63 \u0338= #\u00bb0 , then Span{#\u00bb\ud835\udc63 } = {#\u00bb0 + \ud835\udc61#\u00bb\ud835\udc63 : \ud835\udc61 \u2208 R} is the line through the origin \ud835\udc42 with #\u00bb\ud835\udc63 as a\ndirection vector.\nFigure 2.3.5: In R\ud835\udc5b, Span{#\u00bb\ud835\udc63 } = {#\u00bb0 + \ud835\udc61#\u00bb\ud835\udc63 : \ud835\udc61 \u2208 R} is a line through the origin\nREMARK\nIf a line can be expressed as the span of one vector, then the line must pass through the\norigin.\nExample 2.3.7\nThe set Span\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n2\n4\n6\n8\n\u23a4\n\u23a5\u23a5\u23a6\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\nis a line \u2112 in R4 that goes through the origin and points in the\ndirection of\n\u23a1\n\u23a2\u23a2\u23a3\n2\n4\n6\n8\n\u23a4\n\u23a5\u23a5\u23a6. It is shorthand for \u2112 =\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\ud835\udc61\n\u23a1\n\u23a2\u23a2\u23a3\n2\n4\n6\n8\n\u23a4\n\u23a5\u23a5\u23a6 : \ud835\udc61 \u2208 R\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n.40\nChapter 2\nSpan, Lines and Planes\n2.4", "The Vector Equation of a Plane in R\ud835\udc5b\nIn this section we will be working in R\ud835\udc5b where \ud835\udc5b \u2265 2.\nDefinition 2.4.1\nPlane in R\ud835\udc5b\nThrough the\nOrigin\nLet #\u00bb\ud835\udc63 , #\u00bb\ud835\udc64 be non-zero vectors in R\ud835\udc5b with #\u00bb\ud835\udc63 \u0338= \ud835\udc50#\u00bb\ud835\udc64 for any \ud835\udc50 \u2208 R. Then\n\ud835\udcab = Span{#\u00bb\ud835\udc63 , #\u00bb\ud835\udc64} = {\ud835\udc60#\u00bb\ud835\udc63 + \ud835\udc61#\u00bb\ud835\udc64 : \ud835\udc60, \ud835\udc61 \u2208 R}\nis a plane in R\ud835\udc5b through the origin with direction vectors #\u00bb\ud835\udc63 and #\u00bb\ud835\udc64.\nFigure 2.4.6: Plane \ud835\udcab = Span{#\u00bb\ud835\udc63 , #\u00bb\n\ud835\udc64} in gray.\nThree points on \ud835\udcab are illustrated: #\u00bb\ud835\udc5e = #\u00bb\ud835\udc63 + #\u00bb\n\ud835\udc64, #\u00bb\ud835\udc5f = 3#\u00bb\ud835\udc63 + #\u00bb\n\ud835\udc64 and #\u00bb\ud835\udc60 = \u22122#\u00bb\ud835\udc63 \u2212 #\u00bb\n\ud835\udc64.\nREMARKS\n\u2022 \ud835\udcab contains the points \ud835\udc49 and \ud835\udc4a, which are the terminal points associated with the\nvectors #\u00bb\ud835\udc63 and #\u00bb\ud835\udc64 respectively.\n\u2022 If a point \ud835\udc43 with associated vector #\u00bb\ud835\udc5d lies on the plane, then #\u00bb\ud835\udc5d = \ud835\udc60#\u00bb\ud835\udc63 + \ud835\udc61#\u00bb\ud835\udc64, for some\n\ud835\udc60, \ud835\udc61 \u2208 R.\n\u2022 Any plane defined by the span of two vectors must pass through the origin.\n\u2022 To form a plane, #\u00bb\ud835\udc63 , #\u00bb\ud835\udc64 must be non-zero vectors with #\u00bb\ud835\udc64 \u0338= \ud835\udc50#\u00bb\ud835\udc63 for any \ud835\udc50 \u2208 R. If exactly\none of #\u00bb\ud835\udc63 and #\u00bb\ud835\udc64 is #\u00bb0 , or if #\u00bb\ud835\udc64 = \ud835\udc50#\u00bb\ud835\udc63 for some \ud835\udc50 \u2208 R, then Span{#\u00bb\ud835\udc63 , #\u00bb\ud835\udc64} is a line, not a\nplane. If #\u00bb\ud835\udc63 = #\u00bb\ud835\udc64 = #\u00bb0 , then Span{#\u00bb\ud835\udc63 , #\u00bb\ud835\udc64} = #\u00bb0 ; this is not a plane, but rather a single\npoint, the origin.\nDefinition 2.4.2\nVector Equation of\na Plane in R\ud835\udc5b\nThrough the\nOrigin\nLet #\u00bb\ud835\udc63 , #\u00bb\ud835\udc64 be non-zero vectors in R\ud835\udc5b with #\u00bb\ud835\udc63 \u0338= \ud835\udc50#\u00bb\ud835\udc64 for any \ud835\udc50 \u2208 R. The expression\n#\u00bb\ud835\udc5d = \ud835\udc60#\u00bb\ud835\udc63 + \ud835\udc61#\u00bb\ud835\udc64\nis a vector equation of the plane in R\ud835\udc5b through the origin with direction vectors\n#\u00bb\ud835\udc63 and #\u00bb\ud835\udc64.Section 2.4\nThe Vector Equation of a Plane in R\ud835\udc5b\n41\nExample 2.4.3\nDetermine a vector equation of the plane in R3 through the origin with direction vectors\n\u23a1\n\u23a3\n2\n4\n6\n\u23a4\n\u23a6 and\n\u23a1\n\u23a3\n\u22121\n2\n\u22123\n\u23a4\n\u23a6.\nSolution: A vector equation of this plane is\n#\u00bb\ud835\udc5d = \ud835\udc60\n\u23a1\n\u23a3\n2\n4\n6\n\u23a4\n\u23a6 + \ud835\udc61\n\u23a1\n\u23a3\n\u22121\n2\n\u22123\n\u23a4\n\u23a6 , \ud835\udc60, \ud835\udc61 \u2208 R.\nNotice that the points (2, 4, 6) and (\u22121, 2, \u22123) are on this plane.\nExample 2.4.4\nGive a vector equation of the plane in R5 that passes through the origin with direction\nvectors\n[\ufe00\n5 4 3 2 1\n]\ufe00\ud835\udc47 and\n[\ufe00\n\u22125 4 \u22123 2 \u22121\n]\ufe00\ud835\udc47 .\nSolution: A vector equation of this plane is\n#\u00bb\ud835\udc5d = \ud835\udc60\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n5\n4\n3\n2\n1\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\n+ \ud835\udc61\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n\u22125\n4\n\u22123\n2\n\u22121\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\n, \ud835\udc60, \ud835\udc61 \u2208 R.\nNotice that the points (5, 4, 3, 2, 1) and (\u22125, 4, \u22123, 2, \u22121) in R5 are on this plane.\nDefinition 2.4.5\nPlane in R\ud835\udc5b\nLet #\u00bb\ud835\udc62 \u2208 R\ud835\udc5b and let #\u00bb\ud835\udc63 and #\u00bb\ud835\udc64 be non-zero vectors in R\ud835\udc5b with #\u00bb\ud835\udc63 \u0338= \ud835\udc50#\u00bb\ud835\udc64, for any \ud835\udc50 \u2208 R. Then\n\ud835\udcab = {#\u00bb\ud835\udc62 + \ud835\udc60#\u00bb\ud835\udc63 + \ud835\udc61#\u00bb\ud835\udc64 : \ud835\udc60, \ud835\udc61 \u2208 R}\nis a plane in R\ud835\udc5b through #\u00bb\ud835\udc62 with direction vectors #\u00bb\ud835\udc63 and #\u00bb\ud835\udc64. We say that #\u00bb\ud835\udc63 and #\u00bb\ud835\udc64\nare parallel to \ud835\udcab.\nREMARKS\n\u2022 Letting \ud835\udc60 = \ud835\udc61 = 0 gives us that the vector #\u00bb\ud835\udc62 is on the plane.\n\u2022 The plane passes through the terminal point \ud835\udc48 associated with #\u00bb\ud835\udc62. The other points\non the plane move from \ud835\udc48 in the #\u00bb\ud835\udc63 and the #\u00bb\ud835\udc64 directions by linear combinations of #\u00bb\ud835\udc63\nand #\u00bb\ud835\udc64.\n\u2022 The terminal points, \ud835\udc49 and \ud835\udc4a, associated with the vectors, #\u00bb\ud835\udc63 and #\u00bb\ud835\udc64, are not usually\non the plane. In fact, \ud835\udc49 is a point on the plane if and only if #\u00bb\ud835\udc62 \u2208 Span{#\u00bb\ud835\udc63 , #\u00bb\ud835\udc64}; that\nis, if and only if \ud835\udc48 lies on the plane through the origin that contains \ud835\udc49 and \ud835\udc4a.42\nChapter 2\nSpan, Lines and Planes\nExample 2.4.6\nSince the plane \u2133 =\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n0\n0\n1\n\u23a4\n\u23a6 + \ud835\udc60\n\u23a1\n\u23a3\n2\n4\n6\n\u23a4\n\u23a6 + \ud835\udc61\n\u23a1\n\u23a3\n\u22121\n2\n\u22123\n\u23a4\n\u23a6 : \ud835\udc60, \ud835\udc61 \u2208 R\n\u23ab\n\u23ac\n\u23ad has the same direction vectors\nas the plane \ud835\udcab =\n\u23a7\n\u23a8\n\u23a9\ud835\udc60\n\u23a1\n\u23a3\n2\n4\n6\n\u23a4\n\u23a6 + \ud835\udc61\n\u23a1\n\u23a3\n\u22121\n2\n\u22123\n\u23a4\n\u23a6 : \ud835\udc60, \ud835\udc61 \u2208 R\n\u23ab\n\u23ac\n\u23ad from Example 2.4.3, then \u2133 is parallel to\n\ud835\udcab. It can be shown that \u2133 does not pass through the origin.\nDefinition 2.4.7\nVector Equation of\na Plane\nLet #\u00bb\ud835\udc62 \u2208 R\ud835\udc5b and let #\u00bb\ud835\udc63 and #\u00bb\ud835\udc64 be non-zero vectors in R\ud835\udc5b with #\u00bb\ud835\udc63 \u0338= \ud835\udc50#\u00bb\ud835\udc64, for any \ud835\udc50 \u2208 R. Then\n#\u00bb\ud835\udc5d = #\u00bb\ud835\udc62 + \ud835\udc60#\u00bb\ud835\udc63 + \ud835\udc61#\u00bb\ud835\udc64,\n\ud835\udc60, \ud835\udc61 \u2208 R\nis a vector equation of the plane in R\ud835\udc5b through #\u00bb\ud835\udc62 with direction vectors #\u00bb\ud835\udc63 and\n#\u00bb\ud835\udc64.\nExample 2.4.8\nGive a vector equation of a plane in R3 which passes through the point (1, \u22124, 6), and has\nvectors\n\u23a1\n\u23a3\n2\n4\n6\n\u23a4\n\u23a6 and\n\u23a1\n\u23a3\n\u22121\n2\n\u22123\n\u23a4\n\u23a6 parallel to it.\nSolution: A vector equation of this plane is\n#\u00bb\ud835\udc5d =\n\u23a1\n\u23a3\n1\n\u22124\n6\n\u23a4\n\u23a6 + \ud835\udc60\n\u23a1\n\u23a3\n2\n4\n6\n\u23a4\n\u23a6 + \ud835\udc61\n\u23a1\n\u23a3\n\u22121\n2\n\u22123\n\u23a4\n\u23a6 , \ud835\udc60, \ud835\udc61 \u2208 R.\nNote that the points (2, 4, 6) and (\u22121, 2, \u22123) are not on this plane; however, the vectors\n\u23a1\n\u23a3\n2\n4\n6\n\u23a4\n\u23a6 and\n\u23a1\n\u23a3\n\u22121\n2\n\u22123\n\u23a4\n\u23a6 are parallel to this plane.\nFigure 2.4.7: Plane \ud835\udcab with equation #\u00bb\ud835\udc5d = #\u00bb\ud835\udc62 + \ud835\udc60#\u00bb\ud835\udc63 + \ud835\udc61#\u00bb\n\ud835\udc64 in gray.\nPlane \ud835\udcab includes #\u00bb\ud835\udc5e = #\u00bb\ud835\udc62 + #\u00bb\ud835\udc63 + #\u00bb\n\ud835\udc64 and #\u00bb\ud835\udc5f = #\u00bb\ud835\udc62 + 3#\u00bb\ud835\udc63 + #\u00bb\n\ud835\udc64 and #\u00bb\ud835\udc65 = #\u00bb\ud835\udc62 \u2212 2#\u00bb\ud835\udc63 \u2212 #\u00bb\n\ud835\udc64.Section 2.4\nThe Vector Equation of a Plane in R\ud835\udc5b\n43\nExample 2.4.9\nGive a vector equation of a plane \ud835\udcab in R5 that passes through the point (1, \u22124, 5, \u22122, 7)\nand has direction vectors\n[\ufe00\n2 4 6 8 10\n]\ufe00\ud835\udc47 and\n[\ufe00\n\u22121 2 \u22123 4 \u22125\n]\ufe00\ud835\udc47 .\nSolution: A vector equation of this plane is\n#\u00bb\ud835\udc5d =\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n1\n\u22124\n5\n\u22122\n7\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\n+ \ud835\udc60\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n2\n4\n6\n8\n10\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\n+ \ud835\udc61\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n\u22121\n2\n\u22123\n4\n\u22125\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\n, \ud835\udc60, \ud835\udc61 \u2208 R.\nNote that the points (2, 4, 6, 8, 10) and (\u22121, 2, \u22123, 4, \u22125) are not on \ud835\udcab. However, the vectors\n[\ufe00\n2 4 6 8 10\n]\ufe00\ud835\udc47 and\n[\ufe00\n\u22121 2 \u22123 4 \u22125\n]\ufe00\ud835\udc47 are parallel to \ud835\udcab.\nNoticing that\n[\ufe00\n2 4 6 8 10\n]\ufe00\ud835\udc47 = 2\n[\ufe00\n1 2 3 4 5\n]\ufe00\ud835\udc47 , a different vector equation for \ud835\udcab is\n#\u00bb\ud835\udc5d =\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n1\n\u22124\n5\n\u22122\n7\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\n+ \ud835\udc60\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n1\n2\n3\n4\n5\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\n+ \ud835\udc61\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n\u22121\n2\n\u22123\n4\n\u22125\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\n, \ud835\udc60, \ud835\udc61 \u2208 R.\nREMARK\nThere are many different vector equations that could be used to describe the same plane \ud835\udcab.\nEXERCISE\nDetermine two different vector equations for the plane #\u00bb\ud835\udc5d =\n\u23a1\n\u23a3\n0\n1\n0\n\u23a4\n\u23a6+\ud835\udc60\n\u23a1\n\u23a3\n1\n2\n3\n\u23a4\n\u23a6+\ud835\udc61\n\u23a1\n\u23a3\n1\n\u22121\n\u22121\n\u23a4\n\u23a6 , \ud835\udc60, \ud835\udc61 \u2208 R.\nWe can also uniquely define a plane using three points. Let \ud835\udc48, \ud835\udc44 and \ud835\udc45 be three non-colinear\npoints in R\ud835\udc5b (that is, three points which do not all lie on the same line), with associated\nvectors #\u00bb\ud835\udc62, #\u00bb\ud835\udc5e , and #\u00bb\ud835\udc5f , respectively. Suppose that we want the equation of the unique plane\ncontaining these three points. The vectors #\u00bb\ud835\udc63 = #\u00bb\ud835\udc5e \u2212 #\u00bb\ud835\udc62 and #\u00bb\ud835\udc64 = #\u00bb\ud835\udc5f \u2212 #\u00bb\ud835\udc62 are parallel to the\nplane, and thus, we can express the equation of the plane as\n\ud835\udcab = {#\u00bb\ud835\udc62 + \ud835\udc60(#\u00bb\ud835\udc5e \u2212 #\u00bb\ud835\udc62) + \ud835\udc61(#\u00bb\ud835\udc5f \u2212 #\u00bb\ud835\udc62) : \ud835\udc60, \ud835\udc61 \u2208 R}.\nExample 2.4.10\nFind a vector equation of a plane in R4 which contains the following points:\n\ud835\udc48 = (2, \u22124, 6, \u22128), \ud835\udc44 = (1, 3, \u22122, \u22124), and \ud835\udc45 = (9, 7, 5, 3).\nSolution: We need to determine two non-parallel direction vectors. We have:44\nChapter 2\nSpan, Lines and Planes\nFigure 2.4.8: Plane \ud835\udcab = {#\u00bb\ud835\udc62 + \ud835\udc60(#\u00bb\ud835\udc5e \u2212 #\u00bb\ud835\udc62) + \ud835\udc61(#\u00bb\ud835\udc5f \u2212 #\u00bb\ud835\udc62) : \ud835\udc60, \ud835\udc61 \u2208 R} in gray.\n#\u00bb\ud835\udc5e \u2212 #\u00bb\ud835\udc62 =\n\u23a1\n\u23a2\u23a2\u23a3\n1\n3\n\u22122\n\u22124\n\u23a4\n\u23a5\u23a5\u23a6 \u2212\n\u23a1\n\u23a2\u23a2\u23a3\n2\n\u22124\n6\n\u22128\n\u23a4\n\u23a5\u23a5\u23a6 =\n\u23a1\n\u23a2\u23a2\u23a3\n\u22121\n7\n\u22128\n4\n\u23a4\n\u23a5\u23a5\u23a6 and #\u00bb\ud835\udc5f \u2212 #\u00bb\ud835\udc62 =\n\u23a1\n\u23a2\u23a2\u23a3\n9\n7\n5\n3\n\u23a4\n\u23a5\u23a5\u23a6 \u2212\n\u23a1\n\u23a2\u23a2\u23a3\n2\n\u22124\n6\n\u22128\n\u23a4\n\u23a5\u23a5\u23a6 =\n\u23a1\n\u23a2\u23a2\u23a3\n7\n11\n\u22121\n11\n\u23a4\n\u23a5\u23a5\u23a6 .\nA vector equation of this plane is then\n#\u00bb\ud835\udc5d = #\u00bb\ud835\udc62 + \ud835\udc60(#\u00bb\ud835\udc5e \u2212 #\u00bb\ud835\udc62) + \ud835\udc61(#\u00bb\ud835\udc5f \u2212 #\u00bb\ud835\udc62) =\n\u23a1\n\u23a2\u23a2\u23a3\n2\n\u22124\n6\n\u22128\n\u23a4\n\u23a5\u23a5\u23a6 + \ud835\udc60\n\u23a1\n\u23a2\u23a2\u23a3\n\u22121\n7\n\u22128\n4\n\u23a4\n\u23a5\u23a5\u23a6 + \ud835\udc61\n\u23a1\n\u23a2\u23a2\u23a3\n7\n11\n\u22121\n11\n\u23a4\n\u23a5\u23a5\u23a6 ,\n\ud835\udc60, \ud835\udc61 \u2208 R.\n2.5", "Scalar Equation of a Plane in R3\nIn R3 (and only in R3!), there is an additional way to generate an equation of a plane, using\nthe cross product.\nLet #\u00bb\ud835\udc63 and #\u00bb\ud835\udc64 be non-zero vectors in R3 with #\u00bb\ud835\udc63 \u0338= \ud835\udc50#\u00bb\ud835\udc64, for any \ud835\udc50 \u2208 R.\nWe know that\nthe cross product, #\u00bb\ud835\udc5b = #\u00bb\ud835\udc63 \u00d7 #\u00bb\ud835\udc64, is orthogonal to any plane to which #\u00bb\ud835\udc63 and #\u00bb\ud835\udc64 are both\ndirection vectors. The vector #\u00bb\ud835\udc5b is referred to as a normal vector to such a plane. Suppose\nthat \ud835\udc48 and \ud835\udc43 are points on the plane, with associated vectors, #\u00bb\ud835\udc62 and #\u00bb\ud835\udc5d , respectively.\nThen the vector #\u00bb\ud835\udc5d \u2212 #\u00bb\ud835\udc62 is parallel to the plane and is therefore orthogonal to #\u00bb\ud835\udc5b; that is,\n#\u00bb\ud835\udc5b \u00b7 (#\u00bb\ud835\udc5d \u2212 #\u00bb\ud835\udc62) = (#\u00bb\ud835\udc63 \u00d7 #\u00bb\ud835\udc64) \u00b7 (#\u00bb\ud835\udc5d \u2212 #\u00bb\ud835\udc62) = 0.\nDefinition 2.5.1\nNormal Form,\nScalar Equation of\na Plane in R3\nLet \ud835\udcab be a plane in R3 with direction vectors #\u00bb\ud835\udc63 and #\u00bb\ud835\udc64 and a normal vector #\u00bb\ud835\udc5b =\n\u23a1\n\u23a3\n\ud835\udc4e\n\ud835\udc4f\n\ud835\udc50\n\u23a4\n\u23a6 \u0338= #\u00bb0 .\nLet #\u00bb\ud835\udc62 \u2208 \ud835\udcab and #\u00bb\ud835\udc5d =\n\u23a1\n\u23a3\n\ud835\udc65\n\ud835\udc66\n\ud835\udc67\n\u23a4\n\u23a6 \u2208 \ud835\udcab where #\u00bb\ud835\udc5d \u0338= #\u00bb\ud835\udc62. A normal form of \ud835\udcab is given by\n#\u00bb\ud835\udc5b \u00b7 (#\u00bb\ud835\udc5d \u2212 #\u00bb\ud835\udc62) = 0.\nExpanding this, we arrive at a scalar equation (or general form) of \ud835\udcab,\n\ud835\udc4e\ud835\udc65 + \ud835\udc4f\ud835\udc66 + \ud835\udc50\ud835\udc67 = \ud835\udc51,\nwhere \ud835\udc51 = #\u00bb\ud835\udc5b \u00b7 #\u00bb\ud835\udc62.Section 2.5\nScalar Equation of a Plane in R3\n45\nREMARK\nThe plane goes through the origin, \ud835\udc42\n\u2022 if and only if the vector #\u00bb0 satisfies this equation\n\u2022 if and only if (#\u00bb\ud835\udc63 \u00d7 #\u00bb\ud835\udc64) \u00b7 (#\u00bb0 \u2212 #\u00bb\ud835\udc62) = 0\n\u2022 if and only if #\u00bb\ud835\udc62 = \ud835\udc4e#\u00bb\ud835\udc63 + \ud835\udc4f#\u00bb\ud835\udc64, for some \ud835\udc4e, \ud835\udc4f \u2208 R.\nGeometrically, the plane goes through the origin if and only if both \ud835\udc49 and \ud835\udc4a lie on the\nplane.\nFigure 2.5.9: Let #\u00bb\ud835\udc5b = #\u00bb\ud835\udc63 \u00d7 #\u00bb\n\ud835\udc64. The plane in R3 with normal form (#\u00bb\ud835\udc63 \u00d7 #\u00bb\n\ud835\udc64) \u00b7 (#\u00bb\ud835\udc5d \u2212 #\u00bb\ud835\udc62) = 0 is in gray. It passes\nthrough #\u00bb\ud835\udc62 and has direction vectors #\u00bb\ud835\udc63 and #\u00bb\n\ud835\udc64.\nExample 2.5.2\nFind a scalar equation of the plane in R3 which passes through the origin and has direction\nvectors\n\u23a1\n\u23a3\n2\n4\n7\n\u23a4\n\u23a6 and\n\u23a1\n\u23a3\n\u22121\n2\n\u22123\n\u23a4\n\u23a6.\nSolution: Let #\u00bb\ud835\udc5b be a normal to the plane and let #\u00bb\ud835\udc5d =\n\u23a1\n\u23a3\n\ud835\udc65\n\ud835\udc66\n\ud835\udc67\n\u23a4\n\u23a6 be any vector on the plane.\nThen\n#\u00bb\ud835\udc5b =\n\u23a1\n\u23a3\n2\n4\n7\n\u23a4\n\u23a6 \u00d7\n\u23a1\n\u23a3\n\u22121\n2\n\u22123\n\u23a4\n\u23a6 =\n\u23a1\n\u23a3\n\u221226\n\u22121\n8\n\u23a4\n\u23a6 .\nA normal form of the plane (going through the origin) is thus given by\n\u23a1\n\u23a3\n\ud835\udc65\n\ud835\udc66\n\ud835\udc67\n\u23a4\n\u23a6 \u00b7\n\u23a1\n\u23a3\n\u221226\n\u22121\n8\n\u23a4\n\u23a6 = 0.\nExpanding this, we obtain a scalar equation of the plane\n\u221226\ud835\udc65 \u2212 \ud835\udc66 + 8\ud835\udc67 = 0.46\nChapter 2\nSpan, Lines and Planes\nNote that the two points (2, 4, 7) and (\u22121, 2, \u22123) lie on this plane.\nExample 2.5.3\nGive a scalar equation of the plane in R3 which passes through the point (1, \u22124, 3) and has\nthe two vectors\n\u23a1\n\u23a3\n2\n4\n7\n\u23a4\n\u23a6 and\n\u23a1\n\u23a3\n\u22121\n2\n\u22123\n\u23a4\n\u23a6 parallel to it.\nSolution: Let #\u00bb\ud835\udc5b be a normal to the plane and #\u00bb\ud835\udc5d =\n\u23a1\n\u23a3\n\ud835\udc65\n\ud835\udc66\n\ud835\udc67\n\u23a4\n\u23a6 be any vector on the plane.\n#\u00bb\ud835\udc5b =\n\u23a1\n\u23a3\n2\n4\n7\n\u23a4\n\u23a6 \u00d7\n\u23a1\n\u23a3\n\u22121\n2\n\u22123\n\u23a4\n\u23a6 =\n\u23a1\n\u23a3\n\u221226\n\u22121\n8\n\u23a4\n\u23a6 .\nA scalar equation of the plane (not going through the origin) is then given by\n\u239b\n\u239d\n\u23a1\n\u23a3\n\ud835\udc65\n\ud835\udc66\n\ud835\udc67\n\u23a4\n\u23a6 \u2212\n\u23a1\n\u23a3\n1\n\u22124\n3\n\u23a4\n\u23a6\n\u239e\n\u23a0 \u00b7\n\u23a1\n\u23a3\n\u221226\n\u22121\n8\n\u23a4\n\u23a6\n=\n0\n\u221226(\ud835\udc65 \u2212 1) \u2212 (\ud835\udc66 + 4) + 8(\ud835\udc67 \u2212 3)\n=\n0\n\u221226\ud835\udc65 \u2212 \ud835\udc66 + 8\ud835\udc67\n=\n2.\nNote that the two points (2, 4, 7) and (\u22121, 2, \u22123) do not lie on this plane.\nREMARKS\n1. Examining the definition of a scalar equation of a plane above, we see that the com-\nponents of a normal vector #\u00bb\ud835\udc5b =\n\u23a1\n\u23a3\n\ud835\udc4e\n\ud835\udc4f\n\ud835\udc50\n\u23a4\n\u23a6 are recorded as the coefficients of \ud835\udc65, \ud835\udc66, \ud835\udc67 in a\nscalar equation. We can use this information to quickly retrieve a normal form from\na scalar equation by identifying a single vector on the plane.\n2. We use the language \u201ca scalar equation\u201d, \u201ca normal vector\u201d, and \u201ca normal form\u201d of\na plane \ud835\udcab to emphasize that these are not unique.\n\u2022 Normal vectors of a plane are simply non-zero vectors that are orthogonal to\nany vector that is parallel to \ud835\udcab. If #\u00bb\ud835\udc5b is a normal vector of \ud835\udcab, then so is \ud835\udc50#\u00bb\ud835\udc5b for\nany non-zero scalar \ud835\udc50 \u2208 R, so \ud835\udcab does not have a unique normal vector (and thus\nnormal form). That said, all normal vectors of \ud835\udcab lie on the same line.\n\u2022 A scalar equation of a plane is an equation which all vectors of \ud835\udcab satisfy. We\nknow that multiplying an equation by a non-zero \ud835\udc50 \u2208 R does not change the\nsolution set to that equation, so \ud835\udcab does not have a unique scalar equation.Section 2.5\nScalar Equation of a Plane in R3\n47\nExample 2.5.4\nLet \ud835\udcab be a plane in R3 with scalar equation 2\ud835\udc65 \u2212 \ud835\udc66 + \ud835\udc67 = 7. Give a normal form of \ud835\udcab.\nSolution: From the scalar equation, we see that a normal vector of \ud835\udcab is #\u00bb\ud835\udc5b =\n\u23a1\n\u23a3\n2\n\u22121\n1\n\u23a4\n\u23a6. To\nidentify a vector on \ud835\udcab, we can pick any constants we want for exactly two of \ud835\udc65, \ud835\udc66, \ud835\udc67 and\nsolve for the third value. Taking \ud835\udc65 = \ud835\udc66 = 0, we have\n7 = 2(0) \u2212 0 + \ud835\udc67 = \ud835\udc67,\nso #\u00bb\ud835\udc62 =\n\u23a1\n\u23a3\n0\n0\n7\n\u23a4\n\u23a6 \u2208 \ud835\udcab. Therefore, a normal form of \ud835\udcab is\n\u23a1\n\u23a3\n2\n\u22121\n1\n\u23a4\n\u23a6 \u00b7\n\u239b\n\u239d\n\u23a1\n\u23a3\n\ud835\udc65\n\ud835\udc66\n\ud835\udc67\n\u23a4\n\u23a6 \u2212\n\u23a1\n\u23a3\n0\n0\n7\n\u23a4\n\u23a6\n\u239e\n\u23a0 = 0.Chapter 3\nSystems of Linear Equations\n3.1", "Introduction\nWe begin with some introductory examples in which linear systems of equations naturally\narise.\nExample 3.1.1\nAt the market, 3 watermelons and 7 kiwis cost $19 and 2 watermelons and 5 kiwis cost $13.\nHow much does a watermelon cost and how much does a kiwi cost?\nSolution: Let \ud835\udc64 denote the price of a watermelon and let \ud835\udc58 denote the price of a kiwi. We\nconvert the given information into a system of two equations.\n3\ud835\udc64 + 7\ud835\udc58 = 19\n(\ud835\udc521)\n2\ud835\udc64 + 5\ud835\udc58 = 13\n(\ud835\udc522)\nWe must find values for \ud835\udc64 and \ud835\udc58 that satisfy the equations (\ud835\udc521) and (\ud835\udc522) simultaneously.\nIf we multiply (\ud835\udc521) by 2 and subtract from that 3 times (\ud835\udc522), we obtain\n[2(3) \u2212 3(2)]\ud835\udc64 + [2(7) \u2212 3(5)]\ud835\udc58 = 2(19) \u2212 3(13).\nThat is, \u2212\ud835\udc58 = \u22121, which implies that \ud835\udc58 = 1.\nSubstituting this value for \ud835\udc58 into equation (\ud835\udc521) gives \ud835\udc64 = 19\u22127(1)\n3\n= 4.\nTherefore, the price of a watermelon is $4 and the price of a kiwi is $1.\nSubstituting these values into the two equations\n3(4) + 7(1) = 19\n2(4) + 5(1) = 13\nshows that they satisfy both equations.\nThe crucial step in solving this problem is that of taking the combination 2(\ud835\udc521) \u2212 3(\ud835\udc522).\nThis step is determined by looking at the coefficients of \ud835\udc64 in the two equations (\ud835\udc521) and\n(\ud835\udc522), which are 3 and 2, respectively. The combination of 2(\ud835\udc521) \u2212 3(\ud835\udc522) produces a new\nequation in which \ud835\udc64 has been eliminated. We then solve this new equation for the other\n48Section 3.2", "Systems of Linear Equations\n49\nvariable, \ud835\udc58. Once we have a value for \ud835\udc58, we then substitute it into one of the original two\nequations and solve for the value of the other variable, \ud835\udc64.\nAlternatively, we could have considered the combination 5(\ud835\udc521) \u2212 7(\ud835\udc522), to eliminate the\nvariable \ud835\udc58, and then solve for \ud835\udc64. We then could substitute its value into either equation,\n(\ud835\udc521) or (\ud835\udc522) in order to find the value of \ud835\udc58.\nExample 3.1.2\nFind the equation of the line that passes through the points (2, 3) and (\u22123, 4).\nSolution: The general equation of a line is \ud835\udc66 = \ud835\udc5a\ud835\udc65 + \ud835\udc4f. We must determine the values\nof the constants \ud835\udc5a and \ud835\udc4f. Since both points lie on the line, they must both satisfy the\nequation. Therefore,\n3 = 2\ud835\udc5a + \ud835\udc4f\nand\n4 = \u22123\ud835\udc5a + \ud835\udc4f.\nThus, we have a system with two equations and two variables, \ud835\udc5a and \ud835\udc4f:\n2\ud835\udc5a + \ud835\udc4f = 3\n\u22123\ud835\udc5a + \ud835\udc4f = 4\nWe will not solve this system now.\nExample 3.1.3\nDetermine whether the vector \u20d7\ud835\udc63 =\n\u23a1\n\u23a3\n1\n2\n3\n\u23a4\n\u23a6 lies in Span\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n\u22121\n2\n\u22123\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n1\n1\n1\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad .\nSolution: The vector \u20d7\ud835\udc63 will lie in the span of the two given vectors if, and only if, there\nexist scalars \ud835\udc4e, \ud835\udc4f \u2208 R, such that\n\u23a1\n\u23a3\n1\n2\n3\n\u23a4\n\u23a6 = \ud835\udc4e\n\u23a1\n\u23a3\n\u22121\n2\n\u22123\n\u23a4\n\u23a6 + \ud835\udc4f\n\u23a1\n\u23a3\n1\n1\n1\n\u23a4\n\u23a6 ,\nor equivalently\n1\n=\n\u22121\ud835\udc4e\n+\ud835\udc4f\n2\n=\n2\ud835\udc4e\n+\ud835\udc4f\n3\n=\n\u22123\ud835\udc4e\n+\ud835\udc4f\n.\nWe have a system with three equations and two variables. We will not solve this system\nnow.\n3.2\nSystems of Linear Equations\nDefinition 3.2.1\nLinear Equation,\nCoefficient,\nConstant Term\nA linear equation in \ud835\udc5b variables (or unknowns) \ud835\udc651, \ud835\udc652, . . . , \ud835\udc65\ud835\udc5b is an equation that can\nbe written in the form \ud835\udc4e1\ud835\udc651 + \ud835\udc4e2\ud835\udc652 + \u00b7 \u00b7 \u00b7 + \ud835\udc4e\ud835\udc5b\ud835\udc65\ud835\udc5b = \ud835\udc4f, where \ud835\udc4e1, \ud835\udc4e2, . . . , \ud835\udc4e\ud835\udc5b, \ud835\udc4f \u2208 F.\nThe\nscalars \ud835\udc4e1, \ud835\udc4e2, . . . , \ud835\udc4e\ud835\udc5b are the coefficients of \ud835\udc651, \ud835\udc652, . . . , \ud835\udc65\ud835\udc5b, respectively, and \ud835\udc4f is called the\nconstant term.50\nChapter 3\nSystems of Linear Equations\nDefinition 3.2.2\nSystem of Linear\nEquations\nA system of linear equations is a collection of \ud835\udc5a linear equations in \ud835\udc5b variables,\n\ud835\udc651, . . . , \ud835\udc65\ud835\udc5b:\n\ud835\udc4e11\ud835\udc651\n+\ud835\udc4e12\ud835\udc652\n+\n\u00b7 \u00b7 \u00b7\n+\ud835\udc4e1\ud835\udc5b\ud835\udc65\ud835\udc5b\n=\n\ud835\udc4f1\n\ud835\udc4e21\ud835\udc651\n+\ud835\udc4e22\ud835\udc652\n+\n\u00b7 \u00b7 \u00b7\n+\ud835\udc4e2\ud835\udc5b\ud835\udc65\ud835\udc5b\n=\n\ud835\udc4f2\n...\n\ud835\udc4e\ud835\udc5a1\ud835\udc651\n+\ud835\udc4e\ud835\udc5a2\ud835\udc652\n+\n\u00b7 \u00b7 \u00b7\n+\ud835\udc4e\ud835\udc5a\ud835\udc5b\ud835\udc65\ud835\udc5b\n=\n\ud835\udc4f\ud835\udc5a\nWe will use the convention that \ud835\udc4e\ud835\udc56\ud835\udc57 is the coefficient of \ud835\udc65\ud835\udc57 in the \ud835\udc56\ud835\udc61\u210e equation.\nDefinition 3.2.3\nSolve, Solution\nWe say that the scalars \ud835\udc661, \ud835\udc662, . . . , \ud835\udc66\ud835\udc5b in F solve a system of linear equations if, when we\nset \ud835\udc651 = \ud835\udc661, \ud835\udc652 = \ud835\udc662, . . . , \ud835\udc65\ud835\udc5b = \ud835\udc66\ud835\udc5b in the system, then each of the equations is satisfied:\n\ud835\udc4e11\ud835\udc661\n+\ud835\udc4e12\ud835\udc662\n+\n\u00b7 \u00b7 \u00b7\n+\ud835\udc4e1\ud835\udc5b\ud835\udc66\ud835\udc5b\n=\n\ud835\udc4f1\n\ud835\udc4e21\ud835\udc661\n+\ud835\udc4e22\ud835\udc662\n+\n\u00b7 \u00b7 \u00b7\n+\ud835\udc4e2\ud835\udc5b\ud835\udc66\ud835\udc5b\n=\n\ud835\udc4f2\n...\n\ud835\udc4e\ud835\udc5a1\ud835\udc661\n+\ud835\udc4e\ud835\udc5a2\ud835\udc662\n+\n\u00b7 \u00b7 \u00b7\n+\ud835\udc4e\ud835\udc5a\ud835\udc5b\ud835\udc66\ud835\udc5b\n=\n\ud835\udc4f\ud835\udc5a\nWe also say that the vector \u20d7\ud835\udc66 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc661\n\ud835\udc662\n...\n\ud835\udc66\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 is a solution to the system.\nNote that if at least one equation in the system of linear equations is not satisfied by the\nentries in #\u00bb\ud835\udc66 , then #\u00bb\ud835\udc66 is not a solution.\nExample 3.2.4\nConsider the following system of linear equations:\n\ud835\udc651\n\u22122\ud835\udc652\n+3\ud835\udc653\n=\n1\n2\ud835\udc651\n\u22124\ud835\udc652\n+6\ud835\udc653\n=\n2\n3\ud835\udc651\n\u2212\ud835\udc652\n+\ud835\udc653\n=\n3\n.\nThe vector\n\u23a1\n\u23a3\n1\n0\n0\n\u23a4\n\u23a6 is a solution, as\n1(1) \u2212 2(0) + 3(0) = 1\n2(1) \u2212 4(0) + 6(0) = 2\n3(1) \u2212 1(0) + 1(0) = 3\n.\nHowever,\n\u23a1\n\u23a3\n\u22122\n0\n1\n\u23a4\n\u23a6 is not a solution, because even though 1(\u22122) \u2212 2(0) + 3(1) = 1 and\n2(\u22122) \u2212 4(0) + 6(1) = 2, we have that 3(\u22122) \u2212 1(0) + 1(1) = \u22125 \u0338= 3.Section 3.2\nSystems of Linear Equations\n51\nDefinition 3.2.5\nSolution Set\nThe set of all solutions to a system of linear equations is called the solution set to the\nsystem.\nExample 3.2.6\nSolve 2\ud835\udc65 = 4. That is, find the solution set to this system of linear equations (a system\nwith one equation).\nSolution: The solution to this equation is \ud835\udc65 = 2 and thus, the solution set \ud835\udc46 is {2}. We\ncan verify that 2(2) = 4.\nExample 3.2.7\nSolve 2\ud835\udc65 + 4\ud835\udc66 = 6.\nSolution: We have only one equation for the two unknowns, \ud835\udc65 and \ud835\udc66. There will be an\ninfinite number of solutions to this equation. Indeed, given any real number \ud835\udc66, we can solve\nfor \ud835\udc65 to obtain \ud835\udc65 = 3 \u2212 2\ud835\udc66.\nIn this way we see that \ud835\udc65 depends on \ud835\udc66, but that \ud835\udc66 can be freely chosen to be any real\nnumber. We emphasize this point by writing \ud835\udc66 = \ud835\udc61, where the variable \ud835\udc61 \u2208 R is called a\nparameter. Then \ud835\udc65 = 3 \u2212 2\ud835\udc61, and therefore the solution set, \ud835\udc46, can be expressed as\n\ud835\udc46 =\n{\ufe02[\ufe023 \u2212 2\ud835\udc61\n\ud835\udc61\n]\ufe02\n: \ud835\udc61 \u2208 R\n}\ufe02\n.\nWe can verify our solution by setting \ud835\udc66 = \ud835\udc61 and \ud835\udc65 = 3 \u2212 2\ud835\udc61:\n2\ud835\udc65 + 4\ud835\udc66 = 2(3 \u2212 2\ud835\udc61) + 4\ud835\udc61 = 6 \u2212 4\ud835\udc61 + 4\ud835\udc61 = 6,\nwhich is the right-hand side of the equation.\nNote that declaring \ud835\udc66 = \ud835\udc61 as our parameter was an arbitrary choice. We could have just\nas well let \ud835\udc65 = \ud835\udc61 and solved for \ud835\udc66 in terms of \ud835\udc61. The important property to note is that a\nparameter was needed to describe the solution set \ud835\udc46.\nExample 3.2.8\nSolve the system of linear equations\n2\ud835\udc65 + 3\ud835\udc66 = 4\n2\ud835\udc65 + 3\ud835\udc66 = 5\nSolution: Since both equations have identical left-hand sides, but different right-hand\nsides, it will be impossible to find values for \ud835\udc65 and \ud835\udc66 that satisfy both of these equations.\nTherefore, the solutions set is \ud835\udc46 = \u2205.\nTheorem 3.2.9\n(The Solution Set to a System of Linear Equations)\nThe solution set to a system of linear equations is exactly one of the following:\n(a) empty (there are no solutions),\n(b) contains exactly one element (there is a unique solution), or\n(c) contains an infinite number of elements (the solution set has one or more parameters).52\nChapter 3\nSystems of Linear Equations\nWe have given examples above to illustrate these three outcomes. However, at this time,\nwe will not give a proof of this result.\nDefinition 3.2.10\nInconsistent and\nConsistent Systems\nIf the solution set to a system of linear equations is empty, then we say that the system is\ninconsistent.\nIf the solution set has a unique solution or infinitely many solutions, then we say that the\nsystem is consistent.\nExample 3.2.11\nSolve the system \ud835\udc65 = 1\n\ud835\udc65 = 2 .\nSolution: There is no solution and \ud835\udc46 = \u2205. This system is inconsistent.\nExample 3.2.12\nSolve the system \ud835\udc65 + \ud835\udc66 = 2\n\ud835\udc65 \u2212 \ud835\udc66 = 4 .\nSolution: There is a unique solution, \ud835\udc65 = 3 and \ud835\udc66 = \u22121. Therefore, \ud835\udc46 =\n{\ufe02[\ufe02 3\n\u22121\n]\ufe02}\ufe02\n. This\nsystem is consistent.\nExample 3.2.13\nSolve the system \ud835\udc65 + \ud835\udc66 = 1.\nSolution: Let \ud835\udc66 = \ud835\udc61, where \ud835\udc61 \u2208 R. Therefore, \ud835\udc65 = 1\u2212\ud835\udc61. We obtain infinitely many solutions\nand \ud835\udc46 =\n{\ufe02[\ufe021 \u2212 \ud835\udc61\n\ud835\udc61\n]\ufe02\n: \ud835\udc61 \u2208 R\n}\ufe02\n. This system is consistent.\nNote that if we had let \ud835\udc65 = \ud835\udc61, where \ud835\udc61 \u2208 R, we would obtain \ud835\udc66 = 1 \u2212 \ud835\udc61, and\n\ud835\udc46 =\n{\ufe02[\ufe02\n\ud835\udc61\n1 \u2212 \ud835\udc61\n]\ufe02\n: \ud835\udc61 \u2208 R\n}\ufe02\n.\nThese are two different representations of the same set \ud835\udc46. Generally there will be many\ndifferent ways of expressing any given set.\nIt is usually not obvious whether a system is inconsistent, will have a unique solution, or\nwill have infinitely many solutions. The key idea to solving a system of equations is to\nmanipulate the system into another system of equations which is easier to solve and has\nthe same solution set as the original system.\nDefinition 3.2.14\nEquivalent Systems\nWe say that two linear systems are equivalent whenever they have the same solution set.\nGiven a system of linear equations, we will manipulate it into equivalent systems and we\nwill stop once we have obtained an equivalent system whose solution set is easily obtained.\nThe question then becomes: what manipulations can we do to a system which will produce\nan equivalent system?Section 3.2\nSystems of Linear Equations\n53\nExample 3.2.15\nConsider the system\n\ud835\udc65\n+\ud835\udc66\n=\n1\n2\ud835\udc65\n+3\ud835\udc66\n=\n6 . If we multiply the first equation by zero, we get a\nnew system:\n0 = 0\n2\ud835\udc65 + 3\ud835\udc66 = 6\nThis system is not equivalent to the original system. For example, \ud835\udc65 = 3 and \ud835\udc66 = 0 is a\nsolution to the new system, but it is not a solution to the original system. We have lost\ninformation by multiplying the first equation by zero.\nExample 3.2.16\nConsider the system\n\ud835\udc65\n+\ud835\udc66\n+\ud835\udc67\n=\n3\n2\ud835\udc65\n+3\ud835\udc66\n\u22122\ud835\udc67\n=\n3\nWe could add an additional equation to get a new system.\n\ud835\udc65\n+\ud835\udc66\n+\ud835\udc67\n=\n3\n2\ud835\udc65\n+3\ud835\udc66\n\u22122\ud835\udc67\n=\n3\n\ud835\udc65\n+2\ud835\udc66\n\u22123\ud835\udc67\n=\n5\nThis new system is not equivalent to the old one. For example, \ud835\udc65 = 1, \ud835\udc66 = 1, \ud835\udc67 = 1 is a\nsolution to the original system, but it is not a solution to the new system. We have added\nan extra restriction on the variables by adding in this new equation. When manipulating a\nsystem, we must be careful that we neither lose information nor add information.\nDefinition 3.2.17\nElementary\nOperations\nConsider a system of \ud835\udc5a linear equations in \ud835\udc5b variables. The equations are ordered and\nlabelled from \ud835\udc521 to \ud835\udc52\ud835\udc5a. The following three operations are known as elementary opera-\ntions.\nEquation swap elementary operation: interchange two equations.\n\ud835\udc52\ud835\udc56 \u2194 \ud835\udc52\ud835\udc57\nInterchange equations \ud835\udc52\ud835\udc56 and \ud835\udc52\ud835\udc57.\nEquation scale elementary operation: multiply one equation by a non-zero con-\nstant.\n\ud835\udc52\ud835\udc56 \u2192 \ud835\udc5a\ud835\udc52\ud835\udc56, \ud835\udc5a \u2208 F\u2216{0}\nReplace equation \ud835\udc52\ud835\udc56 by \ud835\udc5a times equation \ud835\udc52\ud835\udc56.\nEquation addition elementary operation: add a multiple of one equation to another\nequation.\n\ud835\udc52\ud835\udc57 \u2192 \ud835\udc50\ud835\udc52\ud835\udc56 + \ud835\udc52\ud835\udc57\n\ud835\udc56 \u0338= \ud835\udc57, \ud835\udc50 \u2208 F\n}\ufe03\nReplace equation \ud835\udc52\ud835\udc57 by adding \ud835\udc52\ud835\udc57 and a multiple of equation \ud835\udc52\ud835\udc56.\nSome sources refer to these operations as Type I, Type II, and Type III operations,\nrespectively.\nWhen performing a series of elementary operations, we will use the convention that \ud835\udc52\ud835\udc56 and\n\ud835\udc52\ud835\udc57 refer to the current system we are working with. Therefore, \ud835\udc52\ud835\udc56 and \ud835\udc52\ud835\udc57 will change as the\nsystem is manipulated.54\nChapter 3\nSystems of Linear Equations\nTheorem 3.2.18\n(Elementary Operations)\nIf a single elementary operation of any type is performed on a system of linear equations,\nthen the system produced will be equivalent to the original system.\nIn practice, there might be other operations that we want to perform. These operations will\nnot be elementary operations, instead they will be combinations of elementary operations.\nFor example,\n\ud835\udc52\ud835\udc57 \u2192 \ud835\udc50\ud835\udc52\ud835\udc56 \u2212 \ud835\udc52\ud835\udc57\nis not an elementary operation, but rather it is a combination of two elementary operations.\nCan you determine which ones?\nUsing these operations will still produce an equivalent system, but they will cause confusion\nlater. Therefore, when manipulating a system of equations, we will make use of the three\nelementary operations only.\nNote that if at any point we produce an equation of the form\n0 = \ud835\udc4e, where \ud835\udc4e \u0338= 0,\nthen the system is inconsistent and we stop at once.\nDefinition 3.2.19\nTrivial Equation\nWe refer to the equation 0 = 0 as the trivial equation. Any other equation is known as a\nnon-trivial equation.\nThe trivial equation is always true and it has no information content.\nIf at any point\nwhen performing elementary operations we produce the trivial equation, then we move this\nequation to the end of the system, by performing an equation swap elementary operation.\nWe might be tempted to ignore such equations and not write them down. In practice, we\nkeep any (there may be more than one) equations of this form in our new system, so that\nwe will always have the same number of equations in any of the equivalent systems.\nThe goal of performing elementary operations is to obtain a system whose solution set is\neasier to determine. Let us refer to this system as our \u201cfinal equivalent system.\u201d The final\nequivalent system is not unique and depends on the sequence of elementary operations used.\nExample 3.2.20\nSolve the following system of three linear equations in three unknowns:\n\u22122\ud835\udc651\n\u22124\ud835\udc652\n\u22126\ud835\udc653\n=\n4\n3\ud835\udc651\n+6\ud835\udc652\n+10\ud835\udc653\n=\n6\n\ud835\udc652\n+2\ud835\udc653\n=\n5\n.\nSolution: Suppose that we perform the elementary operation\n\ud835\udc521 \u2192 \u22121\n2\ud835\udc521\nto get the new system\n\ud835\udc651\n+2\ud835\udc652\n+3\ud835\udc653\n=\n\u22122\n3\ud835\udc651\n+6\ud835\udc652\n+10\ud835\udc653\n=\n6\n\ud835\udc652\n+2\ud835\udc653\n=\n5\n.Section 3.3", "An Approach to Solving Systems of Linear Equations\n55\nWe will now make use of this new equation \ud835\udc521 to remove the \ud835\udc651 term from \ud835\udc522.\n\ud835\udc522 \u2192 \u22123\ud835\udc521 + \ud835\udc522\ngives\n\ud835\udc651\n+2\ud835\udc652\n+3\ud835\udc653\n=\n\u22122\n\ud835\udc653\n=\n12\n\ud835\udc652\n+2\ud835\udc653\n=\n5\nThis could be our final equivalent system. From \ud835\udc522 we obtain that \ud835\udc653 = 12. We could make\nuse of this fact and \ud835\udc523 to get \ud835\udc652 + 2(12) = 5, so that \ud835\udc652 = \u221219. We can put the values for\n\ud835\udc652 and \ud835\udc653 into \ud835\udc521 to get \ud835\udc651 + 2(\u221219) + 3(12) = \u22122, so that \ud835\udc651 = 0.\nHowever, instead of doing these substitutions, we may wish to continue applying elementary\noperations. We perform the operation\n\ud835\udc522 \u2194 \ud835\udc523 to get\n\ud835\udc651\n+2\ud835\udc652\n+3\ud835\udc653\n=\n\u22122\n\ud835\udc652\n+2\ud835\udc653\n=\n5\n\ud835\udc653\n=\n12\n.\nThen we perform\n\ud835\udc522 \u2192 \u22122\ud835\udc523 + \ud835\udc522\nto get\n\ud835\udc651\n+2\ud835\udc652\n+3\ud835\udc653\n=\n\u22122\n\ud835\udc652\n=\n\u221219\n\ud835\udc653\n=\n12\n,\n\ud835\udc521 \u2192 \u22123\ud835\udc523 + \ud835\udc521\nto get\n\ud835\udc651\n+2\ud835\udc652\n=\n\u221238\n\ud835\udc652\n=\n\u221219\n\ud835\udc653\n=\n12\n,\n\ud835\udc521 \u2192 \u22122\ud835\udc522 + \ud835\udc521\nto finally get\n\ud835\udc651\n=\n0\n\ud835\udc652\n=\n\u221219\n\ud835\udc653\n=\n12\n.\nThis is our final equivalent system, and its solution set is\n\ud835\udc46 =\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n0\n\u221219\n12\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad .\nIt is clear from this example that there will be plenty of choices on which elementary\noperations to apply at any stage and also that there will be choices as to when we will stop\nat our final equivalent system. There is no \u201cbest\u201d final equivalent system. However, there\nare two particular forms that are preferable for the final equivalent system. We will attempt\nto motivate these two forms and discuss how they can be obtained.\n3.3\nAn Approach to Solving Systems of Linear Equations\nLet us consider a system of \ud835\udc5a linear equations and \ud835\udc5b unknowns. We normally try to solve\nfor the variables of the system in the alphabetical or numerical order in which they appear.\nLet us assume that the variables are labelled \ud835\udc651, \ud835\udc652, . . . , \ud835\udc65\ud835\udc5b. We assume that there is at least\none equation with the variable \ud835\udc651 appearing in it with a non-zero coefficient (by relabeling\nthe variables, if necessary).56\nChapter 3\nSystems of Linear Equations\nWe would like the first equation to tell us about the first variable, \ud835\udc651, so that it is of the\nform\n\ud835\udc4e1\ud835\udc651 + \u00b7 \u00b7 \u00b7 = \ud835\udc4f1,\nwith \ud835\udc4e1 \u0338= 0. We will make use of the first equation to remove the variable \ud835\udc651 from all\nthe other equations after the first equation by performing equation addition elementary\noperations.\nWe would like the second equation to tell us about the next variable that can be obtained.\nCall this \ud835\udc65\ud835\udc56. Often this would be the variable \ud835\udc652, so that \ud835\udc56 = 2, but this is not always the\ncase. The (new) second equation has the form\n\ud835\udc4e\ud835\udc56\ud835\udc65\ud835\udc56 + \u00b7 \u00b7 \u00b7 = \ud835\udc4f2,\nwith \ud835\udc4e\ud835\udc56 \u0338= 0. We will make use of the second equation to remove the variable \ud835\udc65\ud835\udc56 from all\nthe other equations after the second equation by performing equation addition elementary\noperations.\nWe repeat this process, moving down through the equations, performing equation swap and\nequation addition elementary operations as needed. We also move any trivial equations to\nthe end of the system.\nWe assume that the \ud835\udc5f\ud835\udc61\u210e equation is the last non-trivial equation. (It is possible that \ud835\udc5f is\nequal to \ud835\udc5a.) We also assume that this equation tells us about the \ud835\udc58\ud835\udc61\u210e variable, \ud835\udc65\ud835\udc58. Note\nthat this equation should not involve the variables which were removed from the preceding\nequations by the process above. (\ud835\udc651 from equation 1, \ud835\udc65\ud835\udc56 from equation 2, etc.) Therefore,\nwe have an equation of the form\n\ud835\udc4e\ud835\udc58\ud835\udc65\ud835\udc58 + \u00b7 \u00b7 \u00b7 = \ud835\udc4f\ud835\udc5f,\nwith \ud835\udc4e\ud835\udc58 \u0338= 0.\nWe illustrate the process up to this point with the following example.\nExample 3.3.1\nSolve the following system of five linear equations in four unknowns:\n\ud835\udc651\n+2\ud835\udc652\n=\n1\n\ud835\udc651\n+2\ud835\udc652\n+3\ud835\udc653\n+\ud835\udc654\n=\n0\n\u2212\ud835\udc651\n\u2212\ud835\udc652\n+\ud835\udc653\n+\ud835\udc654\n=\n\u22122\n\ud835\udc652\n+\ud835\udc653\n+\ud835\udc654\n=\n\u22121\n\u2212\ud835\udc652\n+2\ud835\udc653\n=\n0\n.\nSolution: We will apply elementary operations, usually just one or two at a time. At each\nstage, we will produce an equivalent system. We will stop the process when we produce an\nequivalent system whose solution set is relatively easily obtained.\nWe notice that \ud835\udc521 has \ud835\udc651 in it and we will use it to eliminate the variable \ud835\udc651 from all the\nequations below it. (If \ud835\udc521 did not have any \ud835\udc651 terms, then we would have switched it with\none that did.)\nWe perform the elementary operations\n\ud835\udc522 \u2192 \u2212\ud835\udc521 + \ud835\udc522\n\ud835\udc523 \u2192 \ud835\udc521 + \ud835\udc523Section 3.3\nAn Approach to Solving Systems of Linear Equations\n57\nWe notice that \ud835\udc524 and \ud835\udc525 do not contain \ud835\udc651 and so they are not modified at this stage. We\nget\n\ud835\udc651\n+2\ud835\udc652\n=\n1\n3\ud835\udc653\n+\ud835\udc654\n=\n\u22121\n\ud835\udc652\n+\ud835\udc653\n+\ud835\udc654\n=\n\u22121\n\ud835\udc652\n+\ud835\udc653\n+\ud835\udc654\n=\n\u22121\n\u2212\ud835\udc652\n+2\ud835\udc653\n=\n0\n.\nWe notice that \ud835\udc522 does not have an \ud835\udc652 variable, but \ud835\udc523 does. Therefore, we perform the\nelementary operation\n\ud835\udc522 \u2194 \ud835\udc523\nto get\n\ud835\udc651\n+2\ud835\udc652\n=\n1\n\ud835\udc652\n+\ud835\udc653\n+\ud835\udc654\n=\n\u22121\n3\ud835\udc653\n+\ud835\udc654\n=\n\u22121\n\ud835\udc652\n+\ud835\udc653\n+\ud835\udc654\n=\n\u22121\n\u2212\ud835\udc652\n+2\ud835\udc653\n=\n0\n.\nThere is an \ud835\udc652 in \ud835\udc522 and we can make use of this fact to remove the variable \ud835\udc652 from the\nequations below it.\nPerforming the elementary operations\n\ud835\udc524 \u2192 \u2212\ud835\udc522 + \ud835\udc524\n\ud835\udc525 \u2192 \ud835\udc522 + \ud835\udc525\nyields\n\ud835\udc651\n+2\ud835\udc652\n=\n1\n\ud835\udc652\n+\ud835\udc653\n+\ud835\udc654\n=\n\u22121\n3\ud835\udc653\n+\ud835\udc654\n=\n\u22121\n0\n=\n0\n3\ud835\udc653\n+\ud835\udc654\n=\n\u22121\n.\nThere is an \ud835\udc653 in \ud835\udc523 and we make use of this fact to remove \ud835\udc653 from all the equations below\nit. In this case, we need only perform\n\ud835\udc525 \u2192 \u2212\ud835\udc523 + \ud835\udc525\nto obtain\n\ud835\udc651\n+2\ud835\udc652\n=\n1\n\ud835\udc652\n+\ud835\udc653\n+\ud835\udc654\n=\n\u22121\n3\ud835\udc653\n+\ud835\udc654\n=\n\u22121\n0\n=\n0\n0\n=\n0\n.\nNotice that the two trivial equations are at the end.\nAt this point in the process, the form of the equivalent system of equations has a particularly\nsimple appearance. We may choose to stop performing elementary operations at this point,\nand so this would be our final equivalent system.\nNote that a different sequence of elementary operations could produce a different final58\nChapter 3\nSystems of Linear Equations\nequivalent system of a similar form. For example, a final equivalent system could involve\nthe equation 6\ud835\udc653 + 2\ud835\udc654 = \u22122.\nProceeding from the original system to the final equivalent system in this form is known as\nthe forward elimination phase.\nOnce we have a final equivalent system in this form, we can obtain the solution set using a\nprocess known as back substitution. We use the information given in the \ud835\udc5f\ud835\udc61\u210e equation for\nthe variable \ud835\udc65\ud835\udc58 to then back substitute for the variable \ud835\udc65\ud835\udc58 into all the previous equations\nin our final equivalent system. Then we repeat this process moving back up the system.\nOur last step is to use the information given in the second equation for the variable \ud835\udc65\ud835\udc56 to\nback substitute for the variable \ud835\udc65\ud835\udc56 into the first equation (if it appears there).\nLet us return to our example.\nExample 3.3.1\nOur final equivalent system was\n\ud835\udc651\n+2\ud835\udc652\n=\n1\n\ud835\udc652\n+\ud835\udc653\n+\ud835\udc654\n=\n\u22121\n3\ud835\udc653\n+\ud835\udc654\n=\n\u22121\n0\n=\n0\n0\n=\n0\n.\nWe have completed the forward elimination phase and this system is a good choice for a\nfinal equivalent system. It will have the same solution set as the original system and we\ncan obtain its solution by back substitution.\nWe notice that \ud835\udc524 and \ud835\udc525 are trivial equations and do not give us any information. We also\nnotice that \ud835\udc523 gives us a relationship between variables \ud835\udc653 and \ud835\udc654. One of these variables\ncan arbitrarily be assigned any real value and the value of the other variable will depend\non this arbitrary value.\nWe will choose to assign \ud835\udc654 any real value and to emphasize this fact we will let \ud835\udc654 = \ud835\udc61,\nwhere \ud835\udc61 \u2208 R.\nTherefore, \ud835\udc523 tells us that\n\ud835\udc653 = 1\n3(\u22121 \u2212 \ud835\udc61).\nThen \ud835\udc522 tells us that\n\ud835\udc652 = \u22121 \u2212 \ud835\udc653 \u2212 \ud835\udc654 = \u22121 \u2212 1\n3(\u22121 \u2212 \ud835\udc61) \u2212 \ud835\udc61 = \u22122\n3 \u2212 2\ud835\udc61\n3 .\nThen \ud835\udc521 tells us that\n\ud835\udc651 = 1 \u2212 2\ud835\udc652 = 1 \u2212 2\n(\ufe02\n\u22122\n3 \u2212 2\ud835\udc61\n3\n)\ufe02\n= 7\n3 + 4\ud835\udc61\n3 .\nTherefore, the solution set is\n\ud835\udc46 =\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n7\n3 + 4\n3\ud835\udc61\n\u2212 2\n3 \u2212 2\n3\ud835\udc61\n\u2212 1\n3 \u2212 1\n3\ud835\udc61\n\ud835\udc61\n\u23a4\n\u23a5\u23a5\u23a6 : \ud835\udc61 \u2208 R\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n=\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n7\n3\n\u2212 2\n3\n\u2212 1\n3\n0\n\u23a4\n\u23a5\u23a5\u23a6 + \ud835\udc61\n\u23a1\n\u23a2\u23a2\u23a3\n4\n3\n\u2212 2\n3\n\u2212 1\n3\n1\n\u23a4\n\u23a5\u23a5\u23a6 : \ud835\udc61 \u2208 R\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n.Section 3.3\nAn Approach to Solving Systems of Linear Equations\n59\nAn alternative way to proceed, instead of performing back substitution, is to continue to\nsimplify the system. The following extension yields a unique final equivalent system, which\nis particularly simple.\nFirst, using equation scale elementary operations, scale each of the non-trivial equations of\nthe current system. Scale the first equation by the factor\n1\n\ud835\udc4e1 , the second equation by the\nfactor\n1\n\ud835\udc4e\ud835\udc56 and so on, scaling the \ud835\udc5f\ud835\udc61\u210e equation by the factor\n1\n\ud835\udc4e\ud835\udc58 .\nUsing the \ud835\udc5f\ud835\udc61\u210e equation and equation addition elementary operations, we eliminate the vari-\nable \ud835\udc65\ud835\udc58 from all the equations above it. We then examine the (\ud835\udc5f \u2212 1)\ud835\udc60\ud835\udc61 equation, which will\nbe of the form\n\ud835\udc65\ud835\udc57 + \u00b7 \u00b7 \u00b7 = \ud835\udc4f\ud835\udc5f\u22121,\nfor some natural number \ud835\udc57 < \ud835\udc58. Using this equation and equation addition elementary\noperations, we eliminate the variable \ud835\udc65\ud835\udc57 from all the equations above it.\nWe repeat this process, moving up through the equations, and performing equation addition\nelementary operations to eliminate variables. The process ends when we use the second\nequation to eliminate the variable \ud835\udc65\ud835\udc56 from the first equation.\nThese additional steps, performed after the end of the forward elimination phase, are collec-\ntively known as the backward elimination phase. When we are performing these steps\nwe say that we are doing backward elimination.\nFor a given system, there are many different possibilities for the equivalent system after\ndoing forward elimination, depending on the particular elementary operations used. How-\never, regardless of the elementary operations used, the same final equivalent system will\nbe obtained after performing both forward and backward elimination. We will formally\nestablish this result in Theorem 3.5.8 (Unique RREF).\nOnce again we return to our example.\nExample 3.3.1\nOur final equivalent system after the forward elimination phase was\n\ud835\udc651\n+2\ud835\udc652\n=\n1\n\ud835\udc652\n+\ud835\udc653\n+\ud835\udc654\n=\n\u22121\n3\ud835\udc653\n+\ud835\udc654\n=\n\u22121\n0\n=\n0\n0\n=\n0\nand instead of using back substitution, we continue performing elementary operations.\nWe observe that the last two equations are trivial equations and \ud835\udc523 is in terms of both\nvariables \ud835\udc653 and \ud835\udc654. We perform the elementary operation\n\ud835\udc523 \u2192 1\n3\ud835\udc523\nto get\n\ud835\udc651\n+2\ud835\udc652\n=\n1\n\ud835\udc652\n+\ud835\udc653\n+\ud835\udc654\n=\n\u22121\n\ud835\udc653\n+ 1\n3\ud835\udc654\n=\n\u2212 1\n3\n0\n=\n0\n0\n=\n0\n.60\nChapter 3\nSystems of Linear Equations\nWe use \ud835\udc523 to eliminate the variable \ud835\udc653 from the equations above it, by performing\n\ud835\udc522 \u2192 \u2212\ud835\udc523 + \ud835\udc522\nto get\n\ud835\udc651\n+2\ud835\udc652\n=\n1\n\ud835\udc652\n+ 2\n3\ud835\udc654\n=\n\u2212 2\n3\n\ud835\udc653\n+ 1\n3\ud835\udc654\n=\n\u2212 1\n3\n0\n=\n0\n0\n=\n0\n.\nWe use \ud835\udc522 to eliminate variable \ud835\udc652 from the equation above it by performing\n\ud835\udc521 \u2192 \u22122\ud835\udc522 + \ud835\udc521\nto get\n\ud835\udc651\n\u2212 4\n3\ud835\udc654\n=\n7\n3\n\ud835\udc652\n+ 2\n3\ud835\udc654\n=\n\u2212 2\n3\n\ud835\udc653\n+ 1\n3\ud835\udc654\n=\n\u2212 1\n3\n0\n=\n0\n0\n=\n0\n.\nWe have completed the backward elimination phase. We have that \ud835\udc654 = \ud835\udc61, \ud835\udc61 \u2208 R. From \ud835\udc521\nwe obtain that\n\ud835\udc651 = 7\n3 + 4\n3\ud835\udc61.\nFrom \ud835\udc522 we obtain that\n\ud835\udc652 = \u22122\n3 \u2212 2\n3\ud835\udc61.\nFrom \ud835\udc523 we obtain that\n\ud835\udc653 = \u22121\n3 \u2212 1\n3\ud835\udc61.\nTherefore, the solution set is\n\ud835\udc46 =\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n7\n3 + 4\n3\ud835\udc61\n\u2212 2\n3 \u2212 2\n3\ud835\udc61\n\u2212 1\n3 \u2212 1\n3\ud835\udc61\n\ud835\udc61\n\u23a4\n\u23a5\u23a5\u23a6 : \ud835\udc61 \u2208 R\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n=\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n7\n3\n\u2212 2\n3\n\u2212 1\n3\n0\n\u23a4\n\u23a5\u23a5\u23a6 + \ud835\udc61\n\u23a1\n\u23a2\u23a2\u23a3\n4\n3\n\u2212 2\n3\n\u2212 1\n3\n1\n\u23a4\n\u23a5\u23a5\u23a6 : \ud835\udc61 \u2208 R\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n.\nIf we use another parameter, \ud835\udc62 = \ud835\udc61\n3, then we remove some of the fractions to get\n\ud835\udc46 =\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n7\n3 + 4\ud835\udc62\n\u2212 2\n3 \u2212 2\ud835\udc62\n\u2212 1\n3 \u2212 \ud835\udc62\n3\ud835\udc62\n\u23a4\n\u23a5\u23a5\u23a6 : \ud835\udc62 \u2208 R\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n=\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n7\n3\n\u2212 2\n3\n\u2212 1\n3\n0\n\u23a4\n\u23a5\u23a5\u23a6 + \ud835\udc62\n\u23a1\n\u23a2\u23a2\u23a3\n4\n\u22122\n\u22121\n3\n\u23a4\n\u23a5\u23a5\u23a6 : \ud835\udc62 \u2208 R\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n.\nAlternatively, we could let \ud835\udc60 = \ud835\udc61 \u2212 2\n3\nand get an even nicer looking solution set\n\ud835\udc46 =\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n5\n\u22122\n\u22121\n2\n\u23a4\n\u23a5\u23a5\u23a6 + \ud835\udc60\n\u23a1\n\u23a2\u23a2\u23a3\n4\n\u22122\n\u22121\n3\n\u23a4\n\u23a5\u23a5\u23a6 : \ud835\udc60 \u2208 R\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n.Section 3.4", "Solving Systems of Linear Equations Using Matrices\n61\nREMARK\nRemember that, when a solution set contains at least one parameter, you can obtain par-\nticular solutions by setting particular values to parameters. In the case of Example 3.3.1,\nthe solution set of a system of linear equations is given by\n\ud835\udc46 =\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n5\n\u22122\n\u22121\n2\n\u23a4\n\u23a5\u23a5\u23a6 + \ud835\udc60\n\u23a1\n\u23a2\u23a2\u23a3\n4\n\u22122\n\u22121\n3\n\u23a4\n\u23a5\u23a5\u23a6 : \ud835\udc60 \u2208 R\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n.\nBy setting \ud835\udc60 = \u22121, \ud835\udc60 = 0 and \ud835\udc60 = 1, we find that\n\u23a1\n\u23a2\u23a2\u23a3\n1\n0\n0\n\u22121\n\u23a4\n\u23a5\u23a5\u23a6 ,\n\u23a1\n\u23a2\u23a2\u23a3\n5\n\u22122\n\u22121\n2\n\u23a4\n\u23a5\u23a5\u23a6\nand\n\u23a1\n\u23a2\u23a2\u23a3\n9\n\u22124\n\u22122\n5\n\u23a4\n\u23a5\u23a5\u23a6\nare particular solutions to the given system of linear equations.\n3.4\nSolving Systems of Linear Equations Using Matrices\nWhen we are solving a system of equations, we manipulate the system using elementary\noperations. At each stage, we have an equivalent system of equations. That is, each system\nhas the same solution set. We can stop at any stage with any equivalent system as soon as\nwe find that we can write down the solution set.\nIn the systems of equations that we have solved, notice that we write down the variables\nmany times in the process, but it turns out they are only really important at the beginning\nand the end of the process.\nMoving forwards, we will only need to write down the coefficients and the constant terms\nin the intermediate steps. To do this, we will make use of matrices.\nDefinition 3.4.1\nMatrix, Entry\nAn \ud835\udc5a \u00d7 \ud835\udc5b matrix, \ud835\udc34, is a rectangular array of scalars with \ud835\udc5a rows and \ud835\udc5b columns. The\nscalar in the \ud835\udc56\ud835\udc61\u210e row and \ud835\udc57\ud835\udc61\u210e column is the (\ud835\udc56, \ud835\udc57)\ud835\udc61\u210e entry and is denoted \ud835\udc4e\ud835\udc56\ud835\udc57 or (\ud835\udc34)\ud835\udc56\ud835\udc57. That\nis,\n\ud835\udc34 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc4e11 \ud835\udc4e12 \u00b7 \u00b7 \u00b7 \ud835\udc4e1\ud835\udc5b\n\ud835\udc4e21 \ud835\udc4e22 \u00b7 \u00b7 \u00b7 \ud835\udc4e2\ud835\udc5b\n...\n...\n...\n...\n\ud835\udc4e\ud835\udc5a1 \ud835\udc4e\ud835\udc5a2 \u00b7 \u00b7 \u00b7 \ud835\udc4e\ud835\udc5a\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 .\nDefinition 3.4.2\nCoefficient Matrix,\nAugmented Matrix\nFor a given system of linear equations,\n\ud835\udc4e11\ud835\udc651\n+\ud835\udc4e12\ud835\udc652\n+\n\u00b7 \u00b7 \u00b7\n+\ud835\udc4e1\ud835\udc5b\ud835\udc65\ud835\udc5b\n=\n\ud835\udc4f1\n\ud835\udc4e21\ud835\udc651\n+\ud835\udc4e22\ud835\udc652\n+\n\u00b7 \u00b7 \u00b7\n+\ud835\udc4e2\ud835\udc5b\ud835\udc65\ud835\udc5b\n=\n\ud835\udc4f2\n...\n\ud835\udc4e\ud835\udc5a1\ud835\udc651\n+\ud835\udc4e\ud835\udc5a2\ud835\udc652\n+\n\u00b7 \u00b7 \u00b7\n+\ud835\udc4e\ud835\udc5a\ud835\udc5b\ud835\udc65\ud835\udc5b\n=\n\ud835\udc4f\ud835\udc5a\n,62\nChapter 3\nSystems of Linear Equations\nthe coefficient matrix, \ud835\udc34, of the system is the matrix\n\ud835\udc34 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc4e11 \ud835\udc4e12 \u00b7 \u00b7 \u00b7 \ud835\udc4e1\ud835\udc5b\n\ud835\udc4e21 \ud835\udc4e22 \u00b7 \u00b7 \u00b7 \ud835\udc4e2\ud835\udc5b\n...\n...\n...\n...\n\ud835\udc4e\ud835\udc5a1 \ud835\udc4e\ud835\udc5a2 \u00b7 \u00b7 \u00b7 \ud835\udc4e\ud835\udc5a\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 .\nThe entry \ud835\udc4e\ud835\udc56\ud835\udc57 is the coefficient of the variable \ud835\udc65\ud835\udc57 in the \ud835\udc56\ud835\udc61\u210e equation.\nThe augmented matrix, [\ud835\udc34|#\u00bb\ud835\udc4f ], of the system is\n[\ud835\udc34|#\u00bb\ud835\udc4f ] =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc4e11\n\ud835\udc4e12\n\u00b7 \u00b7 \u00b7\n\ud835\udc4e1\ud835\udc5b\n\ud835\udc4f1\n\ud835\udc4e21\n\ud835\udc4e22\n\u00b7 \u00b7 \u00b7\n\ud835\udc4e2\ud835\udc5b\n\ud835\udc4f2\n...\n...\n...\n...\n...\n\ud835\udc4e\ud835\udc5a1\n\ud835\udc4e\ud835\udc5a2\n\u00b7 \u00b7 \u00b7\n\ud835\udc4e\ud835\udc5a\ud835\udc5b\n\ud835\udc4f\ud835\udc5a\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 ,\nwhere #\u00bb\ud835\udc4f is a column whose entries are the constant terms on the right-hand side of the\nequations.\nThe augmented matrix is the coefficient matrix, \ud835\udc34, with the extra column, #\u00bb\ud835\udc4f , added.\nIn solving a system of equations, we can manipulate the rows of the augmented matrix,\nwhich will correspond to manipulating the equations.\nDefinition 3.4.3\nElementary Row\nOperation (ERO)\nElementary row operations (EROs) are the operations performed on the coefficient\nand/or augmented matrix which correspond to the elementary operations performed on the\nsystem of equations.\nElementary operation\nEquation\nRow\nRow swap\n\ud835\udc52\ud835\udc56 \u2194 \ud835\udc52\ud835\udc57\n\ud835\udc45\ud835\udc56 \u2194 \ud835\udc45\ud835\udc57\nRow scale\n\ud835\udc52\ud835\udc56 \u2192 \ud835\udc50\ud835\udc52\ud835\udc56, \ud835\udc50 \u0338= 0\n\ud835\udc45\ud835\udc56 \u2192 \ud835\udc50\ud835\udc45\ud835\udc56, \ud835\udc50 \u0338= 0\nRow addition\n\ud835\udc52\ud835\udc56 \u2192 \ud835\udc50\ud835\udc52\ud835\udc57 + \ud835\udc52\ud835\udc56, \ud835\udc56 \u0338= \ud835\udc57\n\ud835\udc45\ud835\udc56 \u2192 \ud835\udc50\ud835\udc45\ud835\udc57 + \ud835\udc45\ud835\udc56, \ud835\udc56 \u0338= \ud835\udc57\nAs with the equation operations, these EROs are referred to in some sources as Type I,\nType II, and Type III operations, respectively.\nDefinition 3.4.4\nZero Row\nIn a matrix, we refer to a row that has all zero entries as a zero row.\nDefinition 3.4.5\nRow Equivalent\nIf a matrix \ud835\udc35 is obtained from a matrix \ud835\udc34 by a finite number of EROs, then we say that \ud835\udc35\nis row equivalent to \ud835\udc34.\nAt any point in the process of manipulating the rows of an augmented matrix, we could stop\nand immediately write down the corresponding system of linear equations. The first column\nin the matrix corresponds to the variable \ud835\udc651, the second column in the matrix corresponds\nto the variable \ud835\udc652 and so on up to the second-last column in the matrix which correspondsSection 3.4\nSolving Systems of Linear Equations Using Matrices\n63\nto the variable \ud835\udc65\ud835\udc5b. The last column in the matrix corresponds to the constants on the right\nhand side of the system.\nThe augmented matrix at any stage is row equivalent to the original augmented matrix.\nTherefore, the system of equations corresponding to this augmented matrix is equivalent to\nthe system of equations corresponding to the original augmented matrix.\nExample 3.4.6\nSolve the following system (the same system as in Example 3.3.1) using augmented matrices\nand EROs.\n\ud835\udc651\n+2\ud835\udc652\n=\n1\n\ud835\udc651\n+2\ud835\udc652\n+3\ud835\udc653\n+\ud835\udc654\n=\n0\n\u2212\ud835\udc651\n\u2212\ud835\udc652\n+\ud835\udc653\n+\ud835\udc654\n=\n\u22122\n\ud835\udc652\n+\ud835\udc653\n+\ud835\udc654\n=\n\u22121\n\u2212\ud835\udc652\n+2\ud835\udc653\n=\n0\n.\nSolution: The augmented matrix for this system is\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n1\n2\n0\n0\n1\n1\n2\n3\n1\n0\n\u22121\n\u22121\n1\n1\n\u22122\n0\n1\n1\n1\n\u22121\n0\n\u22121\n2\n0\n0\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\n.\nWe begin by eliminating \ud835\udc651 from the second and third equations by performing the following\nEROs\n\ud835\udc452 \u2192 \u2212\ud835\udc451 + \ud835\udc452\n\ud835\udc453 \u2192 \ud835\udc451 + \ud835\udc453\nto get\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n1\n2\n0\n0\n1\n0\n0\n3\n1\n\u22121\n0\n1\n1\n1\n\u22121\n0\n1\n1\n1\n\u22121\n0\n\u22121\n2\n0\n0\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\n.\nThe second row does not contain the variable \ud835\udc652, but the third one does and so we swap\nthese two rows, \ud835\udc452 \u2194 \ud835\udc453, to get\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n1\n2\n0\n0\n1\n0\n1\n1\n1\n\u22121\n0\n0\n3\n1\n\u22121\n0\n1\n1\n1\n\u22121\n0\n\u22121\n2\n0\n0\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\n.\nWe now make use of the new second row to eliminate \ud835\udc652 from all rows after the second one,\nby performing the following EROs\n\ud835\udc454 \u2192 \u2212\ud835\udc452 + \ud835\udc454\n\ud835\udc455 \u2192 \ud835\udc452 + \ud835\udc455\nto get\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n1\n2\n0\n0\n1\n0\n1\n1\n1\n\u22121\n0\n0\n3\n1\n\u22121\n0\n0\n0\n0\n0\n0\n0\n3\n1\n\u22121\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\n.64\nChapter 3\nSystems of Linear Equations\nWe use the third row to eliminate \ud835\udc653 from the rows after it, by performing the following\nERO\n\ud835\udc455 \u2192 \u2212\ud835\udc453 + \ud835\udc455\nto get\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n1\n2\n0\n0\n1\n0\n1\n1\n1\n\u22121\n0\n0\n3\n1\n\u22121\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\n.\nAt this point, we have completed the forward elimination phase using a sequence of EROs\nequivalent to how we manipulated the equations in Example 3.3.1.\nWe can write down the system of equations that corresponds to the final augmented matrix\nthat we obtained. This system of equations is equivalent to the original system.\n\ud835\udc651\n+2\ud835\udc652\n=\n1\n\ud835\udc652\n+\ud835\udc653\n+\ud835\udc654\n=\n\u22121\n3\ud835\udc653\n+\ud835\udc654\n=\n\u22121\n0\n=\n0\n0\n=\n0\nThis system is the same system we obtained after the forward elimination phase when we\nwere using elementary operations. As before we can use back substitution to obtain the\nsolution set\n\ud835\udc46 =\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n7\n3 + 4\n3\ud835\udc61\n\u2212 2\n3 \u2212 2\n3\ud835\udc61\n\u2212 1\n3 \u2212 1\n3\ud835\udc61\n\ud835\udc61\n\u23a4\n\u23a5\u23a5\u23a6 : \ud835\udc61 \u2208 R\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n=\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n7\n3\n\u2212 2\n3\n\u2212 1\n3\n0\n\u23a4\n\u23a5\u23a5\u23a6 + \ud835\udc61\n\u23a1\n\u23a2\u23a2\u23a3\n4\n3\n\u2212 2\n3\n\u2212 1\n3\n1\n\u23a4\n\u23a5\u23a5\u23a6 : \ud835\udc61 \u2208 R\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n.\nInstead of using back substitution we can continue using EROs to obtain an even simpler\nsystem.\nWe scale the third row by performing the following ERO\n\ud835\udc453 \u2192 1\n3\ud835\udc453\nto get\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n1\n2\n0\n0\n\u22121\n0\n1\n1\n1\n\u22121\n0\n0\n1\n1\n3\n\u2212 1\n3\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\n.\nNext, we use the third row to eliminate \ud835\udc653 from the equations above it. We do this by\nperforming the following ERO\n\ud835\udc452 \u2192 \u2212\ud835\udc453 + \ud835\udc452\nyielding\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n1\n2\n0\n0\n\u22121\n0\n1\n0\n2\n3\n\u2212 2\n3\n0\n0\n1\n1\n3\n\u2212 1\n3\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\n.Section 3.5\nSolving Systems of Linear Equations Using Matrices\n65\nThe last step of the backward elimination phase is to eliminate \ud835\udc652 from the first equation,\nwhich is achieved by the ERO\n\ud835\udc451 \u2192 \u22122\ud835\udc452 + \ud835\udc451\nyielding\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n1\n0\n0\n\u2212 4\n3\n7\n3\n0\n1\n0\n2\n3\n\u2212 2\n3\n0\n0\n1\n1\n3\n\u2212 1\n3\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\n.\nThis augmented matrix has a very simple structure. We could argue that it has the simplest\nstructure of all the augmented matrices we have seen in this example. In the next section\nwe will introduce terminology to formalize this structure.\nThe system of equations corresponding to the last augmented matrix above is\n\ud835\udc651\n\u2212 4\n3\ud835\udc654\n=\n7\n3\n\ud835\udc652\n+ 2\n3\ud835\udc654\n=\n\u2212 2\n3\n\ud835\udc653\n+ 1\n3\ud835\udc654\n=\n\u2212 1\n3\n0\n=\n0\n0\n=\n0\nThis system is the same system we obtained after the forward and backward elimination\nphases when we were using elementary operations. Therefore, the solution set is\n\ud835\udc46 =\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n7\n3 + 4\n3\ud835\udc61\n\u2212 2\n3 \u2212 2\n3\ud835\udc61\n\u2212 1\n3 \u2212 1\n3\ud835\udc61\n\ud835\udc61\n\u23a4\n\u23a5\u23a5\u23a6 : \ud835\udc61 \u2208 R\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n=\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n7\n3\n\u2212 2\n3\n\u2212 1\n3\n0\n\u23a4\n\u23a5\u23a5\u23a6 + \ud835\udc61\n\u23a1\n\u23a2\u23a2\u23a3\n4\n3\n\u2212 2\n3\n\u2212 1\n3\n1\n\u23a4\n\u23a5\u23a5\u23a6 : \ud835\udc61 \u2208 R\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n.\nREMARK\nIn an augmented matrix, a zero row corresponds to the equation 0 = 0.\nIn the above\nexample, the last two rows of the augmented matrix eventually became zero rows. Although\nthese equations do not give us any information about the solution to the system of equations,\nwe continued to write them down so that we would not forget that our system started with\nfive equations.\nIf at any point we have a zero row in the coefficient matrix and the last entry in the\ncorresponding row in the augmented matrix is \ud835\udc4f \u0338= 0, then we can stop and deduce that our\nsystem is inconsistent, since one of the equations has become 0 = \ud835\udc4f, where \ud835\udc4f \u0338= 0.66\nChapter 3\nSystems of Linear Equations\n3.5\nThe Gauss\u2013Jordan Algorithm for Solving Systems of Lin-\near Equations\nConsider a system of \ud835\udc5a linear equations in \ud835\udc5b variables (unknowns). We assume the variables\nare labelled \ud835\udc651, \ud835\udc652, . . . , \ud835\udc65\ud835\udc5b. The Gauss\u2013Jordan algorithm is the formalization of the strategy\nwe used in the previous section to solve such a system. In this algorithm, we use EROs to\nmanipulate the augmented matrix into a simpler form from which it is easier to determine\nthe solution of the system. The process of performing EROs on the matrix to bring it into\nthese simpler forms is called row reduction or Gaussian elimination after Carl Friedrich\nGauss (1777-1855) who outlined the process; a similar method for solving systems of linear\nequations was known to the Chinese around 250 B.C.\nIn the previous section, we obtained two simpler forms of the augmented matrix.\nThe\nfirst was obtained after completing the forward elimination process and is called the row\nechelon form. The second is obtained after completing both the forward and backward\nelimination processes and is called the reduced row echelon form. We now give the\nformal definitions of these forms in terms of leading entries and pivots.\nDefinition 3.5.1\nLeading Entry,\nLeading One\nThe leftmost non-zero entry in any non-zero row of a matrix is called the leading entry\nof that row. If the leading entry is a 1, then it is called a leading one.\nDefinition 3.5.2\nRow Echelon Form\nWe say that a matrix is in row echelon form (REF) whenever both of the following two\nconditions are satisfied:\n1. All zero rows occur as the final rows in the matrix.\n2. The leading entry in any non-zero row appears in a column to the right of the columns\ncontaining the leading entries of any of the rows above it.\nWe say that the matrix \ud835\udc45 is a row echelon form of matrix \ud835\udc34 to mean that \ud835\udc45 is in row\nechelon form and that \ud835\udc45 can be obtained from \ud835\udc34 by performing a finite number of EROs\nto \ud835\udc34.\nDefinition 3.5.3\nPivot, Pivot\nPosition, Pivot\nColumn, Pivot\nRow\nIf a matrix is in REF, then the leading entries are referred to as pivots and their positions\nin the matrix are called pivot positions. Any column that contains a pivot position is\ncalled a pivot column. Any row that contains a pivot position is called a pivot row.\nDue to the structure of REF, any pivot column will contain exactly one pivot and any pivot\nrow will contain exactly one pivot.\nExample 3.5.4\nThe matrix\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n3 2 \u22123 4\n0 0 2\n0\n0 0 0 \u22125\n0 0 0\n0\n0 0 0\n0\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6Section 3.5", "The Gauss\u2013Jordan Algorithm for Solving Systems of Linear Equations\n67\nis in REF, with pivots in the (1, 1), (2, 3) and (3, 4) entries. However, the matrix\n\u23a1\n\u23a3\n\u22123 3 5 7\n0 2 6 0\n1 0 1 \u22122\n\u23a4\n\u23a6\nis not in REF because the leading entry in the third row (marked in red) is not to the right\nof the leading entry of one (in fact both of) the rows above it.\nDefinition 3.5.5\nReduced Row\nEchelon Form\nWe say that a matrix is in reduced row echelon form (RREF) whenever all of the\nfollowing three conditions are satisfied:\n1. It is in REF.\n2. All its pivots are leading ones.\n3. The only non-zero entry in a pivot column is the pivot itself.\nREMARK\nItem \u201c3.\u201d from the definition of RREF above implies that all entries above and below a\npivot MUST be zero for a matrix in RREF; in other words, any column of a matrix in\nRREF with two or more non-zero entries is not a pivot column.\nExample 3.5.6\nThe matrix\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n3 2 \u22123 4\n0 0 2\n0\n0 0 0 \u22125\n0 0 0\n0\n0 0 0\n0\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\nfrom the previous example is in REF, but not in RREF, because its pivots are not leading\nones, and moreover, the third and fourth pivot columns contain non-zero entries that are\nnot pivots.\nThe matrix\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n1 2 0 0\n0 0 1 0\n0 0 0 1\n0 0 0 0\n0 0 0 0\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\nis in RREF.\nExample 3.5.7\nList all possible 2 \u00d7 2 matrices that are in RREF.68\nChapter 3\nSystems of Linear Equations\nSolution: Since a 2 \u00d7 2 matrix has two rows and two columns, then the number of pivots\nis either zero, one or two. If there are zero pivots, then all entries in the matrix must be 0.\nTherefore, we obtain the matrix\n[\ufe020 0\n0 0\n]\ufe02\n.\nIf there is one pivot, then this pivot must occur in the first row and the second row must\nbe a zero row. The pivot could occur in the first column or the second column. If the pivot\noccurs in the first column, then the (1, 2) entry could be anything. Therefore, we obtain an\ninfinite number of matrices of the form\n[\ufe021 \ud835\udc4e\n0 0\n]\ufe02\n, \ud835\udc4e \u2208 F.\nIf the pivot occurs in the second column, then the (1, 1) entry must be 0. Therefore, we\nobtain the matrix\n[\ufe020 1\n0 0\n]\ufe02\n.\nIf there are two pivots, then they must occur in the positions (1, 1) and (2, 2) and the other\nentries must be 0. Therefore, we obtain the matrix\n[\ufe021 0\n0 1\n]\ufe02\n.\nIf \ud835\udc34 is not a matrix of all zeros, then there are an infinite number of matrices which are\nREFs of \ud835\udc34. However, the pivot positions of \ud835\udc34 are unique, as well as is its RREF. At this\npoint, we do not have the tools to prove this result.\nTheorem 3.5.8\n(Unique RREF)\nLet \ud835\udc34 be a matrix with REFs \ud835\udc451 and \ud835\udc452. Then \ud835\udc451 and \ud835\udc452 will have the same set of pivot\npositions. Moreover, there is a unique matrix \ud835\udc45 such that \ud835\udc45 is the RREF of \ud835\udc34.\nBecause the RREF of a given matrix \ud835\udc34 is unique, we can introduce notation to refer to it.\nDefinition 3.5.9\nRREF(\ud835\udc34)\nWe say that the matrix \ud835\udc45 is the reduced row echelon form of matrix \ud835\udc34, and we write\n\ud835\udc45 = RREF(\ud835\udc34), if \ud835\udc45 is in reduced row echelon form and if \ud835\udc45 can be obtained from \ud835\udc34 by\nperforming a finite number of EROs to \ud835\udc34.\nHaving laid down the needed definitions, we now outline an algorithm that takes as input a\ngiven matrix \ud835\udc34 and produces a row equivalent matrix \ud835\udc45 in REF. This algorithm corresponds\nto the forward elimination process for a consistent system.\nALGORITHM (Obtaining an REF)Section 3.5\nThe Gauss\u2013Jordan Algorithm for Solving Systems of Linear Equations\n69\n1. Consider the leftmost non-zero column of the matrix. Use EROs to obtain a leading\nentry in the top position of this column. This entry is now a pivot and this row is\nnow a pivot row.\n2. Use EROs to change all other entries below the pivot in this pivot column to 0.\n3. Consider the submatrix formed by covering up the current pivot row and all previous\npivot rows. If there are no more rows or if the only remaining rows are zero rows,\nwe are finished. Otherwise, repeat steps 1 and 2 on the submatrix. Continue in this\nmanner, covering up the current pivot row to obtain a matrix with one less row until\nno rows remain or we obtain a submatrix with only zero rows.\nWe can also outline a similar algorithm that takes as input a matrix \ud835\udc45 in REF and produces\nthe RREF of \ud835\udc45. This will correspond to the backward elimination process.\nALGORITHM (Obtaining the RREF from an REF)\nStart with a matrix in REF.\n1. Select the rightmost pivot column. If the pivot is not already 1, use EROs to change\nit to 1.\n2. Use EROs to change all entries above the pivot in this pivot column to 0.\n3. Consider the submatrix formed by covering up the current pivot row and all other\nrows below it. If there are no more rows, then we are finished. Otherwise, repeat\nsteps 1 and 2 on the submatrix until no rows remain.\nThe preceding two algorithms can be run in sequence to take a matrix \ud835\udc34 and produce\nRREF(\ud835\udc34). This process is known as the Gauss\u2013Jordan1 algorithm.\nREMARKS\n\u2022 If the system is inconsistent, then at some point we will obtain a row of the form\n[\ufe00\n0\n\u00b7 \u00b7 \u00b7\n0\n\ud835\udc4f\n]\ufe00\n, where \ud835\udc4f \u0338= 0. This row corresponds to the equation 0 = \ud835\udc4f, where\n\ud835\udc4f \u0338= 0. As soon as we obtain such a row, we can stop the algorithm and conclude that\nthe system is inconsistent.\n\u2022 We will not always blindly follow these algorithms when finding an REF or the RREF.\nThere may be other choices along the way that lead to fewer calculations, or we may\nwant to avoid fractions for as long as possible. When determining an REF we often\ntry to obtain leading 1s, even though they are not required, because they are easier\nto work with.\n1Named after the aforementioned Gauss and Wilhelm Jordan (1842-1899), a German engineer who pop-\nularized this method for solving systems of equations.70\nChapter 3\nSystems of Linear Equations\nWe will apply the Gauss\u2013Jordan algorithm to the augmented matrix obtained from a system\nof linear equations. This will allow us to easily obtain the solution set to the system. The\nfollowing terminology will be helpful in describing these solution sets.\nDefinition 3.5.10\nBasic Variable, Free\nVariable\nConsider a system of linear equations. Let \ud835\udc45 be an REF of the coefficient matrix of this\nsystem. If the \ud835\udc56\ud835\udc61\u210e column of this matrix contains a pivot, then we call \ud835\udc65\ud835\udc56 a basic variable.\nOtherwise, we call \ud835\udc65\ud835\udc56 a free variable.\nThis terminology reflects the fact that we will be able to assign parameters to the free\nvariables, and then we will be able to express the basic variables in terms of these parameters.\nSee the examples below.\nExample 3.5.11\nSolve the following system.\n\u2212\ud835\udc651\n\u22122\ud835\udc652\n+2\ud835\udc653\n+4\ud835\udc654\n=\n3\n2\ud835\udc651\n+4\ud835\udc652\n\u22122\ud835\udc653\n\u22122\ud835\udc654\n=\n4\n\ud835\udc651\n+2\ud835\udc652\n\u2212\ud835\udc653\n\u22122\ud835\udc654\n=\n0\n2\ud835\udc651\n+4\ud835\udc652\n\u22126\ud835\udc653\n\u22128\ud835\udc654\n=\n\u22124\nSolution: We begin by giving the augmented matrix for the system.\n\u23a1\n\u23a2\u23a2\u23a3\n\u22121\n\u22122\n2\n4\n3\n2\n4\n\u22122\n\u22122\n4\n1\n2\n\u22121\n\u22122\n0\n2\n4\n\u22126\n\u22128\n\u22124\n\u23a4\n\u23a5\u23a5\u23a6\nThe leftmost non-zero column is the first column.\nTherefore, our first goal is to get a\nleading entry (which will become a pivot) in the top position of this column. It will make\nour calculations easier if this is a leading one, so we will perform the ERO \ud835\udc451 \u2190\u2192 \ud835\udc453 to\nget\n\u23a1\n\u23a2\u23a2\u23a3\n1\n2\n\u22121\n\u22122\n0\n2\n4\n\u22122\n\u22122\n4\n\u22121\n\u22122\n2\n4\n3\n2\n4\n\u22126\n\u22128\n\u22124\n\u23a4\n\u23a5\u23a5\u23a6 .\nNext, we want to change all entries below the pivot in this column to 0. So we perform the\nfollowing EROs\n\ud835\udc452 \u2192 \u22122\ud835\udc451 + \ud835\udc452\n\ud835\udc453 \u2192 \ud835\udc451 + \ud835\udc453\n\ud835\udc454 \u2192 \u22122\ud835\udc451 + \ud835\udc454\nto get\n\u23a1\n\u23a2\u23a2\u23a3\n1\n2\n\u22121\n\u22122\n0\n0\n0\n0\n2\n4\n0\n0\n1\n2\n3\n0\n0\n\u22124\n\u22124\n\u22124\n\u23a4\n\u23a5\u23a5\u23a6 .\nCovering up the first row, the leftmost non-zero column is the third column. We need to\nget a leading entry (which will become a pivot) in the top position of this column (with theSection 3.5\nThe Gauss\u2013Jordan Algorithm for Solving Systems of Linear Equations\n71\nfirst row covered) and so we need to get a pivot in the (2,3) position. The simplest way to\ndo this is to perform the ERO \ud835\udc452 \u2190\u2192 \ud835\udc453 to get\n\u23a1\n\u23a2\u23a2\u23a3\n1\n2\n\u22121\n\u22122\n0\n0\n0\n1\n2\n3\n0\n0\n0\n2\n4\n0\n0\n\u22124\n\u22124\n\u22124\n\u23a4\n\u23a5\u23a5\u23a6 .\nNext, we want to change all entries below the pivot in this column to 0. So we perform the\nfollowing ERO\n\ud835\udc454 \u2192 4\ud835\udc452 + \ud835\udc454\nto get\n\u23a1\n\u23a2\u23a2\u23a3\n1\n2\n\u22121\n\u22122\n0\n0\n0\n1\n2\n3\n0\n0\n0\n2\n4\n0\n0\n0\n4\n8\n\u23a4\n\u23a5\u23a5\u23a6 .\nCovering up the first two rows, the leftmost non-zero column is the fourth column. We\nneed to get a leading entry (which will become a pivot) in the top position of this column\n(with the first two rows covered) and so we need to get a pivot in the (3,4) position. There\nalready is a leading entry there and so no EROs are needed.\nNext, we want to change all entries below the pivot in this column to 0. So we perform the\nfollowing ERO\n\ud835\udc454 \u2192 \u22122\ud835\udc453 + \ud835\udc454\nto get\n\u23a1\n\u23a2\u23a2\u23a3\n1\n2\n\u22121\n\u22122\n0\n0\n0\n1\n2\n3\n0\n0\n0\n2\n4\n0\n0\n0\n0\n0\n\u23a4\n\u23a5\u23a5\u23a6 .\nCovering up the first three rows, all remaining rows are zero rows and so we now have an\naugmented matrix in REF. We write down the system of equations that corresponds to this\naugmented matrix and solve this system using back substitution.\nThe corresponding system of equations is\n\ud835\udc651\n+2\ud835\udc652\n\u2212\ud835\udc653\n\u22122\ud835\udc654\n=\n0\n\ud835\udc653\n+2\ud835\udc654\n=\n3\n2\ud835\udc654\n=\n4\n0\n=\n0\n.\nThe third equation tells us that \ud835\udc654 = 2. Substituting this into the second equation, we\nobtain that \ud835\udc653 = \u22121. Substituting both of these values into the first equation, we obtain\nthat \ud835\udc651 + 2\ud835\udc652 = 3. Using our convention, we set \ud835\udc651 to be a basic variable and \ud835\udc652 to be a\nfree variable. Therefore, \ud835\udc652 = \ud835\udc61, \ud835\udc61 \u2208 R and \ud835\udc651 = 3 \u2212 2\ud835\udc61.\nTherefore, the solution set is \ud835\udc46 =\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n3 \u2212 2\ud835\udc61\n\ud835\udc61\n\u22121\n2\n\u23a4\n\u23a5\u23a5\u23a6 : \ud835\udc61 \u2208 R\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n=\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n3\n0\n\u22121\n2\n\u23a4\n\u23a5\u23a5\u23a6 + \ud835\udc61\n\u23a1\n\u23a2\u23a2\u23a3\n\u22122\n1\n0\n0\n\u23a4\n\u23a5\u23a5\u23a6 : \ud835\udc61 \u2208 R\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n.72\nChapter 3\nSystems of Linear Equations\nInstead of stopping at REF and using back substitution, we could continue to do row\nreduction until we reached an augmented matrix in RREF (the Gauss-Jordan algorithm).\nBeginning with\n\u23a1\n\u23a2\u23a2\u23a3\n1\n2\n\u22121\n\u22122\n0\n0\n0\n1\n2\n3\n0\n0\n0\n2\n4\n0\n0\n0\n0\n0\n\u23a4\n\u23a5\u23a5\u23a6\nwe identify the rightmost pivot column, which is the fourth column. We change the pivot\nto 1 by performing the ERO \ud835\udc453 \u2192 1\n2\ud835\udc453 to get\n\u23a1\n\u23a2\u23a2\u23a3\n1\n2\n\u22121\n\u22122\n0\n0\n0\n1\n2\n3\n0\n0\n0\n1\n2\n0\n0\n0\n0\n0\n\u23a4\n\u23a5\u23a5\u23a6 .\nNext, we want to change all entries above this pivot to 0. So we perform the EROs\n\ud835\udc451 \u2192 2\ud835\udc453 + \ud835\udc451\n\ud835\udc452 \u2192 \u22122\ud835\udc453 + \ud835\udc452\nto get\n\u23a1\n\u23a2\u23a2\u23a3\n1\n2\n\u22121\n0\n4\n0\n0\n1\n0\n\u22121\n0\n0\n0\n1\n2\n0\n0\n0\n0\n0\n\u23a4\n\u23a5\u23a5\u23a6 .\nCovering up the bottom two rows, the rightmost pivot column is the third column. The\npivot in this column is already 1 so no ERO is necessary. We want to change all entries\nabove this pivot to 0 and so we perform the ERO\n\ud835\udc451 \u2192 \ud835\udc452 + \ud835\udc451\nto get\n\u23a1\n\u23a2\u23a2\u23a3\n1\n2\n0\n0\n3\n0\n0\n1\n0\n\u22121\n0\n0\n0\n1\n2\n0\n0\n0\n0\n0\n\u23a4\n\u23a5\u23a5\u23a6 .\nCovering up the bottom three rows, the rightmost pivot column is the first column. The\npivot in this column is already 1 so no ERO is necessary.\nThere are now no more rows to adjust and so our augmented matrix is in RREF.\nThe corresponding system of equations is\n\ud835\udc651\n+2\ud835\udc652\n=\n3\n\ud835\udc653\n=\n\u22121\n\ud835\udc654\n=\n2\n0\n=\n0\nThe second and third equations give us values for \ud835\udc653 and \ud835\udc654, respectively. We set \ud835\udc652 to be a\nfree variable and thus \ud835\udc652 = \ud835\udc61, \ud835\udc61 \u2208 R, which implies that \ud835\udc651 = 3 \u2212 2\ud835\udc61. Therefore, the solutionSection 3.5\nThe Gauss\u2013Jordan Algorithm for Solving Systems of Linear Equations\n73\nset is \ud835\udc46 =\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n3 \u2212 2\ud835\udc61\n\ud835\udc61\n\u22121\n2\n\u23a4\n\u23a5\u23a5\u23a6 : \ud835\udc61 \u2208 R\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n=\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n3\n0\n\u22121\n2\n\u23a4\n\u23a5\u23a5\u23a6 + \ud835\udc61\n\u23a1\n\u23a2\u23a2\u23a3\n\u22122\n1\n0\n0\n\u23a4\n\u23a5\u23a5\u23a6 : \ud835\udc61 \u2208 R\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\nwhich is the same solution\nset we obtained earlier.\nExample 3.5.12\nSolve the following system.\n2\ud835\udc651\n+4\ud835\udc652\n\u22122\ud835\udc653\n=\n2\n3\ud835\udc651\n+7\ud835\udc652\n+\ud835\udc653\n=\n0\n2\ud835\udc651\n+5\ud835\udc652\n+2\ud835\udc653\n=\n1\nSolution: We begin by giving the augmented matrix for the system.\n\u23a1\n\u23a3\n2\n4\n\u22122\n2\n3\n7\n1\n0\n2\n5\n2\n1\n\u23a4\n\u23a6\nOur first goal is to get a leading entry (which will become a pivot) in the top position of the\nfirst column, since is it the leftmost non-zero column. It will actually make our calculations\neasier if this is a leading one and so we will perform the ERO \ud835\udc451 \u2192 1\n2\ud835\udc451 to obtain\n\u23a1\n\u23a3\n1\n2\n\u22121\n1\n3\n7\n1\n0\n2\n5\n2\n1\n\u23a4\n\u23a6 .\nNext, we want to change all entries below the pivot in this column to 0. So we perform the\nfollowing row addition EROs\n\ud835\udc452 \u2192 \u22123\ud835\udc451 + \ud835\udc452\n\ud835\udc453 \u2192 \u22122\ud835\udc451 + \ud835\udc453\nto obtain\n\u23a1\n\u23a3\n1\n2\n\u22121\n1\n0\n1\n4\n\u22123\n0\n1\n4\n\u22121\n\u23a4\n\u23a6 .\nCovering up the first row, the leftmost non-zero column is the second column. We need to\nobtain a leading entry (which will become a pivot) in the top position of this column (with\nthe first row covered) and so we need to get a pivot in the (2,2) position. There already is\na pivot there and so no ERO is necessary. Next, we want to change all entries below this\npivot to 0 and so we perform the ERO \ud835\udc453 \u2192 \u2212\ud835\udc452 + \ud835\udc453 to obtain\n\u23a1\n\u23a3\n1\n2\n\u22121\n1\n0\n1\n4\n\u22123\n0\n0\n0\n2\n\u23a4\n\u23a6 .\nThe third row is of the form\n[\ufe00\n0\n0\n0\n\ud835\udc4f\n]\ufe00\n, where \ud835\udc4f \u0338= 0 and so we can stop the algorithm here\nand declare that this system is inconsistent. (The third row corresponds to the equation\n0 = 2.)74\nChapter 3\nSystems of Linear Equations\nWe will include one more example in which we give far less commentary. We will simply\noutline the EROs that we are using. We will make use of the Gauss\u2013Jordan algorithm\n(forward and backward elimination).\nExample 3.5.13\nSolve the following system.\n3\ud835\udc651\n+5\ud835\udc652\n+3\ud835\udc653\n=\n9\n\u22122\ud835\udc651\n\u2212\ud835\udc652\n+6\ud835\udc653\n=\n10\n4\ud835\udc651\n+10\ud835\udc652\n\u22123\ud835\udc653\n=\n\u22122\nSolution: The augmented matrix for the system is\n\u23a1\n\u23a3\n3\n5\n3\n9\n\u22122\n\u22121\n6\n10\n4\n10\n\u22123\n\u22122\n\u23a4\n\u23a6 .\nWe determine an REF.\n\ud835\udc451 \u2192 \ud835\udc452 + \ud835\udc451 gives\n\u23a1\n\u23a3\n1\n4\n9\n19\n\u22122\n\u22121\n6\n10\n4\n10\n\u22123\n\u22122\n\u23a4\n\u23a6 .\n{\ufe03\n\ud835\udc452 \u2192 2\ud835\udc451 + \ud835\udc452\n\ud835\udc453 \u2192 \u22124\ud835\udc451 + \ud835\udc453\ngives\n\u23a1\n\u23a3\n1\n4\n9\n19\n0\n7\n24\n48\n0\n\u22126\n\u221239\n\u221278\n\u23a4\n\u23a6 .\n\ud835\udc452 \u2192 \ud835\udc453 + \ud835\udc452 gives\n\u23a1\n\u23a3\n1\n4\n9\n19\n0\n1\n\u221215\n\u221230\n0\n\u22126\n\u221239\n\u221278\n\u23a4\n\u23a6 .\n\ud835\udc453 \u2192 6\ud835\udc452 + \ud835\udc453 gives\n\u23a1\n\u23a3\n1\n4\n9\n19\n0\n1\n\u221215\n\u221230\n0\n0\n\u2212129\n\u2212258\n\u23a4\n\u23a6 .\nThis augmented matrix is in REF. At this point we could use back substitution, but we\nwill continue on to RREF.\n\ud835\udc453 \u2192 \u2212 1\n129\ud835\udc453 gives\n\u23a1\n\u23a3\n1\n4\n9\n19\n0\n1\n\u221215\n\u221230\n0\n0\n1\n2\n\u23a4\n\u23a6 .\n{\ufe03\n\ud835\udc451 \u2192 \u22129\ud835\udc453 + \ud835\udc451\n\ud835\udc452 \u2192 15\ud835\udc453 + \ud835\udc452\ngives\n\u23a1\n\u23a3\n1\n4\n0\n1\n0\n1\n0\n0\n0\n0\n1\n2\n\u23a4\n\u23a6 .\n\ud835\udc451 \u2192 \u22124\ud835\udc452 + \ud835\udc451 gives\n\u23a1\n\u23a3\n1\n0\n0\n1\n0\n1\n0\n0\n0\n0\n1\n2\n\u23a4\n\u23a6 .\nGiven this augmented matrix we can see that the solution is \ud835\udc651 = 1, \ud835\udc652 = 0 and \ud835\udc653 = 2.\nTherefore, the solution set is \ud835\udc46 =\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n1\n0\n2\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad.Section 3.6", "Rank and Nullity\n75\n3.6\nRank and Nullity\nDefinition 3.6.1\n\ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(R), \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(C),\n\ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F)\nWe use \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(R) to denote to the set of all \ud835\udc5a \u00d7 \ud835\udc5b matrices with real entries.\nWe use \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(C) to denote to the set of all \ud835\udc5a \u00d7 \ud835\udc5b matrices with complex entries.\nIf we do not need to distinguish between real and complex entries we will use \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F).\nREMARK\nIf \ud835\udc5a = \ud835\udc5b it is common to abbreviate \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F) as \ud835\udc40\ud835\udc5b(F).\nLet us consider a system of \ud835\udc5a linear equations in \ud835\udc5b variables.\nThe coefficient matrix\nof this system, \ud835\udc34, belongs to \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F) and the augmented matrix,\n[\ufe01\n\ud835\udc34 | #\u00bb\ud835\udc4f\n]\ufe01\n, belongs to\n\ud835\udc40\ud835\udc5a\u00d7(\ud835\udc5b+1)(F). In other words, the augmented matrix has exactly one more column than\nthe coefficient matrix.\nThere are three important questions that we would like to consider about this system.\n1. Is the system consistent or inconsistent?\n2. If the system is consistent, does it have a unique solution?\n3. If the system is consistent and does not have a unique solution, how many parameters\nare there in the solution set?\nWe will be able to answer these questions once we have an REF or the RREF of the\naugmented matrix\n[\ufe01\n\ud835\udc34 | #\u00bb\ud835\udc4f\n]\ufe01\neven before we have found the solution set.\nDefinition 3.6.2\nRank\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F) such that RREF(\ud835\udc34) has exactly \ud835\udc5f pivots. Then we say that the rank of\n\ud835\udc34 is \ud835\udc5f, and we write rank(\ud835\udc34) = \ud835\udc5f.\nAlthough there are infinitely many REFs of a matrix \ud835\udc34, Theorem 3.5.8 (Unique RREF)\ntells us that they will all have the same pivot positions, hence the same number of pivots.\nSince RREF(\ud835\udc34) is an REF of \ud835\udc34, all REFs of \ud835\udc34 will have the same number of pivots as\nRREF(\ud835\udc34). Therefore, we can use any REF of \ud835\udc34 to determine its rank.\nProposition 3.6.3\n(Rank Bounds)\nIf \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F), then rank(\ud835\udc34) \u2264 min{\ud835\udc5a, \ud835\udc5b}.\nProof: Since there is at most one pivot in each row, then rank(\ud835\udc34) \u2264 \ud835\udc5a. Also, since there\nis at most one pivot in each column, then rank(\ud835\udc34) \u2264 \ud835\udc5b.\nComparing the rank of the coefficient matrix of a system of linear equations to the rank of\nits augmented matrix will tell us whether the system is consistent or inconsistent.76\nChapter 3\nSystems of Linear Equations\nProposition 3.6.4\n(Consistent System Test)\nLet \ud835\udc34 be the coefficient matrix of a system of linear equations and let\n[\ufe01\n\ud835\udc34 | #\u00bb\ud835\udc4f\n]\ufe01\nbe the augmented matrix of the system.\nThe system is consistent if and only if\nrank(\ud835\udc34) = rank\n(\ufe01 [\ufe01\n\ud835\udc34 | #\u00bb\ud835\udc4f\n]\ufe01 )\ufe01\n.\nProof: Suppose that we perform a sequence of EROs on\n[\ufe01\n\ud835\udc34 | #\u00bb\ud835\udc4f\n]\ufe01\nto manipulate it into its\nRREF, which we will call\n[\ufe01\n\ud835\udc45 | #\u00bb\ud835\udc50\n]\ufe01\n. If we perform the same sequence of EROs on \ud835\udc34, we will\nobtain the matrix \ud835\udc45, which is the RREF of \ud835\udc34. The only difference between \ud835\udc45 and\n[\ufe01\n\ud835\udc45 | #\u00bb\ud835\udc50\n]\ufe01\nis that\n[\ufe01\n\ud835\udc45 | #\u00bb\ud835\udc50\n]\ufe01\nhas an additional column. Therefore, rank(\ud835\udc34) \u2264 rank\n(\ufe01 [\ufe01\n\ud835\udc34 | #\u00bb\ud835\udc4f\n]\ufe01 )\ufe01\n.\nAssume that the system is inconsistent. Then\n[\ufe01\n\ud835\udc45 | #\u00bb\ud835\udc50\n]\ufe01\ncontains a row of the form [0 \u00b7 \u00b7 \u00b7 0|1]\nand so\n[\ufe01\n\ud835\udc45 | #\u00bb\ud835\udc50\n]\ufe01\nhas a pivot in its final column. Therefore, rank(\ud835\udc34) < rank\n(\ufe01 [\ufe01\n\ud835\udc34 | #\u00bb\ud835\udc4f\n]\ufe01 )\ufe01\n.\nAssume that the system is consistent. Then\n[\ufe01\n\ud835\udc45 | #\u00bb\ud835\udc50\n]\ufe01\ndoes not contain a row of the form\n[0 \u00b7 \u00b7 \u00b7 0|1] and so \ud835\udc45 and [\ud835\udc45|#\u00bb\ud835\udc50 ] have the same pivots. Therefore, rank(\ud835\udc34) = rank\n(\ufe01 [\ufe01\n\ud835\udc34 | #\u00bb\ud835\udc4f\n]\ufe01 )\ufe01\n.\nIn summary, the system is consistent if and only if rank(\ud835\udc34) = rank\n(\ufe01 [\ufe01\n\ud835\udc34 | #\u00bb\ud835\udc4f\n]\ufe01 )\ufe01\n.\nExample 3.6.5\nSuppose we have a system of linear equations and we perform EROs on the augmented\nmatrix to obtain the following REF.\n\u23a1\n\u23a2\u23a2\u23a3\n2\n\u22125\n5\n\u22127\n4\n0\n0\n4\n\u22129\n3\n0\n0\n0\n5\n2\n0\n0\n0\n0\n1\n\u23a4\n\u23a5\u23a5\u23a6\nDetermine whether the system is consistent or inconsistent.\nSolution:\nThe rank of the coefficient matrix is 3 and the rank of the augmented matrix is 4. Therefore,\nthe system is inconsistent. The fact that the system is inconsistent is also evident from the\nfact that the final row of the augmented matrix corresponds to the equation 0 = 1.\nExample 3.6.6\nSuppose we have a system of linear equations and we perform EROs on the augmented\nmatrix to obtain the following REF.\n\u23a1\n\u23a2\u23a2\u23a3\n2\n\u22125\n5\n\u22127\n4\n0\n0\n4\n\u22129\n3\n0\n0\n0\n5\n2\n0\n0\n0\n0\n0\n\u23a4\n\u23a5\u23a5\u23a6\nDetermine whether the system is consistent or inconsistent.\nSolution: The ranks of the coefficient matrix and the augmented matrix are both 3.\nTherefore, the system is consistent.Section 3.6\nRank and Nullity\n77\nComparing the ranks of \ud835\udc34 and\n[\ufe01\n\ud835\udc34 | #\u00bb\ud835\udc4f\n]\ufe01\ngives us a quick way of determining whether or not\na system of linear equations is consistent.\nIf the system is consistent, then we usually want to know how many parameters, if any,\nappear in the solution set. We can also answer this question using rank(\ud835\udc34), as our next\nresult shows.\nTheorem 3.6.7\n(System Rank Theorem)\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F) with rank(\ud835\udc34) = \ud835\udc5f.\n(a) Let #\u00bb\ud835\udc4f \u2208 F\ud835\udc5a. If the system of linear equations with augmented matrix [\ud835\udc34 | #\u00bb\ud835\udc4f ] is consis-\ntent, then the solution set to this system will contain \ud835\udc5b \u2212 \ud835\udc5f parameters.\n(b) The system with augmented matrix\n[\ufe01\n\ud835\udc34 | #\u00bb\ud835\udc4f\n]\ufe01\nis consistent for every #\u00bb\ud835\udc4f \u2208 F\ud835\udc5a if and only\nif \ud835\udc5f = \ud835\udc5a.\nProof:\n(a) Since \ud835\udc34 has \ud835\udc5b columns, the system of equations has \ud835\udc5b variables.\nSince\nrank(\ud835\udc34) = \ud835\udc5f, RREF(\ud835\udc34) will have \ud835\udc5f pivot columns. Therefore, the system will have \ud835\udc5f\nbasic variables and \ud835\udc5b\u2212\ud835\udc5f free variables. In determining the solution set, we assign each\nfree variable a parameter. Therefore, the solution set will contain \ud835\udc5b \u2212 \ud835\udc5f parameters.\n(b) We prove the contrapositive which says that the system with augmented matrix\n[\ufe01\n\ud835\udc34 | #\u00bb\ud835\udc4f\n]\ufe01\nis inconsistent for some #\u00bb\ud835\udc4f \u2208 F\ud835\udc5a if and only if \ud835\udc5f \u0338= \ud835\udc5a.\nWe begin with the forward direction and assume that the system with augmented\nmatrix\n[\ufe01\n\ud835\udc34 | #\u00bb\ud835\udc4f\n]\ufe01\nis inconsistent for some #\u00bb\ud835\udc4f \u2208 F\ud835\udc5a. Then, as in the proof of Proposition\n3.6.4 (Consistent System Test), RREF\n(\ufe01 [\ufe01\n\ud835\udc34 | #\u00bb\ud835\udc4f\n]\ufe01 )\ufe01\nwill include a row of the form\n[0 \u00b7 \u00b7 \u00b7 0|1]. Therefore, RREF(\ud835\udc34) will include a row of all zeros. Since RREF(\ud835\udc34) has \ud835\udc5a\nrows, it follows that rank(\ud835\udc34) < \ud835\udc5a.\nFor the backward direction we assume that \ud835\udc5f \u0338= \ud835\udc5a.\nBy Proposition 3.6.3 (Rank\nBounds), we get that \ud835\udc5f < \ud835\udc5a.\nIf we let \ud835\udc45 = RREF(\ud835\udc34), then \ud835\udc45 must include a\nrow of all zeros. Consider the augmented matrix\n[\ufe01\n\ud835\udc45 | #\u00bb\ud835\udc52 \ud835\udc5a\n]\ufe01\n, where #\u00bb\ud835\udc52 \ud835\udc5a is the vector\nfrom the standard basis of F\ud835\udc5a whose \ud835\udc5a\ud835\udc61\u210e component is 1 with all other components\n0. It corresponds to an inconsistent system. Since all EROs are reversible, we can\napply to\n[\ufe01\n\ud835\udc45 | #\u00bb\ud835\udc52 \ud835\udc5a\n]\ufe01\nthe reverse of the EROs needed to row reduce \ud835\udc34 to \ud835\udc45. Applying\nthese reverse EROs will result in an augmented matrix of the form\n[\ufe01\n\ud835\udc34 | #\u00bb\ud835\udc4f\n]\ufe01\n, for some\n#\u00bb\ud835\udc4f \u2208 F\ud835\udc5a.\nThe matrix is row equivalent to\n[\ufe01\n\ud835\udc45 | #\u00bb\ud835\udc52 \ud835\udc5a\n]\ufe01\n.\nTherefore,\n[\ufe01\n\ud835\udc34 | #\u00bb\ud835\udc4f\n]\ufe01\nis the\naugmented matrix of an inconsistent system.\nDefinition 3.6.8\nNullity\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F) with rank(\ud835\udc34) = \ud835\udc5f. We define the nullity of \ud835\udc34, written nullity(\ud835\udc34), to be\nthe integer \ud835\udc5b \u2212 \ud835\udc5f.78\nChapter 3\nSystems of Linear Equations\nThus Theorem 3.6.7 (System Rank Theorem) shows that, if\n[\ufe01\n\ud835\udc34 | #\u00bb\ud835\udc4f\n]\ufe01\nis the augmented\nmatrix of a consistent system, the number of parameters in the solution set of this system\nis given by nullity(\ud835\udc34).\nExample 3.6.9\nReturning to Example 3.6.6, we have an augmented matrix with the following REF:\n\u23a1\n\u23a2\u23a2\u23a3\n2\n\u22125\n5\n\u22127\n4\n0\n0\n4\n\u22129\n3\n0\n0\n0\n5\n2\n0\n0\n0\n0\n0\n\u23a4\n\u23a5\u23a5\u23a6 .\nHow many parameters will there be in the solution set of the corresponding system?\nSolution:\nWe already determined that this system was consistent. The system has four variables and\nthree pivots. Using Theorem 3.6.7 (System Rank Theorem), the number of parameters in\nthe solution set to this system is 4 \u2212 3 = 1 (i.e. the nullity is 1). The variable \ud835\udc652 is a free\nvariable because the second column is not a pivot column. All other variables are basic.\n3.7", "Homogeneous and Non-Homogeneous Systems, Nullspace\nWe examine a series of examples that will help us state general facts about solving systems\nof linear equations.\nExample 3.7.1\nSolve the following system of linear equations:\n\ud835\udc651\n\u22122\ud835\udc652\n\u2212\ud835\udc653\n+3\ud835\udc654\n=\n1\n2\ud835\udc651\n\u22124\ud835\udc652\n+\ud835\udc653\n=\n5\n\ud835\udc651\n\u22122\ud835\udc652\n+2\ud835\udc653\n\u22123\ud835\udc654\n=\n4\n.\nSolution:\nThe augmented matrix\n[\ufe01\n\ud835\udc34 | #\u00bb\ud835\udc4f\n]\ufe01\nfor the system is\n\u23a1\n\u23a3\n1\n\u22122\n\u22121\n3\n1\n2\n\u22124\n1\n0\n5\n1\n\u22122\n2\n\u22123\n4\n\u23a4\n\u23a6 .\nWe perform the following EROs.\n{\ufe03\n\ud835\udc452 \u2192 \u22122\ud835\udc451 + \ud835\udc452\n\ud835\udc453 \u2192 \u2212\ud835\udc451 + \ud835\udc453\ngives\n\u23a1\n\u23a3\n1\n\u22122\n\u22121\n3\n1\n0\n0\n3\n\u22126\n3\n0\n0\n3\n\u22126\n3\n\u23a4\n\u23a6 .\n\ud835\udc452 \u2192 1\n3\ud835\udc452 gives\n\u23a1\n\u23a3\n1\n\u22122\n\u22121\n3\n1\n0\n0\n1\n\u22122\n1\n0\n0\n3\n\u22126\n3\n\u23a4\n\u23a6 .\n\ud835\udc453 \u2192 \u22123\ud835\udc452 + 3\ud835\udc453 gives\n\u23a1\n\u23a3\n1\n\u22122\n\u22121\n3\n1\n0\n0\n1\n\u22122\n1\n0\n0\n0\n0\n0\n\u23a4\n\u23a6 .Section 3.7\nHomogeneous and Non-Homogeneous Systems, Nullspace\n79\nThis matrix is in REF and since rank(\ud835\udc34) = rank\n(\ufe01[\ufe01\n\ud835\udc34 | #\u00bb\ud835\udc4f\n]\ufe01)\ufe01\n= 2, then we conclude that\nthis system is consistent.\nWe perform the following ERO.\n\ud835\udc451 \u2192 \ud835\udc451 + \ud835\udc452 gives\n\u23a1\n\u23a3\n1\n\u22122\n0\n1\n2\n0\n0\n1\n\u22122\n1\n0\n0\n0\n0\n0\n\u23a4\n\u23a6 .\nThis matrix is in RREF. Since there are four variables and rank(\ud835\udc34) = 2, the number of\nparameters is 4 \u2212 2 = 2. We let the free variables \ud835\udc652 and \ud835\udc654 be \ud835\udc60 and \ud835\udc61 respectively, where\n\ud835\udc60, \ud835\udc61 \u2208 R.\nSolving for the basic variables, we get \ud835\udc651 = 2+2\ud835\udc60\u2212\ud835\udc61 and \ud835\udc653 = 1+2\ud835\udc61, for \ud835\udc60, \ud835\udc61 \u2208 R. Therefore,\nthe solution set is\n\ud835\udc46 =\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n2 + 2\ud835\udc60 \u2212 \ud835\udc61\n\ud835\udc60\n1 + 2\ud835\udc61\n\ud835\udc61\n\u23a4\n\u23a5\u23a5\u23a6 : \ud835\udc60, \ud835\udc61 \u2208 R\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n=\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n2\n0\n1\n0\n\u23a4\n\u23a5\u23a5\u23a6 + \ud835\udc60\n\u23a1\n\u23a2\u23a2\u23a3\n2\n1\n0\n0\n\u23a4\n\u23a5\u23a5\u23a6 + \ud835\udc61\n\u23a1\n\u23a2\u23a2\u23a3\n\u22121\n0\n2\n1\n\u23a4\n\u23a5\u23a5\u23a6 : \ud835\udc60, \ud835\udc61 \u2208 R\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n.\nExample 3.7.2\nSolve the following system of linear equations:\n\ud835\udc651\n\u22122\ud835\udc652\n\u2212\ud835\udc653\n+3\ud835\udc654\n=\n1\n2\ud835\udc651\n\u22124\ud835\udc652\n+\ud835\udc653\n=\n2\n\ud835\udc651\n\u22122\ud835\udc652\n+2\ud835\udc653\n\u22123\ud835\udc654\n=\n3\n.\nSolution:\nThe augmented matrix is:\n\u23a1\n\u23a3\n1\n\u22122\n\u22121\n3\n1\n2\n\u22124\n1\n0\n2\n1\n\u22122\n2\n\u22123\n3\n\u23a4\n\u23a6 .\nThe coefficient matrix for this system is exactly the same as it was for the previous system.\nSo we perform the exact same sequence of EROs to obtain the following augmented matrix.\n(Only the constant terms will be different.)\n\u23a1\n\u23a3\n1\n\u22122\n\u22121\n3\n1\n0\n0\n1\n\u22122\n0\n0\n0\n0\n0\n2\n\u23a4\n\u23a6 .\nThis matrix is in REF and since rank(\ud835\udc34) = 2 is not equal to rank\n(\ufe01[\ufe01\n\ud835\udc34 | #\u00bb\ud835\udc4f\n]\ufe01)\ufe01\n= 3, we con-\nclude that this system is inconsistent. (We could also notice that the third row corresponds\nto the equation 0 = 2.)\nThe solution set is \ud835\udc47 = \u2205.80\nChapter 3\nSystems of Linear Equations\nExample 3.7.3\nSolve the following system of linear equations:\n\ud835\udc651\n\u22122\ud835\udc652\n\u2212\ud835\udc653\n+3\ud835\udc654\n=\n\u22121\n2\ud835\udc651\n\u22124\ud835\udc652\n+\ud835\udc653\n=\n4\n\ud835\udc651\n\u22122\ud835\udc652\n+2\ud835\udc653\n\u22123\ud835\udc654\n=\n5\n.\nSolution:\nAgain we observe that we have the same coefficient matrix and thus, we will perform the\nsame sequence of EROs as in the two previous examples to obtain the following augmented\nmatrix.\n\u23a1\n\u23a3\n1\n\u22122\n\u22121\n3\n\u22121\n0\n0\n1\n\u22122\n2\n0\n0\n0\n0\n0\n\u23a4\n\u23a6 .\nThis matrix is in REF, and since rank(\ud835\udc34) = rank\n(\ufe01[\ufe01\n\ud835\udc34 | #\u00bb\ud835\udc4f\n]\ufe01)\ufe01\n= 2, we conclude that this\nsystem is consistent. This time the RREF will be\n\u23a1\n\u23a3\n1\n\u22122\n0\n1\n1\n0\n0\n1\n\u22122\n2\n0\n0\n0\n0\n0\n\u23a4\n\u23a6 .\nSince there are four variables and rank(\ud835\udc34) = 2, then the number of parameters is 4\u22122 = 2.\nWe let the free variables \ud835\udc652 and \ud835\udc654 be \ud835\udc60 and \ud835\udc61 respectively, where \ud835\udc60, \ud835\udc61 \u2208 R.\nSolving for the basic variables, we get \ud835\udc651 = 1+2\ud835\udc60\u2212\ud835\udc61 and \ud835\udc653 = 2+2\ud835\udc61, for \ud835\udc60, \ud835\udc61 \u2208 R. Therefore,\nthe solution set is\n\ud835\udc48 =\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n1 + 2\ud835\udc60 \u2212 \ud835\udc61\n\ud835\udc60\n2 + 2\ud835\udc61\n\ud835\udc61\n\u23a4\n\u23a5\u23a5\u23a6 : \ud835\udc60, \ud835\udc61 \u2208 R\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n=\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n1\n0\n2\n0\n\u23a4\n\u23a5\u23a5\u23a6 + \ud835\udc60\n\u23a1\n\u23a2\u23a2\u23a3\n2\n1\n0\n0\n\u23a4\n\u23a5\u23a5\u23a6 + \ud835\udc61\n\u23a1\n\u23a2\u23a2\u23a3\n\u22121\n0\n2\n1\n\u23a4\n\u23a5\u23a5\u23a6 : \ud835\udc60, \ud835\udc61 \u2208 R\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n.\nExample 3.7.4\nSolve the following system of linear equations:\n\ud835\udc651\n\u22122\ud835\udc652\n\u2212\ud835\udc653\n+3\ud835\udc654\n=\n0\n2\ud835\udc651\n\u22124\ud835\udc652\n+\ud835\udc653\n=\n0\n\ud835\udc651\n\u22122\ud835\udc652\n+2\ud835\udc653\n\u22123\ud835\udc654\n=\n0\n.\nSolution:\nOnce again, we observe that we have the same coefficient matrix and thus we will be\nperforming the same sequence of EROs as in the previous three examples. We also note\nthat this system is guaranteed to be consistent since all of the constant terms are originally\n0 and no ERO will change this fact. We can always set all of the variables to 0 to obtain a\nsolution. The RREF of this system isSection 3.7\nHomogeneous and Non-Homogeneous Systems, Nullspace\n81\n\u23a1\n\u23a3\n1\n\u22122\n0\n1\n0\n0\n0\n1\n\u22122\n0\n0\n0\n0\n0\n0\n\u23a4\n\u23a6 .\nAs before we let the free variables \ud835\udc652 and \ud835\udc654 be \ud835\udc60 and \ud835\udc61 respectively, where \ud835\udc60, \ud835\udc61 \u2208 R.\nSolving for the basic variables, we get \ud835\udc651 = 2\ud835\udc60 \u2212 \ud835\udc61 and \ud835\udc653 = 2\ud835\udc61, for \ud835\udc60, \ud835\udc61 \u2208 R. Therefore, the\nsolution set is\n\ud835\udc49 =\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n2\ud835\udc60 \u2212 \ud835\udc61\n\ud835\udc60\n2\ud835\udc61\n\ud835\udc61\n\u23a4\n\u23a5\u23a5\u23a6 : \ud835\udc60, \ud835\udc61 \u2208 R\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n=\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\ud835\udc60\n\u23a1\n\u23a2\u23a2\u23a3\n2\n1\n0\n0\n\u23a4\n\u23a5\u23a5\u23a6 + \ud835\udc61\n\u23a1\n\u23a2\u23a2\u23a3\n\u22121\n0\n2\n1\n\u23a4\n\u23a5\u23a5\u23a6 : \ud835\udc60, \ud835\udc61 \u2208 R\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n.\nNote that in this final example, the solution set, \ud835\udc49 , can be written as all linear combinations\nof the vectors\n[\ufe00\n2 1 0 0\n]\ufe00\ud835\udc47 and\n[\ufe00\n\u22121 0 2 1\n]\ufe00\ud835\udc47 . Therefore, we can write the solution set as the\nspan of these two vectors:\n\ud835\udc49 =\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\ud835\udc60\n\u23a1\n\u23a2\u23a2\u23a3\n2\n1\n0\n0\n\u23a4\n\u23a5\u23a5\u23a6 + \ud835\udc61\n\u23a1\n\u23a2\u23a2\u23a3\n\u22121\n0\n2\n1\n\u23a4\n\u23a5\u23a5\u23a6 : \ud835\udc60, \ud835\udc61 \u2208 R\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n= Span\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n2\n1\n0\n0\n\u23a4\n\u23a5\u23a5\u23a6 ,\n\u23a1\n\u23a2\u23a2\u23a3\n\u22121\n0\n2\n1\n\u23a4\n\u23a5\u23a5\u23a6\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n.\nThere are several observations we can make by comparing these four systems of linear\nequations.\nThe first observation is that the last system is the simplest to solve because all the constant\nterms are zero. We give a name to such a system and its solution set.\nDefinition 3.7.5\nHomogeneous and\nNon-homogeneous\nSystems\nWe say that a system of linear equations is homogeneous if all the constant terms on\nthe right-hand side of the equations are zero.\nOtherwise we say the system is non-\nhomogeneous.\nThus, if\n[\ufe01\n\ud835\udc34 | #\u00bb\ud835\udc4f\n]\ufe01\nis the augmented matrix of a system of linear equations, then the system\nis homogeneous if #\u00bb\ud835\udc4f = \u20d70, and non-homogeneous if #\u00bb\ud835\udc4f \u0338= \u20d70.\nAs we noted in Example 3.7.4, a homogeneous system will always be consistent. We can set\nall of the variables to 0 to obtain a solution. This solution is special in its consideration,\nand we formally define it below.\nDefinition 3.7.6\nTrivial Solution\nFor a homogeneous system with variables \ud835\udc651, \ud835\udc652, ..., \ud835\udc65\ud835\udc5b, the trivial solution is the solution\n\ud835\udc651 = \ud835\udc652 = \u00b7 \u00b7 \u00b7 = \ud835\udc65\ud835\udc5b = 0.\nMoreover, if we collect all the solutions of a homogeneous system into a single set, that set\nhas a special relationship with the matrix \ud835\udc34. We define this set formally below.82\nChapter 3\nSystems of Linear Equations\nDefinition 3.7.7\nNullspace\nThe solution set of a homogeneous system of linear equations with coefficient matrix \ud835\udc34 is\ncalled the nullspace of \ud835\udc34 and is denoted Null(\ud835\udc34).\nConsider the solution sets of the three consistent systems in our previous examples.\n\ud835\udc46 =\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n2\n0\n1\n0\n\u23a4\n\u23a5\u23a5\u23a6 + \ud835\udc60\n\u23a1\n\u23a2\u23a2\u23a3\n2\n1\n0\n0\n\u23a4\n\u23a5\u23a5\u23a6 + \ud835\udc61\n\u23a1\n\u23a2\u23a2\u23a3\n\u22121\n0\n2\n1\n\u23a4\n\u23a5\u23a5\u23a6 : \ud835\udc60, \ud835\udc61 \u2208 R\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n.\n\ud835\udc48 =\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n1\n0\n2\n0\n\u23a4\n\u23a5\u23a5\u23a6 + \ud835\udc60\n\u23a1\n\u23a2\u23a2\u23a3\n2\n1\n0\n0\n\u23a4\n\u23a5\u23a5\u23a6 + \ud835\udc61\n\u23a1\n\u23a2\u23a2\u23a3\n\u22121\n0\n2\n1\n\u23a4\n\u23a5\u23a5\u23a6 : \ud835\udc60, \ud835\udc61 \u2208 R\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n.\n\ud835\udc49 =\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\ud835\udc60\n\u23a1\n\u23a2\u23a2\u23a3\n2\n1\n0\n0\n\u23a4\n\u23a5\u23a5\u23a6 + \ud835\udc61\n\u23a1\n\u23a2\u23a2\u23a3\n\u22121\n0\n2\n1\n\u23a4\n\u23a5\u23a5\u23a6 : \ud835\udc60, \ud835\udc61 \u2208 R\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n= Span\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n2\n1\n0\n0\n\u23a4\n\u23a5\u23a5\u23a6 ,\n\u23a1\n\u23a2\u23a2\u23a3\n\u22121\n0\n2\n1\n\u23a4\n\u23a5\u23a5\u23a6\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n.\nNote that \ud835\udc49 = Null(\ud835\udc34), where \ud835\udc34 =\n\u23a1\n\u23a3\n1 \u22122 \u22121 3\n2 \u22124 1\n0\n1 \u22122 2 \u22123\n\u23a4\n\u23a6 is the common coefficient matrix of all\nthree systems.\nThe second observation is that the solution set for the homogeneous system of equations can\nbe written as the span of a set of vectors. The solution sets for the two non-homogeneous\nsystems of equations cannot be written as the span of a set of vectors because these solution\nsets do not include \u20d70.\nThe third observation is that the solution sets \ud835\udc46, \ud835\udc48 and \ud835\udc49 are very similar. To be more\nprecise, the solution sets \ud835\udc46 and \ud835\udc48 of the non-homogeneous systems differ by only a constant\nvector and the part which they have in common is \ud835\udc49 . We will return to this observation\nlater and formalize it in Theorem 3.11.6 (Solutions to \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb0 and \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f ).\nThe systems in Examples 3.7.1, 3.7.2, 3.7.3 and 3.7.4 have the same coefficient matrix, \ud835\udc34,\nbut different right-hand sides:\n\u23a1\n\u23a3\n1\n5\n4\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n1\n2\n3\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n\u22121\n4\n5\n\u23a4\n\u23a6\nand\n\u23a1\n\u23a3\n0\n0\n0\n\u23a4\n\u23a6 ,\nrespectively. To solve each of the previous four examples, we performed the same sequence\nof EROs.\nWe can solve all four systems at once using the following \u201csuper-augmented\nmatrix\u201d,\n\u23a1\n\u23a3\n1\n\u22122\n\u22121\n3\n1\n1\n\u22121\n0\n2\n\u22124\n1\n0\n5\n2\n4\n0\n1\n\u22122\n2\n\u22123\n4\n3\n5\n0\n\u23a4\n\u23a6 ,Section 3.8\nHomogeneous and Non-Homogeneous Systems, Nullspace\n83\nwhich has RREF\n\u23a1\n\u23a3\n1\n\u22122\n0\n1\n2\n1\n1\n0\n0\n0\n1\n\u22122\n1\n0\n2\n0\n0\n0\n0\n0\n0\n2\n0\n0\n\u23a4\n\u23a6 .\nWe use the RREF of the \u201csuper-augmented matrix\u201d to solve the four systems. For the first\nsystem, we need the first column after the vertical line.\n\u23a1\n\u23a3\n1\n\u22122\n0\n1\n2\n0\n0\n1\n\u22122\n1\n0\n0\n0\n0\n0\n\u23a4\n\u23a6\nThis corresponds to the system of equations\n\ud835\udc651\n\u22122\ud835\udc652\n+\ud835\udc654\n=\n2\n\ud835\udc653\n\u22122\ud835\udc654\n=\n1\n0\n=\n0\nwith solution set\n\ud835\udc46 =\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n2\n0\n1\n0\n\u23a4\n\u23a5\u23a5\u23a6 + \ud835\udc60\n\u23a1\n\u23a2\u23a2\u23a3\n2\n1\n0\n0\n\u23a4\n\u23a5\u23a5\u23a6 + \ud835\udc61\n\u23a1\n\u23a2\u23a2\u23a3\n\u22121\n0\n2\n1\n\u23a4\n\u23a5\u23a5\u23a6 : \ud835\udc60, \ud835\udc61 \u2208 R\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n.\nFor the second system, we need the second column after the vertical line.\n\u23a1\n\u23a3\n1\n\u22122\n0\n1\n1\n0\n0\n1\n\u22122\n0\n0\n0\n0\n0\n2\n\u23a4\n\u23a6\nThis is an inconsistent system and has solution set \ud835\udc47 = \u2205.\nFor the third and fourth systems we need the third and fourth columns after the vertical\nline, respectively,\n\u23a1\n\u23a3\n1\n\u22122\n0\n1\n1\n0\n0\n1\n\u22122\n2\n0\n0\n0\n0\n0\n\u23a4\n\u23a6 and\n\u23a1\n\u23a3\n1\n\u22122\n0\n1\n0\n0\n0\n1\n\u22122\n0\n0\n0\n0\n0\n0\n\u23a4\n\u23a6 .\nThese correspond to solution sets\n\ud835\udc48 =\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n1\n0\n2\n0\n\u23a4\n\u23a5\u23a5\u23a6 + \ud835\udc4e\n\u23a1\n\u23a2\u23a2\u23a3\n2\n1\n0\n0\n\u23a4\n\u23a5\u23a5\u23a6 + \ud835\udc4f\n\u23a1\n\u23a2\u23a2\u23a3\n\u22121\n0\n2\n1\n\u23a4\n\u23a5\u23a5\u23a6 : \ud835\udc4e, \ud835\udc4f \u2208 R\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\nand\n\ud835\udc49 =\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\ud835\udc60\n\u23a1\n\u23a2\u23a2\u23a3\n2\n1\n0\n0\n\u23a4\n\u23a5\u23a5\u23a6 + \ud835\udc61\n\u23a1\n\u23a2\u23a2\u23a3\n\u22121\n0\n2\n1\n\u23a4\n\u23a5\u23a5\u23a6 : \ud835\udc60, \ud835\udc61 \u2208 R\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n= Span\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n2\n1\n0\n0\n\u23a4\n\u23a5\u23a5\u23a6 ,\n\u23a1\n\u23a2\u23a2\u23a3\n\u22121\n0\n2\n1\n\u23a4\n\u23a5\u23a5\u23a6\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n,\nrespectively.84\nChapter 3\nSystems of Linear Equations\n3.8", "Solving Systems of Linear Equations over C\nThe Gauss\u2013Jordan Algorithm works just as well over C as it does over R. The only new fea-\nture is that the arithmetic is more intricate because of the complex numbers. If parameters\nare introduced in the solution, then these parameters take on all complex values instead of\njust real values.\nREMARK\nRecall that for \ud835\udc67 = \ud835\udc4e + \ud835\udc4f\ud835\udc56 \u2208 C, \ud835\udc67 \u0338= 0, that 1\n\ud835\udc67 = \ud835\udc67\n\ud835\udc67\ud835\udc67 = \ud835\udc4e \u2212 \ud835\udc4f\ud835\udc56\n\ud835\udc4e2 + \ud835\udc4f2 .\nExample 3.8.1\nSolve the following system of linear equations over C.\n(1 + \ud835\udc56) \ud835\udc671\n+(\u22122 \u2212 3\ud835\udc56)\ud835\udc672\n=\n\u221215\ud835\udc56\n(1 + 3\ud835\udc56) \ud835\udc671\n+(\u22121 \u2212 8\ud835\udc56)\ud835\udc672\n=\n15 \u2212 30\ud835\udc56\nSolution:\nThe augmented matrix is\n[\ufe02 1 + \ud835\udc56\n\u22122 \u2212 3\ud835\udc56\n\u221215\ud835\udc56\n1 + 3\ud835\udc56\n\u22121 \u2212 8\ud835\udc56\n15 \u2212 30\ud835\udc56\n]\ufe02\n.\nWe perform the following EROs.\n\ud835\udc451 \u2192\n1\n1 + \ud835\udc56\ud835\udc451\n(\ufe02\n=\n(\ufe021\n2 \u2212 1\n2\ud835\udc56\n)\ufe02\n\ud835\udc451\n)\ufe02\ngives\n[\ufe02\n1\n\u2212 5\n2 \u2212 1\n2\ud835\udc56\n\u2212 15\n2 \u2212 15\n2 \ud835\udc56\n1 + 3\ud835\udc56\n\u22121 \u2212 8\ud835\udc56\n15 \u2212 30\ud835\udc56\n]\ufe02\n.\n\ud835\udc452 \u2192 \u2212(1 + 3\ud835\udc56)\ud835\udc451 + \ud835\udc452 gives\n[\ufe021\n\u2212 5\n2 \u2212 1\n2\ud835\udc56\n\u2212 15\n2 \u2212 15\n2 \ud835\udc56\n0\n0\n0\n]\ufe02\n.\nThis matrix is in RREF. The rank of the coefficient matrix and the rank of the augmented\nmatrix are both equal to 1 and so the system is consistent. The number of parameters in\nthe solution set is 2 \u2212 1 = 1 parameter in the solution set. We let the free variable \ud835\udc672 = \ud835\udc61\nfor \ud835\udc61 \u2208 C. Solving for the basic variable \ud835\udc671 we get \ud835\udc671 = \u2212 15\n2 \u2212 15\n2 \ud835\udc56 +\n(\ufe00 5\n2 + 1\n2\ud835\udc56\n)\ufe00\n\ud835\udc61. Therefore,\nthe solution set, \ud835\udc46, is\n\ud835\udc46 =\n{\ufe02[\ufe02(\ufe00\n\u2212 15\n2 \u2212 15\n2 \ud835\udc56\n)\ufe00\n+\n(\ufe00 5\n2 + 1\n2\ud835\udc56\n)\ufe00\n\ud835\udc61\n\ud835\udc61\n]\ufe02\n: \ud835\udc61 \u2208 C\n}\ufe02\n=\n{\ufe02[\ufe02\u2212 15\n2 \u2212 15\n2 \ud835\udc56\n0\n]\ufe02\n+\n[\ufe02 5\n2 + 1\n2\ud835\udc56\n1\n]\ufe02\n\ud835\udc61 : \ud835\udc61 \u2208 C\n}\ufe02\n3.9", "Matrix\u2013Vector Multiplication\nIn this section we will define a notion of matrix\u2013vector multiplication that will be very\nuseful in our study of systems of linear equations. However, before we give the definition,\nwe will consider some different ways that we can partition a matrix.Section 3.9\nMatrix\u2013Vector Multiplication\n85\nDefinition 3.9.1\nRow Vector\nA row vector is a matrix with exactly one row. For a matrix \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F), we will denote\nthe \ud835\udc56\ud835\udc61\u210e row of \ud835\udc34 by #      \u00bb\nrow\ud835\udc56(\ud835\udc34). That is,\n#      \u00bb\nrow\ud835\udc56(\ud835\udc34) =\n[\ufe00\n\ud835\udc4e\ud835\udc561 \ud835\udc4e\ud835\udc562 \u00b7 \u00b7 \u00b7 \ud835\udc4e\ud835\udc56\ud835\udc5b\n]\ufe00\n.\nWe can write an \ud835\udc5a \u00d7 \ud835\udc5b matrix \ud835\udc34 as\n\ud835\udc34 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n#       \u00bb\nrow1(\ud835\udc34)\n#       \u00bb\nrow2(\ud835\udc34)\n...\n#        \u00bb\nrow\ud835\udc5a(\ud835\udc34)\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 .\nIn other words, we can partition \ud835\udc34 into \ud835\udc5a row vectors, each with \ud835\udc5b components.\nExample 3.9.2\nLet \ud835\udc34 =\n[\ufe025 \u22122 0\n2 1 \u22128\n]\ufe02\n. Then #       \u00bb\nrow1(\ud835\udc34) =\n[\ufe00\n5 \u22122 0\n]\ufe00\nand #       \u00bb\nrow2(\ud835\udc34) =\n[\ufe00\n2 1 \u22128\n]\ufe00\n.\nSimilarly, we can think of an \ud835\udc5a \u00d7 \ud835\udc5b matrix \ud835\udc34 as \ud835\udc34 =\n[\ufe00 #\u00bb\n\ud835\udc4e1 #\u00bb\n\ud835\udc4e2 . . . # \u00bb\n\ud835\udc4e\ud835\udc5b\n]\ufe00\n, where #\u00bb\n\ud835\udc4e\ud835\udc56 \u2208 F\ud835\udc5a. In\nother words, we can partition \ud835\udc34 into \ud835\udc5b column vectors, each with \ud835\udc5a components. We will\nuse the convention, demonstrated here, where an upper case letter refers to the matrix and\nthe corresponding lower case letter with subscripts refers to the columns.\nExample 3.9.3\nLet \ud835\udc35 =\n\u23a1\n\u23a3\n1\n2\n\u22123 \u22124\n7\n9\n\u23a4\n\u23a6. Then \ud835\udc35 =\n[\ufe01 #\u00bb\n\ud835\udc4f1\n#\u00bb\n\ud835\udc4f2\n]\ufe01\n, where #\u00bb\ud835\udc4f 1 =\n\u23a1\n\u23a3\n1\n\u22123\n7\n\u23a4\n\u23a6 and #\u00bb\ud835\udc4f 2 =\n\u23a1\n\u23a3\n2\n\u22124\n9\n\u23a4\n\u23a6.\nWe now define the product of an \ud835\udc5a \u00d7 \ud835\udc5b matrix and a (column) vector in F\ud835\udc5b.\nDefinition 3.9.4\nMatrix\u2013Vector\nMultiplication in\nTerms of the\nIndividual Entries\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F) and #\u00bb\ud835\udc65 \u2208 F\ud835\udc5b. We define the product \ud835\udc34#\u00bb\ud835\udc65 as follows:\n\ud835\udc34#\u00bb\ud835\udc65 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc4e11 \ud835\udc4e12 . . . \ud835\udc4e1\ud835\udc5b\n\ud835\udc4e21 \ud835\udc4e22 . . . \ud835\udc4e2\ud835\udc5b\n...\n...\n...\n...\n\ud835\udc4e\ud835\udc5a1 \ud835\udc4e\ud835\udc5a2 . . . \ud835\udc4e\ud835\udc5a\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc651\n\ud835\udc652\n...\n\ud835\udc65\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc4e11\ud835\udc651 + \ud835\udc4e12\ud835\udc652 + \u00b7 \u00b7 \u00b7 + \ud835\udc4e1\ud835\udc5b\ud835\udc65\ud835\udc5b\n\ud835\udc4e21\ud835\udc651 + \ud835\udc4e22\ud835\udc652 + \u00b7 \u00b7 \u00b7 + \ud835\udc4e2\ud835\udc5b\ud835\udc65\ud835\udc5b\n...\n\ud835\udc4e\ud835\udc5a1\ud835\udc651 + \ud835\udc4e\ud835\udc5a2\ud835\udc652 + \u00b7 \u00b7 \u00b7 + \ud835\udc4e\ud835\udc5a\ud835\udc5b\ud835\udc65\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 .\nREMARK\nNotice that we have defined the product of an \ud835\udc5a \u00d7 \ud835\udc5b matrix \ud835\udc34 with a vector #\u00bb\ud835\udc65 only if\n#\u00bb\ud835\udc65 \u2208 F\ud835\udc5b. The expression \ud835\udc34#\u00bb\ud835\udc66 is meaningless if #\u00bb\ud835\udc66 \u2208 F\ud835\udc58 with \ud835\udc58 \u0338= \ud835\udc5b.\nIn other words, the number of components of #\u00bb\ud835\udc65 must be equal to the number of columns\nof \ud835\udc34 for the product \ud835\udc34#\u00bb\ud835\udc65 to be defined.86\nChapter 3\nSystems of Linear Equations\nThe resulting product \ud835\udc34#\u00bb\ud835\udc65 of \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F) and #\u00bb\ud835\udc65 \u2208 F\ud835\udc5b is a vector in F\ud835\udc5a.\nThe \ud835\udc56\ud835\udc61\u210e\ncomponent of \ud835\udc34#\u00bb\ud835\udc65 is the sum\n\ud835\udc4e\ud835\udc561\ud835\udc651 + \ud835\udc4e\ud835\udc562\ud835\udc652 + \u00b7 \u00b7 \u00b7 + \ud835\udc4e\ud835\udc56\ud835\udc5b\ud835\udc65\ud835\udc5b =\n\ud835\udc5b\n\u2211\ufe01\n\ud835\udc57=1\n\ud835\udc4e\ud835\udc56\ud835\udc57\ud835\udc65\ud835\udc57 =\n\ud835\udc5b\n\u2211\ufe01\n\ud835\udc57=1\n(#      \u00bb\nrow\ud835\udc56(\ud835\udc34))\ud835\udc57\ud835\udc65\ud835\udc57.\nInformally, we can think of the sum above as something analogous to a \u201cdot product\u201d of\nthe \ud835\udc56\ud835\udc61\u210e row of \ud835\udc34 with the vector #\u00bb\ud835\udc65.\nExample 3.9.5\nCompute the product \ud835\udc34#\u00bb\ud835\udc65 where \ud835\udc34 =\n\u23a1\n\u23a3\n1 6 1\n3 4 5\n5 2 \u22123\n\u23a4\n\u23a6 and #\u00bb\ud835\udc65 =\n\u23a1\n\u23a3\n1\n\u22124\n6\n\u23a4\n\u23a6.\nSolution: We have coloured the matrix red and the vector blue to emphasize the role their\nentries play in calculating the product.\nFirst, we calculate the components of the product by calculating \u201cdot products\u201d of the rows\nof \ud835\udc34 with #\u00bb\ud835\udc65.\n\u23a1\n\u23a3\n1 6 1\n3 4 5\n5 2 \u22123\n\u23a4\n\u23a6\n\u23a1\n\u23a3\n1\n\u22124\n6\n\u23a4\n\u23a6 =\n\u23a1\n\u23a3\n(1)(1) + (6)(\u22124) + (1)(6)\n(3)(1) + (4)(\u22124) + (5)(6)\n(5)(1) + (2)(\u22124) + (\u22123)(6)\n\u23a4\n\u23a6 =\n\u23a1\n\u23a3\n\u221217\n17\n\u221221\n\u23a4\n\u23a6 .\nWe also make the observation that\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc4e11\ud835\udc651 + \ud835\udc4e12\ud835\udc652 + \u00b7 \u00b7 \u00b7 + \ud835\udc4e1\ud835\udc5b\ud835\udc65\ud835\udc5b\n\ud835\udc4e21\ud835\udc651 + \ud835\udc4e22\ud835\udc652 + \u00b7 \u00b7 \u00b7 + \ud835\udc4e2\ud835\udc5b\ud835\udc65\ud835\udc5b\n...\n\ud835\udc4e\ud835\udc5a1\ud835\udc651 + \ud835\udc4e\ud835\udc5a2\ud835\udc652 + \u00b7 \u00b7 \u00b7 + \ud835\udc4e\ud835\udc5a\ud835\udc5b\ud835\udc65\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 = \ud835\udc651\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc4e11\n\ud835\udc4e21\n...\n\ud835\udc4e\ud835\udc5a1\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 + \ud835\udc652\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc4e12\n\ud835\udc4e22\n...\n\ud835\udc4e\ud835\udc5a2\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 + \u00b7 \u00b7 \u00b7 + \ud835\udc65\ud835\udc5b\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc4e1\ud835\udc5b\n\ud835\udc4e2\ud835\udc5b\n...\n\ud835\udc4e\ud835\udc5a\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 ,\nwhich is a linear combination of the columns of \ud835\udc34. Therefore, we can re-express matrix\u2013\nvector multiplication in terms of the columns of \ud835\udc34.\nProposition 3.9.6\n(Matrix\u2013Vector Multiplication in Terms of Columns)\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F) and #\u00bb\ud835\udc65 \u2208 F\ud835\udc5b. Then\n\ud835\udc34#\u00bb\ud835\udc65 =\n[\ufe00 #\u00bb\ud835\udc4e 1 #\u00bb\ud835\udc4e 2 \u00b7 \u00b7 \u00b7 #\u00bb\ud835\udc4e \ud835\udc5b\n]\ufe00\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc651\n\ud835\udc652\n...\n\ud835\udc65\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 = \ud835\udc651 #\u00bb\ud835\udc4e 1 + \ud835\udc652 #\u00bb\ud835\udc4e 2 + \u00b7 \u00b7 \u00b7 + \ud835\udc65\ud835\udc5b #\u00bb\ud835\udc4e \ud835\udc5b.\nExample 3.9.7\nWe will compute\n\u23a1\n\u23a3\n1 6 1\n3 4 5\n5 2 \u22123\n\u23a4\n\u23a6\n\u23a1\n\u23a3\n1\n\u22124\n6\n\u23a4\n\u23a6 again, this time by thinking of the product as a linearSection 3.9\nMatrix\u2013Vector Multiplication\n87\ncombination of the columns of \ud835\udc34:\n\u23a1\n\u23a3\n1 6 1\n3 4 5\n5 2 \u22123\n\u23a4\n\u23a6\n\u23a1\n\u23a3\n1\n\u22124\n6\n\u23a4\n\u23a6 = (1)\n\u23a1\n\u23a3\n1\n3\n5\n\u23a4\n\u23a6 + (\u22124)\n\u23a1\n\u23a3\n6\n4\n2\n\u23a4\n\u23a6 + (6)\n\u23a1\n\u23a3\n1\n5\n\u22123\n\u23a4\n\u23a6\n=\n\u23a1\n\u23a3\n1\n3\n5\n\u23a4\n\u23a6 +\n\u23a1\n\u23a3\n\u221224\n\u221216\n\u22128\n\u23a4\n\u23a6 +\n\u23a1\n\u23a3\n6\n30\n\u221218\n\u23a4\n\u23a6\n=\n\u23a1\n\u23a3\n\u221217\n17\n\u221221\n\u23a4\n\u23a6 .\nExample 3.9.8\nCompute the product \ud835\udc34#\u00bb\ud835\udc65 where \ud835\udc34 =\n[\ufe02 1 + \ud835\udc56\n2 + 2\ud835\udc56\n3 \u2212 \ud835\udc56\n2 + 3\ud835\udc56\n4 + \ud835\udc56\n5 \u2212 2\ud835\udc56\n]\ufe02\nand #\u00bb\ud835\udc65 =\n\u23a1\n\u23a3\n1\n1 \u2212 \ud835\udc56\n2 \u2212 3\ud835\udc56\n\u23a4\n\u23a6.\nSolution: We compute the product in two different ways. We have coloured the matrix\nred and the vector blue to emphasize the role their entries play in calculating the product.\nFirst, we calculate the components of the product by calculating \u201cdot products\u201d of the rows\nof \ud835\udc34 with #\u00bb\ud835\udc65.\n\ud835\udc34#\u00bb\ud835\udc65 =\n[\ufe02 1 + \ud835\udc56 2 + 2\ud835\udc56 3 \u2212 \ud835\udc56\n2 + 3\ud835\udc56 4 + \ud835\udc56 5 \u2212 2\ud835\udc56\n]\ufe02\u23a1\n\u23a3\n1\n1 \u2212 \ud835\udc56\n2 \u2212 3\ud835\udc56\n\u23a4\n\u23a6\n=\n[\ufe02 (1 + \ud835\udc56)(1) + (2 + 2\ud835\udc56)(1 \u2212 \ud835\udc56) + (3 \u2212 \ud835\udc56)(2 \u2212 3\ud835\udc56)\n(2 + 3\ud835\udc56)(1) + (4 + \ud835\udc56)(1 \u2212 \ud835\udc56) + (5 \u2212 2\ud835\udc56)(2 \u2212 3\ud835\udc56)\n]\ufe02\n=\n[\ufe02 8 \u2212 10\ud835\udc56\n11 \u2212 19\ud835\udc56\n]\ufe02\n.\nSecond, we calculate the product by thinking of the product as a linear combination of the\ncolumns of \ud835\udc34.\n\ud835\udc34#\u00bb\ud835\udc65 =\n[\ufe02 1 + \ud835\udc56 2 + 2\ud835\udc56 3 \u2212 \ud835\udc56\n2 + 3\ud835\udc56 4 + \ud835\udc56 5 \u2212 2\ud835\udc56\n]\ufe02\u23a1\n\u23a3\n1\n1 \u2212 \ud835\udc56\n2 \u2212 3\ud835\udc56\n\u23a4\n\u23a6\n= (1)\n[\ufe02 1 + \ud835\udc56\n2 + 3\ud835\udc56\n]\ufe02\n+ (1 \u2212 \ud835\udc56)\n[\ufe022 + 2\ud835\udc56\n4 + \ud835\udc56\n]\ufe02\n+ (2 \u2212 3\ud835\udc56)\n[\ufe02 3 \u2212 \ud835\udc56\n5 \u2212 2\ud835\udc56\n]\ufe02\n=\n[\ufe02 1 + \ud835\udc56\n2 + 3\ud835\udc56\n]\ufe02\n+\n[\ufe02\n4\n5 \u2212 3\ud835\udc56\n]\ufe02\n+\n[\ufe023 \u2212 11\ud835\udc56\n4 \u2212 19\ud835\udc56\n]\ufe02\n=\n[\ufe02 8 \u2212 10\ud835\udc56\n11 \u2212 19\ud835\udc56\n]\ufe02\n.\nThe following useful result can be proved using Proposition 3.9.6 (Matrix\u2013Vector Multipli-\ncation in Terms of Columns).\nTheorem 3.9.9\n(Linearity of Matrix\u2013Vector Multiplication)\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F). Let #\u00bb\ud835\udc65, #\u00bb\ud835\udc66 \u2208 F\ud835\udc5b and \ud835\udc50 \u2208 F. Then88\nChapter 3\nSystems of Linear Equations\n(a) \ud835\udc34(#\u00bb\ud835\udc65 + #\u00bb\ud835\udc66 ) = \ud835\udc34#\u00bb\ud835\udc65 + \ud835\udc34#\u00bb\ud835\udc66 .\n(b) \ud835\udc34(\ud835\udc50#\u00bb\ud835\udc65) = \ud835\udc50\ud835\udc34#\u00bb\ud835\udc65.\n3.10", "Using a Matrix\u2013Vector Product to Express a System of\nLinear Equations\nConsider the system of linear equations\n\ud835\udc4e11\ud835\udc651\n+\ud835\udc4e12\ud835\udc652\n+\n\u00b7 \u00b7 \u00b7\n+\ud835\udc4e1\ud835\udc5b\ud835\udc65\ud835\udc5b\n=\n\ud835\udc4f1\n\ud835\udc4e21\ud835\udc651\n+\ud835\udc4e22\ud835\udc652\n+\n\u00b7 \u00b7 \u00b7\n+\ud835\udc4e2\ud835\udc5b\ud835\udc65\ud835\udc5b\n=\n\ud835\udc4f2\n...\n\ud835\udc4e\ud835\udc5a1\ud835\udc651\n+\ud835\udc4e\ud835\udc5a2\ud835\udc652\n+\n\u00b7 \u00b7 \u00b7\n+\ud835\udc4e\ud835\udc5a\ud835\udc5b\ud835\udc65\ud835\udc5b\n=\n\ud835\udc4f\ud835\udc5a\nwith coefficient matrix \ud835\udc34 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc4e11 \ud835\udc4e12 \u00b7 \u00b7 \u00b7 \ud835\udc4e1\ud835\udc5b\n\ud835\udc4e21 \ud835\udc4e22 \u00b7 \u00b7 \u00b7 \ud835\udc4e2\ud835\udc5b\n...\n...\n...\n...\n\ud835\udc4e\ud835\udc5a1 \ud835\udc4e\ud835\udc5a2 \u00b7 \u00b7 \u00b7 \ud835\udc4e\ud835\udc5a\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 .\nThis system can now be represented as \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f , where #\u00bb\ud835\udc65 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc651\n\ud835\udc652\n...\n\ud835\udc65\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 and #\u00bb\ud835\udc4f =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc4f1\n\ud835\udc4f2\n...\n\ud835\udc4f\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6.\nGoing forwards, we will also refer to expressions of the form \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f , with \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F),\n#\u00bb\ud835\udc65 \u2208 F\ud835\udc5a and #\u00bb\ud835\udc4f \u2208 F\ud835\udc5a, as \u201ca system of linear equations\u201d, acknowledging the equivalence of\na system of \ud835\udc5a linear equations (as given above) to the expression \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f .\nExample 3.10.1\nThe system of equations\n5\ud835\udc651\n+4\ud835\udc652\n\u22127\ud835\udc653\n+2\ud835\udc654\n=\n\u22121\n\u22126\ud835\udc651\n\u22122\ud835\udc652\n+3\ud835\udc653\n=\n2\n+3\ud835\udc652\n+5\ud835\udc653\n+5\ud835\udc654\n=\n7\ncan be represented as \ud835\udc34\u20d7\ud835\udc65 = \u20d7\ud835\udc4f, where\n\ud835\udc34 =\n\u23a1\n\u23a3\n5\n4 \u22127 2\n\u22126 \u22122 3 0\n0\n3\n5 5\n\u23a4\n\u23a6 and \u20d7\ud835\udc4f =\n\u23a1\n\u23a3\n\u22121\n2\n7\n\u23a4\n\u23a6 .\nUsing this notation and the linearity of matrix\u2013vector multiplication, we can prove a result\nthat is essentially a corollary of Theorem 3.6.7 (System Rank Theorem).Section 3.11", "Solution Sets to Systems of Linear Equations\n89\nProposition 3.10.2\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F). If for every vector #\u00bb\n\ud835\udc52\ud835\udc56 in the standard basis of F\ud835\udc5a the system of equations\n\ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\n\ud835\udc52\ud835\udc56 is consistent, then rank(\ud835\udc34) = \ud835\udc5a.\nProof: We begin by assuming that for every vector #\u00bb\n\ud835\udc52\ud835\udc56 in the standard basis of F\ud835\udc5a, the\nsystem of equations \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\n\ud835\udc52\ud835\udc56 is consistent. Let #\u00bb\n\ud835\udc65\ud835\udc56 be a solution to \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\n\ud835\udc52\ud835\udc56.\nWe know that for any vector #\u00bb\ud835\udc4f \u2208 F\ud835\udc5a, we can write #\u00bb\ud835\udc4f as a linear combination of the vectors\nin the standard basis for F\ud835\udc5a. That is, there exists \ud835\udc501, . . . , \ud835\udc50\ud835\udc5a \u2208 F such that\n#\u00bb\ud835\udc4f = \ud835\udc501 #\u00bb\n\ud835\udc521 + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc5a #  \u00bb\n\ud835\udc52\ud835\udc5a.\nUsing these scalars, the solutions #\u00bb\ud835\udc65 \ud835\udc56 to \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\n\ud835\udc52\ud835\udc56 and the linearity of matrix-vector multi-\nplication we find that\n\ud835\udc34(\ud835\udc501 #\u00bb\ud835\udc65 1 + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc5a #\u00bb\ud835\udc65 \ud835\udc5a) = \ud835\udc501\ud835\udc34#\u00bb\ud835\udc65 1 + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc5a\ud835\udc34#\u00bb\ud835\udc65 \ud835\udc5a = \ud835\udc501 #\u00bb\n\ud835\udc521 + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc5a #  \u00bb\n\ud835\udc52\ud835\udc5a = #\u00bb\ud835\udc4f .\nTherefore, \ud835\udc501 # \u00bb\n\ud835\udc651 + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc5a #  \u00bb\n\ud835\udc65\ud835\udc5a is a solution to \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f .\nThus, \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f is consistent\nfor every #\u00bb\ud835\udc4f \u2208 F\ud835\udc5a.\nTherefore, by Part (b) of Theorem 3.6.7 (System Rank Theorem),\nrank(\ud835\udc34) = \ud835\udc5a.\n3.11\nSolution Sets to Systems of Linear Equations\nLet \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f be a system of linear equations. If #\u00bb\ud835\udc4f = #\u00bb0 , then the system is homogeneous.\nIf #\u00bb\ud835\udc4f \u0338= #\u00bb0 , then the system is non-homogeneous.\nWe will consider the solution sets of\nhomogeneous and non-homogeneous systems with the same coefficient matrix.\nAs we noted in Section 3.7, a homogeneous system of linear equations is always consistent,\nsince we can always set all of the variables to 0 (the trivial solution). In other words, the\nsolution set to a homogeneous system always contains the zero vector (the trivial solution),\nand thus, it is never empty. The solution set of a non-homogeneous system does not contain\nthe trivial solution. Non-homogeneous systems may be consistent or inconsistent.\nThe next result gives another important property of the solution set to a homogeneous\nsystem.\nProposition 3.11.1\nLet \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb0 be a homogeneous system of linear equations with solution set \ud835\udc46. If #\u00bb\ud835\udc65, #\u00bb\ud835\udc66 \u2208 \ud835\udc46,\nand if \ud835\udc50 \u2208 F, then #\u00bb\ud835\udc65 + #\u00bb\ud835\udc66 \u2208 \ud835\udc46 and \ud835\udc50#\u00bb\ud835\udc65 \u2208 \ud835\udc46.\nProof: Assume that #\u00bb\ud835\udc65, #\u00bb\ud835\udc66 \u2208 \ud835\udc46. Then #\u00bb\ud835\udc65 and #\u00bb\ud835\udc66 are solutions to the homogeneous system\nand \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb0 and \ud835\udc34#\u00bb\ud835\udc66 = #\u00bb0 . Using the linearity of matrix multiplication,\n\ud835\udc34(#\u00bb\ud835\udc65 + #\u00bb\ud835\udc66 ) = \ud835\udc34#\u00bb\ud835\udc65 + \ud835\udc34#\u00bb\ud835\udc66 = #\u00bb0 + #\u00bb0 = #\u00bb0\nand\n\ud835\udc34(\ud835\udc50#\u00bb\ud835\udc65) = \ud835\udc50(\ud835\udc34#\u00bb\ud835\udc65) = \ud835\udc50(#\u00bb0 ) = #\u00bb0 .\nTherefore, #\u00bb\ud835\udc65 + #\u00bb\ud835\udc66 \u2208 \ud835\udc46 and \ud835\udc50#\u00bb\ud835\udc65 \u2208 \ud835\udc46.90\nChapter 3\nSystems of Linear Equations\nWe can combine these two results to state that\nIf #\u00bb\ud835\udc65, #\u00bb\ud835\udc66 \u2208 \ud835\udc46 and if \ud835\udc50, \ud835\udc51 \u2208 F, then \ud835\udc50#\u00bb\ud835\udc65 + \ud835\udc51#\u00bb\ud835\udc66 \u2208 \ud835\udc46.\nWe can also extend this result inductively to \ud835\udc5b vectors in \ud835\udc46 and \ud835\udc5b scalars in F. In other\nwords, given \ud835\udc5b solutions to a homogeneous system of linear equations, then any linear\ncombination of these solutions is also a solution to the homogeneous system. We say that\n\ud835\udc46 is closed under addition and scalar multiplication. This fact, along with the fact that\n\ud835\udc46 is non-empty means that \ud835\udc46 forms a type of object called a subspace. We will explore\nsubspaces later in the course.\nExample 3.11.2\nConsider the homogeneous system given in Example 3.7.4 of Section 3.7. It has coefficient\nmatrix\n\ud835\udc34 =\n\u23a1\n\u23a3\n1 \u22122 \u22121 3\n2 \u22124 1\n0\n1 \u22122 2 \u22123\n\u23a4\n\u23a6\nand solution set\n\ud835\udc49 =\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\ud835\udc60\n\u23a1\n\u23a2\u23a2\u23a3\n2\n1\n0\n0\n\u23a4\n\u23a5\u23a5\u23a6 + \ud835\udc61\n\u23a1\n\u23a2\u23a2\u23a3\n\u22121\n0\n2\n1\n\u23a4\n\u23a5\u23a5\u23a6 : \ud835\udc60, \ud835\udc61 \u2208 R\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n.\nBy choosing \ud835\udc60 = 1, \ud835\udc61 = 0 and then \ud835\udc60 = 0, \ud835\udc61 = 1, we get the solutions #\u00bb\ud835\udc65 =\n[\ufe00\n2 1 0 0\n]\ufe00\ud835\udc47\nand #\u00bb\ud835\udc66 =\n[\ufe00\n\u22121 0 2 1\n]\ufe00\ud835\udc47 , respectively. Let #\u00bb\ud835\udc67 be the following linear combination of these two\nsolutions:\n#\u00bb\ud835\udc67 = 2#\u00bb\ud835\udc65 + 3#\u00bb\ud835\udc66 =\n[\ufe00\n1 2 6 3\n]\ufe00\ud835\udc47 .\nThen\n\ud835\udc34#\u00bb\ud835\udc67 =\n\u23a1\n\u23a3\n1 \u22122 \u22121 3\n2 \u22124 1\n0\n1 \u22122 2 \u22123\n\u23a4\n\u23a6\n\u23a1\n\u23a2\u23a2\u23a3\n1\n2\n6\n3\n\u23a4\n\u23a5\u23a5\u23a6 =\n\u23a1\n\u23a3\n0\n0\n0\n\u23a4\n\u23a6 .\nAnd so #\u00bb\ud835\udc67 \u2208 \ud835\udc49 as predicted by Proposition 3.11.1.\nDefinition 3.11.3\nAssociated\nHomogeneous\nSystem\nLet \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f , where #\u00bb\ud835\udc4f \u0338= #\u00bb0 , be a non-homogeneous system of linear equations.\nThe\nassociated homogeneous system to this system is the system \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb0 .\nExample 3.11.4\n(a)\n\u23a1\n\u23a3\n1\n2 3\n\u22124 \u22125 7\n2 \u22124 6\n\u23a4\n\u23a6 #\u00bb\ud835\udc65 =\n\u23a1\n\u23a3\n0\n0\n0\n\u23a4\n\u23a6 is a homogeneous system of 3 equations in 3 unknowns.\n(b)\n\u23a1\n\u23a3\n1\n2 3 4\n\u22124 \u22125 7 \u22129\n2 \u22124 6 \u22124\n\u23a4\n\u23a6 #\u00bb\ud835\udc66 =\n\u23a1\n\u23a3\n2\n4\n6\n\u23a4\n\u23a6 is a non-homogeneous system of 3 equations in 4 unknowns,\nwith associated homogeneous system of equations\n\u23a1\n\u23a3\n1\n2 3 4\n\u22124 \u22125 7 \u22129\n2 \u22124 6 \u22124\n\u23a4\n\u23a6 #\u00bb\ud835\udc66 =\n\u23a1\n\u23a3\n0\n0\n0\n\u23a4\n\u23a6.Section 3.11\nSolution Sets to Systems of Linear Equations\n91\nDefinition 3.11.5\nParticular Solution\nLet \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f be a consistent system of linear equations. We refer to a solution of this\nsystem, # \u00bb\n\ud835\udc65\ud835\udc5d, as a particular solution to this system.\nSince a consistent system \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f either has a unique solution or it has an infinite number\nof solutions, there may be an infinite number of choices for a particular solution.\nWe can use a particular solution to a non-homogeneous system to find a relationship between\nthe non-homogeneous system and its associated homogeneous system. Specifically, we can\nexpress the solution set of a consistent, non-homogeneous system \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f in terms of a\nparticular solution to the system and the solution set of its associated homogeneous system\n\ud835\udc34#\u00bb\ud835\udc65 = #\u00bb0 as follows.\nTheorem 3.11.6\n(Solutions to \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb0 and \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f )\nLet \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f , where #\u00bb\ud835\udc4f \u0338= #\u00bb0 , be a consistent non-homogeneous system of linear equations\nwith solution set \u02dc\ud835\udc46. Let \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb0 be the associated homogeneous system with solution set\n\ud835\udc46. If # \u00bb\n\ud835\udc65\ud835\udc5d \u2208 \u02dc\ud835\udc46, then\n\u02dc\ud835\udc46 = {# \u00bb\n\ud835\udc65\ud835\udc5d + #\u00bb\ud835\udc65 : #\u00bb\ud835\udc65 \u2208 \ud835\udc46}.\nProof: Let # \u00bb\n\ud835\udc65\ud835\udc5d \u2208 \u02dc\ud835\udc46. Therefore, \ud835\udc34# \u00bb\n\ud835\udc65\ud835\udc5d = #\u00bb\ud835\udc4f . Let #\u00bb\ud835\udc65 be a solution of its associated homogeneous\nsystem. Therefore, \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb0 . To show that \u02dc\ud835\udc46 = {# \u00bb\n\ud835\udc65\ud835\udc5d + #\u00bb\ud835\udc65 : #\u00bb\ud835\udc65 \u2208 \ud835\udc46}, we will show that\n\u02dc\ud835\udc46 \u2286 {# \u00bb\n\ud835\udc65\ud835\udc5d + #\u00bb\ud835\udc65 : #\u00bb\ud835\udc65 \u2208 \ud835\udc46} and {# \u00bb\n\ud835\udc65\ud835\udc5d + #\u00bb\ud835\udc65 : #\u00bb\ud835\udc65 \u2208 \ud835\udc46} \u2286 \u02dc\ud835\udc46.\nSuppose that #\u00bb\ud835\udc66 \u2208 \u02dc\ud835\udc46. Therefore, \ud835\udc34#\u00bb\ud835\udc66 = #\u00bb\ud835\udc4f . We can write #\u00bb\ud835\udc66 as #\u00bb\ud835\udc66 = # \u00bb\n\ud835\udc65\ud835\udc5d + #\u00bb\ud835\udc66 \u2212 # \u00bb\n\ud835\udc65\ud835\udc5d. Using the\nlinearity of matrix-vector multiplication we have that\n\ud835\udc34(#\u00bb\ud835\udc66 \u2212 # \u00bb\n\ud835\udc65\ud835\udc5d) = \ud835\udc34#\u00bb\ud835\udc66 \u2212 \ud835\udc34# \u00bb\n\ud835\udc65\ud835\udc5d = #\u00bb\ud835\udc4f \u2212 #\u00bb\ud835\udc4f = #\u00bb0 ,\nwhich implies that #\u00bb\ud835\udc66 \u2212 # \u00bb\n\ud835\udc65\ud835\udc5d \u2208 \ud835\udc46. Therefore, #\u00bb\ud835\udc66 \u2208 {# \u00bb\n\ud835\udc65\ud835\udc5d + #\u00bb\ud835\udc65 : #\u00bb\ud835\udc65 \u2208 \ud835\udc46}. Thus, we have shown\nthat \u02dc\ud835\udc46 \u2286 {# \u00bb\n\ud835\udc65\ud835\udc5d + #\u00bb\ud835\udc65 : #\u00bb\ud835\udc65 \u2208 \ud835\udc46}.\nNow, suppose that #\u00bb\ud835\udc67 \u2208 {# \u00bb\n\ud835\udc65\ud835\udc5d + #\u00bb\ud835\udc65 : #\u00bb\ud835\udc65 \u2208 \ud835\udc46}. Then #\u00bb\ud835\udc67 = # \u00bb\n\ud835\udc65\ud835\udc5d + #\u00bb\ud835\udc65 1 for some #\u00bb\ud835\udc65 1 \u2208 \ud835\udc46. Since\n\u20d7\ud835\udc651 \u2208 \ud835\udc46, \ud835\udc34\u20d7\ud835\udc651 = #\u00bb0 . Again using the linearity of matrix-vector multiplication, we have that\n\ud835\udc34#\u00bb\ud835\udc67 = \ud835\udc34(# \u00bb\n\ud835\udc65\ud835\udc5d + #\u00bb\ud835\udc65 1) = \ud835\udc34# \u00bb\n\ud835\udc65\ud835\udc5d + \ud835\udc34#\u00bb\ud835\udc65 1 = #\u00bb\ud835\udc4f + #\u00bb0 = #\u00bb\ud835\udc4f .\nTherefore, #\u00bb\ud835\udc67 \u2208 \u02dc\ud835\udc46. Thus, we have shown {# \u00bb\n\ud835\udc65\ud835\udc5d + #\u00bb\ud835\udc65 : #\u00bb\ud835\udc65 \u2208 \ud835\udc46} \u2286 \u02dc\ud835\udc46.\nThe next example illustrates the idea from this theorem.\nExample 3.11.7\nLet \ud835\udc34 =\n[\ufe021 2\n2 4\n]\ufe02\n. Solve the following systems and represent their solutions sets graphically.\n(a) \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb0\n(b) \ud835\udc34#\u00bb\ud835\udc65 =\n[\ufe024\n8\n]\ufe0292\nChapter 3\nSystems of Linear Equations\n(c) \ud835\udc34#\u00bb\ud835\udc65 =\n[\ufe02\u22122\n\u22124\n]\ufe02\nSolution: We solve all three systems simultaneously by row-reducing the \u201csuper-augmented\nmatrix\u201d\n[\ufe02 1\n2\n0\n4\n\u22122\n2\n4\n0\n8\n\u22124\n]\ufe02\n.\nWe perform the ERO \u22122\ud835\udc451 + \ud835\udc452 to obtain the following matrix which is in RREF:\n[\ufe02 1\n2\n0\n4\n\u22122\n0\n0\n0\n0\n0\n]\ufe02\n.\nTherefore, the solution set to the first system, which is a homogeneous system, is\n\ud835\udc46 =\n{\ufe02[\ufe02\u22122\n1\n]\ufe02\n\ud835\udc61 : \ud835\udc61 \u2208 R\n}\ufe02\n.\nThe solution to the second system is\n\ud835\udc47 =\n{\ufe02[\ufe024\n0\n]\ufe02\n+\n[\ufe02\u22122\n1\n]\ufe02\n\ud835\udc61 : \ud835\udc61 \u2208 R\n}\ufe02\n.\nThe solution to the third system is\n\ud835\udc48 =\n{\ufe02[\ufe02\u22122\n0\n]\ufe02\n+\n[\ufe02\u22122\n1\n]\ufe02\n\ud835\udc61 : \ud835\udc61 \u2208 R\n}\ufe02\n.\nWe represent these solution sets graphically. The solution sets are labelled in the diagram.Section 3.11\nSolution Sets to Systems of Linear Equations\n93\nWe see that \ud835\udc46 is a line through the origin, which is to be expected because it is the solution\nset to a homogeneous system. The solution sets \ud835\udc47 and \ud835\udc48 are translations of the set \ud835\udc46.\nThe solution set \ud835\udc47 is obtained by translating every vector in \ud835\udc46 to the right by 4 units, which\nis equivalent to adding\n[\ufe024\n0\n]\ufe02\n, a particular solution to the system in (b), to every vector in \ud835\udc46.\nSimilarly, the solution set \ud835\udc48 is obtained by translating every vector in \ud835\udc46 to the left by 2\nunits, which is equivalent to adding\n[\ufe02\u22122\n0\n]\ufe02\n, a particular solution to the system in (c), to\nevery vector in \ud835\udc46.\nLet\u2019s consider another example in R3.\nExample 3.11.8\nLet \ud835\udc34 =\n\u23a1\n\u23a3\n1 2 3\n2 4 6\n3 6 9\n\u23a4\n\u23a6. Solve the following systems and represent their solutions sets graphically.\n(a) \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb0\n(b) \ud835\udc34#\u00bb\ud835\udc65 =\n\u23a1\n\u23a3\n6\n12\n18\n\u23a4\n\u23a6\n(c) \ud835\udc34#\u00bb\ud835\udc65 =\n\u23a1\n\u23a3\n\u22124\n\u22128\n\u221212\n\u23a4\n\u23a6\nSolution: We solve all three systems simultaneously by row-reducing the \u201csuper-augmented\nmatrix\u201d\n\u23a1\n\u23a3\n1\n2\n3\n0\n6\n\u22124\n2\n4\n6\n0\n12\n\u22128\n3\n6\n9\n0\n18\n\u221212\n\u23a4\n\u23a6 .\nWe perform the EROs \u22122\ud835\udc451 + \ud835\udc452 and \u22123\ud835\udc451 + \ud835\udc453 to obtain the following matrix which is\nin RREF:\n\u23a1\n\u23a3\n1\n2\n3\n0\n6\n\u22124\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\u23a4\n\u23a6 .\nTherefore, the solution set to the first system, which is a homogeneous system, is\n\ud835\udc46 =\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n\u22122\n1\n0\n\u23a4\n\u23a6 \ud835\udc61 +\n\u23a1\n\u23a3\n\u22123\n0\n1\n\u23a4\n\u23a6 \ud835\udc60 : \ud835\udc61, \ud835\udc60 \u2208 R\n\u23ab\n\u23ac\n\u23ad = Span\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n\u22122\n1\n0\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n\u22123\n0\n1\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad .\nThe solution to the second system is\n\ud835\udc47 =\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n6\n0\n0\n\u23a4\n\u23a6 +\n\u23a1\n\u23a3\n\u22122\n1\n0\n\u23a4\n\u23a6 \ud835\udc61 +\n\u23a1\n\u23a3\n\u22123\n0\n1\n\u23a4\n\u23a6 \ud835\udc60 : \ud835\udc61, \ud835\udc60 \u2208 R\n\u23ab\n\u23ac\n\u23ad .94\nChapter 3\nSystems of Linear Equations\nThe solution to the third system is\n\ud835\udc48 =\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n\u22124\n0\n0\n\u23a4\n\u23a6 +\n\u23a1\n\u23a3\n\u22122\n1\n0\n\u23a4\n\u23a6 \ud835\udc61 +\n\u23a1\n\u23a3\n\u22123\n0\n1\n\u23a4\n\u23a6 \ud835\udc60 : \ud835\udc61, \ud835\udc60 \u2208 R\n\u23ab\n\u23ac\n\u23ad .\nWe represent these solution sets graphically. The solution sets are labelled in the diagram\nWe see that \ud835\udc46 is a plane through the origin, which is to be expected because it is the solution\nset to a homogeneous system.\nThe solution sets \ud835\udc47 and \ud835\udc48 are translations of the set \ud835\udc46. For \ud835\udc47, every vector in \ud835\udc46 has\nbeen translated in the direction of\n\u23a1\n\u23a3\n6\n0\n0\n\u23a4\n\u23a6, a particular solution to the system in (b). For \ud835\udc48,\nevery vector in \ud835\udc46 has been translated in the direction of\n\u23a1\n\u23a3\n\u22124\n0\n0\n\u23a4\n\u23a6, a particular solution to the\nsystem in (c).\nIn the previous two examples, we see that we can find the solution set \ud835\udc48 by subtracting\nfrom every element in \ud835\udc47 a particular solution of \ud835\udc47 and then adding a particular solution of\n\ud835\udc48. Let\u2019s focus on the sets in Example 3.11.8.\nLet #\u00bb\ud835\udc67 \u2208 \ud835\udc47, and let #\u00bb\ud835\udc62 \ud835\udc5d =\n\u23a1\n\u23a3\n\u22124\n0\n0\n\u23a4\n\u23a6 and #\u00bb\ud835\udc61 \ud835\udc5d =\n\u23a1\n\u23a3\n6\n0\n0\n\u23a4\n\u23a6 be particular solutions of \ud835\udc48 and \ud835\udc47,\nrespectively. From Theorem 3.11.6 (Solutions to \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb0 and \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f ), as #\u00bb\ud835\udc67 \u2208 \ud835\udc47, we\nknow that\n#\u00bb\ud835\udc67 = #\u00bb\ud835\udc61 \ud835\udc5d + #\u00bb\ud835\udc65Section 3.11\nSolution Sets to Systems of Linear Equations\n95\nfor some #\u00bb\ud835\udc65 \u2208 \ud835\udc46, the solution set of the associated homogeneous system. From above, we\nwould express\n#\u00bb\ud835\udc65 =\n\u23a1\n\u23a3\n\u22122\n1\n0\n\u23a4\n\u23a6 \ud835\udc61 +\n\u23a1\n\u23a3\n\u22123\n0\n1\n\u23a4\n\u23a6 \ud835\udc60 for some \ud835\udc60, \ud835\udc61 \u2208 R.\nAs we can certainly write #\u00bb\ud835\udc62 \ud835\udc5d = #\u00bb\ud835\udc62 \ud835\udc5d \u2212 #\u00bb\ud835\udc61 \ud835\udc5d + #\u00bb\ud835\udc61 \ud835\udc5d and any vector #\u00bb\ud835\udc62 \u2208 \ud835\udc48 as #\u00bb\ud835\udc62 = #\u00bb\ud835\udc62 \ud835\udc5d + #\u00bb\ud835\udc65 for\nsome #\u00bb\ud835\udc65 \u2208 \ud835\udc46 by Theorem 3.11.6 (Solutions to \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb0 and \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f ), we have\n\ud835\udc48 = {#\u00bb\ud835\udc62 \ud835\udc5d + #\u00bb\ud835\udc65 : #\u00bb\ud835\udc65 \u2208 \ud835\udc46}\n=\n{\ufe00(\ufe00#\u00bb\ud835\udc62 \ud835\udc5d \u2212 #\u00bb\ud835\udc61 \ud835\udc5d + #\u00bb\ud835\udc61 \ud835\udc5d\n)\ufe00\n+ #\u00bb\ud835\udc65 : #\u00bb\ud835\udc65 \u2208 \ud835\udc46\n}\ufe00\n= {\n(\ufe00#\u00bb\ud835\udc62 \ud835\udc5d \u2212 #\u00bb\ud835\udc61 \ud835\udc5d\n)\ufe00\n+\n(\ufe00#\u00bb\ud835\udc61 \ud835\udc5d + #\u00bb\ud835\udc65\n)\ufe00\n\u23df\n \u23de\n \nelement of \ud835\udc47\n: #\u00bb\ud835\udc65 \u2208 \ud835\udc46}\n=\n{\ufe00(\ufe00#\u00bb\ud835\udc62 \ud835\udc5d \u2212 #\u00bb\ud835\udc61 \ud835\udc5d\n)\ufe00\n+ #\u00bb\ud835\udc67 : #\u00bb\ud835\udc67 \u2208 \ud835\udc47\n}\ufe00\n.\nThis holds in general and provides a nice way to understand the relationships between\nparallel lines and between parallel planes. We formalize this discussion below.\nCorollary 3.11.9\n(Solutions to \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f and \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc50 )\nConsider the two consistent, non-homogeneous systems\n\ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f , and \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc50 ,\nwhere #\u00bb\ud835\udc4f \u0338= #\u00bb\ud835\udc50 . If \u02dc\ud835\udc46\ud835\udc4f and \u02dc\ud835\udc46\ud835\udc50 are their respective solution sets, with particular solutions #\u00bb\n\ud835\udc65\ud835\udc4f\nand #\u00bb\n\ud835\udc65\ud835\udc50, respectively, then\n\u02dc\ud835\udc46\ud835\udc50 = {(#\u00bb\n\ud835\udc65\ud835\udc50 \u2212 #\u00bb\n\ud835\udc65\ud835\udc4f) + #\u00bb\ud835\udc67 : #\u00bb\ud835\udc67 \u2208 \u02dc\ud835\udc46\ud835\udc4f}.\nWe can use this result to help us find the solution set to a consistent, non-homogeneous\nsystem, provided we have a particular solution to the system and we have the solution set\nto another consistent, non-homogeneous system which shares the coefficient matrix. Note\nthat finding a particular solution of a system is not always a simple task.\nExample 3.11.10\nUsing Example 3.11.8, solve the consistent non-homogeneous system \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc50 using the\nsolution to \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f , where\n\ud835\udc34 =\n\u23a1\n\u23a3\n1 2 3\n2 4 6\n3 6 9\n\u23a4\n\u23a6 and #\u00bb\ud835\udc4f =\n\u23a1\n\u23a3\n6\n12\n18\n\u23a4\n\u23a6 , #\u00bb\ud835\udc50 =\n\u23a1\n\u23a3\n1\n2\n3\n\u23a4\n\u23a6 .\nSolution: From Example 3.11.8, we have that the solution set to \ud835\udc34#\u00bb\ud835\udc65 =\n[\ufe00\n6 12 18\n]\ufe00\ud835\udc47 is\n\ud835\udc47 = \u02dc\ud835\udc46\ud835\udc4f =\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n6\n0\n0\n\u23a4\n\u23a6 +\n\u23a1\n\u23a3\n\u22122\n1\n0\n\u23a4\n\u23a6 \ud835\udc61 +\n\u23a1\n\u23a3\n\u22123\n0\n1\n\u23a4\n\u23a6 \ud835\udc60 : \ud835\udc61, \ud835\udc60 \u2208 R\n\u23ab\n\u23ac\n\u23ad .\nBy inspection, we can see that\n[\ufe00\n1 0 0\n]\ufe00\ud835\udc47 is a particular solution to \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc50 .96\nChapter 3\nSystems of Linear Equations\nTherefore, by Corollary 3.11.9 (Solutions to \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f and \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc50 ), the solution set to\n\ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc50 is\n\u02dc\ud835\udc46\ud835\udc50 =\n{\ufe03 \u239b\n\u239d\n\u23a1\n\u23a3\n1\n0\n0\n\u23a4\n\u23a6 \u2212\n\u23a1\n\u23a3\n6\n0\n0\n\u23a4\n\u23a6\n\u239e\n\u23a0 +\n\u23a1\n\u23a3\n6\n0\n0\n\u23a4\n\u23a6 +\n\u23a1\n\u23a3\n\u22122\n1\n0\n\u23a4\n\u23a6 \ud835\udc61 +\n\u23a1\n\u23a3\n\u22123\n0\n1\n\u23a4\n\u23a6 \ud835\udc60\n\u23df\n \u23de\n \n#\u00bb\ud835\udc67 \u2208 \u02dc\ud835\udc46\ud835\udc4f\n: \ud835\udc61, \ud835\udc60 \u2208 R\n}\ufe03\nNote that in the final solution above, simplifying the expression in the set gives us\n\u02dc\ud835\udc46\ud835\udc50 =\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n1\n0\n0\n\u23a4\n\u23a6 +\n\u23a1\n\u23a3\n\u22122\n1\n0\n\u23a4\n\u23a6 \ud835\udc61 +\n\u23a1\n\u23a3\n\u22123\n0\n1\n\u23a4\n\u23a6 \ud835\udc60 : \ud835\udc61, \ud835\udc60 \u2208 R\n\u23ab\n\u23ac\n\u23ad =\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n1\n0\n0\n\u23a4\n\u23a6 + #\u00bb\ud835\udc65 : #\u00bb\ud835\udc65 \u2208 \ud835\udc46\n\u23ab\n\u23ac\n\u23ad ,\nwhere \ud835\udc46 is the solution set of the associated homogeneous system, which is in alignment\nwith Theorem 3.11.6 (Solutions to \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb0 and \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f ).Chapter 4\nMatrices\n4.1", "The Column and Row Spaces of a Matrix\nIn the previous chapter, we introduced the concept of a matrix, which was built from the\ncoefficients of a system of equations. It turns out that matrices are interesting and powerful\nmathematical objects all by themselves. In this chapter, we will explore matrices further.\nWe saw in Proposition 3.9.6 that the matrix\u2013vector product \ud835\udc34#\u00bb\ud835\udc65 is a linear combination of\nthe columns of \ud835\udc34. We give the set of all linear combinations of the columns of \ud835\udc34 a name.\nDefinition 4.1.1\nColumn Space\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F). We define the column space of \ud835\udc34, denoted by Col(\ud835\udc34), to be the span\nof the columns of \ud835\udc34. That is,\nCol(\ud835\udc34) = Span{#\u00bb\n\ud835\udc4e1, #\u00bb\n\ud835\udc4e2, . . . , # \u00bb\n\ud835\udc4e\ud835\udc5b}.\nProposition 4.1.2\n(Consistent System and Column Space)\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F) and #\u00bb\ud835\udc4f \u2208 F\ud835\udc5a. The system of linear equations \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f is consistent\nif and only if #\u00bb\ud835\udc4f \u2208 Col(\ud835\udc34).\nProof: We must prove the statement in both directions. We begin with the forward direc-\ntion. Assume that there exists a vector #\u00bb\ud835\udc66 =\n[\ufe00\n\ud835\udc661 \ud835\udc662 \u00b7 \u00b7 \u00b7 \ud835\udc66\ud835\udc5b\n]\ufe00\ud835\udc47 such that \ud835\udc34#\u00bb\ud835\udc66 = #\u00bb\ud835\udc4f . Thus,\n[\ufe00 #\u00bb\n\ud835\udc4e1 #\u00bb\n\ud835\udc4e2 \u00b7 \u00b7 \u00b7 # \u00bb\n\ud835\udc4e\ud835\udc5b\n]\ufe00 [\ufe00\n\ud835\udc661 \ud835\udc662 \u00b7 \u00b7 \u00b7 \ud835\udc66\ud835\udc5b\n]\ufe00\ud835\udc47 = #\u00bb\ud835\udc4f .\nTherefore,\n\ud835\udc661 #\u00bb\n\ud835\udc4e1 + \ud835\udc662 #\u00bb\n\ud835\udc4e2 + \u00b7 \u00b7 \u00b7 + \ud835\udc66\ud835\udc5b # \u00bb\n\ud835\udc4e\ud835\udc5b = #\u00bb\ud835\udc4f .\nThus, #\u00bb\ud835\udc4f is a linear combination of the columns of the matrix \ud835\udc34, and so #\u00bb\ud835\udc4f \u2208 Col(\ud835\udc34).\nNow we prove the backward direction. Assume that #\u00bb\ud835\udc4f \u2208 Col(\ud835\udc34). Then\n#\u00bb\ud835\udc4f = \ud835\udc601 #\u00bb\n\ud835\udc4e1 + \ud835\udc602 #\u00bb\n\ud835\udc4e2 + \u00b7 \u00b7 \u00b7 + \ud835\udc60\ud835\udc5b # \u00bb\n\ud835\udc4e\ud835\udc5b\nfor some \ud835\udc601, \ud835\udc602, . . . , \ud835\udc60\ud835\udc5b \u2208 F. Let #\u00bb\ud835\udc60 =\n[\ufe00\n\ud835\udc601 \ud835\udc602 \u00b7 \u00b7 \u00b7 \ud835\udc60\ud835\udc5b\n]\ufe00\ud835\udc47 . Then\n\ud835\udc34#\u00bb\ud835\udc60 = \ud835\udc601 #\u00bb\n\ud835\udc4e1 + \ud835\udc602 #\u00bb\n\ud835\udc4e2 + \u00b7 \u00b7 \u00b7 + \ud835\udc60\ud835\udc5b # \u00bb\n\ud835\udc4e\ud835\udc5b = #\u00bb\ud835\udc4f .\nThus, \ud835\udc34#\u00bb\ud835\udc60 = #\u00bb\ud835\udc4f , and so #\u00bb\ud835\udc60 is a solution to the system. Therefore, \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f is consistent.\n9798\nChapter 4\nMatrices\nWe now begin our examination of a similar space for the rows of the matrix. First, we need\nthe notion of the transpose of a matrix.\nDefinition 4.1.3\nTranspose\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F). We define the transpose of \ud835\udc34, denoted \ud835\udc34\ud835\udc47 , by (\ud835\udc34\ud835\udc47 )\ud835\udc56\ud835\udc57 = (\ud835\udc34)\ud835\udc57\ud835\udc56.\nIf \ud835\udc34 is an \ud835\udc5a \u00d7 \ud835\udc5b matrix, then \ud835\udc34\ud835\udc47 is an \ud835\udc5b \u00d7 \ud835\udc5a matrix. It is formed by making all the rows\nof \ud835\udc34 into the columns of \ud835\udc34\ud835\udc47 in the order in which they appear.\nThis definition is the motivation behind the notation that we have used to write a vector\nfrom F\ud835\udc5b horizontally: #\u00bb\ud835\udc63 =\n[\ufe00\n\ud835\udc631 . . . \ud835\udc63\ud835\udc5b\n]\ufe00\ud835\udc47 .\nExample 4.1.4\nIf \ud835\udc34 =\n[\ufe021 2 \u22123\n4 \u22125 6\n]\ufe02\n, then \ud835\udc34\ud835\udc47 =\n\u23a1\n\u23a3\n1\n4\n2 \u22125\n\u22123 6\n\u23a4\n\u23a6 .\nIn Section 3.9, we introduced the idea of thinking of an \ud835\udc5a \u00d7 \ud835\udc5b matrix \ud835\udc34 as\n\ud835\udc34 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n#       \u00bb\nrow1(\ud835\udc34)\n#       \u00bb\nrow2(\ud835\udc34)\n...\n#        \u00bb\nrow\ud835\udc5a(\ud835\udc34)\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 .\nIn other words, we partition \ud835\udc34 into \ud835\udc5a row vectors, each with \ud835\udc5b components. If we transpose\nthese row vectors, we get vectors in R\ud835\udc5b. We use these vectors to define the row space of \ud835\udc34.\nDefinition 4.1.5\nRow Space\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F). We define the row space of \ud835\udc34, denoted by Row(\ud835\udc34), to be the span of\nthe transposed rows of \ud835\udc34. That is,\nRow(\ud835\udc34) = Span\n{\ufe01(\ufe00#       \u00bb\nrow1(\ud835\udc34)\n)\ufe00\ud835\udc47 ,\n(\ufe00#       \u00bb\nrow2(\ud835\udc34)\n)\ufe00\ud835\udc47 , . . . ,\n(\ufe00#        \u00bb\nrow\ud835\udc5a(\ud835\udc34)\n)\ufe00\ud835\udc47 }\ufe01\n.\nNotice that, if \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F), Row(\ud835\udc34) is a subset of F\ud835\udc5b while Col(\ud835\udc34) is a subset of F\ud835\udc5a.\nExample 4.1.6\nIf \ud835\udc34 =\n\u23a1\n\u23a2\u23a2\u23a3\n1 4 1\n2 3 \u22121\n3 2 1\n4 1 \u22121\n\u23a4\n\u23a5\u23a5\u23a6, then Row(\ud835\udc34) = Span\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n1\n4\n1\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n2\n3\n\u22121\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n3\n2\n1\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n4\n1\n\u22121\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad .\nREMARK\nSince the transposed rows of \ud835\udc34 are the columns of \ud835\udc34\ud835\udc47 , we see that Row(\ud835\udc34) = Col(\ud835\udc34\ud835\udc47 ).\nApplying EROs to a matrix does not affect the row space. We formalize this below.Section 4.2", "Matrix Equality and Multiplication\n99\nProposition 4.1.7\nLet \ud835\udc34, \ud835\udc35 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F). If \ud835\udc35 is row equivalent to \ud835\udc34, then\nRow(\ud835\udc35) = Row(\ud835\udc34).\nProof: Using the remark above, we note that Row(\ud835\udc34) = Col(\ud835\udc34\ud835\udc47 ) and Row(\ud835\udc35) = Col(\ud835\udc35\ud835\udc47 ).\nTherefore, if we can show that Col(\ud835\udc35\ud835\udc47 ) = Col(\ud835\udc34\ud835\udc47 ), then the proposition will be proved.\nWe begin by considering the case where \ud835\udc35 is obtained from \ud835\udc34 by applying exactly one ERO.\nWhen we perform a single ERO of any type to \ud835\udc34 to obtain \ud835\udc35, each column of \ud835\udc35\ud835\udc47 will be\na linear combination of the columns of \ud835\udc34\ud835\udc47 . Therefore, Col(\ud835\udc35\ud835\udc47 ) \u2286 Col(\ud835\udc34\ud835\udc47 ).\nAs we know from Theorem 3.2. 18 (Elementary Operations), the operations which re-\nverse EROs are themselves EROs. Therefore, we can obtain \ud835\udc34 from \ud835\udc35 by doing a single\nERO. Thus, every column of \ud835\udc34\ud835\udc47 is a linear combination of the columns of \ud835\udc35\ud835\udc47 . Therefore,\nCol(\ud835\udc34\ud835\udc47 ) \u2286 Col(\ud835\udc35\ud835\udc47 ) and we have that Col(\ud835\udc35\ud835\udc47 ) = Col(\ud835\udc34\ud835\udc47 ).\nIn the case that \ud835\udc35 is obtained from \ud835\udc34 by applying multiple EROs, we can apply the above\nargument multiple times, once for each of the EROs.\nREMARK\nOne might expect that a similar result would hold for the column space. That is, if \ud835\udc34, \ud835\udc35 \u2208\n\ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F), and if \ud835\udc35 is row equivalent to \ud835\udc34, then Col(\ud835\udc35) = Col(\ud835\udc34). However, this result\nis not true. For example, the matrix \ud835\udc35 =\n[\ufe021 1\n0 0\n]\ufe02\nis row equivalent to \ud835\udc34 =\n[\ufe020 0\n1 1\n]\ufe02\n, but\nCol(\ud835\udc35) = Span\n{\ufe02[\ufe021\n0\n]\ufe02}\ufe02\nwhile Col(\ud835\udc34) = Span\n{\ufe02[\ufe020\n1\n]\ufe02}\ufe02\n.\n4.2\nMatrix Equality and Multiplication\nAs a preliminary step toward discussing statements involving algebraic matrix operations,\nwe establish what it means for matrices to be equal.\nDefinition 4.2.1\nMatrix Equality\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F) and \ud835\udc35 \u2208 \ud835\udc40\ud835\udc5d\u00d7\ud835\udc5e(F). We say that \ud835\udc34 and \ud835\udc35 are equal if\n1. \ud835\udc34 and \ud835\udc35 have the same size, that is, \ud835\udc5a = \ud835\udc5d and \ud835\udc5b = \ud835\udc5e, and\n2. The corresponding entries of \ud835\udc34 and \ud835\udc35 are equal, i.e., \ud835\udc4e\ud835\udc56\ud835\udc57 = \ud835\udc4f\ud835\udc56\ud835\udc57, for all \ud835\udc56 = 1, 2, . . . , \ud835\udc5a\nand \ud835\udc57 = 1, 2, . . . , \ud835\udc5b.\nWe denote this by writing \ud835\udc34 = \ud835\udc35.\nWhile this definition seems to suggest that matrix equality should always be determined\nthrough exhaustive comparison of matrix entries, we can also uniquely identify matrices\nbased on their action on other objects. Our next theorem gives a very useful criterion for100\nChapter 4\nMatrices\nchecking that two given matrices of the same size are equal based on their behaviour in\nmatrix-vector products. It requires a preliminary lemma, which is important in its own\nright.\nLemma 4.2.2\n(Column Extraction)\nLet \ud835\udc34 =\n[\ufe00 #\u00bb\n\ud835\udc4e1 \u00b7 \u00b7 \u00b7 # \u00bb\n\ud835\udc4e\ud835\udc5b\n]\ufe00\n\u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F). Then \ud835\udc34#\u00bb\n\ud835\udc52\ud835\udc56 = #\u00bb\n\ud835\udc4e\ud835\udc56 for all \ud835\udc56 = 1, . . . , \ud835\udc5b.\nIn other words, the matrix-vector multiplication of \ud835\udc34 and the \ud835\udc56\ud835\udc61\u210e standard basis vector #\u00bb\n\ud835\udc52\ud835\udc56\nyields the \ud835\udc56\ud835\udc61\u210e column of \ud835\udc34.\nProof: According to the definition of matrix-vector multiplication,\n\ud835\udc34#\u00bb\n\ud835\udc521 =\n1 \u00b7 #\u00bb\n\ud835\udc4e1 + 0 \u00b7 #\u00bb\n\ud835\udc4e2 + 0 \u00b7 #\u00bb\n\ud835\udc4e3 + \u00b7 \u00b7 \u00b7 + 0 \u00b7 # \u00bb\n\ud835\udc4e\ud835\udc5b\n= #\u00bb\n\ud835\udc4e1,\n\ud835\udc34#\u00bb\n\ud835\udc522 =\n0 \u00b7 #\u00bb\n\ud835\udc4e1 + 1 \u00b7 #\u00bb\n\ud835\udc4e2 + 0 \u00b7 #\u00bb\n\ud835\udc4e3 + \u00b7 \u00b7 \u00b7 + 0 \u00b7 # \u00bb\n\ud835\udc4e\ud835\udc5b\n= #\u00bb\n\ud835\udc4e2,\n...\n\ud835\udc34#\u00bb\n\ud835\udc52\ud835\udc5b =\n0 \u00b7 #\u00bb\n\ud835\udc4e1 + 0 \u00b7 #\u00bb\n\ud835\udc4e2 + 0 \u00b7 #\u00bb\n\ud835\udc4e3 + \u00b7 \u00b7 \u00b7 + 1 \u00b7 # \u00bb\n\ud835\udc4e\ud835\udc5b\n= # \u00bb\n\ud835\udc4e\ud835\udc5b.\nTheorem 4.2.3\n(Equality of Matrices)\nLet \ud835\udc34, \ud835\udc35 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F). Then\n\ud835\udc34 = \ud835\udc35 if and only if \ud835\udc34#\u00bb\ud835\udc65 = \ud835\udc35 #\u00bb\ud835\udc65 for all #\u00bb\ud835\udc65 \u2208 F\ud835\udc5b.\nProof: If \ud835\udc34 = \ud835\udc35, then it is clear that \ud835\udc34#\u00bb\ud835\udc65 = \ud835\udc35 #\u00bb\ud835\udc65 for all #\u00bb\ud835\udc65 \u2208 F\ud835\udc5b.\nNow, let \ud835\udc34 =\n[\ufe00 #\u00bb\n\ud835\udc4e1 \u00b7 \u00b7 \u00b7 # \u00bb\n\ud835\udc4e\ud835\udc5b\n]\ufe00\n, \ud835\udc35 =\n[\ufe01 #\u00bb\n\ud835\udc4f1 \u00b7 \u00b7 \u00b7 #\u00bb\n\ud835\udc4f\ud835\udc5b\n]\ufe01\n, and suppose that \ud835\udc34#\u00bb\ud835\udc65 = \ud835\udc35 #\u00bb\ud835\udc65 for all #\u00bb\ud835\udc65 \u2208 F\ud835\udc5b.\nThen we can take #\u00bb\ud835\udc65 equal to the \ud835\udc56\ud835\udc61\u210e standard basis vector #\u00bb\n\ud835\udc52\ud835\udc56 and conclude that \ud835\udc34#\u00bb\n\ud835\udc52\ud835\udc56 = \ud835\udc35 #\u00bb\n\ud835\udc52\ud835\udc56\nfor all \ud835\udc56 = 1, . . . , \ud835\udc5b. But then it follows from Lemma 4.2.2 (Column Extraction) that\n\u20d7\ud835\udc4e\ud835\udc56 = \ud835\udc34#\u00bb\n\ud835\udc52\ud835\udc56 = \ud835\udc35 #\u00bb\n\ud835\udc52\ud835\udc56 = #\u00bb\ud835\udc4f\ud835\udc56.\nSince the columns of \ud835\udc34 and \ud835\udc35 are the same, we conclude that the matrices are equal.\nRecall that we can calculate the matrix\u2013vector product \ud835\udc34#\u00bb\ud835\udc65 provided the sizes of \ud835\udc34 and #\u00bb\ud835\udc65\nare compatible: we need \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F) and #\u00bb\ud835\udc65 \u2208 F\ud835\udc5b. We extend this process to multiplying\nseveral column vectors, of the correct size, by the same matrix simultaneously.\nDefinition 4.2.4\nMatrix\nMultiplication\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F) and \ud835\udc35 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5d(F). We define the matrix product \ud835\udc34\ud835\udc35 = \ud835\udc36 to be the\nmatrix \ud835\udc36 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5d(F), constructed as follows:\n\ud835\udc36 = \ud835\udc34\ud835\udc35 = \ud835\udc34\n[\ufe01 #\u00bb\n\ud835\udc4f1\n#\u00bb\n\ud835\udc4f2 \u00b7 \u00b7 \u00b7 #\u00bb\n\ud835\udc4f\ud835\udc5d\n]\ufe01\n=\n[\ufe01\n\ud835\udc34#\u00bb\n\ud835\udc4f1 \ud835\udc34#\u00bb\n\ud835\udc4f2 \u00b7 \u00b7 \u00b7 \ud835\udc34#\u00bb\n\ud835\udc4f\ud835\udc5d\n]\ufe01\n.\nThat is, the \ud835\udc57\ud835\udc61\u210e column of \ud835\udc36, #\u00bb\n\ud835\udc50\ud835\udc57, is obtained by multiplying the matrix \ud835\udc34 by the \ud835\udc57\ud835\udc61\u210e column\nof the matrix \ud835\udc35:\n#\u00bb\n\ud835\udc50\ud835\udc57 = \ud835\udc34#\u00bb\n\ud835\udc4f\ud835\udc57, for all \ud835\udc57 = 1, . . . , \ud835\udc5d.Section 4.2\nMatrix Equality and Multiplication\n101\nThus, we can construct the product \ud835\udc34\ud835\udc35, column by column, by calculating a sequence of\nmatrix\u2013vector products \ud835\udc34#\u00bb\n\ud835\udc4f\ud835\udc57.\nREMARKS\n\u2022 In calculating the product \ud835\udc34\ud835\udc35, the number of columns of the first matrix, \ud835\udc34, must be\nequal to the number of rows of the second matrix, \ud835\udc35. If these values do not match,\nthen the product is undefined.\n\u2022 Matrix multiplication is generally non-commutative, so the order of multiplication\nmatters. In other words, for matrices \ud835\udc34 and \ud835\udc35, we are not guaranteed that \ud835\udc34\ud835\udc35 = \ud835\udc35\ud835\udc34.\n\u2022 We can immediately connect the definition of matrix multiplication to our under-\nstanding of column spaces. As the \ud835\udc57\ud835\udc61\u210e column of \ud835\udc36 = \ud835\udc34\ud835\udc35 is obtained by multiplying\nthe matrix \ud835\udc34 by the \ud835\udc57\ud835\udc61\u210e column of the matrix \ud835\udc35, the \ud835\udc57\ud835\udc61\u210e column of \ud835\udc36 must be a linear\ncombination of the columns of \ud835\udc34 (by Proposition 3.9.6 (Matrix\u2013Vector Multiplication\nin Terms of Columns)), and therefore is a member of Col(\ud835\udc34).\nExample 4.2.5\nGiven \ud835\udc34 =\n\u23a1\n\u23a3\n1 2\n3 5\n8 7\n\u23a4\n\u23a6 and \ud835\udc35 =\n[\ufe02\u22121\n3\n2\n\u22124\n]\ufe02\n, calculate the products \ud835\udc34\ud835\udc35 and \ud835\udc35\ud835\udc34 if possible.\nSolution: First, we note that the number of columns of \ud835\udc34 is equal to the number of rows\nof \ud835\udc35 and so the product is defined. Also, since \ud835\udc34 has three rows and \ud835\udc35 has two columns,\nthen the size of the product will be 3 \u00d7 2.\nWe have coloured the entries of \ud835\udc34 blue and the entries of \ud835\udc35 red to emphasize the role their\nentries play in calculating the product.\n\u23a1\n\u23a3\n1 2\n3 5\n8 7\n\u23a4\n\u23a6\n[\ufe02\u22121\n3\n2\n\u22124\n]\ufe02\n=\n\u23a1\n\u23a3\n\u23a1\n\u23a3\n1 2\n3 5\n8 7\n\u23a4\n\u23a6\n[\ufe02\u22121\n2\n]\ufe02\n\u23a1\n\u23a3\n1 2\n3 5\n8 7\n\u23a4\n\u23a6\n[\ufe02 3\n\u22124\n]\ufe02\u23a4\n\u23a6\n=\n\u23a1\n\u23a3\n(1)(\u22121) + (2)(2)\n(1)(3) + (2)(\u22124)\n(3)(\u22121) + (5)(2)\n(3)(3) + (5)(\u22124)\n(8)(\u22121) + (7)(2)\n(8)(3) + (7)(\u22124)\n\u23a4\n\u23a6\n=\n\u23a1\n\u23a3\n3 \u22125\n7 \u221211\n6 \u22124\n\u23a4\n\u23a6 .\nThe product \ud835\udc35\ud835\udc34 is undefined, since \ud835\udc35 has 2 columns, \ud835\udc34 has 3 rows and 2 \u0338= 3.\nExample 4.2.6\nGiven \ud835\udc34 =\n[\ufe02 2 \u2212 \ud835\udc56 1 \u2212 2\ud835\udc56\n3 \u2212 2\ud835\udc56 1 \u2212 3\ud835\udc56\n]\ufe02\nand \ud835\udc35 =\n[\ufe02 1 + \ud835\udc56\n\u22122 + \ud835\udc56\n\u22121 + \ud835\udc56 3 + 2\ud835\udc56\n]\ufe02\n, calculate the products \ud835\udc34\ud835\udc35 and\n\ud835\udc35\ud835\udc34 if possible.\nSolution: First, we note that the number of columns of \ud835\udc34 is equal to the number of rows\nof \ud835\udc35 and so the product is defined. Also, since \ud835\udc34 has two rows and \ud835\udc35 has two columns,\nthen the size of the product will be 2 \u00d7 2.102\nChapter 4\nMatrices\nWe have coloured the entries of \ud835\udc34 blue and the entries of \ud835\udc35 red to emphasize the role their\nentries play in calculating the product.\n[\ufe02 2 \u2212 \ud835\udc56 1 \u2212 2\ud835\udc56\n3 \u2212 2\ud835\udc56 1 \u2212 3\ud835\udc56\n]\ufe02[\ufe02 1 + \ud835\udc56\n\u22122 + \ud835\udc56\n\u22121 + \ud835\udc56 3 + 2\ud835\udc56\n]\ufe02\n=\n[\ufe02[\ufe02 2 \u2212 \ud835\udc56 1 \u2212 2\ud835\udc56\n3 \u2212 2\ud835\udc56 1 \u2212 3\ud835\udc56\n]\ufe02[\ufe02 1 + \ud835\udc56\n\u22121 + \ud835\udc56\n]\ufe02\n[\ufe02 2 \u2212 \ud835\udc56 1 \u2212 2\ud835\udc56\n3 \u2212 2\ud835\udc56 1 \u2212 3\ud835\udc56\n]\ufe02[\ufe02\u22122 + \ud835\udc56\n3 + 2\ud835\udc56\n]\ufe02]\ufe02\n=\n[\ufe02 (2 \u2212 \ud835\udc56)(1 + \ud835\udc56) + (1 \u2212 2\ud835\udc56)(\u22121 + \ud835\udc56)\n(2 \u2212 \ud835\udc56)(\u22122 + \ud835\udc56) + (1 \u2212 2\ud835\udc56)(3 + 2\ud835\udc56)\n(3 \u2212 2\ud835\udc56)(1 + \ud835\udc56) + (1 \u2212 3\ud835\udc56)(\u22121 + \ud835\udc56)\n(3 \u2212 2\ud835\udc56)(\u22122 + \ud835\udc56) + (1 \u2212 3\ud835\udc56)(3 + 2\ud835\udc56)\n]\ufe02\n=\n[\ufe024 + 4\ud835\udc56 4\n7 + 5\ud835\udc56 5\n]\ufe02\n.\nThe product \ud835\udc35\ud835\udc34 is also defined since the number of columns of \ud835\udc35 is equal to the number\nof rows of \ud835\udc34.\n[\ufe02 1 + \ud835\udc56\n\u22122 + \ud835\udc56\n\u22121 + \ud835\udc56 3 + 2\ud835\udc56\n]\ufe02[\ufe02 2 \u2212 \ud835\udc56 1 \u2212 2\ud835\udc56\n3 \u2212 2\ud835\udc56 1 \u2212 3\ud835\udc56\n]\ufe02\n=\n[\ufe02[\ufe02 1 + \ud835\udc56\n\u22122 + \ud835\udc56\n\u22121 + \ud835\udc56 3 + 2\ud835\udc56\n]\ufe02[\ufe02 2 \u2212 \ud835\udc56\n3 \u2212 2\ud835\udc56\n]\ufe02\n[\ufe02 1 + \ud835\udc56\n\u22122 + \ud835\udc56\n\u22121 + \ud835\udc56 3 + 2\ud835\udc56\n]\ufe02[\ufe021 \u2212 2\ud835\udc56\n1 \u2212 3\ud835\udc56\n]\ufe02]\ufe02\n=\n[\ufe02 (1 + \ud835\udc56)(2 \u2212 \ud835\udc56) + (\u22122 + \ud835\udc56)(3 \u2212 2\ud835\udc56)\n(1 + \ud835\udc56)(1 \u2212 2\ud835\udc56) + (\u22122 + \ud835\udc56)(1 \u2212 3\ud835\udc56)\n(\u22121 + \ud835\udc56)(2 \u2212 \ud835\udc56) + (3 + 2\ud835\udc56)(3 \u2212 2\ud835\udc56)\n(\u22121 + \ud835\udc56)(1 \u2212 2\ud835\udc56) + (3 + 2\ud835\udc56)(1 \u2212 3\ud835\udc56)\n]\ufe02\n=\n[\ufe02\u22121 + 8\ud835\udc56 4 + 6\ud835\udc56\n12 + 3\ud835\udc56 10 \u2212 4\ud835\udc56\n]\ufe02\n.\nNotice that even though \ud835\udc34\ud835\udc35 and \ud835\udc35\ud835\udc34 are both defined, we have that \ud835\udc34\ud835\udc35 \u0338= \ud835\udc35\ud835\udc34.\nIn practice, we usually construct the product \ud835\udc34\ud835\udc35 = \ud835\udc36 one entry at a time. The entry\n(\ud835\udc36)\ud835\udc56\ud835\udc57 is in the \ud835\udc56\ud835\udc61\u210e row and the \ud835\udc57\ud835\udc61\u210e column of the product. Therefore, (\ud835\udc36)\ud835\udc56\ud835\udc57 = (#\u00bb\n\ud835\udc50\ud835\udc57)\ud835\udc56, where\n#\u00bb\n\ud835\udc50\ud835\udc57 = \ud835\udc34#\u00bb\n\ud835\udc4f\ud835\udc57. For \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F), \ud835\udc35 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5d(F), and \ud835\udc36 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5d(F), the \ud835\udc56\ud835\udc61\u210e entry of \ud835\udc34#\u00bb\n\ud835\udc4f\ud835\udc57 is\n\ud835\udc5b\n\u2211\ufe01\n\ud835\udc58=1\n\ud835\udc4e\ud835\udc56\ud835\udc58\ud835\udc4f\ud835\udc58\ud835\udc57 = \ud835\udc4e\ud835\udc561\ud835\udc4f1\ud835\udc57 + \ud835\udc4e\ud835\udc562\ud835\udc4f2\ud835\udc57 + \u00b7 \u00b7 \u00b7 + \ud835\udc4e\ud835\udc56\ud835\udc5b\ud835\udc4f\ud835\udc5b\ud835\udc57.\nThus,\n(\ud835\udc36)\ud835\udc56\ud835\udc57 = (\ud835\udc34#\u00bb\n\ud835\udc4f\ud835\udc57)\ud835\udc56 =\n\ud835\udc5b\n\u2211\ufe01\n\ud835\udc58=1\n\ud835\udc4e\ud835\udc56\ud835\udc58\ud835\udc4f\ud835\udc58\ud835\udc57.\nConsequently, in order to obtain the (\ud835\udc56, \ud835\udc57)\ud835\udc61\u210e entry of \ud835\udc34\ud835\udc35, we need to multiply the corre-\nsponding entries of the \ud835\udc56\ud835\udc61\u210e row of \ud835\udc34 and the \ud835\udc57\ud835\udc61\u210e column of \ud835\udc35 and sum them up. We can\nre-write this last expression in a more suggestive manner:\n(\ud835\udc36)\ud835\udc56\ud835\udc57 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc4e\ud835\udc561\n\ud835\udc4e\ud835\udc562\n...\n\ud835\udc4e\ud835\udc56\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 \u00b7\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc4f1\ud835\udc57\n\ud835\udc4f2\ud835\udc57\n...\n\ud835\udc4f\ud835\udc5b\ud835\udc57\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 .Section 4.3", "Arithmetic Operations on Matrices\n103\nREMARK\nThe equation above shows that the (\ud835\udc56, \ud835\udc57)\ud835\udc61\u210e entry of \ud835\udc34\ud835\udc35 may be obtained by taking the dot\nproduct of the (transposed) \ud835\udc56\ud835\udc61\u210e row of \ud835\udc34 with the \ud835\udc57\ud835\udc61\u210e column of \ud835\udc35.\nExample 4.2.7\nDetermine the (2, 2)\ud835\udc61\u210e entry of the product\n\ud835\udc34\ud835\udc35 = \ud835\udc36 =\n\u23a1\n\u23a3\n1 2\n3 5\n8 7\n\u23a4\n\u23a6\n[\ufe02\u22121\n3\n2\n\u22124\n]\ufe02\n.\nSolution: We use the second row of \ud835\udc34 and the second column of \ud835\udc35 to calculate\n\ud835\udc5022 =\n[\ufe00\n3 5\n]\ufe00\ud835\udc47 \u00b7\n[\ufe02 3\n\u22124\n]\ufe02\n=\n[\ufe023\n5\n]\ufe02\n\u00b7\n[\ufe02 3\n\u22124\n]\ufe02\n= 9 \u2212 20 = \u221211.\nExample 4.2.8\nDetermine the (2, 1)\ud835\udc61\u210e entry of the product\n\ud835\udc36\ud835\udc37 = \ud835\udc38 =\n[\ufe02 2 \u2212 \ud835\udc56 1 \u2212 2\ud835\udc56\n3 \u2212 2\ud835\udc56 1 \u2212 3\ud835\udc56\n]\ufe02[\ufe02 1 + \ud835\udc56\n\u22122 + \ud835\udc56\n\u22121 + \ud835\udc56 3 + 2\ud835\udc56\n]\ufe02\n.\nSolution: We use the second row of \ud835\udc36 and the first column of \ud835\udc37 to calculate\n\ud835\udc5221 =\n[\ufe00\n3 \u2212 2\ud835\udc56 1 \u2212 3\ud835\udc56\n]\ufe00\ud835\udc47 \u00b7\n[\ufe02 1 + \ud835\udc56\n\u22121 + \ud835\udc56\n]\ufe02\n=\n[\ufe023 \u2212 2\ud835\udc56\n1 \u2212 3\ud835\udc56\n]\ufe02\n\u00b7\n[\ufe02 1 + \ud835\udc56\n\u22121 + \ud835\udc56\n]\ufe02\n= (3 \u2212 2\ud835\udc56)(1 + \ud835\udc56) + (1 \u2212 3\ud835\udc56)(\u22121 + \ud835\udc56)\n= 7 + 5\ud835\udc56.\n4.3\nArithmetic Operations on Matrices\nIn this section, we will introduce additional operations that can be performed on matrices.\nWe will also see that, while the sets \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(R) and \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(C) are very similar to R\ud835\udc5b and\nC\ud835\udc5b, in certain respects, there also exist quite a few important distinctions between them.\nDefinition 4.3.1\nSum of Matrices\nLet \ud835\udc34, \ud835\udc35 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F).\nWe define the matrix sum \ud835\udc34 + \ud835\udc35 = \ud835\udc36 to be the matrix\n\ud835\udc36 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F) whose (\ud835\udc56, \ud835\udc57)\ud835\udc61\u210e entry is \ud835\udc50\ud835\udc56\ud835\udc57 = \ud835\udc4e\ud835\udc56\ud835\udc57 + \ud835\udc4f\ud835\udc56\ud835\udc57, for all \ud835\udc56 = 1, . . . , \ud835\udc5a and \ud835\udc57 = 1, . . . , \ud835\udc5b.104\nChapter 4\nMatrices\nREMARK\nAddition is not defined for matrices that do not have the same size.\nExample 4.3.2\nFor \ud835\udc34 =\n[\ufe020 2\n3 0\n]\ufe02\nand \ud835\udc35 =\n[\ufe021 0\n0 \u22124\n]\ufe02\n, we have the sum \ud835\udc34 + \ud835\udc35 =\n[\ufe020 2\n3 0\n]\ufe02\n+\n[\ufe021 0\n0 \u22124\n]\ufe02\n=\n[\ufe021 2\n3 \u22124\n]\ufe02\n.\nSome basic properties of matrix addition and matrix multiplication are given in the next\ntwo propositions.\nProposition 4.3.3\n(Matrix Addition)\nIf \ud835\udc34, \ud835\udc35, \ud835\udc36 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F), then\n(a) \ud835\udc34 + \ud835\udc35 = \ud835\udc35 + \ud835\udc34.\n(b) \ud835\udc34 + \ud835\udc35 + \ud835\udc36 = (\ud835\udc34 + \ud835\udc35) + \ud835\udc36 = \ud835\udc34 + (\ud835\udc35 + \ud835\udc36).\nProposition 4.3.4\n(Matrix Multiplication)\nIf \ud835\udc34, \ud835\udc35 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F), \ud835\udc36, \ud835\udc37 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5d(F) and \ud835\udc38 \u2208 \ud835\udc40\ud835\udc5d\u00d7\ud835\udc5e(F), then\n(a) (\ud835\udc34 + \ud835\udc35)\ud835\udc36 = \ud835\udc34\ud835\udc36 + \ud835\udc35\ud835\udc36.\n(b) \ud835\udc34(\ud835\udc36 + \ud835\udc37) = \ud835\udc34\ud835\udc36 + \ud835\udc34\ud835\udc37.\n(c) (\ud835\udc34\ud835\udc36)\ud835\udc38 = \ud835\udc34(\ud835\udc36\ud835\udc38) = \ud835\udc34\ud835\udc36\ud835\udc38.\nEXERCISE\nProve the previous two Propositions.\nDefinition 4.3.5\nAdditive Inverse\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F). We define the additive inverse of \ud835\udc34 to be the matrix \u2212\ud835\udc34 whose\n(\ud835\udc56, \ud835\udc57)\ud835\udc61\u210e entry is \u2212\ud835\udc4e\ud835\udc56\ud835\udc57 for all \ud835\udc56 = 1, . . . , \ud835\udc5a and \ud835\udc57 = 1, . . . , \ud835\udc5b.\nExample 4.3.6\nIf \ud835\udc34 =\n[\ufe021 2\n3 \u22124\n]\ufe02\n, then the additive inverse of \ud835\udc34 is \u2212\ud835\udc34 =\n[\ufe02\u22121 \u22122\n\u22123 4\n]\ufe02\n.\nDefinition 4.3.7\nZero Matrix\nThe \ud835\udc5a \u00d7 \ud835\udc5b zero matrix is the matrix \ud835\udcaa\ud835\udc5a\u00d7\ud835\udc5b \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F) all of whose entries are 0.Section 4.3\nArithmetic Operations on Matrices\n105\nREMARK\n1. It is important to distinguish the zero matrix \ud835\udcaa\ud835\udc5a\u00d7\ud835\udc5b from the zero scalar 0 and the\nzero vector \u20d70.\n2. Usually, the context in which the zero matrix is used is sufficient for us to determine\nits size, in which case we, denote it by \ud835\udcaa.\nExample 4.3.8\nWe have \ud835\udcaa2\u00d73 =\n[\ufe020 0 0\n0 0 0\n]\ufe02\nand \ud835\udcaa1\u00d71 = [0]. Note that \ud835\udcaa1\u00d71 is technically different from the\nzero scalar 0.\nOn the other hand, \ud835\udcaa\ud835\udc5a\u00d71 =\n\u23a1\n\u23a2\u23a3\n0\n...\n0\n\u23a4\n\u23a5\u23a6 is the zero vector in F\ud835\udc5a.\nProposition 4.3.9\n(Properties of the Additive Inverse and the Zero Matrix)\nIf \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F), then\n(a) \ud835\udcaa + \ud835\udc34 = \ud835\udc34 + \ud835\udcaa = \ud835\udc34.\n(b) \ud835\udc34 + (\u2212\ud835\udc34) = (\u2212\ud835\udc34) + \ud835\udc34 = \ud835\udcaa.\nEXERCISE\nProve the previous Proposition.\nDefinition 4.3.10\nMultiplication of a\nMatrix by a Scalar\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F) and \ud835\udc50 \u2208 F.\nWe define the product of \ud835\udc50 and \ud835\udc34 to be the matrix\n\ud835\udc50\ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F) whose (\ud835\udc56, \ud835\udc57)\ud835\udc61\u210e entry is (\ud835\udc50\ud835\udc34)\ud835\udc56\ud835\udc57 = \ud835\udc50\ud835\udc4e\ud835\udc56\ud835\udc57 for all \ud835\udc56 = 1, . . . , \ud835\udc5a and \ud835\udc57 = 1, . . . , \ud835\udc5b.\nNotice that the product (\u22121)\ud835\udc34 (of the scalar \u22121 and the matrix \ud835\udc34) is \u2212\ud835\udc34, the additive\ninverse of \ud835\udc34. That is,\n(\u22121)\ud835\udc34 = \u2212\ud835\udc34.\nSo, our notational choices are compatible. The following proposition gives some additional\nproperties of scalar multiplication.\nProposition 4.3.11\n(Properties of Multiplication of a Matrix by a Scalar)\nIf \ud835\udc34, \ud835\udc35 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F), \ud835\udc36 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc58(F), and \ud835\udc5f, \ud835\udc60 \u2208 F, then\n(a) \ud835\udc60(\ud835\udc34 + \ud835\udc35) = \ud835\udc60\ud835\udc34 + \ud835\udc60\ud835\udc35.106\nChapter 4\nMatrices\n(b) (\ud835\udc5f + \ud835\udc60)\ud835\udc34 = \ud835\udc5f\ud835\udc34 + \ud835\udc60\ud835\udc34.\n(c) \ud835\udc5f(\ud835\udc60\ud835\udc34) = (\ud835\udc5f\ud835\udc60)\ud835\udc34.\n(d) \ud835\udc60(\ud835\udc34\ud835\udc36) = (\ud835\udc60\ud835\udc34)\ud835\udc36 = \ud835\udc34(\ud835\udc60\ud835\udc36). Thus, we may write \ud835\udc60\ud835\udc34\ud835\udc36 for any of these three quantities\nunambiguously.\nEXERCISE\nProve the previous Proposition.\nOur previous results demonstrate that matrix operations behave like their scalar counter-\nparts. However, there are significant differences. For instance, while it is true that \ud835\udc4e\ud835\udc4f = \ud835\udc4f\ud835\udc4e\nfor all \ud835\udc4e, \ud835\udc4f \u2208 F, we have already seen an example of matrices \ud835\udc34 and \ud835\udc35 where \ud835\udc34\ud835\udc35 \u0338= \ud835\udc35\ud835\udc34,\neven when both \ud835\udc34\ud835\udc35 and \ud835\udc35\ud835\udc34 are defined. (See Example 4.2.6.)\nTwo other results that apply to scalars which students are tempted to apply to matrices\nare the following:\n1. If \ud835\udc4e\ud835\udc4f = \ud835\udc4e\ud835\udc50 and \ud835\udc4e \u0338= 0, then \ud835\udc4f = \ud835\udc50 (cancellation law).\n2. \ud835\udc4e\ud835\udc4f = 0 if and only if \ud835\udc4e = 0 or \ud835\udc4f = 0.\nThese results do not extend to matrix arithmetic, in general.\nExample 4.3.12\n1. Let \ud835\udc34 =\n[\ufe020 1\n0 2\n]\ufe02\n, \ud835\udc35 =\n[\ufe021 1\n3 4\n]\ufe02\n, and \ud835\udc36 =\n[\ufe022 5\n3 4\n]\ufe02\n. Then \ud835\udc34\ud835\udc35 = \ud835\udc34\ud835\udc36 =\n[\ufe023 4\n6 8\n]\ufe02\nand \ud835\udc34 \u0338= \ud835\udcaa, but\n\ud835\udc35 \u0338= \ud835\udc36. Thus, the cancellation law does not apply to matrices.\n2. Let \ud835\udc34 =\n[\ufe020 1\n0 2\n]\ufe02\nand \ud835\udc35 =\n[\ufe023 7\n0 0\n]\ufe02\n. Then \ud835\udc34\ud835\udc35 = \ud835\udcaa, but \ud835\udc34 \u0338= \ud835\udcaa and \ud835\udc35 \u0338= \ud835\udcaa.\nIn Section 4.1 we were introduced to the transpose \ud835\udc34\ud835\udc47 of a matrix \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F). Recall\nthat (\ud835\udc34\ud835\udc47 )\ud835\udc56\ud835\udc57 = (\ud835\udc34)\ud835\udc57\ud835\udc56. Our next Proposition describes the interplay between transpose and\nthe other operations on matrices.\nProposition 4.3.13\n(Properties of Matrix Transpose)\nIf \ud835\udc34, \ud835\udc35 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F), \ud835\udc36 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc58(F), and \ud835\udc60 \u2208 F, then\n(a) (\ud835\udc34 + \ud835\udc35)\ud835\udc47 = \ud835\udc34\ud835\udc47 + \ud835\udc35\ud835\udc47 .\n(b) (\ud835\udc60\ud835\udc34)\ud835\udc47 = \ud835\udc60\ud835\udc34\ud835\udc47 .\n(c) (\ud835\udc34\ud835\udc36)\ud835\udc47 = \ud835\udc36\ud835\udc47 \ud835\udc34\ud835\udc47 .\n(d) (\ud835\udc34\ud835\udc47 )\ud835\udc47 = \ud835\udc34.Section 4.4", "Properties of Square Matrices\n107\nREMARK\nPay close attention to Property (c).\nThe transpose of a product is the product of the\ntransposes in reverse!\nEXERCISE\nProve the previous Proposition.\n4.4\nProperties of Square Matrices\nWe turn our attention to matrices that have the same number of rows as columns.\nDefinition 4.4.1\nSquare Matrix\nA matrix \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) where the number of rows is equal to the number of columns is\ncalled a square matrix .\nREMARK\nFor the case where \ud835\udc5a = \ud835\udc5b, it is common to refer to \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) as \ud835\udc40\ud835\udc5b(F).\nExample 4.4.2\nThe matrix\n[\ufe023 2 1\n1 1 1\n]\ufe02\nis not a square matrix, since it has 2 rows and 3 columns. The matrix\n[\ufe02\u22122 + \ud835\udc56 3 \u2212 2\ud835\udc56\n2 + 2\ud835\udc56 6 \u2212 7\ud835\udc56\n]\ufe02\nis a square matrix, since it has 2 rows and 2 columns.\nDefinition 4.4.3\nUpper Triangular\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F). We say that \ud835\udc34 is upper triangular if \ud835\udc4e\ud835\udc56\ud835\udc57 = 0 for \ud835\udc56 > \ud835\udc57 with \ud835\udc56 = 1, . . . , \ud835\udc5b\nand \ud835\udc57 = 1, . . . , \ud835\udc5b.\nExample 4.4.4\nThe matrices\n[\ufe021 + \ud835\udc56 \u22127\n0\n1 \u2212 \ud835\udc56\n]\ufe02\n,\n\u23a1\n\u23a3\n3 \u22124 6\n0 5 9\n0 0 7\n\u23a4\n\u23a6 , and\n\u23a1\n\u23a3\n\ud835\udc56 4 \u2212 \ud835\udc56 6 \u2212 4\ud835\udc56\n0 1 + \ud835\udc56\n7\ud835\udc56\n0\n0\n2 \u2212 4\ud835\udc56\n\u23a4\n\u23a6 are upper-triangular.\nDefinition 4.4.5\nLower Triangular\nLet \ud835\udc35 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F). We say that \ud835\udc35 is lower triangular if \ud835\udc4f\ud835\udc56\ud835\udc57 = 0 for \ud835\udc56 < \ud835\udc57 with \ud835\udc56 = 1, . . . , \ud835\udc5b\nand \ud835\udc57 = 1, . . . , \ud835\udc5b.\nExample 4.4.6\nThe matrices\n[\ufe02 \ud835\udc56\n0\n4 1 \u2212 \ud835\udc56\n]\ufe02\n,\n\u23a1\n\u23a3\n3 0 0\n3 4 0\n0 7 0\n\u23a4\n\u23a6 , and\n\u23a1\n\u23a2\u23a2\u23a3\n\ud835\udc56\n0\n0\n0\n7\ud835\udc56\n1 + \ud835\udc56\n0\n0\n6\n2 + \ud835\udc56 2 \u2212 4\ud835\udc56\n0\n3 \u2212 5\ud835\udc56\n5\n0\n4 + 3\ud835\udc56\n\u23a4\n\u23a5\u23a5\u23a6 are lower triangular.108\nChapter 4\nMatrices\nREMARKS\n\u2022 The transpose of an upper (lower) triangular matrix is a lower (upper) triangular\nmatrix, respectively.\n\u2022 The product of upper (lower) triangular \ud835\udc5b \u00d7 \ud835\udc5b matrices is upper (lower) triangular,\nrespectively.\nDefinition 4.4.7\nDiagonal\nWe say that an \ud835\udc5b \u00d7 \ud835\udc5b matrix \ud835\udc34 is diagonal if \ud835\udc4e\ud835\udc56\ud835\udc57 = 0 for \ud835\udc56 \u0338= \ud835\udc57 with \ud835\udc56 = 1, . . . , \ud835\udc5b and\n\ud835\udc57 = 1, . . . , \ud835\udc5b. We refer to the entries \ud835\udc4e\ud835\udc56\ud835\udc56 as the diagonal entries of \ud835\udc34, and denote our\nmatrix \ud835\udc34 by \ud835\udc34 = diag(\ud835\udc4e11, \ud835\udc4e22, . . . , \ud835\udc4e\ud835\udc5b\ud835\udc5b).\nExample 4.4.8\nThe matrices\n[\ufe02 \ud835\udc56\n0\n0 1 \u2212 \ud835\udc56\n]\ufe02\n,\n\u23a1\n\u23a3\n3 0 0\n0 4 0\n0 0 0\n\u23a4\n\u23a6 , and\n\u23a1\n\u23a2\u23a2\u23a3\n\ud835\udc56\n0\n0\n0\n0 1 + \ud835\udc56\n0\n0\n0\n0\n2 \u2212 4\ud835\udc56\n0\n0\n0\n0\n4 + 3\ud835\udc56\n\u23a4\n\u23a5\u23a5\u23a6 are diagonal.\nExample 4.4.9\nIf \ud835\udc36 = diag(1, \u22122, 3), then \ud835\udc36 =\n\u23a1\n\u23a3\n1 0 0\n0 \u22122 0\n0 0 3\n\u23a4\n\u23a6.\nREMARKS\n\u2022 Perhaps the most simple example of a diagonal matrix is the \ud835\udc5b\u00d7\ud835\udc5b zero matrix \ud835\udcaa\ud835\udc5b\u00d7\ud835\udc5b.\n\u2022 All diagonal matrices are also upper triangular and lower triangular matrices.\nAnother simple (and important) example is the identity matrix, which we define as follows.\nDefinition 4.4.10\nIdentity Matrix\nThe diagonal matrix diag(1, 1, . . . , 1) is called the identity matrix, and is denoted by \ud835\udc3c.\nIf we wish to indicate that the size of the identity matrix is \ud835\udc5b \u00d7 \ud835\udc5b, we add a subscript \ud835\udc5b\nand write \ud835\udc3c\ud835\udc5b.\nExample 4.4.11\n\ud835\udc3c1 = [1], \ud835\udc3c2 =\n[\ufe021 0\n0 1\n]\ufe02\n, \ud835\udc3c3 =\n\u23a1\n\u23a3\n1 0 0\n0 1 0\n0 0 1\n\u23a4\n\u23a6 , and \ud835\udc3c4 =\n\u23a1\n\u23a2\u23a2\u23a3\n1 0 0 0\n0 1 0 0\n0 0 1 0\n0 0 0 1\n\u23a4\n\u23a5\u23a5\u23a6 .Section 4.5", "Elementary Matrices\n109\nREMARK\nThe identity matrix behaves as a multiplicative identity: for any \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F) we have\nthat\n\ud835\udc3c\ud835\udc5a\ud835\udc34 = \ud835\udc34\nand\n\ud835\udc34\ud835\udc3c\ud835\udc5b = \ud835\udc34.\nIn particular, this also holds for vectors in F\ud835\udc5b, so \ud835\udc3c\ud835\udc5b #\u00bb\ud835\udc65 = #\u00bb\ud835\udc65 for all #\u00bb\ud835\udc65 \u2208 F\ud835\udc5b.\nWhen the identity matrix is multiplied by a scalar \ud835\udc50 \u2208 F, the result is a diagonal matrix\nwhose diagonal entries are all equal to \ud835\udc50:\n\ud835\udc50\ud835\udc3c\ud835\udc5b = diag(\ud835\udc50, \ud835\udc50, . . . , \ud835\udc50).\nExample 4.4.12\nIf \ud835\udc34 =\n[\ufe021 2\n3 4\n]\ufe02\n, then \ud835\udc34\ud835\udc3c2 = \ud835\udc3c2\ud835\udc34 = \ud835\udc34.\nIf \ud835\udc35 =\n[\ufe021 2 3\n3 4 0\n]\ufe02\n, then \ud835\udc35\ud835\udc3c3 = \ud835\udc3c2\ud835\udc35 = \ud835\udc35.\nExample 4.4.13\nIf \ud835\udc50 \u2208 F, then \ud835\udc50\ud835\udc3c2 =\n[\ufe02\ud835\udc50 0\n0 \ud835\udc50\n]\ufe02\n.\n4.5\nElementary Matrices\nIn this section we will show that performing an elementary row operation (ERO) on a\nmatrix is equivalent to multiplying that matrix on the left by a square matrix of a certain\ntype.\nDefinition 4.5.1\nElementary\nMatrices\nA matrix that can be obtained by performing a single ERO on the identity matrix is called\nan elementary matrix.\nIf we wish to be more precise, we refer to elementary matrices using the same names as we\nhave for EROs.\nExample 4.5.2\nThe following matrices are examples of elementary matrices:\n\u2022 \ud835\udc381 =\n\u23a1\n\u23a3\n0 0 1\n0 1 0\n1 0 0\n\u23a4\n\u23a6 is a row swap elementary matrix, since performing \ud835\udc451 \u2194 \ud835\udc453 on \ud835\udc3c3 will\nproduce \ud835\udc381.\n\u2022 \ud835\udc382 =\n[\ufe025 0\n0 1\n]\ufe02\nis a row scale elementary matrix, since performing \ud835\udc451 \u2192 5\ud835\udc451 on \ud835\udc3c2 will\nproduce \ud835\udc382.110\nChapter 4\nMatrices\n\u2022 \ud835\udc383 =\n\u23a1\n\u23a3\n1 0 0\n0 1 \u22122\n0 0 1\n\u23a4\n\u23a6 is a row addition elementary matrix, since performing \ud835\udc452 \u2192 \u22122\ud835\udc453 +\n\ud835\udc452 on \ud835\udc3c3 will produce \ud835\udc383.\nElementary matrices are useful because they can be used to carry out EROs. The next two\nresults make this statement precise.\nProposition 4.5.3\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F) and suppose that a single ERO is performed on it to produce matrix \ud835\udc35.\nSuppose, also, that we perform the same ERO on the matrix \ud835\udc3c\ud835\udc5a to produce the elementary\nmatrix \ud835\udc38. Then\n\ud835\udc35 = \ud835\udc38\ud835\udc34.\nProof: We will prove the result only for row swap elementary matrices and leave the rest\nas an exercise. Let \ud835\udc34 be an \ud835\udc5a \u00d7 \ud835\udc5b matrix with \ud835\udc5a > 1, and consider its transpose \ud835\udc34\ud835\udc47 . The\ncolumns of \ud835\udc34\ud835\udc47 are #\u00bb\n\ud835\udc5f1\ud835\udc47 , . . . , #  \u00bb\n\ud835\udc5f\ud835\udc5a\ud835\udc47 , where #\u00bb\ud835\udc5f\ud835\udc56 = #      \u00bb\nrow\ud835\udc56(\ud835\udc34) is the \ud835\udc56\ud835\udc61\u210e row of \ud835\udc34. Thus\n\ud835\udc34\ud835\udc47 =\n[\ufe00 #\u00bb\n\ud835\udc5f1\ud835\udc47 \u00b7 \u00b7 \u00b7 #\u00bb\ud835\udc5f\ud835\udc56\ud835\udc47 \u00b7 \u00b7 \u00b7 #\u00bb\n\ud835\udc5f\ud835\udc57\ud835\udc47 \u00b7 \u00b7 \u00b7 #  \u00bb\n\ud835\udc5f\ud835\udc5a\ud835\udc47 ]\ufe00\n.\nInterchanging rows \ud835\udc56 and \ud835\udc57 of \ud835\udc34 yields the matrix \ud835\udc35 whose transpose is\n\ud835\udc35\ud835\udc47 =\n[\ufe00 #\u00bb\n\ud835\udc5f1\ud835\udc47\n\u00b7 \u00b7 \u00b7\n#\u00bb\n\ud835\udc5f\ud835\udc57\ud835\udc47\n\u00b7 \u00b7 \u00b7\n#\u00bb\ud835\udc5f\ud835\udc56\ud835\udc47\n\u00b7 \u00b7 \u00b7\n#  \u00bb\n\ud835\udc5f\ud835\udc5a\ud835\udc47 ]\ufe00\n.\nOn the other hand, let\n\ud835\udc38 =\n[\ufe00 #\u00bb\n\ud835\udc521 \u00b7 \u00b7 \u00b7\n#\u00bb\n\ud835\udc52\ud835\udc57 \u00b7 \u00b7 \u00b7\n#\u00bb\n\ud835\udc52\ud835\udc56 \u00b7 \u00b7 \u00b7 #  \u00bb\n\ud835\udc52\ud835\udc5a\n]\ufe00\nbe the elementary matrix that corresponds to the row swap \ud835\udc45\ud835\udc56 \u2194 \ud835\udc45\ud835\udc57. One can quickly\nshow that \ud835\udc38 = \ud835\udc38\ud835\udc47 ; it then follows from Lemma 4.2.2 (Column Extraction) that\n(\ud835\udc38\ud835\udc34)\ud835\udc47 = \ud835\udc34\ud835\udc47 \ud835\udc38\ud835\udc47\n= \ud835\udc34\ud835\udc47 \ud835\udc38\n= \ud835\udc34\ud835\udc47 [\ufe00 #\u00bb\n\ud835\udc521 \u00b7 \u00b7 \u00b7\n#\u00bb\n\ud835\udc52\ud835\udc57 \u00b7 \u00b7 \u00b7\n#\u00bb\n\ud835\udc52\ud835\udc56 \u00b7 \u00b7 \u00b7 #  \u00bb\n\ud835\udc52\ud835\udc5a\n]\ufe00\n=\n[\ufe00\n\ud835\udc34\ud835\udc47 #\u00bb\n\ud835\udc521 \u00b7 \u00b7 \u00b7 \ud835\udc34\ud835\udc47 #\u00bb\n\ud835\udc52\ud835\udc57 \u00b7 \u00b7 \u00b7 \ud835\udc34\ud835\udc47 #\u00bb\n\ud835\udc52\ud835\udc56 \u00b7 \u00b7 \u00b7 \ud835\udc34\ud835\udc47 #  \u00bb\n\ud835\udc52\ud835\udc5a\n]\ufe00\n=\n[\ufe00 #\u00bb\n\ud835\udc5f1\ud835\udc47\n\u00b7 \u00b7 \u00b7\n#\u00bb\n\ud835\udc5f\ud835\udc57\ud835\udc47\n\u00b7 \u00b7 \u00b7\n#\u00bb\ud835\udc5f\ud835\udc56\ud835\udc47\n\u00b7 \u00b7 \u00b7\n#  \u00bb\n\ud835\udc5f\ud835\udc5a\ud835\udc47 ]\ufe00\n= \ud835\udc35\ud835\udc47\nSince \ud835\udc35\ud835\udc47 = (\ud835\udc38\ud835\udc34)\ud835\udc47 , we see that \ud835\udc35 = \ud835\udc38\ud835\udc34 by Property (d) in Proposition 4.3.13 (Properties\nof Matrix Transpose).\nThe previous Proposition tells us that we can perform an ERO on \ud835\udc34 by multiplying \ud835\udc34 on\nthe left by the appropriate elementary matrix \ud835\udc38. We can also carry out a sequence of EROs\nby multiplying \ud835\udc34 on the left by a sequence of appropriate elementary matrices.\nCorollary 4.5.4\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F) and suppose that a finite number of EROs, numbered 1 through \ud835\udc58, are\nperformed on \ud835\udc34 to produce a matrix \ud835\udc35. Let \ud835\udc38\ud835\udc56 denote the elementary matrix corresponding\nto the \ud835\udc56\ud835\udc61\u210e ERO (1 \u2264 \ud835\udc56 \u2264 \ud835\udc58) applied to \ud835\udc3c\ud835\udc5a. Then\n\ud835\udc35 = \ud835\udc38\ud835\udc58 . . . \ud835\udc382\ud835\udc381\ud835\udc34.Section 4.5\nElementary Matrices\n111\nProof: Use the Principle of Mathematical Induction on \ud835\udc58 and Proposition 4.5.3.\nPay attention to the order in which the elementary matrices appear in this product.\nExample 4.5.5\nLet us revisit Example 3.7.1 in Section 3.7. The augmented matrix, \ud835\udc35, was given by\n\ud835\udc35 =\n\u23a1\n\u23a3\n1\n\u22122\n\u22121\n3\n1\n2\n\u22124\n1\n0\n5\n1\n\u22122\n2\n\u22123\n4\n\u23a4\n\u23a6 .\nWe perform the following EROs:\n{\ufe03\n\ud835\udc452 \u2192 \u22122\ud835\udc451 + \ud835\udc452\n\ud835\udc453 \u2192 \u2212\ud835\udc451 + \ud835\udc453\ngives\n\u23a1\n\u23a3\n1\n\u22122\n\u22121\n3\n1\n0\n0\n3\n\u22126\n3\n0\n0\n3\n\u22126\n3\n\u23a4\n\u23a6 = \ud835\udc36,\n\ud835\udc452 \u2192 1\n3\ud835\udc452 gives\n\u23a1\n\u23a3\n1\n\u22122\n\u22121\n3\n1\n0\n0\n1\n\u22122\n1\n0\n0\n3\n\u22126\n3\n\u23a4\n\u23a6 = \ud835\udc37,\n\ud835\udc453 \u2192 \u22123\ud835\udc452 + \ud835\udc453 gives\n\u23a1\n\u23a3\n1\n\u22122\n\u22121\n3\n1\n0\n0\n1\n\u22122\n1\n0\n0\n0\n0\n0\n\u23a4\n\u23a6 = \ud835\udc39.\nFor each of the four EROs, we give the corresponding elementary matrix:\n\ud835\udc452 \u2192 \u22122\ud835\udc451 + \ud835\udc452 gives\n\u23a1\n\u23a3\n1 0 0\n\u22122 1 0\n0 0 1\n\u23a4\n\u23a6 = \ud835\udc381,\n\ud835\udc453 \u2192 \u2212\ud835\udc451 + \ud835\udc453 gives\n\u23a1\n\u23a3\n1 0 0\n0 1 0\n\u22121 0 1\n\u23a4\n\u23a6 = \ud835\udc382.\nNotice that \ud835\udc36 = \ud835\udc382\ud835\udc381\ud835\udc35. Further,\n\ud835\udc452 \u2192 1\n3\ud835\udc452 gives\n\u23a1\n\u23a3\n1 0 0\n0 1\n3 0\n0 0 1\n\u23a4\n\u23a6 = \ud835\udc383,\n\ud835\udc453 \u2192 \u22123\ud835\udc452 + \ud835\udc453 gives\n\u23a1\n\u23a3\n1 0 0\n0 1 0\n0 \u22123 1\n\u23a4\n\u23a6 = \ud835\udc384.\nNotice that \ud835\udc37 = \ud835\udc383\ud835\udc36 and \ud835\udc39 = \ud835\udc384\ud835\udc37.\nWe can now verify our result by evaluating the product \ud835\udc384\ud835\udc383\ud835\udc382\ud835\udc381\ud835\udc35 = \ud835\udc384(\ud835\udc383(\ud835\udc382(\ud835\udc381\ud835\udc35))):112\nChapter 4\nMatrices\n\u23a1\n\u23a3\n1 0 0\n0 1 0\n0 \u22123 1\n\u23a4\n\u23a6\n\u23a1\n\u23a3\n1 0 0\n0 1\n3 0\n0 0 1\n\u23a4\n\u23a6\n\u23a1\n\u23a3\n1 0 0\n0 1 0\n\u22121 0 1\n\u23a4\n\u23a6\n\u23a1\n\u23a3\n1 0 0\n\u22122 1 0\n0 0 1\n\u23a4\n\u23a6\n\u23a1\n\u23a3\n1\n\u22122\n\u22121\n3\n1\n2\n\u22124\n1\n0\n5\n1\n\u22122\n2\n\u22123\n4\n\u23a4\n\u23a6\n=\n\u23a1\n\u23a3\n1 0 0\n0 1 0\n0 \u22123 1\n\u23a4\n\u23a6\n\u23a1\n\u23a3\n1 0 0\n0 1\n3 0\n0 0 1\n\u23a4\n\u23a6\n\u23a1\n\u23a3\n1 0 0\n0 1 0\n\u22121 0 1\n\u23a4\n\u23a6\n\u23a1\n\u23a3\n1\n\u22122\n\u22121\n3\n1\n0\n0\n3\n\u22126\n3\n1\n\u22122\n2\n\u22123\n4\n\u23a4\n\u23a6\n=\n\u23a1\n\u23a3\n1 0 0\n0 1 0\n0 \u22123 1\n\u23a4\n\u23a6\n\u23a1\n\u23a3\n1 0 0\n0 1\n3 0\n0 0 1\n\u23a4\n\u23a6\n\u23a1\n\u23a3\n1\n\u22122\n\u22121\n3\n1\n0\n0\n3\n\u22126\n3\n0\n0\n3\n\u22126\n3\n\u23a4\n\u23a6\n=\n\u23a1\n\u23a3\n1 0 0\n0 1 0\n0 \u22123 1\n\u23a4\n\u23a6\n\u23a1\n\u23a3\n1\n\u22122\n\u22121\n3\n1\n0\n0\n1\n\u22122\n1\n0\n0\n3\n\u22126\n3\n\u23a4\n\u23a6\n=\n\u23a1\n\u23a3\n1\n\u22122\n\u22121\n3\n1\n0\n0\n1\n\u22122\n1\n0\n0\n0\n0\n0\n\u23a4\n\u23a6 = \ud835\udc39.\n4.6", "Matrix Inverse\nLet \ud835\udc34 be an \ud835\udc5a \u00d7 \ud835\udc5b matrix. In this section, we aim to explore the following two questions:\n\u2022 Does there exist an \ud835\udc5b \u00d7 \ud835\udc5a matrix \ud835\udc35 such that, for all #\u00bb\ud835\udc65 \u2208 F\ud835\udc5a, \ud835\udc34\ud835\udc35 #\u00bb\ud835\udc65 = #\u00bb\ud835\udc65?\n\u2022 Does there exist an \ud835\udc5b \u00d7 \ud835\udc5a matrix \ud835\udc36 such that, for all #\u00bb\ud835\udc65 \u2208 F\ud835\udc5b, \ud835\udc36\ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc65?\nIn the first case, you can think of the matrix \ud835\udc34 as the one that \u201ccancels out\u201d the action\nof \ud835\udc35. In the second case, you can think of the matrix \ud835\udc36 as the one that \u201ccancels out\u201d the\naction of \ud835\udc34.\nIn view of the Theorem 4.2.3 (Equality of Matrices), let us reformulate our two motivating\nquestions as follows:\n\u2022 Given an \ud835\udc5a \u00d7 \ud835\udc5b matrix \ud835\udc34, does there exist an \ud835\udc5b \u00d7 \ud835\udc5a matrix \ud835\udc35 such that \ud835\udc34\ud835\udc35 = \ud835\udc3c\ud835\udc5a?\n\u2022 Given an \ud835\udc5a \u00d7 \ud835\udc5b matrix \ud835\udc34, does there exist an \ud835\udc5b \u00d7 \ud835\udc5a matrix \ud835\udc36 such that \ud835\udc36\ud835\udc34 = \ud835\udc3c\ud835\udc5b?\nIf the matrices \ud835\udc35 and \ud835\udc36 exist, we refer to them as a right inverse and a left inverse of\n\ud835\udc34, respectively.\nNotice that if \ud835\udc35 and \ud835\udc36 exist and all of \ud835\udc34, \ud835\udc35 and \ud835\udc36 are square, then\n\ud835\udc34\ud835\udc35 = \ud835\udc36\ud835\udc34 = \ud835\udc3c\ud835\udc5b. This case is the most interesting to us, and it motivates the following\ndefinition.\nDefinition 4.6.1\nInvertible Matrix\nWe say that an \ud835\udc5b \u00d7 \ud835\udc5b matrix \ud835\udc34 is invertible if there exist \ud835\udc5b \u00d7 \ud835\udc5b matrices \ud835\udc35 and \ud835\udc36 such\nthat \ud835\udc34\ud835\udc35 = \ud835\udc36\ud835\udc34 = \ud835\udc3c\ud835\udc5b.Section 4.6\nMatrix Inverse\n113\nThe following theorem demonstrates that if an \ud835\udc5b \u00d7 \ud835\udc5b matrix \ud835\udc34 is invertible, then its left\nand right inverses are equal.\nProposition 4.6.2\n(Equality of Left and Right Inverses)\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F). If there exist matrices \ud835\udc35 and \ud835\udc36 in \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) such that \ud835\udc34\ud835\udc35 = \ud835\udc36\ud835\udc34 = \ud835\udc3c\ud835\udc5b,\nthen \ud835\udc35 = \ud835\udc36.\nProof: We have \ud835\udc35 = \ud835\udc3c\ud835\udc5b\ud835\udc35 = (\ud835\udc36\ud835\udc34)\ud835\udc35 = \ud835\udc36(\ud835\udc34\ud835\udc35) = \ud835\udc36\ud835\udc3c\ud835\udc5b = \ud835\udc36.\nSo far, we have learned that if both left and right inverses exist, then they must be equal.\nThe next result guarantees that for square matrices the left inverse exists if and only if the\nright inverse exists.\nTheorem 4.6.3\n(Left Invertible Iff Right Invertible)\nFor \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F), there exists an \ud835\udc5b \u00d7 \ud835\udc5b matrix \ud835\udc35 such that \ud835\udc34\ud835\udc35 = \ud835\udc3c\ud835\udc5b if and only if there\nexists an \ud835\udc5b \u00d7 \ud835\udc5b matrix \ud835\udc36 such that \ud835\udc36\ud835\udc34 = \ud835\udc3c\ud835\udc5b.\nProof: Let \ud835\udc34 be an \ud835\udc5b \u00d7 \ud835\udc5b matrix.\nTo prove the forward direction, suppose that there exists an \ud835\udc5b \u00d7 \ud835\udc5b matrix \ud835\udc35 such that\n\ud835\udc34\ud835\udc35 = \ud835\udc3c\ud835\udc5b. Consider the homogeneous system\n\ud835\udc35 #\u00bb\ud835\udc65 = #\u00bb0 .\nMultiplying both sides of this equation by \ud835\udc34 on the left, we have that\n\ud835\udc34\ud835\udc35 #\u00bb\ud835\udc65 = \ud835\udc34#\u00bb0 =\u21d2 \ud835\udc3c\ud835\udc5b #\u00bb\ud835\udc65 = #\u00bb0 =\u21d2 #\u00bb\ud835\udc65 = #\u00bb0 .\nThus, the homogeneous system \ud835\udc35 #\u00bb\ud835\udc65 = #\u00bb0 has the unique solution #\u00bb\ud835\udc65 = #\u00bb0 . Therefore, its\nsolution set has no parameters, and so it follows from Part (a) of Theorem 3.6.7 (System\nRank Theorem) that rank(\ud835\udc35) = \ud835\udc5b. It then follows from Part (b) of Theorem 3.6.7 (System\nRank Theorem) that the system \ud835\udc35 #\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f has a solution for every #\u00bb\ud835\udc4f \u2208 F\ud835\udc5b. Thus, for any\n#\u00bb\ud835\udc4f \u2208 F\ud835\udc5b, there exists #\u00bb\ud835\udc65 \u2208 F\ud835\udc5b such that #\u00bb\ud835\udc4f = \ud835\udc35 #\u00bb\ud835\udc65. Consequently,\n(\ud835\udc35\ud835\udc34)#\u00bb\ud835\udc4f = \ud835\udc35\ud835\udc34(\ud835\udc35 #\u00bb\ud835\udc65) = \ud835\udc35(\ud835\udc34\ud835\udc35)#\u00bb\ud835\udc65 = \ud835\udc35\ud835\udc3c\ud835\udc5b #\u00bb\ud835\udc65 = \ud835\udc35 #\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f = \ud835\udc3c\ud835\udc5b\n#\u00bb\ud835\udc4f .\nSince the identity (\ud835\udc35\ud835\udc34)#\u00bb\ud835\udc4f = \ud835\udc3c\ud835\udc5b\n#\u00bb\ud835\udc4f holds for all #\u00bb\ud835\udc4f \u2208 F\ud835\udc5b, it follows from Theorem 4.2.3\n(Equality of Matrices) that \ud835\udc35\ud835\udc34 = \ud835\udc3c\ud835\udc5b. Taking \ud835\udc36 = \ud835\udc35, the result follows.\nTo prove the backward direction, suppose that there exists an \ud835\udc5b \u00d7 \ud835\udc5b matrix \ud835\udc36 such that\n\ud835\udc36\ud835\udc34 = \ud835\udc3c\ud835\udc5b. Then\n\ud835\udc3c\ud835\udc5b = \ud835\udc3c\ud835\udc47\n\ud835\udc5b = (\ud835\udc36\ud835\udc34)\ud835\udc47 = \ud835\udc34\ud835\udc47 \ud835\udc36\ud835\udc47 .\nThus, \ud835\udc36\ud835\udc47 is the right inverse of \ud835\udc34\ud835\udc47 , and so it follows from the proof of the forward direction\nthat \ud835\udc36\ud835\udc47 is also the left inverse of \ud835\udc34\ud835\udc47 , that is,\n\ud835\udc36\ud835\udc47 \ud835\udc34\ud835\udc47 = \ud835\udc3c\ud835\udc5b.\nBut then\n\ud835\udc3c\ud835\udc5b = \ud835\udc3c\ud835\udc47\n\ud835\udc5b = (\ud835\udc36\ud835\udc47 \ud835\udc34\ud835\udc47 )\ud835\udc47 = (\ud835\udc34\ud835\udc47 )\ud835\udc47 (\ud835\udc36\ud835\udc47 )\ud835\udc47 = \ud835\udc34\ud835\udc36.\nTaking \ud835\udc35 = \ud835\udc36, the result follows.114\nChapter 4\nMatrices\nNotice that if a matrix \ud835\udc34 is invertible, then there exists a unique matrix \ud835\udc35 such that\n\ud835\udc34\ud835\udc35 = \ud835\udc3c\ud835\udc5b. Indeed, suppose that \ud835\udc34\ud835\udc351 = \ud835\udc3c\ud835\udc5b and \ud835\udc34\ud835\udc352 = \ud835\udc3c\ud835\udc5b. Since \ud835\udc34\ud835\udc351 = \ud835\udc34\ud835\udc352, we see that\n\ud835\udc351\ud835\udc34\ud835\udc351 = \ud835\udc351\ud835\udc34\ud835\udc352. By Theorem 4.6.3 (Left Invertible Iff Right Invertible), we know that\n\ud835\udc351\ud835\udc34 = \ud835\udc3c\ud835\udc5b, so \ud835\udc351 = \ud835\udc352. In view of this, consider the following definition.\nDefinition 4.6.4\nInverse of a Matrix\nIf an \ud835\udc5b \u00d7 \ud835\udc5b matrix \ud835\udc34 is invertible, we refer to the matrix \ud835\udc35 such that \ud835\udc34\ud835\udc35 = \ud835\udc3c\ud835\udc5b as the\ninverse of \ud835\udc34. We denote the inverse of \ud835\udc34 by \ud835\udc34\u22121. The inverse of \ud835\udc34 satisfies\n\ud835\udc34\ud835\udc34\u22121 = \ud835\udc34\u22121\ud835\udc34 = \ud835\udc3c\ud835\udc5b.\nREMARK\nThe above results tell us that, in order to verify that the matrix \ud835\udc35 is the inverse of \ud835\udc34, it is\nsufficient to verify that \ud835\udc34\ud835\udc35 = \ud835\udc3c\ud835\udc5b. We do not need to also verify that \ud835\udc35\ud835\udc34 = \ud835\udc3c\ud835\udc5b.\nExample 4.6.5\nThe matrix \ud835\udc35 =\n[\ufe021 + \ud835\udc56 \ud835\udc56\n1\n\ud835\udc56\n]\ufe02\nis the inverse of \ud835\udc34 =\n[\ufe02\u2212\ud835\udc56\n\ud835\udc56\n1 \u22121 \u2212 \ud835\udc56\n]\ufe02\n, because\n\ud835\udc34\ud835\udc35 =\n[\ufe02\u2212\ud835\udc56\n\ud835\udc56\n1 \u22121 \u2212 \ud835\udc56\n]\ufe02 [\ufe021 + \ud835\udc56 \ud835\udc56\n1\n\ud835\udc56\n]\ufe02\n=\n[\ufe021 0\n0 1\n]\ufe02\n.\nExample 4.6.6\nThe matrix \ud835\udc35 =\n[\ufe021 1\n1 2\n]\ufe02\nis not the inverse of \ud835\udc34 =\n[\ufe02 2 \u22121\n\u22122 2\n]\ufe02\n, because\n\ud835\udc34\ud835\udc35 =\n[\ufe02 2 \u22121\n\u22122 2\n]\ufe02 [\ufe021 1\n1 2\n]\ufe02\n=\n[\ufe021 0\n0 2\n]\ufe02\n\u0338=\n[\ufe021 0\n0 1\n]\ufe02\n.\nWhile there exist numerous criteria for the invertibility of a matrix, for now we will outline\nonly three of them.\nTheorem 4.6.7\n(Invertibility Criteria \u2013 First Version)\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F). The following three conditions are equivalent:\n(a) \ud835\udc34 is invertible.\n(b) rank(\ud835\udc34) = \ud835\udc5b.\n(c) RREF(\ud835\udc34) = \ud835\udc3c\ud835\udc5b.\nProof: ((\ud835\udc4e) \u21d2 (\ud835\udc4f)):\nSuppose that \ud835\udc34 is invertible. Then there exists a matrix \ud835\udc35 such that \ud835\udc35\ud835\udc34 = \ud835\udc3c\ud835\udc5b. We can\nshow that rank(\ud835\udc34) = \ud835\udc5b as in the proof of Theorem 4.6.3 (Left Invertible Iff Right Invertible).Section 4.6\nMatrix Inverse\n115\n((\ud835\udc4f) \u21d2 (\ud835\udc50)):\nSuppose that rank(\ud835\udc34) = \ud835\udc5b. Then every row and every column of the \ud835\udc5b\u00d7\ud835\udc5b matrix RREF(\ud835\udc34)\nhas a pivot. The only matrix that can satisfy this condition is the \ud835\udc5b \u00d7 \ud835\udc5b identity matrix \ud835\udc3c\ud835\udc5b.\n((\ud835\udc50) \u21d2 (\ud835\udc4e)):\nSuppose that RREF(\ud835\udc34) = \ud835\udc3c\ud835\udc5b. Then the rank of \ud835\udc34 is equal to the number of rows of \ud835\udc34, which\nmeans that the system \ud835\udc34#\u00bb\ud835\udc65 = \u20d7\ud835\udc4f is consistent for every \u20d7\ud835\udc4f \u2208 F\ud835\udc5b. Thus, we let #\u00bb\ud835\udc4f\ud835\udc56 be a solution\nto \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\n\ud835\udc52\ud835\udc56 for \ud835\udc56 = 1, . . . , \ud835\udc5b. If we now define \ud835\udc35 =\n[\ufe01 #\u00bb\n\ud835\udc4f1 \u00b7 \u00b7 \u00b7 #\u00bb\n\ud835\udc4f\ud835\udc5b\n]\ufe01\n, then by construction\n\ud835\udc34\ud835\udc35 = \ud835\udc34\n[\ufe01 #\u00bb\n\ud835\udc4f1 \u00b7 \u00b7 \u00b7 #\u00bb\n\ud835\udc4f\ud835\udc5b\n]\ufe01\n=\n[\ufe01\n\ud835\udc34#\u00bb\n\ud835\udc4f1 \u00b7 \u00b7 \u00b7 \ud835\udc34#\u00bb\n\ud835\udc4f\ud835\udc5b\n]\ufe01\n=\n[\ufe00 #\u00bb\n\ud835\udc521 \u00b7 \u00b7 \u00b7 #\u00bb\n\ud835\udc52\ud835\udc5b\n]\ufe00\n= \ud835\udc3c\ud835\udc5b\nFrom Theorem 4.6.3 (Left Invertible Iff Right Invertible) it follows that there exists a matrix\n\ud835\udc36 such that \ud835\udc36\ud835\udc34 = \ud835\udc3c\ud835\udc5b. Since \ud835\udc34\ud835\udc35 = \ud835\udc36\ud835\udc34 = \ud835\udc3c\ud835\udc5b, we conclude that \ud835\udc34 is invertible.\nLet us look closely at the last part of the proof, as it describes an algorithm for finding the\ninverse of an invertible matrix \ud835\udc34. Indeed, if we are able to solve each of the equations\n\ud835\udc34#\u00bb\n\ud835\udc4f1 = #\u00bb\n\ud835\udc521,\n\ud835\udc34#\u00bb\n\ud835\udc4f2 = #\u00bb\n\ud835\udc522,\n. . . ,\n\ud835\udc34#\u00bb\n\ud835\udc4f\ud835\udc5b = #\u00bb\n\ud835\udc52\ud835\udc5b\nfor #\u00bb\n\ud835\udc4f1, . . . , #\u00bb\n\ud835\udc4f\ud835\udc5b \u2208 F\ud835\udc5b, then \ud835\udc34\u22121 =\n[\ufe01 #\u00bb\n\ud835\udc4f1 \u00b7 \u00b7 \u00b7 #\u00bb\n\ud835\udc4f\ud835\udc5b\n]\ufe01\n.\nLet \ud835\udc45 = RREF(\ud835\udc34), and suppose that a\nsequence of EROs \ud835\udc5f1, . . . , \ud835\udc5f\ud835\udc58 is used to row reduce the augmented matrix \ud835\udc34 to \ud835\udc45. Convince\nyourself that the same sequence of EROs can be used to row reduce any system [\ud835\udc34 | #\u00bb\n\ud835\udc52\ud835\udc56] to\nits RREF, [\ud835\udc45 | #\u00bb\ud835\udc4f\ud835\udc56], for some vector #\u00bb\ud835\udc4f\ud835\udc56. Consequently, the same sequence of EROs can be\nused to row reduce the super-augmented matrix\n[\ud835\udc34 | \ud835\udc3c\ud835\udc5b] =\n[\ufe00\n\ud835\udc34\n#\u00bb\n\ud835\udc521\n\u00b7 \u00b7 \u00b7\n#\u00bb\n\ud835\udc52\ud835\udc5b\n]\ufe00\ninto its RREF\n[\ud835\udc45 | \ud835\udc35] =\n[\ufe01\n\ud835\udc45\n#\u00bb\n\ud835\udc4f1\n\u00b7 \u00b7 \u00b7\n#\u00bb\n\ud835\udc4f\ud835\udc5b\n]\ufe01\nfor some \ud835\udc5b\u00d7\ud835\udc5b matrix \ud835\udc35 =\n[\ufe01 #\u00bb\n\ud835\udc4f1 \u00b7 \u00b7 \u00b7 #\u00bb\n\ud835\udc4f\ud835\udc5b\n]\ufe01\n. Notice how by performing row reduction on a super-\naugmented matrix, we are solving \ud835\udc5b distinct systems of linear equations simultaneously. Of\ncourse, this is possible because these systems \ud835\udc34#\u00bb\ud835\udc4f\ud835\udc56 = #\u00bb\n\ud835\udc52\ud835\udc56 have equal coefficient matrices. By\nTheorem 3.6.7 (System Rank Theorem), we have that\n\u2022 If rank(\ud835\udc34) \u0338= \ud835\udc5b (which is equivalent to \ud835\udc45 \u0338= \ud835\udc3c\ud835\udc5b), there exists an index \ud835\udc56 such that the\nsystem \ud835\udc34#\u00bb\ud835\udc4f\ud835\udc56 = #\u00bb\n\ud835\udc52\ud835\udc56 is inconsistent (by Proposition 3.10.2). Consequently, it is impossible\nto find a matrix \ud835\udc35 such that \ud835\udc34\ud835\udc35 = \ud835\udc3c\ud835\udc5b, which means that \ud835\udc34 is not invertible.\n\u2022 If rank(\ud835\udc34) = \ud835\udc5b (which is equivalent to \ud835\udc45 = \ud835\udc3c\ud835\udc5b), then each system \ud835\udc34#\u00bb\ud835\udc4f\ud835\udc56 = #\u00bb\n\ud835\udc52\ud835\udc56 is\nconsistent, and so the matrix \ud835\udc35 is the inverse \ud835\udc34.\nWe summarize our observations in the following proposition.\nProposition 4.6.8\n(Algorithm for Checking Invertibility and Finding the Inverse)\nThe following algorithm allows you to determine whether an \ud835\udc5b \u00d7 \ud835\udc5b matrix \ud835\udc34 is invertible,\nand if it is, the algorithm will provide the inverse of \ud835\udc34.\n1. Construct a super-augmented matrix [\ud835\udc34 | \ud835\udc3c\ud835\udc5b].\n2. Find the RREF, [\ud835\udc45 | \ud835\udc35], of [\ud835\udc34 | \ud835\udc3c\ud835\udc5b].\n3. If \ud835\udc45 \u0338= \ud835\udc3c\ud835\udc5b, conclude that \ud835\udc34 is not invertible. If \ud835\udc45 = \ud835\udc3c\ud835\udc5b, conclude that \ud835\udc34 is invertible,\nand that \ud835\udc34\u22121 = \ud835\udc35.116\nChapter 4\nMatrices\nExample 4.6.9\nDetermine whether the matrix\n\ud835\udc34 =\n[\ufe021 2\n3 4\n]\ufe02\nis invertible. If it is invertible, find its inverse.\nSolution: In order to find the inverse, we need to solve two systems of equations with\naugmented matrices [\ud835\udc34 | #\u00bb\n\ud835\udc521] and [\ud835\udc34 | #\u00bb\n\ud835\udc522]. Instead of solving them separately, we will solve\nthem simultaneously by forming a super-augmented matrix\n[\ud835\udc34 | \ud835\udc3c2] =\n[\ufe00\n\ud835\udc34\n#\u00bb\n\ud835\udc521\n#\u00bb\n\ud835\udc522\n]\ufe00\n=\n[\ufe02 1\n2\n1\n0\n3\n4\n0\n1\n]\ufe02\nand row reducing it. We have\n\ud835\udc452 \u2192 \ud835\udc452 \u2212 3\ud835\udc451\ngives\n[\ufe02 1\n2\n1\n0\n0\n\u22122\n\u22123\n1\n]\ufe02\n.\nNotice that the matrix that we\u2019ve obtained is in REF. Since it has two pivots, we have that\nrank(\ud835\udc34) = 2, so it must be the case that \ud835\udc34 is invertible. We continue reducing to RREF.\n\ud835\udc452 \u2192 \u2212 1\n2\ud835\udc452\ngives\n[\ufe02 1\n2\n1\n0\n0\n1\n3\n2\n\u2212 1\n2\n]\ufe02\n,\n\ud835\udc451 \u2192 \ud835\udc451 \u2212 2\ud835\udc452\ngives\n[\ufe02 1\n0\n\u22122\n1\n0\n1\n3\n2\n\u2212 1\n2\n]\ufe02\n.\nThus, we conclude that the inverse of \ud835\udc34 is\n\ud835\udc34\u22121 =\n[\ufe02\u22122\n1\n3\n2\n\u2212 1\n2\n]\ufe02\n= \u22121\n2\n[\ufe02 4 \u22122\n\u22123 1\n]\ufe02\n.\nLet us verify our calculations:\n\ud835\udc34\u22121\ud835\udc34 = \u22121\n2\n[\ufe02 4 \u22122\n\u22123 1\n]\ufe02 [\ufe021 2\n3 4\n]\ufe02\n= \u22121\n2\n[\ufe024 \u00b7 1 + (\u22122) \u00b7 3\n4 \u00b7 2 + (\u22122) \u00b7 4\n(\u22123) \u00b7 1 + 1 \u00b7 3\n(\u22123) \u00b7 2 + 1 \u00b7 4\n]\ufe02\n= \u22121\n2\n[\ufe02\u22122 0\n0 \u22122\n]\ufe02\n=\n[\ufe021 0\n0 1\n]\ufe02\n.\nExample 4.6.10\nDetermine whether the matrix\n\ud835\udc35 =\n\u23a1\n\u23a3\n1 2 3\n4 5 6\n7 8 9\n\u23a4\n\u23a6\nis invertible. If it is invertible, find its inverse.\nSolution: We consider the super-augmented matrix [\ud835\udc35 | \ud835\udc3c3] and reduce it to a matrix in\nREF.Section 4.6\nMatrix Inverse\n117\n{\ufe03\n\ud835\udc452 \u2192 \ud835\udc452 \u2212 4\ud835\udc451\n\ud835\udc453 \u2192 \ud835\udc453 \u2212 7\ud835\udc451\ngives\n\u23a1\n\u23a3\n1\n2\n3\n1\n0\n0\n0\n\u22123\n\u22126\n\u22124\n1\n0\n0\n\u22126\n\u221212\n\u22127\n0\n1\n\u23a4\n\u23a6 ,\n\ud835\udc452 \u2192 \u22121\n3\ud835\udc452\ngives\n\u23a1\n\u23a3\n1\n2\n3\n1\n0\n0\n0\n1\n2\n4\n3\n\u2212 1\n3\n0\n0\n\u22126\n\u221212\n\u22127\n0\n1\n\u23a4\n\u23a6 ,\n\ud835\udc453 \u2192 \ud835\udc453 + 6\ud835\udc452\ngives\n\u23a1\n\u23a3\n1\n2\n3\n1\n0\n0\n0\n1\n2\n4\n3\n\u2212 1\n3\n0\n0\n0\n0\n1\n\u22122\n1\n\u23a4\n\u23a6 .\nAt this point, we have that rank(\ud835\udc35) = 2, and so it is not invertible.\nExample 4.6.11\nDetermine whether the matrix\n\ud835\udc36 =\n\u23a1\n\u23a3\n1 2 3\n4 5 6\n7 8 10\n\u23a4\n\u23a6\nis invertible. If it is invertible, find its inverse.\nSolution: We consider the super-augmented matrix [\ud835\udc36 | \ud835\udc3c3] and row reduce it.\n{\ufe03\n\ud835\udc452 \u2192 \ud835\udc452 \u2212 4\ud835\udc451\n\ud835\udc453 \u2192 \ud835\udc453 \u2212 7\ud835\udc451\ngives\n\u23a1\n\u23a3\n1\n2\n3\n1\n0\n0\n0\n\u22123\n\u22126\n\u22124\n1\n0\n0\n\u22126\n\u221211\n\u22127\n0\n1\n\u23a4\n\u23a6 ,\n\ud835\udc452 \u2192 \u22121\n3\ud835\udc452\ngives\n\u23a1\n\u23a3\n1\n2\n3\n1\n0\n0\n0\n1\n2\n4\n3\n\u2212 1\n3\n0\n0\n\u22126\n\u221211\n\u22127\n0\n1\n\u23a4\n\u23a6 ,\n\ud835\udc453 \u2192 \ud835\udc453 + 6\ud835\udc452\ngives\n\u23a1\n\u23a3\n1\n2\n3\n1\n0\n0\n0\n1\n2\n4\n3\n\u2212 1\n3\n0\n0\n0\n1\n1\n\u22122\n1\n\u23a4\n\u23a6 .\nAt this point, we have that rank(\ud835\udc36) = 3, and so it is invertible. We thus continue row\nreducing it to RREF.\n{\ufe03\n\ud835\udc451 \u2192 \ud835\udc451 \u2212 3\ud835\udc453\n\ud835\udc452 \u2192 \ud835\udc452 \u2212 2\ud835\udc453\ngives\n\u23a1\n\u23a3\n1\n2\n0\n\u22122\n6\n\u22123\n0\n1\n0\n\u2212 2\n3\n11\n3\n\u22122\n0\n0\n1\n1\n\u22122\n1\n\u23a4\n\u23a6 ,\n\ud835\udc451 \u2192 \ud835\udc451 \u2212 2\ud835\udc452\ngives\n\u23a1\n\u23a3\n1\n0\n0\n\u2212 2\n3\n\u2212 4\n3\n1\n0\n1\n0\n\u2212 2\n3\n11\n3\n\u22122\n0\n0\n1\n1\n\u22122\n1\n\u23a4\n\u23a6 .\nWe conclude that the inverse of \ud835\udc36 is\n\ud835\udc36\u22121 =\n\u23a1\n\u23a2\u23a3\n\u2212 2\n3 \u2212 4\n3\n1\n\u2212 2\n3\n11\n3\n\u22122\n1\n\u22122\n1\n\u23a4\n\u23a5\u23a6 = 1\n3\n\u23a1\n\u23a3\n\u22122 \u22124 3\n\u22122 11 \u22126\n3 \u22126 3\n\u23a4\n\u23a6 .118\nChapter 4\nMatrices\nLet us verify our calculations.\n\u23a1\n\u23a3\n1 2 3\n4 5 6\n7 8 10\n\u23a4\n\u23a6\n(\ufe021\n3\n)\ufe02 \u23a1\n\u23a3\n\u22122 \u22124 3\n\u22122 11 \u22126\n3 \u22126 3\n\u23a4\n\u23a6 = 1\n3\n\u23a1\n\u23a3\n3 0 0\n0 3 0\n0 0 3\n\u23a4\n\u23a6 = \ud835\udc3c3\nExample 4.6.12\nDetermine whether the matrix\n\ud835\udc37 =\n[\ufe02 \u22121 \u2212 2 \ud835\udc56\n\u22121 \u2212 \ud835\udc56\n1 \u2212 \ud835\udc56\n\u2212\ud835\udc56\n]\ufe02\nis invertible. If it is invertible, find its inverse.\nSolution We consider the super-augmented matrix [\ud835\udc37 | \ud835\udc3c2] and row reduce it.\n[\ud835\udc37 | \ud835\udc3c2] =\n[\ufe02 \u22121 \u2212 2 \ud835\udc56\n\u22121 \u2212 \ud835\udc56\n1\n0\n1 \u2212 \ud835\udc56\n\u2212\ud835\udc56\n0\n1\n]\ufe02\n{\ufe03\n\ud835\udc451 \u2192 (\u22121 + 2\ud835\udc56)\ud835\udc451\n\ud835\udc452 \u2192 (1 + \ud835\udc56)\ud835\udc452\ngives\n[\ufe02 5\n3 \u2212 \ud835\udc56\n\u22121 + 2 \ud835\udc56\n0\n2\n1 \u2212 \ud835\udc56\n0\n1 + \ud835\udc56\n]\ufe02\n\ud835\udc452 \u2192 \u22122\ud835\udc451 + 2\ud835\udc452 gives\n[\ufe02 5\n3 \u2212 \ud835\udc56\n\u22121 + 2 \ud835\udc56\n0\n0\n\u22121 \u2212 3 \ud835\udc56\n2 \u2212 4 \ud835\udc56\n5 + 5 \ud835\udc56\n]\ufe02\nAt this point, we have that rank(\ud835\udc37) = 2 and so \ud835\udc37 is invertible. We thus continue row\nreducing to RREF.\n\ud835\udc452 \u2192 \ud835\udc56\ud835\udc452 gives\n[\ufe02 5\n3 \u2212 \ud835\udc56\n\u22121 + 2 \ud835\udc56\n0\n0\n3 \u2212 \ud835\udc56\n4 + 2 \ud835\udc56\n\u22125 + 5 \ud835\udc56\n]\ufe02\n\ud835\udc451 \u2192 \ud835\udc451 \u2212 \ud835\udc452 gives\n[\ufe02 5\n0\n\u22125\n5 \u2212 5 \ud835\udc56\n0\n3 \u2212 \ud835\udc56\n4 + 2 \ud835\udc56\n\u22125 + 5 \ud835\udc56\n]\ufe02\nAs\n1\n3 \u2212 \ud835\udc56 = 3 + \ud835\udc56\n9 + 1 = 3 + \ud835\udc56\n10 , we complete our reduction with\n{\ufe03\n\ud835\udc451 \u2192 1\n5\ud835\udc451\n\ud835\udc452 \u2192 1\n10(3 + \ud835\udc56)\ud835\udc452\ngives\n[\ufe02 1\n0\n\u22121\n1 \u2212 \ud835\udc56\n0\n1\n1 + \ud835\udc56\n\u22122 + \ud835\udc56\n]\ufe02\nTherefore, we conclude that\n\ud835\udc37\u22121 =\n[\ufe02\n\u22121\n1 \u2212 \ud835\udc56\n1 + \ud835\udc56\n\u22122 + \ud835\udc56\n]\ufe02\nLet us verify our calculations:\n[\ufe02\n\u22121\n1 \u2212 \ud835\udc56\n1 + \ud835\udc56\n\u22122 + \ud835\udc56\n]\ufe02 [\ufe02 \u22121 \u2212 2 \ud835\udc56\n\u22121 \u2212 \ud835\udc56\n1 \u2212 \ud835\udc56\n\u2212\ud835\udc56\n]\ufe02\n=\n[\ufe02\n1 + 2\ud835\udc56 + (1 \u2212 \ud835\udc56)2\n1 + \ud835\udc56 \u2212 \ud835\udc56(1 \u2212 \ud835\udc56)\n(1 + \ud835\udc56)(\u22121 \u2212 2\ud835\udc56) + (\u22122 + \ud835\udc56)(1 \u2212 \ud835\udc56)\n\u2212 (1 + \ud835\udc56)2 \u2212 \ud835\udc56(\u22122 + \ud835\udc56)\n]\ufe02\n=\n[\ufe021 0\n0 1\n]\ufe02\n.Section 4.6\nMatrix Inverse\n119\nThe inverse of a 2 \u00d7 2 matrix may be computed as follows.\nProposition 4.6.13\n(Inverse of a 2 \u00d7 2 Matrix)\nLet \ud835\udc34 =\n[\ufe02\ud835\udc4e \ud835\udc4f\n\ud835\udc50 \ud835\udc51\n]\ufe02\n. Then \ud835\udc34 is invertible if and only if \ud835\udc4e\ud835\udc51\u2212 \ud835\udc4f\ud835\udc50 \u0338= 0. Furthermore, if \ud835\udc4e\ud835\udc51\u2212 \ud835\udc4f\ud835\udc50 \u0338= 0,\nthen\n\ud835\udc34\u22121 =\n1\n\ud835\udc4e\ud835\udc51 \u2212 \ud835\udc4f\ud835\udc50\n[\ufe02 \ud835\udc51 \u2212\ud835\udc4f\n\u2212\ud835\udc50 \ud835\udc4e\n]\ufe02\n.\nProof: If \ud835\udc4e\ud835\udc51 \u2212 \ud835\udc4f\ud835\udc50 \u0338= 0, then we may define a matrix \ud835\udc35 \u2208 \ud835\udc402\u00d72(F) by\n\ud835\udc35 =\n1\n\ud835\udc4e\ud835\udc51 \u2212 \ud835\udc4f\ud835\udc50\n[\ufe02 \ud835\udc51 \u2212\ud835\udc4f\n\u2212\ud835\udc50 \ud835\udc4e\n]\ufe02\n.\nA straightforward computation shows that \ud835\udc34\ud835\udc35 = \ud835\udc35\ud835\udc34 = \ud835\udc3c2. Thus, \ud835\udc34 is invertible in this\ncase and moreover \ud835\udc35 = \ud835\udc34\u22121, as claimed.\nConversely, assume that \ud835\udc4e\ud835\udc51 \u2212 \ud835\udc4f\ud835\udc50 = 0. We will show in this case that \ud835\udc34 is not invertible by\nproving that rank(\ud835\udc34) \u0338= 2. We will have to consider two cases: \ud835\udc51 = 0 and \ud835\udc51 \u0338= 0. If \ud835\udc51 = 0\nthen\n\ud835\udc34 =\n[\ufe02\ud835\udc4e \ud835\udc4f\n\ud835\udc50 0\n]\ufe02\n.\nand \ud835\udc4f\ud835\udc50 = \ud835\udc4e\ud835\udc51 = 0 (since \ud835\udc4e\ud835\udc51 \u2212 \ud835\udc4f\ud835\udc50 = 0 by assumption). So, one of \ud835\udc4f or \ud835\udc50 must be 0. If \ud835\udc50 = 0\nthen \ud835\udc34 has a row of zeros, so it can have at most one pivot, hence rank(\ud835\udc34) \u0338= 2, and \ud835\udc34 is\nnot invertible. A similar argument can be applied if \ud835\udc4f = 0: in that case, there can be at\nmost one pivot (in the first column).\nNext, if \ud835\udc51 \u0338= 0, we can perform the following EROs to \ud835\udc34:\n\ud835\udc451 \u2192 \ud835\udc51\ud835\udc451 gives\n[\ufe02\ud835\udc4e\ud835\udc51 \ud835\udc4f\ud835\udc51\n\ud835\udc50\n\ud835\udc51\n]\ufe02\n.\n\ud835\udc451 \u2192 \u2212\ud835\udc4f\ud835\udc452 + \ud835\udc451 gives\n[\ufe02\ud835\udc4e\ud835\udc51 \u2212 \ud835\udc4f\ud835\udc50 0\n\ud835\udc50\n\ud835\udc51\n]\ufe02\n.\nSince \ud835\udc4e\ud835\udc51 \u2212 \ud835\udc4f\ud835\udc50 = 0, we have thus row reduced \ud835\udc34 to a matrix with a row of zeros. Hence, as\nabove, \ud835\udc34 can have at most one pivot, and therefore, it cannot be invertible.\nThis completes the analysis of all cases.\nREMARK\nIf \ud835\udc34 =\n[\ufe02\ud835\udc4e \ud835\udc4f\n\ud835\udc50 \ud835\udc51\n]\ufe02\n, then the number \ud835\udc4e\ud835\udc51 \u2212 \ud835\udc4f\ud835\udc50 is called the determinant of \ud835\udc34. We will discuss it\nin more detail in Chapter 6.120\nChapter 4\nMatrices\nExample 4.6.14\nFind the inverses of the following matrices, if they exist.\n\ud835\udc34 =\n[\ufe021 2\n3 4\n]\ufe02\n\ud835\udc35 =\n[\ufe021 2\n3 6\n]\ufe02\n\ud835\udc36 =\n[\ufe02\u22121 \u2212 2\ud835\udc56 \u22121 \u2212 \ud835\udc56\n1 \u2212 \ud835\udc56\n\u2212\ud835\udc56\n]\ufe02\nSolution: The determinant of \ud835\udc34 is (1(4) \u2212 2(3)) = \u22122, and so \ud835\udc34 is invertible with\n\ud835\udc34\u22121 = \u22121\n2\n[\ufe02 4 \u22122\n\u22123 1\n]\ufe02\n.\nThe determinant of \ud835\udc35 is (1(6) \u2212 2(3)) = 0, and so \ud835\udc35 is not invertible.\nThe determinant of \ud835\udc36 is\n(\u22121 \u2212 2\ud835\udc56)(\u2212\ud835\udc56) \u2212 (\u22121 \u2212 \ud835\udc56)(1 \u2212 \ud835\udc56) = \u22122 + \ud835\udc56 + 2 = \ud835\udc56\nand so \ud835\udc36 is invertible. As 1\n\ud835\udc56 = \u2212\ud835\udc56, we have\n\ud835\udc36\u22121 = \u2212\ud835\udc56\n[\ufe02\n\u2212\ud835\udc56\n1 + \ud835\udc56\n\u22121 + \ud835\udc56 \u22121 \u2212 2\ud835\udc56\n]\ufe02\n=\n[\ufe02 \u22121\n1 \u2212 \ud835\udc56\n1 + \ud835\udc56 \u22122 + \ud835\udc56\n]\ufe02Chapter 5\nLinear Transformations\n5.1", "The Function Determined by a Matrix\nUp to this point in the course, we have considered matrices as arrays of numbers which\ncontain important information about systems of linear equations through either the coeffi-\ncient matrix, the augmented matrix, or both. Moving forward, we will discover that there\nis much more going on than this. We will make use of multiplication by a matrix to define\nfunctions.\nDefinition 5.1.1\nFunction\nDetermined by a\nMatrix\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F). The function determined by the matrix \ud835\udc34 is the function\n\ud835\udc47\ud835\udc34 : F\ud835\udc5b \u2192 F\ud835\udc5a\ndefined by\n\ud835\udc47\ud835\udc34(#\u00bb\ud835\udc65) = \ud835\udc34#\u00bb\ud835\udc65.\nExample 5.1.2\nLet \ud835\udc34 =\n\u23a1\n\u23a3\n1\n4\n\u22122 \u22125\n4\n6\n\u23a4\n\u23a6. If #\u00bb\ud835\udc65 \u2208 R2, then\n\ud835\udc47\ud835\udc34(#\u00bb\ud835\udc65) =\n\u23a1\n\u23a3\n1\n4\n\u22122 \u22125\n4\n6\n\u23a4\n\u23a6\n[\ufe02\ud835\udc651\n\ud835\udc652\n]\ufe02\n=\n\u23a1\n\u23a3\n\ud835\udc651 + 4\ud835\udc652\n\u22122\ud835\udc651 \u2212 5\ud835\udc652\n4\ud835\udc651 + 6\ud835\udc652\n\u23a4\n\u23a6 .\nNote that \ud835\udc47\ud835\udc34(#\u00bb\ud835\udc65) \u2208 R3.\nFor instance, if #\u00bb\ud835\udc65 =\n[\ufe02\u22122\n3\n]\ufe02\n, then \ud835\udc47\ud835\udc34(#\u00bb\ud835\udc65) = \ud835\udc47\ud835\udc34\n(\ufe02[\ufe02\u22122\n3\n]\ufe02)\ufe02\n=\n\u23a1\n\u23a3\n10\n\u221211\n10\n\u23a4\n\u23a6.\nThe function \ud835\udc47\ud835\udc34 takes as input vectors in R2 and outputs vectors in R3.\n121122\nChapter 5", "Linear Transformations\nExample 5.1.3\nLet \ud835\udc34 =\n[\ufe02\n\ud835\udc56\n1 + 2\ud835\udc56 3 + 2\ud835\udc56\n2 \u2212 \ud835\udc56\n4\n2 \u2212 5\ud835\udc56\n]\ufe02\n. If #\u00bb\ud835\udc67 \u2208 C3, then\n\ud835\udc47\ud835\udc34(#\u00bb\ud835\udc67 ) =\n[\ufe02\n\ud835\udc56\n1 + 2\ud835\udc56\n3 + 2\ud835\udc56\n2 \u2212 \ud835\udc56\n4\n2 \u2212 5\ud835\udc56\n]\ufe02 \u23a1\n\u23a3\n\ud835\udc671\n\ud835\udc672\n\ud835\udc673\n\u23a4\n\u23a6 =\n[\ufe02 \ud835\udc56\ud835\udc671 + (1 + 2\ud835\udc56)\ud835\udc672 + (3 + 2\ud835\udc56)\ud835\udc673\n(2 \u2212 \ud835\udc56)\ud835\udc671 + 4\ud835\udc672 + (2 \u2212 5\ud835\udc56)\ud835\udc673\n]\ufe02\n.\nNote that \ud835\udc47\ud835\udc34(#\u00bb\ud835\udc67 ) \u2208 C2.\nFor instance, if #\u00bb\ud835\udc67 =\n\u23a1\n\u23a3\n3\n2 \u2212 \ud835\udc56\n2\ud835\udc56\n\u23a4\n\u23a6, then \ud835\udc47\ud835\udc34(#\u00bb\ud835\udc67 ) = \ud835\udc47\ud835\udc34\n\u239b\n\u239d\n\u23a1\n\u23a3\n3\n2 \u2212 \ud835\udc56\n2\ud835\udc56\n\u23a4\n\u23a6\n\u239e\n\u23a0 =\n[\ufe02\n12\ud835\udc56\n24 \u2212 3\ud835\udc56\n]\ufe02\n.\nThe function \ud835\udc47\ud835\udc34 takes as input vectors in C3 and outputs vectors in C2.\nThe function \ud835\udc47\ud835\udc34 determined by a matrix \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F) has some rather special features. In\nTheorem 3.9.9 we saw that matrix\u2013vector multiplication is linear: that is, for any #\u00bb\ud835\udc65, #\u00bb\ud835\udc66 \u2208 F\ud835\udc5b\nand any \ud835\udc50 \u2208 F, the following two properties hold:\n\ud835\udc34(#\u00bb\ud835\udc65 + #\u00bb\ud835\udc66 ) = \ud835\udc34#\u00bb\ud835\udc65 + \ud835\udc34#\u00bb\ud835\udc66\n\ud835\udc34(\ud835\udc50#\u00bb\ud835\udc65) = \ud835\udc50\ud835\udc34#\u00bb\ud835\udc65\nIn view of these properties, the following result holds.\nTheorem 5.1.4\n(Function Determined by a Matrix is Linear)\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F) and let \ud835\udc47\ud835\udc34 be the function determined by the matrix \ud835\udc34. Then \ud835\udc47\ud835\udc34 is\nlinear; that is, for any #\u00bb\ud835\udc65, #\u00bb\ud835\udc66 \u2208 F\ud835\udc5b and any \ud835\udc50 \u2208 F, the following two properties hold:\n(a) \ud835\udc47\ud835\udc34(#\u00bb\ud835\udc65 + #\u00bb\ud835\udc66 ) = \ud835\udc47\ud835\udc34(#\u00bb\ud835\udc65) + \ud835\udc47\ud835\udc34(#\u00bb\ud835\udc66 )\n(b) \ud835\udc47\ud835\udc34(\ud835\udc50#\u00bb\ud835\udc65) = \ud835\udc50 \ud835\udc47\ud835\udc34(#\u00bb\ud835\udc65)\nProof:\n\ud835\udc47\ud835\udc34(#\u00bb\ud835\udc65 + #\u00bb\ud835\udc66 ) = \ud835\udc34(#\u00bb\ud835\udc65 + #\u00bb\ud835\udc66 )\nand\n\ud835\udc47\ud835\udc34(\ud835\udc50#\u00bb\ud835\udc65) = \ud835\udc34(\ud835\udc50#\u00bb\ud835\udc65)\n(by definition)\n= \ud835\udc34(#\u00bb\ud835\udc65) + \ud835\udc34(#\u00bb\ud835\udc66 )\n= \ud835\udc50\ud835\udc34#\u00bb\ud835\udc65\n(by Theorem 3.9.9)\n= \ud835\udc47\ud835\udc34(#\u00bb\ud835\udc65) + \ud835\udc47\ud835\udc34(#\u00bb\ud835\udc66 )\n= \ud835\udc50\ud835\udc47\ud835\udc34(#\u00bb\ud835\udc65)\n(by definition).\n5.2\nLinear Transformations\nThe properties exhibited by \ud835\udc47\ud835\udc34 in Theorem 5.1.4 (Function Determined by a Matrix is\nLinear) turn out to be of such importance in linear algebra that we give a name to the class\nof functions that exhibit these properties.Section 5.2\nLinear Transformations\n123\nDefinition 5.2.1\nLinear\nTransformation\nWe say that the function \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5a is a linear transformation (or linear mapping)\nif, for any #\u00bb\ud835\udc65, #\u00bb\ud835\udc66 \u2208 F\ud835\udc5b and any \ud835\udc50 \u2208 F, the following two properties hold:\n1. \ud835\udc47(#\u00bb\ud835\udc65 + #\u00bb\ud835\udc66 ) = \ud835\udc47(#\u00bb\ud835\udc65) + \ud835\udc47(#\u00bb\ud835\udc66 ) (called linearity over addition).\n2. \ud835\udc47(\ud835\udc50#\u00bb\ud835\udc65) = \ud835\udc50\ud835\udc47(#\u00bb\ud835\udc65) (called linearity over scalar multiplication).\nWe refer to F\ud835\udc5b here as the domain of \ud835\udc47 and F\ud835\udc5a as the codomain of \ud835\udc47, as we would for\nany function.\nREMARKS\n\u2022 In linear algebra, the words transformation or mapping are often used instead of\nthe word function.\n\u2022 In high school, you studied a variety of non-linear functions, such as \ud835\udc53(\ud835\udc65) = \ud835\udc652 + 1 or\n\ud835\udc53(\ud835\udc65) = 2\ud835\udc65. These functions usually had a simple domain and codomain, such as R.\nIn linear algebra, the domains and codomains are more complicated (such as R\ud835\udc5b or\nC\ud835\udc5b), but the functions themselves are rather simple \u2014 they are linear. If you go on\nto take a vector calculus course, you may see more complicated functions and more\ncomplicated domains and codomains occurring together.\nREMARK\nA fundamental example of a linear transformation is the function \ud835\udc47\ud835\udc34 determined by a matrix\n\ud835\udc34. The linearity of \ud835\udc47\ud835\udc34 was established in Theorem 5.1.4 (Function Determined by a Matrix\nis Linear).\nFrom this point forward we shall refer to \ud835\udc47\ud835\udc34 as the linear transformation determined by \ud835\udc34,\ninstead of the function determined by \ud835\udc34.\nWe now consider some features of linear transformations. We begin with the result below\nwhich tells us that, if we want, we can check linearity over addition and linearity over\nscalar multiplication simultaneously, instead of checking them separately. We will give a\nfew examples after the following two results.\nProposition 5.2.2\n(Alternate Characterization of a Linear Transformation)\nLet \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5a be a function. Then \ud835\udc47 is a linear transformation if and only if for any\n#\u00bb\ud835\udc65, #\u00bb\ud835\udc66 \u2208 F\ud835\udc5b and any \ud835\udc50 \u2208 F,\n\ud835\udc47(\ud835\udc50#\u00bb\ud835\udc65 + #\u00bb\ud835\udc66 ) = \ud835\udc50\ud835\udc47(#\u00bb\ud835\udc65) + \ud835\udc47(#\u00bb\ud835\udc66 ).\nProof: We begin with the forward direction. Suppose that \ud835\udc47 is a linear transformation.\nLet #\u00bb\ud835\udc65, #\u00bb\ud835\udc66 \u2208 F\ud835\udc5b and \ud835\udc50 \u2208 F. Put #\u00bb\ud835\udc64 = \ud835\udc50#\u00bb\ud835\udc65. Since \ud835\udc47 is linear, we have\n\ud835\udc47(#\u00bb\ud835\udc64 + #\u00bb\ud835\udc66 ) = \ud835\udc47(#\u00bb\ud835\udc64) + \ud835\udc47(#\u00bb\ud835\udc66 )124\nChapter 5\nLinear Transformations\nand\n\ud835\udc47(#\u00bb\ud835\udc64) = \ud835\udc47(\ud835\udc50#\u00bb\ud835\udc65) = \ud835\udc50\ud835\udc47(#\u00bb\ud835\udc65).\nThus, we have\n\ud835\udc47(\ud835\udc50#\u00bb\ud835\udc65 + #\u00bb\ud835\udc66 ) = \ud835\udc47(#\u00bb\ud835\udc64 + #\u00bb\ud835\udc66 )\n= \ud835\udc47(#\u00bb\ud835\udc64) + \ud835\udc47(#\u00bb\ud835\udc66 )\n= \ud835\udc50\ud835\udc47(#\u00bb\ud835\udc65) + \ud835\udc47(#\u00bb\ud835\udc66 ).\nNow for the backward direction. Suppose that for all #\u00bb\ud835\udc65, #\u00bb\ud835\udc66 \u2208 F\ud835\udc5b and for all \ud835\udc50 \u2208 F,\n\ud835\udc47(\ud835\udc50#\u00bb\ud835\udc65 + #\u00bb\ud835\udc66 ) = \ud835\udc50\ud835\udc47(#\u00bb\ud835\udc65) + \ud835\udc47(#\u00bb\ud835\udc66 ).\nTaking \ud835\udc50 = 1, we find that for all #\u00bb\ud835\udc65, #\u00bb\ud835\udc66 \u2208 F\ud835\udc5b,\n\ud835\udc47(#\u00bb\ud835\udc65 + #\u00bb\ud835\udc66 ) = \ud835\udc47(#\u00bb\ud835\udc65) + \ud835\udc47(#\u00bb\ud835\udc66 ).\nTaking #\u00bb\ud835\udc66 = #\u00bb0 , we find that for all #\u00bb\ud835\udc65 \u2208 F\ud835\udc5b and for all \ud835\udc50 \u2208 F,\n\ud835\udc47(\ud835\udc50#\u00bb\ud835\udc65 + #\u00bb\ud835\udc66 ) = \ud835\udc47(\ud835\udc50#\u00bb\ud835\udc65) = \ud835\udc50\ud835\udc47(#\u00bb\ud835\udc65).\nWe conclude that \ud835\udc47 is a linear transformation.\nProposition 5.2.3\n(Zero Maps to Zero)\nLet \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5a be a linear transformation. Then\n\ud835\udc47(#\u00bb0 F\ud835\udc5b) = #\u00bb0 F\ud835\udc5a.\nProof: Notice that #\u00bb0 F\ud835\udc5b = 0 \u00b7 #\u00bb0 F\ud835\udc5b. Since \ud835\udc47 is linear,\n\ud835\udc47(#\u00bb0 F\ud835\udc5b) = \ud835\udc47(0 \u00b7 #\u00bb0 F\ud835\udc5b)\n= 0 \u00b7 \ud835\udc47(#\u00bb0 F\ud835\udc5b)\n= #\u00bb0 F\ud835\udc5a,\nwhere the last equality follows from the fact that for any #\u00bb\ud835\udc65 \u2208 F\ud835\udc5a, 0 \u00b7 #\u00bb\ud835\udc65 = #\u00bb0 F\ud835\udc5a.\nWe will now look at some functions \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5a and determine whether or not they are\nlinear. Towards this end, here are a couple of questions to consider:\n\u2022 Does the zero vector of the domain get mapped to the zero vector of the codomain?\nIf it does not, then the function is not linear.\n\u2022 Does the function look linear?\nAll of its terms must be linear. For example, the terms 2\ud835\udc651,\n\u221a\n3\ud835\udc652, \ud835\udf0b\ud835\udc653, and \u2212\ud835\udc654\nare linear, while the terms of the form \u22123\ud835\udc651\ud835\udc653, \ud835\udc652\n1 or \ud835\udc651\ud835\udc652\ud835\udc653 are not linear. If you\nencounter any such non-linear terms, this indicates that the function is likely not\nlinear. Find a counterexample to definitively prove that the function is not linear.\nIf the answer to both of these questions is yes, then we use the definition to prove linearity.Section 5.2\nLinear Transformations\n125\nExample 5.2.4\nDetermine whether or not the function \ud835\udc471 : R3 \u2192 R2 defined by\n\ud835\udc471\n\u239b\n\u239d\n\u23a1\n\u23a3\n\ud835\udc65\n\ud835\udc66\n\ud835\udc67\n\u23a4\n\u23a6\n\u239e\n\u23a0 =\n[\ufe022\ud835\udc65 + 3\ud835\udc66 + 4\n6\ud835\udc65 \u2212 7\ud835\udc67\n]\ufe02\nis a linear transformation.\nSolution: This transformation is not linear, because\n\ud835\udc471(\n[\ufe00\n0 0 0\n]\ufe00\ud835\udc47 ) =\n[\ufe00\n4 0\n]\ufe00\ud835\udc47 \u0338=\n[\ufe00\n0 0\n]\ufe00\ud835\udc47 .\nExample 5.2.5\nDetermine whether or not the function \ud835\udc472 : C3 \u2192 C2 defined by\n\ud835\udc472\n\u239b\n\u239d\n\u23a1\n\u23a3\n\ud835\udc671\n\ud835\udc672\n\ud835\udc673\n\u23a4\n\u23a6\n\u239e\n\u23a0 =\n[\ufe022\ud835\udc671 + 3\ud835\udc673\n\ud835\udc672\ud835\udc673\n]\ufe02\nis a linear transformation.\nSolution: The zero vector of C3 is mapped to the zero vector of C2 by this function.\nHowever, this function does not look linear because of the product \ud835\udc672\ud835\udc673. We try to construct\na counterexample. The (possibly) troublesome term does not involve \ud835\udc671, so we will set that\nto zero. Since the image under the function does involve the other two variables let us see\nwhat happens for different values (setting both to 1 or 0 is not usually helpful).\nNote that on one hand,\n\ud835\udc472\n\u239b\n\u239d\n\u23a1\n\u23a3\n0\n1\n0\n\u23a4\n\u23a6\n\u239e\n\u23a0 + \ud835\udc472\n\u239b\n\u239d\n\u23a1\n\u23a3\n0\n0\n1\n\u23a4\n\u23a6\n\u239e\n\u23a0 =\n[\ufe020\n0\n]\ufe02\n+\n[\ufe023\n0\n]\ufe02\n=\n[\ufe023\n0\n]\ufe02\n.\nOn the other hand,\n\ud835\udc472\n\u239b\n\u239d\n\u23a1\n\u23a3\n0\n1\n0\n\u23a4\n\u23a6 +\n\u23a1\n\u23a3\n0\n0\n1\n\u23a4\n\u23a6\n\u239e\n\u23a0 = \ud835\udc472\n\u239b\n\u239d\n\u23a1\n\u23a3\n0\n1\n1\n\u23a4\n\u23a6\n\u239e\n\u23a0 =\n[\ufe023\n1\n]\ufe02\n.\nSince\n\ud835\udc472\n\u239b\n\u239d\n\u23a1\n\u23a3\n0\n1\n0\n\u23a4\n\u23a6\n\u239e\n\u23a0 + \ud835\udc472\n\u239b\n\u239d\n\u23a1\n\u23a3\n0\n0\n1\n\u23a4\n\u23a6\n\u239e\n\u23a0 \u0338= \ud835\udc472\n\u239b\n\u239d\n\u23a1\n\u23a3\n0\n1\n0\n\u23a4\n\u23a6 +\n\u23a1\n\u23a3\n0\n0\n1\n\u23a4\n\u23a6\n\u239e\n\u23a0 ,\nthe function \ud835\udc472 is not a linear transformation.\nExample 5.2.6\nDetermine whether or not the function \ud835\udc473 : R2 \u2192 R3 defined by\n\ud835\udc473\n(\ufe02[\ufe02\ud835\udc651\n\ud835\udc652\n]\ufe02)\ufe02\n=\n\u23a1\n\u23a3\n2\ud835\udc651 + 3\ud835\udc652\n6\ud835\udc651 \u2212 5\ud835\udc652\n2\ud835\udc651\n\u23a4\n\u23a6\nis a linear transformation.126\nChapter 5\nLinear Transformations\nSolution: As the zero vector of R2 is mapped to the zero vector of R3 and we do not detect\nany non-linear terms, this function could be linear. Let us prove that this is indeed the\ncase.\nLet #\u00bb\ud835\udc65 =\n[\ufe02\ud835\udc651\n\ud835\udc652\n]\ufe02\n, #\u00bb\ud835\udc66 =\n[\ufe02\ud835\udc661\n\ud835\udc662\n]\ufe02\n\u2208 R2 and \ud835\udc50 \u2208 R. Then, using the definition of \ud835\udc473, we have\n\ud835\udc473(#\u00bb\ud835\udc65) = \ud835\udc473\n(\ufe02[\ufe02\ud835\udc651\n\ud835\udc652\n]\ufe02)\ufe02\n=\n\u23a1\n\u23a3\n2\ud835\udc651 + 3\ud835\udc652\n6\ud835\udc651 \u2212 5\ud835\udc652\n2\ud835\udc651\n\u23a4\n\u23a6\nand\n\ud835\udc473(#\u00bb\ud835\udc66 ) = \ud835\udc473\n(\ufe02[\ufe02\ud835\udc661\n\ud835\udc662\n]\ufe02)\ufe02\n=\n\u23a1\n\u23a3\n2\ud835\udc661 + 3\ud835\udc662\n6\ud835\udc661 \u2212 5\ud835\udc662\n2\ud835\udc661\n\u23a4\n\u23a6 .\nWe also have\n\ud835\udc50#\u00bb\ud835\udc65 + #\u00bb\ud835\udc66 =\n[\ufe02\ud835\udc50\ud835\udc651\n\ud835\udc50\ud835\udc652\n]\ufe02\n+\n[\ufe02\ud835\udc661\n\ud835\udc662\n]\ufe02\n=\n[\ufe02\ud835\udc50\ud835\udc651 + \ud835\udc661\n\ud835\udc50\ud835\udc652 + \ud835\udc662\n]\ufe02\n,\nso that\n\ud835\udc473 (\ud835\udc50#\u00bb\ud835\udc65 + #\u00bb\ud835\udc66 ) = \ud835\udc473\n(\ufe02[\ufe02\ud835\udc50\ud835\udc651 + \ud835\udc661\n\ud835\udc50\ud835\udc652 + \ud835\udc662\n]\ufe02)\ufe02\n=\n\u23a1\n\u23a3\n2(\ud835\udc50\ud835\udc651 + \ud835\udc661) + 3(\ud835\udc50\ud835\udc652 + \ud835\udc662)\n6(\ud835\udc50\ud835\udc651 + \ud835\udc661) \u2212 5(\ud835\udc50\ud835\udc652 + \ud835\udc662)\n2(\ud835\udc50\ud835\udc651 + \ud835\udc661)\n\u23a4\n\u23a6\n= \ud835\udc50\n\u23a1\n\u23a3\n2\ud835\udc651 + 3\ud835\udc652\n6\ud835\udc651 \u2212 5\ud835\udc652\n2\ud835\udc651\n\u23a4\n\u23a6 +\n\u23a1\n\u23a3\n2\ud835\udc661 + 3\ud835\udc662\n6\ud835\udc661 \u2212 5\ud835\udc662\n2\ud835\udc661\n\u23a4\n\u23a6 = \ud835\udc50\ud835\udc473\n(\ufe02[\ufe02\ud835\udc651\n\ud835\udc652\n]\ufe02)\ufe02\n+ \ud835\udc473\n(\ufe02[\ufe02\ud835\udc661\n\ud835\udc662\n]\ufe02)\ufe02\n.\nThat is, \ud835\udc473 (\ud835\udc50#\u00bb\ud835\udc65 + #\u00bb\ud835\udc66 ) = \ud835\udc50\ud835\udc473 (#\u00bb\ud835\udc65) + \ud835\udc473 (#\u00bb\ud835\udc66 ). It follows that \ud835\udc473 is a linear transformation (by\nProposition 5.2.2 (Alternate Characterization of a Linear Transformation)).\nExample 5.2.7\nDetermine whether or not the function \ud835\udc474 : C2 \u2192 C2 defined by\n\ud835\udc474\n(\ufe02[\ufe02\ud835\udc671\n\ud835\udc672\n]\ufe02)\ufe02\n=\n[\ufe02\n2\ud835\udc56\ud835\udc671 + 3\ud835\udc672\n(2 \u2212 \ud835\udc56)\ud835\udc671 \u2212 (1 + 3\ud835\udc56)\ud835\udc672\n]\ufe02\n.\nis a linear transformation.\nSolution: As the zero vector of C2 is mapped to the zero vector of C2 and we do not detect\nany non-linear terms, this function could be linear. Let us prove that this is indeed the\ncase.\nLet #\u00bb\ud835\udc67 =\n[\ufe02\ud835\udc671\n\ud835\udc672\n]\ufe02\n, #\u00bb\ud835\udc64 =\n[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02\n\u2208 C2, and \ud835\udc50 \u2208 C. Then, from the definition of \ud835\udc474, we have\n\ud835\udc474(#\u00bb\ud835\udc67 ) = \ud835\udc474\n(\ufe02[\ufe02\ud835\udc671\n\ud835\udc672\n]\ufe02)\ufe02\n=\n[\ufe02\n2\ud835\udc56\ud835\udc671 + 3\ud835\udc672\n(2 \u2212 \ud835\udc56)\ud835\udc671 \u2212 (1 + 3\ud835\udc56)\ud835\udc672\n]\ufe02\nand\n\ud835\udc474(#\u00bb\ud835\udc64) = \ud835\udc474\n(\ufe02[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02)\ufe02\n=\n[\ufe02\n2\ud835\udc56\ud835\udc641 + 3\ud835\udc642\n(2 \u2212 \ud835\udc56)\ud835\udc641 \u2212 (1 + 3\ud835\udc56)\ud835\udc642\n]\ufe02\n.Section 5.3", "The Range of a Linear Transformation and \u201cOnto\u201d Linear Transformations\n127\nWe also have\n\ud835\udc50#\u00bb\ud835\udc67 + #\u00bb\ud835\udc64 =\n[\ufe02\ud835\udc50\ud835\udc671\n\ud835\udc50\ud835\udc672\n]\ufe02\n+\n[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02\n=\n[\ufe02\ud835\udc50\ud835\udc671 + \ud835\udc641\n\ud835\udc50\ud835\udc672 + \ud835\udc642\n]\ufe02\n,\nso that\n\ud835\udc474 (\ud835\udc50#\u00bb\ud835\udc67 + #\u00bb\ud835\udc64) = \ud835\udc474\n(\ufe02[\ufe02\ud835\udc50\ud835\udc671 + \ud835\udc641\n\ud835\udc50\ud835\udc672 + \ud835\udc642\n]\ufe02)\ufe02\n=\n[\ufe02\n2\ud835\udc56(\ud835\udc50\ud835\udc671 + \ud835\udc641) + 3(\ud835\udc50\ud835\udc672 + \ud835\udc642)\n(2 \u2212 \ud835\udc56)(\ud835\udc50\ud835\udc671 + \ud835\udc641) \u2212 (1 + 3\ud835\udc56)(\ud835\udc50\ud835\udc672 + \ud835\udc642)\n]\ufe02\n= \ud835\udc50\n[\ufe02\n2\ud835\udc56\ud835\udc671 + 3\ud835\udc672\n(2 \u2212 \ud835\udc56)\ud835\udc671 \u2212 (1 + 3\ud835\udc56)\ud835\udc672\n]\ufe02\n+\n[\ufe02\n2\ud835\udc56\ud835\udc641 + 3\ud835\udc642\n(2 \u2212 \ud835\udc56)\ud835\udc641 \u2212 (1 + 3\ud835\udc56)\ud835\udc642\n]\ufe02\n= \ud835\udc50\ud835\udc474\n(\ufe02[\ufe02\ud835\udc671\n\ud835\udc672\n]\ufe02)\ufe02\n+ \ud835\udc474\n(\ufe02[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02)\ufe02\n.\nThat is, \ud835\udc474 (\ud835\udc50#\u00bb\ud835\udc67 + #\u00bb\ud835\udc64) = \ud835\udc50\ud835\udc474 (#\u00bb\ud835\udc67 ) + \ud835\udc474(#\u00bb\ud835\udc64). It follows that \ud835\udc474 is a linear transformation (by\nProposition 5.2.2 (Alternate Characterization of a Linear Transformation)).\n5.3\nThe Range of a Linear Transformation and \u201cOnto\u201d Lin-\near Transformations\nA linear transformation is a special kind of function, and, as with many other functions, we\nconsider the set of all outputs of a linear transformation.\nDefinition 5.3.1\nRange\nLet \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5a be a linear transformation. We define the range of \ud835\udc47, denoted Range(\ud835\udc47),\nto be the set of all outputs of \ud835\udc47. That is,\nRange(\ud835\udc47) = {\ud835\udc47(#\u00bb\ud835\udc65) : #\u00bb\ud835\udc65 \u2208 F\ud835\udc5b} .\nThe range of \ud835\udc47 is a subset of F\ud835\udc5a.\nSince for any linear transformation \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5a we have \ud835\udc47(#\u00bb0 F\ud835\udc5b) = #\u00bb0 F\ud835\udc5a (by Proposition\n5.2.3 (Zero Maps to Zero)), we have that #\u00bb0 F\ud835\udc5a \u2208 Range(\ud835\udc34). Therefore, the range of a linear\ntransformation is never empty.\nProposition 5.3.2\n(Range of a Linear Transformation)\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F), and let \ud835\udc47\ud835\udc34 : F\ud835\udc5b \u2192 F\ud835\udc5a be the linear transformation determined by \ud835\udc34.\nThen\nRange(\ud835\udc47\ud835\udc34) = Col(\ud835\udc34).\nProof: We will show that these two subsets of F\ud835\udc5a are equal by showing that each set is\ncontained in the other.\nFirst, suppose that #\u00bb\ud835\udc66 \u2208 Range(\ud835\udc47\ud835\udc34). Then there exists #\u00bb\ud835\udc65 \u2208 F\ud835\udc5b such that \ud835\udc47\ud835\udc34(#\u00bb\ud835\udc65) = #\u00bb\ud835\udc66 . That\nis, there exists a vector #\u00bb\ud835\udc65 \u2208 F\ud835\udc5b such that \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc66 . Since the system \ud835\udc34\u20d7\ud835\udc65 = \u20d7\ud835\udc66 is consistent\nif and only if #\u00bb\ud835\udc66 \u2208 Col(\ud835\udc34) (see Proposition 4.1.2 (Consistent System and Column Space)),\nwe conclude that #\u00bb\ud835\udc66 \u2208 Col(\ud835\udc34).128\nChapter 5\nLinear Transformations\nNext, suppose that #\u00bb\ud835\udc67 \u2208 Col(\ud835\udc34). Then there exist scalars \ud835\udc651, \ud835\udc652, . . . , \ud835\udc65\ud835\udc5b \u2208 F such that\n#\u00bb\ud835\udc67 = \ud835\udc651 #\u00bb\ud835\udc4e 1 + \ud835\udc652 #\u00bb\ud835\udc4e 2 + \u00b7 \u00b7 \u00b7 + \ud835\udc65\ud835\udc5b #\u00bb\ud835\udc4e \ud835\udc5b. If we let #\u00bb\ud835\udc65 =\n[\ufe00\n\ud835\udc651 \ud835\udc652 \u00b7 \u00b7 \u00b7 \ud835\udc65\ud835\udc5b\n]\ufe00\ud835\udc47 , then \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc67 ; that is,\n#\u00bb\ud835\udc67 = \ud835\udc47\ud835\udc34(#\u00bb\ud835\udc65), and so #\u00bb\ud835\udc67 \u2208 Range(\ud835\udc47\ud835\udc34).\nThus, we conclude that Range(\ud835\udc47\ud835\udc34) = Col(\ud835\udc34).\nREMARK (Connection to Systems of Linear Equations)\nWe have already seen in Proposition 4.1.2 (Consistent System and Column Space) that\nthe system of linear equations \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f\nhas a solution if and only if #\u00bb\ud835\udc4f \u2208 Col(\ud835\udc34).\nWe can now write\n\ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f\nis consistent if and only if #\u00bb\ud835\udc4f \u2208 Range(\ud835\udc47\ud835\udc34).\nExample 5.3.3\nDetermine Range(\ud835\udc47\ud835\udc34), where \ud835\udc34 =\n\u23a1\n\u23a3\n1\n4\n\u22122 \u22125\n4\n6\n\u23a4\n\u23a6.\nSolution: The range of \ud835\udc47\ud835\udc34 is\nRange(\ud835\udc47\ud835\udc34) = Col(\ud835\udc34) = Span\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n1\n\u22122\n4\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n4\n\u22125\n6\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad .\nNote that the system of linear equations \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f is consistent if and only if #\u00bb\ud835\udc4f \u2208 Range(\ud835\udc47\ud835\udc34).\nExample 5.3.4\nDetermine Range(\ud835\udc47\ud835\udc34), where \ud835\udc34 =\n[\ufe02\n\ud835\udc56\n1 + 2\ud835\udc56 3 + 2\ud835\udc56\n2 \u2212 \ud835\udc56\n4\n2 \u2212 5\ud835\udc56\n]\ufe02\n.\nSolution: The range of \ud835\udc47\ud835\udc34 is\nRange(\ud835\udc47\ud835\udc34) = Span\n{\ufe02[\ufe02\n\ud835\udc56\n2 \u2212 \ud835\udc56\n]\ufe02\n,\n[\ufe02 1 + 2\ud835\udc56\n4\n]\ufe02\n,\n[\ufe02 3 + 2\ud835\udc56\n2 \u2212 5\ud835\udc56\n]\ufe02}\ufe02\n.\nIt can be shown that Range(\ud835\udc47\ud835\udc34) = C2, and thus the system of linear equations \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f is\nconsistent for all #\u00bb\ud835\udc4f \u2208 C2.\nLinear transformations whose range is equal to the entire codomain deserve a special name.\nDefinition 5.3.5\nOnto\nWe say that the transformation \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5a is onto (or surjective) if Range(\ud835\udc47) = F\ud835\udc5a.Section 5.4\nThe Range of a Linear Transformation and \u201cOnto\u201d Linear Transformations\n129\nCorollary 5.3.6\n(Onto Criteria)\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F) and let \ud835\udc47\ud835\udc34 be the linear transformation determined by the matrix \ud835\udc34.\nThe following statements are equivalent:\n(a) \ud835\udc47\ud835\udc34 is onto.\n(b) Col(\ud835\udc34) = F\ud835\udc5a.\n(c) rank(\ud835\udc34) = \ud835\udc5a.\nProof: ((\ud835\udc4e) \u21d2 (\ud835\udc4f)):\nSuppose that \ud835\udc47\ud835\udc34 is onto. From Proposition 5.3.2 (Range of a Linear Transformation), it\nfollows that\nCol(\ud835\udc34) = Range(\ud835\udc47\ud835\udc34) = F\ud835\udc5a.\n((\ud835\udc4f) \u21d2 (\ud835\udc50)):\nSuppose that Col(\ud835\udc34) = F\ud835\udc5a. The system \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f is consistent if and only if #\u00bb\ud835\udc4f \u2208 Col(\ud835\udc34)\n(see Proposition 4.1.2 (Consistent System and Column Space)). Thus we have that \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f\nis consistent for all \u20d7\ud835\udc4f \u2208 F\ud835\udc5a. From Part (b) of Theorem 3.6.7 (System Rank Theorem), we\nconclude that rank(\ud835\udc34) = \ud835\udc5a.\n((\ud835\udc50) \u21d2 (\ud835\udc4e)):\nSuppose that rank(\ud835\udc34) = \ud835\udc5a. From Part (b) of Theorem 3.6.7 (System Rank Theorem),\nit follows that the system \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f is consistent for all #\u00bb\ud835\udc4f \u2208 F\ud835\udc5a. By Proposition 4.1.2\n(Consistent System and Column Space), Col(\ud835\udc34) = F\ud835\udc5a. By Proposition 5.3.2 (Range of a\nLinear Transformation), Range(\ud835\udc47\ud835\udc34) = Col(\ud835\udc34) = F\ud835\udc5a.\nExample 5.3.7\nDetermine whether or not the linear transformation \ud835\udc47\ud835\udc34 determined by \ud835\udc34 =\n\u23a1\n\u23a3\n1\n4\n\u22122 \u22125\n4\n6\n\u23a4\n\u23a6 is\nonto.\nSolution: From Example 5.3.3 we know that\nRange(\ud835\udc47\ud835\udc34) = Col(\ud835\udc34) = Span\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n1\n\u22122\n4\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n4\n\u22125\n6\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad .\nThe range of \ud835\udc47\ud835\udc34 is only a plane in R3. Therefore, it cannot be equal to all of R3, and so\nRange(\ud835\udc47\ud835\udc34) \u0338= R3. There will be some vectors #\u00bb\ud835\udc4f in R3 for which the equation \ud835\udc47\ud835\udc34(#\u00bb\ud835\udc65) = #\u00bb\ud835\udc4f\nhas no solution. This will happen for any vector which does not lie on the plane determined\nby Col(\ud835\udc34). One such vector is\n\u23a1\n\u23a3\n1\n0\n0\n\u23a4\n\u23a6. Therefore, the linear transformation \ud835\udc47\ud835\udc34 is not onto.130\nChapter 5\nLinear Transformations\n5.4", "The Kernel of a Linear Transformation and \u201cOne-to-\nOne\u201d Linear Transformations\nWhen analyzing functions, we consider the set of inputs whose output is zero.\nDefinition 5.4.1\nKernel\nLet \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5a be a linear transformation. We define the kernel of \ud835\udc47, denoted Ker(\ud835\udc47),\nto be the set of inputs of \ud835\udc47 whose output is zero. That is,\nKer(\ud835\udc47) =\n{\ufe01#\u00bb\ud835\udc65 \u2208 F\ud835\udc5b : \ud835\udc47(#\u00bb\ud835\udc65) = #\u00bb0 F\ud835\udc5a\n}\ufe01\n.\nThe kernel of \ud835\udc47 is a subset of F\ud835\udc5b.\nSince for any linear transformation \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5a we have \ud835\udc47(#\u00bb0 F\ud835\udc5b) = #\u00bb0 F\ud835\udc5a (by Proposition\n5.2.3 (Zero Maps to Zero)), we have #\u00bb0 F\ud835\udc5b \u2208 Ker(\ud835\udc47). Thus, the kernel of a linear transfor-\nmation is never empty.\nProposition 5.4.2\n(Kernel of a Linear Transformation)\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F) and let \ud835\udc47\ud835\udc34 : F\ud835\udc5b \u2192 F\ud835\udc5a be the linear transformation determined by \ud835\udc34.\nThen\nKer(\ud835\udc47\ud835\udc34) = Null(\ud835\udc34).\nProof: Using the definitions of kernel and nullspace, we find that #\u00bb\ud835\udc65 \u2208 Ker(\ud835\udc47\ud835\udc34)\n\u21d0\u21d2\n\ud835\udc47\ud835\udc34(#\u00bb\ud835\udc65) = #\u00bb0 F\ud835\udc5a \u21d0\u21d2 \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb0 F\ud835\udc5a \u21d0\u21d2 #\u00bb\ud835\udc65 \u2208 Null(\ud835\udc34).\nREMARK\nThe kernel of \ud835\udc47\ud835\udc34 is equal to the solution set of the homogeneous system \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb0 .\nDefinition 5.4.3\nOne-to-One\nWe say that the transformation \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5a is one-to-one (or injective) if, whenever\n\ud835\udc47(#\u00bb\ud835\udc65) = \ud835\udc47(#\u00bb\ud835\udc66 ), then #\u00bb\ud835\udc65 = #\u00bb\ud835\udc66 .\nREMARK\nNotice that the statement\nFor all #\u00bb\ud835\udc65, #\u00bb\ud835\udc66 \u2208 F\ud835\udc5b, if \ud835\udc47(#\u00bb\ud835\udc65) = \ud835\udc47(#\u00bb\ud835\udc66 ) then #\u00bb\ud835\udc65 = #\u00bb\ud835\udc66\nis logically equivalent to its contrapositive\nFor all #\u00bb\ud835\udc65, #\u00bb\ud835\udc66 \u2208 F\ud835\udc5b, if#\u00bb\ud835\udc65 \u0338= #\u00bb\ud835\udc66 then \ud835\udc47(#\u00bb\ud835\udc65) \u0338= \ud835\udc47(#\u00bb\ud835\udc66 )\nThus, one-to-one linear transformations have the nice property that they map distinct\nelements of F\ud835\udc5b to distinct elements of F\ud835\udc5a.Section 5.4\nThe Kernel of a Linear Transformation and \u201cOne-to-One\u201d Linear Transformations\n131\nThere is a simple way to check if a linear transformation is one-to-one.\nProposition 5.4.4\n(One-to-One Test)\nLet \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5a be a linear transformation. Then\n\ud835\udc47 is one-to-one if and only if Ker(\ud835\udc47) = {#\u00bb0 F\ud835\udc5b}.\nProof: Suppose that \ud835\udc47 is one-to-one. We have noted that {#\u00bb0 F\ud835\udc5b} \u2286 Ker(\ud835\udc47), so it remains\nto show that Ker(\ud835\udc47) \u2286 {#\u00bb0 F\ud835\udc5b}. For this purpose, choose an arbitrary vector #\u00bb\ud835\udc65 in Ker(\ud835\udc47),\nso that \ud835\udc47(#\u00bb\ud835\udc65) = #\u00bb0 F\ud835\udc5a. Since \ud835\udc47(#\u00bb0 F\ud835\udc5b) = #\u00bb0 F\ud835\udc5a, we have that \ud835\udc47(#\u00bb\ud835\udc65) = \ud835\udc47(#\u00bb0 F\ud835\udc5b). Since \ud835\udc47 is\none-to-one, we conclude that #\u00bb\ud835\udc65 = #\u00bb0 F\ud835\udc5b. Thus, Ker(\ud835\udc47) \u2286 {#\u00bb0 F\ud835\udc5b}.\nConversely, suppose that Ker(\ud835\udc47) = {#\u00bb0 F\ud835\udc5b}. Given any #\u00bb\ud835\udc65, #\u00bb\ud835\udc66 \u2208 F\ud835\udc5b that satisfy \ud835\udc47(#\u00bb\ud835\udc65) = \ud835\udc47(#\u00bb\ud835\udc66 ),\nwe must show that #\u00bb\ud835\udc65 = #\u00bb\ud835\udc66 . To this end, notice that\n\ud835\udc47(#\u00bb\ud835\udc65) = \ud835\udc47(#\u00bb\ud835\udc66 ) =\u21d2 \ud835\udc47(#\u00bb\ud835\udc65) \u2212 \ud835\udc47(#\u00bb\ud835\udc66 ) = #\u00bb0 F\ud835\udc5a =\u21d2 \ud835\udc47(#\u00bb\ud835\udc65 \u2212 #\u00bb\ud835\udc66 ) = #\u00bb0 F\ud835\udc5a,\nwhere the last implication follows from linearity. This shows that #\u00bb\ud835\udc65 \u2212 #\u00bb\ud835\udc66 \u2208 Ker(\ud835\udc47). Since\nby assumption Ker(\ud835\udc47) = {#\u00bb0 F\ud835\udc5b}, it follows that #\u00bb\ud835\udc65 \u2212 #\u00bb\ud835\udc66 = #\u00bb0 F\ud835\udc5b, and therefore #\u00bb\ud835\udc65 = #\u00bb\ud835\udc66 , as\nrequired.\nIf we know that our linear transformation \ud835\udc47 is of the form \ud835\udc47 = \ud835\udc47\ud835\udc34 for some matrix \ud835\udc34, then\nwe can say a bit more.\nCorollary 5.4.5\n(One-to-One Criteria)\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F) and let \ud835\udc47\ud835\udc34 be the linear transformation determined by the matrix \ud835\udc34.\nThe following statements are equivalent.\n(a) \ud835\udc47\ud835\udc34 is one-to-one.\n(b) Null(\ud835\udc34) = {\u20d70F\ud835\udc5b}.\n(c) nullity(\ud835\udc34) = 0.\n(d) rank(\ud835\udc34) = \ud835\udc5b.\nProof: ((\ud835\udc4e) \u21d2 (\ud835\udc4f)):\nThis follows from Proposition 5.4.2 (Kernel of a Linear Transformation) and Proposition\n5.4.4 (One-to-One Test).\n((\ud835\udc4f) \u21d2 (\ud835\udc50)):\nSuppose that Null(\ud835\udc34) = {#\u00bb0 F\ud835\udc5b}.\nThen the consistent system \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb0 F\ud835\udc5a has a unique\nsolution, namely #\u00bb\ud835\udc65 = #\u00bb0 F\ud835\udc5b. Thus, the solution set of this consistent system has 0 parameters,\nand so it follows from the definition of nullity that nullity(\ud835\udc34) = 0.\n((\ud835\udc50) \u21d2 (\ud835\udc51)):\nSuppose that nullity(\ud835\udc34) = 0. Since nullity(\ud835\udc34) = \ud835\udc5b \u2212 rank(\ud835\udc34) by definition, we see that\nrank(\ud835\udc34) = \ud835\udc5b.132\nChapter 5\nLinear Transformations\n((\ud835\udc51) \u21d2 (\ud835\udc4e)):\nSuppose that rank(\ud835\udc34) = \ud835\udc5b and consider the system \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb0 F\ud835\udc5a. Note that this system is\nconsistent, because #\u00bb\ud835\udc65 = #\u00bb0 F\ud835\udc5b is a solution. From Part (a) of Theorem 3.6.7 (System Rank\nTheorem), it follows that number of parameters in the solution set of this consistent system\nis \ud835\udc5b \u2212 rank(\ud835\udc34) = \ud835\udc5b \u2212 \ud835\udc5b = 0. We conclude that the solution #\u00bb\ud835\udc65 = #\u00bb0 F\ud835\udc5b to \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb0 F\ud835\udc5a is\nunique.\nThis shows that Null(\ud835\udc34) = {#\u00bb0 F\ud835\udc5b}. Thus Ker(\ud835\udc47\ud835\udc34) = {#\u00bb0 F\ud835\udc5b} by Proposition 5.4.2 (Kernel of\na Linear Transformation), and therefore \ud835\udc47\ud835\udc34 is one-to-one by Proposition 5.4.4 (One-to-One\nTest).\nExample 5.4.6\nDetermine whether or not the linear transformation \ud835\udc47\ud835\udc34 : R3\n\u2192\nR3 determined by\n\ud835\udc34 =\n\u23a1\n\u23a3\n2 4\n10\n4 \u22124 \u22124\n6 8\n22\n\u23a4\n\u23a6 is one-to-one.\nSolution: Let us examine the kernel of \ud835\udc47\ud835\udc34, which is the same as looking at the solution\nset to \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb0 . The augmented matrix is\n\u23a1\n\u23a3\n2 4\n10 0\n4 \u22124 \u22124 0\n6 8\n22 0\n\u23a4\n\u23a6 ,\nwhich row reduces to\n\u23a1\n\u23a3\n1 2 5 0\n0 1 2 0\n0 0 0 0\n\u23a4\n\u23a6 .\nThus rank(\ud835\udc34) = 2 < 3 = \ud835\udc5b, and it follows that \ud835\udc47\ud835\udc34 is not one-to-one by Part (d) of Corollary\n5.4.5 (One-to-One Criteria).\nBy combining Corollary 5.3.6 (Onto Criteria) and Corollary 5.4.5 (One-to-One Criteria) we\narrive at the following result concerning square matrices. The proof is left as an exercise.\n(Compare with Theorem 4.6.7 (Invertibility Criteria \u2013 First Version).)\nTheorem 5.4.7\n(Invertibility Criteria \u2013 Second Version)\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) be a square matrix and let \ud835\udc47\ud835\udc34 be the linear transformation determined\nby the matrix \ud835\udc34. The following statements are equivalent.\n(a) \ud835\udc34 is invertible.\n(b) \ud835\udc47\ud835\udc34 is one-to-one.\n(c) \ud835\udc47\ud835\udc34 is onto.\n(d) Null(\ud835\udc34) = {#\u00bb0 }. That is, the only solution to the homogeneous system \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb0 is the\ntrivial solution #\u00bb\ud835\udc65 = #\u00bb0 .\n(e) Col(\ud835\udc34) = F\ud835\udc5b. That is, for every #\u00bb\ud835\udc4f \u2208 F\ud835\udc5b, the system \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f is consistent.\n(f) nullity(\ud835\udc34) = 0.Section 5.5", "Every Linear Transformation is Determined by a Matrix\n133\n(g) rank(\ud835\udc34) = \ud835\udc5b.\n(h) RREF(\ud835\udc34) = \ud835\udc3c\ud835\udc5b.\n5.5\nEvery Linear Transformation is Determined by a Matrix\nIn Section 5.1 we saw that every matrix \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F) determines a linear transformation\n\ud835\udc47\ud835\udc34 : F\ud835\udc5b \u2192 F\ud835\udc5a. We will show in this section that, conversely, every linear transformation\n\ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5a is actually of the form \ud835\udc47 = \ud835\udc47\ud835\udc34 for a certain matrix \ud835\udc34 (that depends on \ud835\udc47). In\nfact, we will show that there is a very natural process that constructs this matrix \ud835\udc34 from\n\ud835\udc47.\nWe will make use of the set\n\u2130 =\n\u23a7\n\u23aa\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n1\n0\n...\n0\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 ,\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n0\n1\n...\n0\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 , \u00b7 \u00b7 \u00b7 ,\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n0\n0\n...\n1\n\u23a4\n\u23a5\u23a5\u23a5\u23a6\n\u23ab\n\u23aa\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23aa\n\u23ad\n= {#\u00bb\n\ud835\udc521, #\u00bb\n\ud835\udc522, . . . , #\u00bb\n\ud835\udc52\ud835\udc5b}\nof standard basis vectors in F\ud835\udc5b (which we had already met in Definition 1.3.15).\nExample 5.5.1\nLet us examine the consequences of linearity in the special case when F\ud835\udc5b = F\ud835\udc5a = F2. Thus\nsuppose that \ud835\udc47 : F2 \u2192 F2 is a linear mapping and let #\u00bb\ud835\udc65 =\n[\ufe02\ud835\udc651\n\ud835\udc652\n]\ufe02\nbe a vector in F2. Then\n\ud835\udc47\n(\ufe02[\ufe02\ud835\udc651\n\ud835\udc652\n]\ufe02)\ufe02\n= \ud835\udc47\n(\ufe02[\ufe02\ud835\udc651\n0\n]\ufe02\n+\n[\ufe02 0\n\ud835\udc652\n]\ufe02)\ufe02\n= \ud835\udc47\n(\ufe02\n\ud835\udc651\n[\ufe021\n0\n]\ufe02\n+ \ud835\udc652\n[\ufe020\n1\n]\ufe02)\ufe02\n= \ud835\udc651 \ud835\udc47\n(\ufe02[\ufe021\n0\n]\ufe02)\ufe02\n+ \ud835\udc652 \ud835\udc47\n(\ufe02[\ufe020\n1\n]\ufe02)\ufe02\n(by linearity)\n=\n[\ufe00\n\ud835\udc47(#\u00bb\n\ud835\udc521) \ud835\udc47(#\u00bb\n\ud835\udc522)\n]\ufe00 [\ufe02\ud835\udc651\n\ud835\udc652\n]\ufe02\n=\n[\ufe00\n\ud835\udc47(#\u00bb\n\ud835\udc521) \ud835\udc47(#\u00bb\n\ud835\udc522)\n]\ufe00 #\u00bb\ud835\udc65.\nThis shows us that the actual effect of the linear transformation can be replicated by the\nintroduction of a matrix\n[\ufe00\n\ud835\udc47(#\u00bb\n\ud835\udc521) \ud835\udc47(#\u00bb\n\ud835\udc522)\n]\ufe00\n.\nIn addition, this matrix\n[\ufe00\n\ud835\udc47(#\u00bb\n\ud835\udc521) \ud835\udc47(#\u00bb\n\ud835\udc522)\n]\ufe00\nhas columns which are constructed by applying \ud835\udc47 to\nthe basis vectors #\u00bb\n\ud835\udc521 and #\u00bb\n\ud835\udc522 in F2. This means that if we know what the linear transformation\ndoes to just these two (standard basis) vectors, then we can determine what it does to all\nvectors in F2.\nFinally, the actual value of \ud835\udc47(#\u00bb\ud835\udc65) can be computed by matrix multiplication of this matrix\n[\ufe00\n\ud835\udc47(#\u00bb\n\ud835\udc521) \ud835\udc47(#\u00bb\n\ud835\udc522)\n]\ufe00\nby the component vector #\u00bb\ud835\udc65. This result extends to higher dimensions.134\nChapter 5\nLinear Transformations\nDefinition 5.5.2\nStandard Matrix\nLet \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5a be a linear transformation. We define the standard matrix of \ud835\udc47, denoted\nby [\ud835\udc47]\u2130, to be \ud835\udc5a \u00d7 \ud835\udc5b matrix whose columns are the images under \ud835\udc47 of the vectors in the\nstandard basis of F\ud835\udc5b:\n[\ud835\udc47]\u2130 =\n[\ufe00\n\ud835\udc47(#\u00bb\n\ud835\udc521) \ud835\udc47(#\u00bb\n\ud835\udc522) \u00b7 \u00b7 \u00b7 \ud835\udc47(#\u00bb\n\ud835\udc52\ud835\udc5b)\n]\ufe00\n=\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\ud835\udc47\n\u239b\n\u239c\n\u239c\n\u239c\n\u239d\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n1\n0\n...\n0\n\u23a4\n\u23a5\u23a5\u23a5\u23a6\n\u239e\n\u239f\n\u239f\n\u239f\n\u23a0 \ud835\udc47\n\u239b\n\u239c\n\u239c\n\u239c\n\u239d\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n0\n1\n...\n0\n\u23a4\n\u23a5\u23a5\u23a5\u23a6\n\u239e\n\u239f\n\u239f\n\u239f\n\u23a0 \u00b7 \u00b7 \u00b7 \ud835\udc47\n\u239b\n\u239c\n\u239c\n\u239c\n\u239d\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n0\n0\n...\n1\n\u23a4\n\u23a5\u23a5\u23a5\u23a6\n\u239e\n\u239f\n\u239f\n\u239f\n\u23a0\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 .\nREMARKS\n\u2022 There is a \ud835\udc47 to remind us of the linear transformation that we are going to represent.\n\u2022 The square brackets in [\ud835\udc47]\u2130 is our way of indicating that we are converting a linear\ntransformation into a matrix.\n\u2022 The \u2130 indicates that the standard basis is being used for both the domain and the\ncodomain. Later we will investigate the consequences of using different bases in either\nor both of these two sets.\nTheorem 5.5.3\n(Every Linear Transformation Is Determined by a Matrix)\nLet \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5a be a linear transformation and let [\ud835\udc47]\u2130 be the standard matrix of \ud835\udc47. Then\nfor all #\u00bb\ud835\udc65 \u2208 F\ud835\udc5b,\n\ud835\udc47(#\u00bb\ud835\udc65) = [\ud835\udc47]\u2130 #\u00bb\ud835\udc65.\nThat is, \ud835\udc47 = \ud835\udc47[\ud835\udc47]\u2130 is the linear transformation determined by the matrix [\ud835\udc47]\u2130.\nProof: Let #\u00bb\ud835\udc65 \u2208 F\ud835\udc5b with #\u00bb\ud835\udc65 =\n[\ufe00\n\ud835\udc651 \ud835\udc652 \u00b7 \u00b7 \u00b7 \ud835\udc65\ud835\udc5b\n]\ufe00\ud835\udc47 . Then\n\ud835\udc47(#\u00bb\ud835\udc65) = \ud835\udc47\n\u239b\n\u239c\n\u239c\n\u239c\n\u239d\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc651\n\ud835\udc652\n...\n\ud835\udc65\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6\n\u239e\n\u239f\n\u239f\n\u239f\n\u23a0\n= \ud835\udc47\n\u239b\n\u239c\n\u239c\n\u239c\n\u239d\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc651\n0\n...\n0\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 +\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n0\n\ud835\udc652\n...\n0\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 + \u00b7 \u00b7 \u00b7 +\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n0\n0\n...\n\ud835\udc65\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6\n\u239e\n\u239f\n\u239f\n\u239f\n\u23a0\n= \ud835\udc47 (\ud835\udc651 #\u00bb\n\ud835\udc521 + \ud835\udc652 #\u00bb\n\ud835\udc522 + \u00b7 \u00b7 \u00b7 + \ud835\udc65\ud835\udc5b #\u00bb\n\ud835\udc52\ud835\udc5b)\n= \ud835\udc651\ud835\udc47 (#\u00bb\n\ud835\udc521) + \ud835\udc652\ud835\udc47 (#\u00bb\n\ud835\udc522) + \u00b7 \u00b7 \u00b7 + \ud835\udc65\ud835\udc5b\ud835\udc47 (#\u00bb\n\ud835\udc52\ud835\udc5b)\n(using linearity)Section 5.5\nEvery Linear Transformation is Determined by a Matrix\n135\n=\n[\ufe00\n\ud835\udc47(#\u00bb\n\ud835\udc521) \ud835\udc47(#\u00bb\n\ud835\udc522) \u00b7 \u00b7 \u00b7 \ud835\udc47(#\u00bb\n\ud835\udc52\ud835\udc5b)\n]\ufe00\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc651\n\ud835\udc652\n...\n\ud835\udc65\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6\n= [\ud835\udc47]\u2130 #\u00bb\ud835\udc65.\nThis result is quite remarkable.\nFirst, the matrix representation provides us with a very elegant and compact way of ex-\npressing the linear transformation.\nSecond, the construction of the standard matrix is very simple. We must only find the\nimages of the \ud835\udc5b standard basis vectors and build the standard matrix column by column\nfrom these images.\nThird, once we have this standard matrix, we can find the image of any vector in F\ud835\udc5b under\nthe linear transformation using matrix\u2013vector multiplication.\nThus, if \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5a is a linear transformation, then once we know \ud835\udc47(#\u00bb\n\ud835\udc521), . . . , \ud835\udc47(#\u00bb\n\ud835\udc52\ud835\udc5b), we\ncan compute \ud835\udc47(#\u00bb\ud835\udc65) for all #\u00bb\ud835\udc65 \u2208 F\ud835\udc5b. This property is incredibly strong and is one of the key\nfeatures of linear transformations.\nIn particular, linear transformations \ud835\udc47 : R \u2192 R are very simple.\nFor example, given\n\ud835\udc54(\ud835\udc65) = \ud835\udc5a\ud835\udc65 (a linear function through the origin), it is possible to determine the value\nof \ud835\udc5a if we are provided with any non-zero point \ud835\udc43 that falls on the line. It turns out that\nthese functions completely categorize linear transformations \ud835\udc47 : R \u2192 R, which is our result\nbelow.\nProposition 5.5.4\nLet \ud835\udc47 : R \u2192 R be a linear transformation. Then there is a real number \ud835\udc5a \u2208 R such that\n\ud835\udc47(\ud835\udc65) = \ud835\udc5a\ud835\udc65 for all \ud835\udc65 \u2208 R.\nProof: We have \ud835\udc47(\ud835\udc65) = [\ud835\udc47]\u2130\ud835\udc65, where the standard matrix [\ud835\udc47]\u2130 of \ud835\udc47 is the 1 \u00d7 1 matrix\n[\ud835\udc47(1)]. Thus, if we let \ud835\udc5a = \ud835\udc47(1), we find that \ud835\udc47(\ud835\udc65) = \ud835\udc5a\ud835\udc65, as required.\nNote that the above property is not true of non-linear transformations. For example, the\n(non-linear) function \ud835\udc53 : R \u2192 R defined by \ud835\udc53(\ud835\udc65) = sin(\ud835\udc65) cannot be determined from\nknowing the value of sin(1).\nTo conclude this section, we summarize what we have learned.\nGiven a matrix\n\ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F), we can define a linear transformation \ud835\udc47\ud835\udc34 : F\ud835\udc5b \u2192 F\ud835\udc5a. Conversely, given\na linear transformation \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5a, we can construct a matrix [\ud835\udc47]\u2130 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F). What\nhappens if we combine these two processes? That is, what can we say about \ud835\udc47[\ud835\udc47]\u2130 and\n[\ud835\udc47\ud835\udc34]\u2130?\nWe answer both these questions and state a couple of useful consequences in the following\nresult.136\nChapter 5\nLinear Transformations\nProposition 5.5.5\n(Properties of a Standard Matrix)\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F), let \ud835\udc47\ud835\udc34 : F\ud835\udc5b \u2192 F\ud835\udc5a be the linear transformation determined by \ud835\udc34, and let\n\ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5a be a linear transformation. Then\n(a) \ud835\udc47[\ud835\udc47]\u2130 = \ud835\udc47.\n(b) [\ud835\udc47\ud835\udc34]\u2130 = \ud835\udc34.\n(c) \ud835\udc47 is onto if and only if rank([\ud835\udc47]\u2130) = \ud835\udc5a.\n(d) \ud835\udc47 is one-to-one if and only if rank([\ud835\udc47]\u2130) = \ud835\udc5b.\nProof: (a) Using the definition of the linear transformation defined by a matrix, we have\n\ud835\udc47[\ud835\udc47]\u2130 #\u00bb\ud835\udc65 = [\ud835\udc47]\u2130 #\u00bb\ud835\udc65 = \ud835\udc47 #\u00bb\ud835\udc65\nfor all #\u00bb\ud835\udc65 \u2208 F\ud835\udc5b,\nwhere the last equality follows from Theorem 5.5.3 (Every Linear Transformation Is\nDetermined by a Matrix). Thus, the two functions \ud835\udc47[\ud835\udc47]\u2130 and \ud835\udc47 have the same values\nat each #\u00bb\ud835\udc65 \u2208 F\ud835\udc5b, so they must be equal.\n(b) Using the definition of the standard matrix, we have\n[\ud835\udc47\ud835\udc34]\u2130 =\n[\ufe00\n\ud835\udc47\ud835\udc34(#\u00bb\n\ud835\udc521) \u00b7 \u00b7 \u00b7 \ud835\udc47\ud835\udc34(#\u00bb\n\ud835\udc52\ud835\udc5b)\n]\ufe00\n=\n[\ufe00\n\ud835\udc34#\u00bb\n\ud835\udc521 \u00b7 \u00b7 \u00b7 \ud835\udc34#\u00bb\n\ud835\udc52\ud835\udc5b\n]\ufe00\n=\n[\ufe00 #\u00bb\n\ud835\udc4e1 \u00b7 \u00b7 \u00b7 # \u00bb\n\ud835\udc4e\ud835\udc5b\n]\ufe00\n(by Lemma 4.2.2 (Column Extraction))\n= \ud835\udc34.\n(c) This follows from Corollary 5.3.6 (Onto Criteria).\n(d) This follows from Corollary 5.4.5 (One-to-One Criteria).\n5.6\nSpecial Linear Transformations: Projection, Perpendic-\nular, Rotation and Reflection\nIn this section, we will revisit the operations of projection and perpendicular discussed in\nChapter 1, prove that both of these types of transformations are linear, and determine their\nstandard matrices. We will do the same for the operations of rotation and reflection.\nExample 5.6.1\n(Projection onto a line through the origin)\nLet #\u00bb\ud835\udc64 =\n[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02\nbe a non-zero vector in R2.\nConsider the projection transformation\nproj #\u00bb\n\ud835\udc64 : R2 \u2192 R2 defined in Section 1.6.\n(a) Prove that proj #\u00bb\n\ud835\udc64 is a linear transformation.Section 5.6", "Special Linear Transformations: Projection, Perpendicular, Rotation and Reflection\n137\n(b) Determine the standard matrix of proj#\u00bb\n\ud835\udc64.\n(c) Determine whether proj #\u00bb\n\ud835\udc64 is onto.\n(d) Determine whether proj #\u00bb\n\ud835\udc64 is one-to-one.\nSolution:\n(a) Recall that if #\u00bb\ud835\udc63 is a vector in R2, then the projection of #\u00bb\ud835\udc63 onto #\u00bb\ud835\udc64 is defined by\nproj #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 ) =\n#\u00bb\ud835\udc63 \u00b7 #\u00bb\ud835\udc64\n\u2016#\u00bb\ud835\udc64\u20162\n#\u00bb\ud835\udc64.\nNow let #\u00bb\ud835\udc62, #\u00bb\ud835\udc63 \u2208 R2 and let \ud835\udc501, \ud835\udc502 \u2208 R. By the linearity properties of the dot product,\nproj #\u00bb\n\ud835\udc64(\ud835\udc501 #\u00bb\ud835\udc62 + \ud835\udc502 #\u00bb\ud835\udc63 ) = \ud835\udc501\n#\u00bb\ud835\udc62 \u00b7 #\u00bb\ud835\udc64\n\u2016#\u00bb\ud835\udc64\u20162\n#\u00bb\ud835\udc64 + \ud835\udc502\n#\u00bb\ud835\udc63 \u00b7 #\u00bb\ud835\udc64\n\u2016#\u00bb\ud835\udc64\u20162\n#\u00bb\ud835\udc64\n= \ud835\udc501 proj #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc62) + \ud835\udc502 proj #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 ).\nWe conclude that proj #\u00bb\n\ud835\udc64 is a linear transformation.\n(b) To find the standard matrix [proj#\u00bb\n\ud835\udc64]\u2130 of proj #\u00bb\n\ud835\udc64, recall that\n[proj #\u00bb\n\ud835\udc64]\u2130 =\n[\ufe00\nproj #\u00bb\n\ud835\udc64(#\u00bb\n\ud835\udc521) proj #\u00bb\n\ud835\udc64(#\u00bb\n\ud835\udc522)\n]\ufe00\n.\nSince\nproj #\u00bb\n\ud835\udc64(#\u00bb\n\ud835\udc521) =\n#\u00bb\n\ud835\udc521 \u00b7 #\u00bb\ud835\udc64\n\u2016#\u00bb\ud835\udc64\u20162\n#\u00bb\ud835\udc64 = \ud835\udc641 \u00b7 1 + \ud835\udc642 \u00b7 0\n\ud835\udc642\n1 + \ud835\udc642\n2\n[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02\n=\n1\n\ud835\udc642\n1 + \ud835\udc642\n2\n[\ufe02 \ud835\udc642\n1\n\ud835\udc641\ud835\udc642\n]\ufe02\nproj #\u00bb\n\ud835\udc64(#\u00bb\n\ud835\udc522) =\n#\u00bb\n\ud835\udc522 \u00b7 #\u00bb\ud835\udc64\n\u2016#\u00bb\ud835\udc64\u20162\n#\u00bb\ud835\udc64 = \ud835\udc641 \u00b7 0 + \ud835\udc642 \u00b7 1\n\ud835\udc642\n1 + \ud835\udc642\n2\n[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02\n=\n1\n\ud835\udc642\n1 + \ud835\udc642\n2\n[\ufe02\ud835\udc641\ud835\udc642\n\ud835\udc642\n2\n]\ufe02\n,\nwe have\n[proj #\u00bb\n\ud835\udc64]\u2130 =\n1\n\ud835\udc642\n1 + \ud835\udc642\n2\n[\ufe02 \ud835\udc642\n1\n\ud835\udc641\ud835\udc642\n\ud835\udc641\ud835\udc642\n\ud835\udc642\n2\n]\ufe02\n.\n(c) There are two ways in which we can argue why proj #\u00bb\n\ud835\udc64 is not an onto linear transfor-\nmation. Thinking geometrically, note that all images of proj#\u00bb\n\ud835\udc64 lie on the line Span{#\u00bb\ud835\udc64}\nand nowhere else in R2. Equivalently,\nRange(proj #\u00bb\n\ud835\udc64) = Span\n{\ufe02\n\ud835\udc641\n\ud835\udc642\n1 + \ud835\udc642\n2\n[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02\n,\n\ud835\udc642\n\ud835\udc642\n1 + \ud835\udc642\n2\n[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02}\ufe02\n= Span\n{\ufe02[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02}\ufe02\n\u0338= R2.\n(d) Once again, there are two ways in which we can argue why proj#\u00bb\n\ud835\udc64 is not a one-to-\none linear transformation. Thinking geometrically, note that there are many different\nvectors which have the same image when they are projected onto the line. Equivalently,\nthe kernel is obtained by solving the system\n1\n\ud835\udc642\n1 + \ud835\udc642\n2\n[\ufe02 \ud835\udc642\n1\n\ud835\udc641\ud835\udc642\n\ud835\udc641\ud835\udc642\n\ud835\udc642\n2\n]\ufe02\n#\u00bb\ud835\udc63 = #\u00bb0 ,\nwhich row-reduces to\n[\ufe02\ud835\udc641 \ud835\udc642\n0\n0\n]\ufe02\n#\u00bb\ud835\udc63 = #\u00bb0 .\nSince the rank of the coefficient matrix is strictly less than 2, it follows that proj#\u00bb\n\ud835\udc64 not\none-to-one from Corollary 5.4.5 (One-to-One Criteria).138\nChapter 5\nLinear Transformations\nNote that if you want to project onto a line that does not pass through the origin, then you\ncan project on the parallel line through the origin and then translate the solution. Note,\nhowever, that this function is not an example of a linear transformation, since #\u00bb0 would not\nbe mapped to #\u00bb0 .\nEXERCISE\nLet\n#\u00bb\ud835\udc64 be a non-zero vector in R\ud835\udc5b and consider the perpendicular transformation\nperp #\u00bb\n\ud835\udc64 : R\ud835\udc5b \u2192 R\ud835\udc5b defined in Section 1.6 for #\u00bb\ud835\udc63 \u2208 R\ud835\udc5b:\nperp #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 ) = #\u00bb\ud835\udc63 \u2212 proj #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 ).\n(a) Prove that perp #\u00bb\n\ud835\udc64 is a linear transformation.\n(b) Determine the standard matrix of perp#\u00bb\n\ud835\udc64.\n(c) Determine whether perp #\u00bb\n\ud835\udc64 is onto.\n(d) Determine whether perp #\u00bb\n\ud835\udc64 is one-to-one.\nExample 5.6.2\n(Projection onto a plane through the origin)\nWe can define the projection map onto a plane through the origin by using a normal vector\nof the plane. For a plane \ud835\udc43 with normal vector #\u00bb\ud835\udc5b, we know every vector #\u00bb\ud835\udc64 \u2208 \ud835\udc43 is orthogonal\nto #\u00bb\ud835\udc5b, so we know that #\u00bb\ud835\udc64 = perp #\u00bb\ud835\udc5b(#\u00bb\ud835\udc64).\nIntuitively, for #\u00bb\ud835\udc63 , #\u00bb\ud835\udc64 \u2208 R3, we think of proj #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 ) as the #\u00bb\ud835\udc64-component of #\u00bb\ud835\udc63 ; the same analogy\ncan be made with planes. With this intuition in place, we define the projection of #\u00bb\ud835\udc63 onto\nthe plane \ud835\udc43 as\nproj\ud835\udc43 (#\u00bb\ud835\udc63 ) = perp #\u00bb\ud835\udc5b(#\u00bb\ud835\udc63 ).\nWith this established, consider the projection map proj\ud835\udc43 : R3 \u2192 R3 onto a plane \ud835\udc43, where\n\ud835\udc43 is defined by the scalar equation 3\ud835\udc65 \u2212 4\ud835\udc66 + 5\ud835\udc67 = 0.Section 5.6\nSpecial Linear Transformations: Projection, Perpendicular, Rotation and Reflection\n139\n(a) Prove that proj\ud835\udc43 is a linear transformation.\n(b) Determine the standard matrix of proj\ud835\udc43 .\n(c) Determine whether proj\ud835\udc43 is onto.\n(d) Determine whether proj\ud835\udc43 is one-to-one.\nSolution:\n(a) Let #\u00bb\ud835\udc5b =\n[\ufe00\n3 \u22124 5\n]\ufe00\ud835\udc47 be a normal to the plane \ud835\udc43. Then proj\ud835\udc43 (#\u00bb\ud835\udc63 ) = perp #\u00bb\ud835\udc5b(#\u00bb\ud835\udc63 ), and\nbecause we know (from the exercise above) that perp #\u00bb\ud835\udc5b is a linear transformation, we\nconclude that proj\ud835\udc43 is a linear transformation as well.\n(b) To find the standard matrix [proj\ud835\udc43 ]\u2130 of proj\ud835\udc43 , recall that\n[proj\ud835\udc43 ]\u2130 =\n[\ufe00\nproj\ud835\udc43 (#\u00bb\n\ud835\udc521) proj\ud835\udc43 (#\u00bb\n\ud835\udc522) proj\ud835\udc43 (#\u00bb\n\ud835\udc523)\n]\ufe00\nSince\nproj\ud835\udc43 (#\u00bb\n\ud835\udc521) = perp #\u00bb\ud835\udc5b(#\u00bb\n\ud835\udc521)\n= #\u00bb\n\ud835\udc521 \u2212 proj #\u00bb\ud835\udc5b(#\u00bb\n\ud835\udc521)\n= #\u00bb\n\ud835\udc521 \u2212\n#\u00bb\n\ud835\udc521 \u00b7 #\u00bb\ud835\udc5b\n\u2016#\u00bb\ud835\udc5b\u20162\n#\u00bb\ud835\udc5b\n=\n\u23a1\n\u23a3\n1\n0\n0\n\u23a4\n\u23a6 \u2212 1 \u00b7 3 + 0 \u00b7 (\u22124) + 0 \u00b7 5\n50\n\u23a1\n\u23a3\n3\n\u22124\n5\n\u23a4\n\u23a6 =\n\u23a1\n\u23a3\n41/50\n6/25\n\u22123/10\n\u23a4\n\u23a6\nproj\ud835\udc43 (#\u00bb\n\ud835\udc522) =\n\u23a1\n\u23a3\n0\n1\n0\n\u23a4\n\u23a6 \u2212 0 \u00b7 3 + 1 \u00b7 (\u22124) + 0 \u00b7 5\n50\n\u23a1\n\u23a3\n3\n\u22124\n5\n\u23a4\n\u23a6 =\n\u23a1\n\u23a3\n6/25\n17/25\n2/5\n\u23a4\n\u23a6\nproj\ud835\udc43 (#\u00bb\n\ud835\udc523) =\n\u23a1\n\u23a3\n0\n0\n1\n\u23a4\n\u23a6 \u2212 0 \u00b7 3 + 0 \u00b7 (\u22124) + 1 \u00b7 5\n50\n\u23a1\n\u23a3\n3\n\u22124\n5\n\u23a4\n\u23a6 =\n\u23a1\n\u23a3\n\u22123/10\n2/5\n1/2\n\u23a4\n\u23a6\nwe have that\n[proj\ud835\udc43 ]\u2130 =\n\u23a1\n\u23a3\n41/50 6/25 \u22123/10\n6/25 17/25\n2/5\n\u22123/10\n2/5\n1/2\n\u23a4\n\u23a6 .\n(c) There are two ways in which we can argue why proj\ud835\udc43 is not onto. Thinking geomet-\nrically, note that all images lie on the plane 3\ud835\udc65 \u2212 4\ud835\udc66 + 5\ud835\udc67 = 0 and nowhere else in R3.\nEquivalently, we could investigate the range and show that it is not R3. This can be\ndone, for example, by finding one vector #\u00bb\ud835\udc63 \u2208 R3 such that the system [proj\ud835\udc43 ]\u2130 #\u00bb\ud835\udc65 = #\u00bb\ud835\udc63\nis inconsistent. This can be achieved by taking any vector #\u00bb\ud835\udc63 /\u2208 \ud835\udc43, such as #\u00bb\ud835\udc63 = #\u00bb\n\ud835\udc521\n(notice that 1 \u00b7 3 + 0 \u00b7 (\u22124) + 0 \u00b7 5 \u0338= 0). Since #\u00bb\ud835\udc63 /\u2208 Range(proj\ud835\udc43 ), we conclude that\nRange(proj\ud835\udc43 ) \u0338= R3, and so proj\ud835\udc43 is not onto.140\nChapter 5\nLinear Transformations\n(d) Once again, there are two ways in which we can argue why proj\ud835\udc43 is not one-to-one.\nThinking geometrically, note that many different points have the same image when they\nare projected onto the plane. Equivalently, the kernel is obtained by solving\n[proj\ud835\udc43 ]\u2130 #\u00bb\ud835\udc65 = #\u00bb0 .\nSince the rank of the coefficient matrix is strictly less than 3, it follows that proj\ud835\udc43 not\none-to-one from Corollary 5.4.5 (One-to-One Criteria).\nExample 5.6.3\n(Rotation about the origin by an angle \ud835\udf03)\nConsider the transformation \ud835\udc45\ud835\udf03 : R2 \u2192 R2 that rotates every vector #\u00bb\ud835\udc65 \u2208 R2 by a fixed\nangle \ud835\udf03 counter-clockwise about the origin. We will assume 0 < \ud835\udf03 < 2\ud835\udf0b so that the rotation\naction is not trivial. This linear transformation is illustrated in the diagram below. Notice\nthat the variable \ud835\udc5f represents the length of a vector #\u00bb\ud835\udc65.\n(a) Prove that \ud835\udc45\ud835\udf03 is a linear transformation.\n(b) Determine the standard matrix of \ud835\udc45\ud835\udf03.\n(c) Determine whether \ud835\udc45\ud835\udf03 is onto.\n(d) Determine whether \ud835\udc45\ud835\udf03 is one-to-one.\nSolution:\n(a) We will prove that \ud835\udc45\ud835\udf03 is a linear transformation by showing that it can be written in\nthe form \ud835\udc45\ud835\udf03(#\u00bb\ud835\udc65) = \ud835\udc34#\u00bb\ud835\udc65 for some matrix \ud835\udc34 \u2208 \ud835\udc402\u00d72(R). Let #\u00bb\ud835\udc65 =\n[\ufe02\ud835\udc651\n\ud835\udc652\n]\ufe02\nbe an arbitrary\nvector in R2.\nRecall that we can convert #\u00bb\ud835\udc65 into its polar representation by taking\n\ud835\udc5f = \u2016#\u00bb\ud835\udc65\u2016 (the length of #\u00bb\ud835\udc65) and multiplying by cos \ud835\udf11 to get the \ud835\udc65-coordinate and sin \ud835\udf11\nto get the \ud835\udc66-coordinate, where \ud835\udf11 is the angle between #\u00bb\n\ud835\udc521 and #\u00bb\ud835\udc65.\nConverting #\u00bb\ud835\udc65 into polar coordinates, we find that #\u00bb\ud835\udc65 =\n[\ufe02\ud835\udc5f cos \ud835\udf11\n\ud835\udc5f sin \ud835\udf11\n]\ufe02\n, Since \ud835\udc45\ud835\udf03(#\u00bb\ud835\udc65) is the\nresult of a counter-clockwise rotation of #\u00bb\ud835\udc65 by an angle \ud835\udf03 about the origin,\n\ud835\udc45\ud835\udf03\n(\ufe02[\ufe02\ud835\udc5f cos \ud835\udf11\n\ud835\udc5f sin \ud835\udf11\n]\ufe02)\ufe02\n=\n[\ufe02\ud835\udc5f cos(\ud835\udf11 + \ud835\udf03)\n\ud835\udc5f sin(\ud835\udf11 + \ud835\udf03)\n]\ufe02\n.Section 5.6\nSpecial Linear Transformations: Projection, Perpendicular, Rotation and Reflection\n141\nBy making use of the trigonometric angle-sum identities\ncos (\ud835\udf11 + \ud835\udf03) = cos \ud835\udf11 cos \ud835\udf03 \u2212 sin \ud835\udf11 sin \ud835\udf03\nand\nsin (\ud835\udf11 + \ud835\udf03) = sin \ud835\udf11 cos \ud835\udf03 + cos \ud835\udf11 sin \ud835\udf03,\nwe have\n\ud835\udc45\ud835\udf03(#\u00bb\ud835\udc65) = \ud835\udc45\ud835\udf03\n(\ufe02[\ufe02\ud835\udc5f cos \ud835\udf11\n\ud835\udc5f sin \ud835\udf11\n]\ufe02)\ufe02\n=\n[\ufe02\ud835\udc5f cos(\ud835\udf11 + \ud835\udf03)\n\ud835\udc5f sin(\ud835\udf11 + \ud835\udf03)\n]\ufe02\n=\n[\ufe02\ud835\udc5f(cos \ud835\udf11 cos \ud835\udf03 \u2212 sin \ud835\udf11 sin \ud835\udf03)\n\ud835\udc5f(sin \ud835\udf11 cos \ud835\udf03 + cos \ud835\udf11 sin \ud835\udf03)\n]\ufe02\n=\n[\ufe02cos \ud835\udf03(\ud835\udc5f cos \ud835\udf11) \u2212 sin \ud835\udf03(\ud835\udc5f sin \ud835\udf11)\nsin \ud835\udf03(\ud835\udc5f cos \ud835\udf11) + cos \ud835\udf03(\ud835\udc5f sin \ud835\udf11)\n]\ufe02\n=\n[\ufe02cos \ud835\udf03 \u2212 sin \ud835\udf03\nsin \ud835\udf03\ncos \ud835\udf03\n]\ufe02 [\ufe02\ud835\udc5f cos \ud835\udf11\n\ud835\udc5f sin \ud835\udf11\n]\ufe02\n= \ud835\udc34#\u00bb\ud835\udc65,\nwhere \ud835\udc34 =\n[\ufe02cos \ud835\udf03 \u2212 sin \ud835\udf03\nsin \ud835\udf03\ncos \ud835\udf03\n]\ufe02\n. Since we were able to express \ud835\udc45\ud835\udf03 in the form of a matrix-\nvector product, it must be the case that \ud835\udc45\ud835\udf03 is a linear transformation.\n(b) From part (a) we find that\n[\ud835\udc45\ud835\udf03]\u2130 = \ud835\udc34 =\n[\ufe02cos \ud835\udf03 \u2212 sin \ud835\udf03\nsin \ud835\udf03\ncos \ud835\udf03\n]\ufe02\n.\n(c) There are two ways in which we can argue why \ud835\udc45\ud835\udf03 is onto. Thinking geometrically,\nnote that any vector in R2 can be obtained by a rotation from an appropriate starting\nvector.\nEquivalently, as Range(\ud835\udc45\ud835\udf03) = Col([\ud835\udc45\ud835\udf03]\u2130) by Proposition 5.3.2 (Range of a\nLinear Transformation), we have\nRange(\ud835\udc45\ud835\udf03) = Span\n{\ufe02[\ufe02cos \ud835\udf03\nsin \ud835\udf03\n]\ufe02\n,\n[\ufe02\u2212 sin \ud835\udf03\ncos \ud835\udf03\n]\ufe02}\ufe02\nand it can be shown that this is R2.\n(d) Once again, there are two ways in which we can argue why \ud835\udc45\ud835\udf03 is one-to-one. Thinking\ngeometrically, note that any two different vectors have different images when they are\nrotated. Equivalently, as Ker(\ud835\udc45\ud835\udf03) = Null([\ud835\udc45\ud835\udf03]\u2130) by Proposition 5.4.2 (Kernel of a Linear\nTransformation), we have\n[\ufe02cos \ud835\udf03 \u2212 sin \ud835\udf03\nsin \ud835\udf03\ncos \ud835\udf03\n]\ufe02\n#\u00bb\ud835\udc65 = #\u00bb0 .\nGiven that the angle \ud835\udf03 is fixed here, we view sin \ud835\udf03 and cos \ud835\udf03 as constants, so we can\nreduce this matrix as normal. We wish to show that the rank of the coefficient matrix\nis 2, so that the only solution to the system above is the trivial solution, allowing us to\nconclude that this linear transformation is one-to-one.142\nChapter 5\nLinear Transformations\nFirst, note that if cos(\ud835\udf03) = 0 or sin(\ud835\udf03) = 0 (conditions which cannot occur simultane-\nously) then the matrix is either in REF or a row swap will establish an REF. As such,\nin these scenarios the rank is 2 and the linear transformation is one-to-one.\nIn the scenarios where sin \ud835\udf03 \u0338= 0 and cos \ud835\udf03 \u0338= 0, we have\n{\ufe03\n\ud835\udc451 \u2192 (sin \ud835\udf03)\ud835\udc451\n\ud835\udc452 \u2192 (cos \ud835\udf03)\ud835\udc452\ngives\n[\ufe02sin \ud835\udf03 cos \ud835\udf03 \u2212 sin2 \ud835\udf03\nsin \ud835\udf03 cos \ud835\udf03\ncos2 \ud835\udf03\n]\ufe02\n\ud835\udc452 \u2192 \ud835\udc452 \u2212 \ud835\udc451 gives\n[\ufe02sin \ud835\udf03 cos \ud835\udf03\n\u2212 sin2 \ud835\udf03\n0\ncos2 \ud835\udf03 + sin2 \ud835\udf03\n]\ufe02\n=\n[\ufe02sin \ud835\udf03 cos \ud835\udf03 \u2212 sin2 \ud835\udf03\n0\n1\n]\ufe02\nWe know sin \ud835\udf03 cos \ud835\udf03 \u0338= 0 as sin \ud835\udf03 \u0338= 0 and cos \ud835\udf03 \u0338= 0, so we can conclude that\n[\ufe02sin \ud835\udf03 cos \ud835\udf03 \u2212 sin2 \ud835\udf03\n0\n1\n]\ufe02\nis an REF of [\ud835\udc45\ud835\udf03]\u2130, so again the rank is 2. Thus, we can say\nin all cases that \ud835\udc45\ud835\udf03 is one-to-one.\nExample 5.6.4\n(Reflection about a line through the origin)\nLet #\u00bb\ud835\udc64 =\n[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02\nbe a non-zero vector in R2, and consider the reflection transformation\nrefl #\u00bb\n\ud835\udc64 : R2 \u2192 R2, which reflects any vector #\u00bb\ud835\udc63 \u2208 R2 about the line Span{#\u00bb\ud835\udc64}. This linear\ntransformation is illustrated in the diagram below.\nUsing the geometric construction above, one can show that any vector #\u00bb\ud835\udc63 \u2208 R2 gets reflected\nabout the line Span{#\u00bb\ud835\udc64} according to the rule below. This is left as an exercise.\nrefl #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 ) = #\u00bb\ud835\udc63 \u2212 2 perp #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 ).\n(a) Prove that refl #\u00bb\n\ud835\udc64 is a linear transformation.\n(b) Determine the standard matrix of refl #\u00bb\n\ud835\udc64.\n(c) Determine whether refl #\u00bb\n\ud835\udc64 is onto.\n(d) Determine whether refl #\u00bb\n\ud835\udc64 is one-to-one.\nSolution:Section 5.7", "Composition of Linear Transformations\n143\n(a) Let #\u00bb\ud835\udc62, #\u00bb\ud835\udc63 \u2208 R2 and let \ud835\udc501, \ud835\udc502 \u2208 F. Since the perpendicular transformation is linear,\nrefl #\u00bb\n\ud835\udc64(\ud835\udc501 #\u00bb\ud835\udc62 + \ud835\udc502 #\u00bb\ud835\udc63 ) = (\ud835\udc501 #\u00bb\ud835\udc62 + \ud835\udc502 #\u00bb\ud835\udc63 ) \u2212 2 perp #\u00bb\n\ud835\udc64(\ud835\udc501 #\u00bb\ud835\udc62 + \ud835\udc502 #\u00bb\ud835\udc63 )\n= (\ud835\udc501 #\u00bb\ud835\udc62 + \ud835\udc502 #\u00bb\ud835\udc63 ) \u2212 2\ud835\udc501 perp #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc62) \u2212 2\ud835\udc502 perp #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 )\n= \ud835\udc501 #\u00bb\ud835\udc62 + \ud835\udc502 #\u00bb\ud835\udc63 \u2212 2\ud835\udc501 perp #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc62) \u2212 2\ud835\udc502 perp #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 )\n= \ud835\udc501(#\u00bb\ud835\udc62 \u2212 2 perp #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc62)) + \ud835\udc502(#\u00bb\ud835\udc63 \u2212 2 perp #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 ))\n= \ud835\udc501 refl #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc62) + \ud835\udc502 refl #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 ).\nWe conclude that refl #\u00bb\n\ud835\udc64 is a linear transformation.\n(b) To find the standard matrix [refl#\u00bb\n\ud835\udc64]\u2130 of refl #\u00bb\n\ud835\udc64, note that\nrefl #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 ) = #\u00bb\ud835\udc63 \u2212 2 perp #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 ) = \u2212#\u00bb\ud835\udc63 + 2 proj #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc63 ).\nSince\nrefl #\u00bb\n\ud835\udc64(#\u00bb\n\ud835\udc521) = \u2212\n[\ufe021\n0\n]\ufe02\n+\n2\n\ud835\udc642\n1 + \ud835\udc642\n2\n[\ufe02 \ud835\udc642\n1\n\ud835\udc641\ud835\udc642\n]\ufe02\n=\n1\n\ud835\udc642\n1 + \ud835\udc642\n2\n[\ufe02\ud835\udc642\n1 \u2212 \ud835\udc642\n2\n2\ud835\udc641\ud835\udc642\n]\ufe02\n,\nrefl #\u00bb\n\ud835\udc64(#\u00bb\n\ud835\udc522) = \u2212\n[\ufe020\n1\n]\ufe02\n+\n2\n\ud835\udc642\n1 + \ud835\udc642\n2\n[\ufe02\ud835\udc641\ud835\udc642\n\ud835\udc642\n2\n]\ufe02\n=\n1\n\ud835\udc642\n1 + \ud835\udc642\n2\n[\ufe02 2\ud835\udc641\ud835\udc642\n\ud835\udc642\n2 \u2212 \ud835\udc642\n1\n]\ufe02\n,\nwe have that\n[refl #\u00bb\n\ud835\udc64]\u2130 =\n[\ufe00\nrefl #\u00bb\n\ud835\udc64(#\u00bb\n\ud835\udc521) refl #\u00bb\n\ud835\udc64(#\u00bb\n\ud835\udc522)\n]\ufe00\n=\n1\n\ud835\udc642\n1 + \ud835\udc642\n2\n[\ufe02\ud835\udc642\n1 \u2212 \ud835\udc642\n2\n2\ud835\udc641\ud835\udc642\n2\ud835\udc641\ud835\udc642 \ud835\udc642\n2 \u2212 \ud835\udc642\n1\n]\ufe02\n.\n(c) There are two ways in which we can argue why refl #\u00bb\n\ud835\udc64 is onto. Thinking geometrically,\nnote that any vector in R2 can be obtained by a reflection from an appropriate starting\nvector. Equivalently, the range is\nRange(refl #\u00bb\n\ud835\udc64) = Span\n{\ufe02[\ufe02\ud835\udc642\n1 \u2212 \ud835\udc642\n2\n2\ud835\udc641\ud835\udc642\n]\ufe02\n,\n[\ufe02 2\ud835\udc641\ud835\udc642\n\ud835\udc642\n2 \u2212 \ud835\udc642\n1\n]\ufe02}\ufe02\nand it can be shown that this is equal to R2.\n(d) Once again, there are two ways in which we can argue why \ud835\udc45\ud835\udf03 is one-to-one. Thinking\ngeometrically, note that any two different vectors have different images when they are\nreflected. Equivalently, the kernel is obtained by solving\n[refl #\u00bb\n\ud835\udc64]\u2130 #\u00bb\ud835\udc65 = #\u00bb0 .\nSince the rank of the coefficient matrix is equal to 2, then the only solution is the trivial\nsolution and so this linear transformation is one-to-one.\n5.7\nComposition of Linear Transformations\nIn this section, we will consider the composition of linear transformations and show how it\nis related to matrix multiplication.144\nChapter 5\nLinear Transformations\nDefinition 5.7.1\nComposition of\nLinear\nTransformations\nLet \ud835\udc471 : F\ud835\udc5b \u2192 F\ud835\udc5a and \ud835\udc472 : F\ud835\udc5a \u2192 F\ud835\udc5d be linear transformations. We define the function\n\ud835\udc472 \u2218 \ud835\udc471 : F\ud835\udc5b \u2192 F\ud835\udc5d by\n(\ud835\udc472 \u2218 \ud835\udc471)(#\u00bb\ud835\udc65) = \ud835\udc472(\ud835\udc471(#\u00bb\ud835\udc65)).\nThe function \ud835\udc472 \u2218 \ud835\udc471 is called the composite function of \ud835\udc472 and \ud835\udc471.\nProposition 5.7.2\n(Composition of Linear Transformations Is Linear)\nLet \ud835\udc471 : F\ud835\udc5b \u2192 F\ud835\udc5a and \ud835\udc472 : F\ud835\udc5a \u2192 F\ud835\udc5d be linear transformations. Then \ud835\udc472 \u2218 \ud835\udc471 is a linear\ntransformation.\nProof: Since \ud835\udc471 is linear, we have that for all #\u00bb\ud835\udc65, #\u00bb\ud835\udc66 \u2208 F\ud835\udc5b, \ud835\udc50 \u2208 F,\n\ud835\udc471(\ud835\udc50#\u00bb\ud835\udc65 + #\u00bb\ud835\udc66 ) = \ud835\udc50\ud835\udc471(#\u00bb\ud835\udc65) + \ud835\udc471(#\u00bb\ud835\udc66 ).\nSince \ud835\udc472 is linear, we have that for all #\u00bb\ud835\udc64, #\u00bb\ud835\udc67 \u2208 F\ud835\udc5a, \ud835\udc4e \u2208 F,\n\ud835\udc472(\ud835\udc4e#\u00bb\ud835\udc64 + #\u00bb\ud835\udc67 ) = \ud835\udc4e\ud835\udc472(#\u00bb\ud835\udc64) + \ud835\udc472(#\u00bb\ud835\udc67 ).\nNow, consider the action of the composition on \ud835\udc50#\u00bb\ud835\udc65 + #\u00bb\ud835\udc66 :\n(\ud835\udc472 \u2218 \ud835\udc471)(\ud835\udc50#\u00bb\ud835\udc65 + #\u00bb\ud835\udc66 ) = \ud835\udc472 (\ud835\udc50\ud835\udc471(#\u00bb\ud835\udc65) + \ud835\udc471(#\u00bb\ud835\udc66 )) .\nWe can let \ud835\udc471(#\u00bb\ud835\udc65) = #\u00bb\ud835\udc64 and \ud835\udc471(#\u00bb\ud835\udc66 ) = #\u00bb\ud835\udc67 , so that\n(\ud835\udc472 \u2218 \ud835\udc471)(\ud835\udc50#\u00bb\ud835\udc65 + #\u00bb\ud835\udc65 2) = \ud835\udc472(\ud835\udc50#\u00bb\ud835\udc64 + #\u00bb\ud835\udc67 )\n= \ud835\udc50\ud835\udc472(#\u00bb\ud835\udc64) + \ud835\udc472(#\u00bb\ud835\udc67 ),\n(by linearity of \ud835\udc472)\n= \ud835\udc50\ud835\udc472(\ud835\udc471(#\u00bb\ud835\udc65)) + \ud835\udc472(\ud835\udc471(#\u00bb\ud835\udc66 ))\n= \ud835\udc50(\ud835\udc472 \u2218 \ud835\udc471)(#\u00bb\ud835\udc65) + (\ud835\udc472 \u2218 \ud835\udc471)(#\u00bb\ud835\udc66 ).\nTherefore, \ud835\udc472 \u2218 \ud835\udc471 is a linear transformation.\nProposition 5.7.3\n(The Standard Matrix of a Composition of Linear Transformations)\nLet \ud835\udc471 : F\ud835\udc5b \u2192 F\ud835\udc5a and \ud835\udc472 : F\ud835\udc5a \u2192 F\ud835\udc5d be linear transformations. Then the standard matrix\nof \ud835\udc472 \u2218 \ud835\udc471 is equal to the product of standard matrices of \ud835\udc472 and \ud835\udc471. That is,\n[\ud835\udc472 \u2218 \ud835\udc471]\u2130 = [\ud835\udc472]\u2130 [\ud835\udc471]\u2130 .\nProof: Let \ud835\udc34 = [\ud835\udc471]\u2130, \ud835\udc35 = [\ud835\udc472]\u2130, and let \ud835\udc47\ud835\udc35\ud835\udc34 : F\ud835\udc5b \u2192 F\ud835\udc5d denote the linear transformation\ndetermined by the matrix \ud835\udc35\ud835\udc34. Note that, for all #\u00bb\ud835\udc63 \u2208 F\ud835\udc5b,\n(\ud835\udc472 \u2218 \ud835\udc471)(#\u00bb\ud835\udc63 ) = \ud835\udc472(\ud835\udc471(#\u00bb\ud835\udc63 ))\n= \ud835\udc472(\ud835\udc34#\u00bb\ud835\udc63 )\n= \ud835\udc35(\ud835\udc34#\u00bb\ud835\udc63 )\n= (\ud835\udc35\ud835\udc34)#\u00bb\ud835\udc63\n= \ud835\udc47\ud835\udc35\ud835\udc34(#\u00bb\ud835\udc63 ).Section 5.7\nComposition of Linear Transformations\n145\nWe conclude that the linear transformations \ud835\udc472 \u2218 \ud835\udc471 and \ud835\udc47\ud835\udc35\ud835\udc34 are identical. Consequently,\n(\ud835\udc472 \u2218 \ud835\udc471)(#\u00bb\n\ud835\udc52\ud835\udc56) = \ud835\udc47\ud835\udc35\ud835\udc34(#\u00bb\n\ud835\udc52\ud835\udc56) for all \ud835\udc56 = 1, . . . , \ud835\udc5b. But then\n[\ud835\udc472 \u2218 \ud835\udc471]\u2130 =\n[\ufe00\n(\ud835\udc472 \u2218 \ud835\udc471)(#\u00bb\n\ud835\udc521) \u00b7 \u00b7 \u00b7 (\ud835\udc472 \u2218 \ud835\udc47\ud835\udc5b)(#\u00bb\n\ud835\udc52\ud835\udc5b)\n]\ufe00\n=\n[\ufe00\n\ud835\udc47\ud835\udc35\ud835\udc34(#\u00bb\n\ud835\udc521) \u00b7 \u00b7 \u00b7 \ud835\udc47\ud835\udc35\ud835\udc34(#\u00bb\n\ud835\udc52\ud835\udc5b)\n]\ufe00\n=\n[\ufe00\n(\ud835\udc35\ud835\udc34)#\u00bb\n\ud835\udc521 \u00b7 \u00b7 \u00b7 (\ud835\udc35\ud835\udc34)#\u00bb\n\ud835\udc52\ud835\udc5b\n]\ufe00\n= \ud835\udc35\ud835\udc34\n(by Lemma 4.2.2 (Column Extraction))\n= [\ud835\udc472]\u2130[\ud835\udc471]\u2130.\nThis result gives us a very efficient way of obtaining the matrix representation of a com-\nposite linear transformation. It also explains a motivation behind the definition of matrix\nmultiplication.\nExample 5.7.4\nLet \ud835\udc34 =\n[\ufe021 + \ud835\udc56\n\u22123\ud835\udc56\n\u22122\n2\n1 + 2\ud835\udc56 4\ud835\udc56\n]\ufe02\nbe a matrix in \ud835\udc402\u00d73(C) and \ud835\udc35 =\n\u23a1\n\u23a3\n3\ud835\udc56\n1 + \ud835\udc56\n1\n0\n1 \u2212 \ud835\udc56 3 \u2212 2\ud835\udc56\n\u23a4\n\u23a6 be a matrix in\n\ud835\udc403\u00d72(C). Let \ud835\udc47\ud835\udc34 and \ud835\udc47\ud835\udc35 be the linear transformations determined by \ud835\udc34 and \ud835\udc35, respectively.\nDetermine the standard matrix of their composite linear transformation \ud835\udc47\ud835\udc35 \u2218 \ud835\udc47\ud835\udc34.\nSolution: By Proposition 5.7.3 (The Standard Matrix of a Composition of Linear Trans-\nformations),\n[\ud835\udc47\ud835\udc35 \u2218 \ud835\udc47\ud835\udc34]\u2130 = [\ud835\udc47\ud835\udc35]\u2130 [\ud835\udc47\ud835\udc34]\u2130 = \ud835\udc35\ud835\udc34.\nTherefore,\n[\ud835\udc47\ud835\udc35 \u2218 \ud835\udc47\ud835\udc34]\u2130 =\n\u23a1\n\u23a3\n3\ud835\udc56\n1 + \ud835\udc56\n1\n0\n1 \u2212 \ud835\udc56 3 \u2212 2\ud835\udc56\n\u23a4\n\u23a6\n[\ufe021 + \ud835\udc56\n\u22123\ud835\udc56\n\u22122\n2\n1 + 2\ud835\udc56 4\ud835\udc56\n]\ufe02\n=\n\u23a1\n\u23a3\n\u22121 + 5\ud835\udc56 8 + 3\ud835\udc56 \u22124 \u2212 2\ud835\udc56\n1 + \ud835\udc56\n\u22123\ud835\udc56\n\u22122\n8 \u2212 4\ud835\udc56\n4 + \ud835\udc56 6 + 14\ud835\udc56\n\u23a4\n\u23a6 .\nExample 5.7.5\nFind the standard matrix of the linear transformation \ud835\udc47 : R2 \u2192 R2 which is defined by \ud835\udc471,\na rotation counter-clockwise about the origin by an angle of \ud835\udf0b\n3 radians, followed by \ud835\udc472, a\nprojection onto the line \ud835\udc66 = \u22123\ud835\udc65.\nSolution From Example 5.6.3 we have that\n[\ud835\udc471]\u2130 = [\ud835\udc45\ud835\udf0b/3]\u2130 =\n[\ufe03\ncos( \ud835\udf0b\n3 ) \u2212 sin( \ud835\udf0b\n3 )\nsin( \ud835\udf0b\n3 )\ncos( \ud835\udf0b\n3 )\n]\ufe03\n=\n[\ufe03 1\n2 \u2212\n\u221a\n3\n2\n\u221a\n3\n2\n1\n2\n]\ufe03\n.\nNext, note that the line \ud835\udc66 = \u22123\ud835\udc65 can be written as Span{\u20d7\ud835\udc64}, where \u20d7\ud835\udc64 =\n[\ufe00\n1 \u22123\n]\ufe00\ud835\udc47 . From\nExample 5.6.1 we have that for\n[\ud835\udc472]\u2130 = [proj #\u00bb\n\ud835\udc64]\u2130 =\n1\n1 + (\u22123)2\n[\ufe02 1 \u22123\n\u22123 9\n]\ufe02\n= 1\n10\n[\ufe02 1 \u22123\n\u22123 9\n]\ufe02\n.\nThus, we have\n[\ud835\udc47]\u2130 = [\ud835\udc472]\u2130 [\ud835\udc471]\u2130 = 1\n10\n[\ufe02 1 \u22123\n\u22123 9\n]\ufe02 [\ufe03 1\n2 \u2212\n\u221a\n3\n2\n\u221a\n3\n2\n1\n2\n]\ufe03\n= 1\n20\n[\ufe03\n1 \u2212 3\n\u221a\n3 \u22123 \u2212\n\u221a\n3\n\u22123 + 9\n\u221a\n3 3\n\u221a\n3 + 9\n]\ufe03\n.146\nChapter 5\nLinear Transformations\nDefinition 5.7.6\nIdentity\nTransformation\nThe linear transformation id\ud835\udc5b : F\ud835\udc5b \u2192 F\ud835\udc5b such that id\ud835\udc5b(#\u00bb\ud835\udc65) = #\u00bb\ud835\udc65 for all #\u00bb\ud835\udc65 \u2208 F\ud835\udc5b is called the\nidentity transformation.\nEXERCISE\nShow that the standard matrix [id\ud835\udc5b]\u2130 of id\ud835\udc5b is the identity matrix \ud835\udc3c\ud835\udc5b.\nA special case of composition arises when \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5b has the same domain and codomain,\nin which case we can apply the linear transformation \ud835\udc47 more than one time.\nDefinition 5.7.7\n\ud835\udc47 \ud835\udc5d\nLet \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5b and let \ud835\udc5d > 1 be an integer. We then define the \ud835\udc5d\ud835\udc61\u210e power of \ud835\udc47, denoted\nby \ud835\udc47 \ud835\udc5d, inductively by\n\ud835\udc47 \ud835\udc5d = \ud835\udc47 \u2218 \ud835\udc47 \ud835\udc5d\u22121.\nWe also define \ud835\udc47 0 = id\ud835\udc5b.\nCorollary 5.7.8\nLet \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5b be a linear transformation and let \ud835\udc5d > 1 be an integer. Then the standard\nmatrix of \ud835\udc47 \ud835\udc5d is the \ud835\udc5d\ud835\udc61\u210e power of the standard matrix of \ud835\udc47. That is,\n[\ud835\udc47 \ud835\udc5d]\u2130 = ([\ud835\udc47]\u2130)\ud835\udc5d .\nProof: Use induction and Proposition 5.7.3 (The Standard Matrix of a Composition of\nLinear Transformations).\nExample 5.7.9\nConsider the linear transformation defined by a rotation about the origin by an angle of \ud835\udf03\ncounter-clockwise in the plane, denoted by \ud835\udc45\ud835\udf03 : R2 \u2192 R2. In Example 5.6.3 we found that\n[\ud835\udc47\ud835\udf03]\u2130 =\n[\ufe02cos \ud835\udf03 \u2212 sin \ud835\udf03\nsin \ud835\udf03\ncos \ud835\udf03\n]\ufe02\n. Determine the standard matrix of \ud835\udc452\n\ud835\udf03.\nSolution: We have\n[\ufe00\n\ud835\udc452\n\ud835\udf03\n]\ufe00\n\u2130 = ([\ud835\udc45\ud835\udf03]\u2130)2 =\n[\ufe02cos(\ud835\udf03) \u2212 sin(\ud835\udf03)\nsin(\ud835\udf03)\ncos(\ud835\udf03)\n]\ufe02 [\ufe02cos(\ud835\udf03) \u2212 sin(\ud835\udf03)\nsin(\ud835\udf03)\ncos(\ud835\udf03)\n]\ufe02\n=\n[\ufe02cos2(\ud835\udf03) \u2212 sin2(\ud835\udf03) \u22122 cos(\ud835\udf03) sin(\ud835\udf03)\n2 cos(\ud835\udf03) sin(\ud835\udf03)\ncos2(\ud835\udf03) \u2212 sin2(\ud835\udf03)\n]\ufe02\nFrom here, we can make use of the trigonometric double-angle identities,\ncos(2\ud835\udf03) = cos2(\ud835\udf03) \u2212 sin2(\ud835\udf03)\nand\nsin(2\ud835\udf03) = 2 cos(\ud835\udf03) sin(\ud835\udf03),\nto obtain\n[\ufe00\n\ud835\udc452\n\ud835\udf03\n]\ufe00\n\u2130 =\n[\ufe02cos(2\ud835\udf03) \u2212 sin(2\ud835\udf03)\nsin(2\ud835\udf03)\ncos(2\ud835\udf03)\n]\ufe02\n,\nwhich is the standard matrix for a rotation of 2\ud835\udf03 counter-clockwise.Chapter 6\nThe Determinant\n6.1", "The Definition of the Determinant\nWhen is an \ud835\udc5b \u00d7 \ud835\udc5b matrix \ud835\udc34 invertible? If \ud835\udc5b = 1 then \ud835\udc34 =\n[\ufe00\n\ud835\udc4e\n]\ufe00\nis invertible if and only if\n\ud835\udc4e \u0338= 0, in which case \ud835\udc34\u22121 =\n[\ufe00 1\n\ud835\udc4e\n]\ufe00\n. If \ud835\udc5b = 2, we saw in Proposition 4.6.13 (Inverse of a 2 \u00d7 2\nMatrix) that \ud835\udc34 =\n[\ufe02\ud835\udc4e \ud835\udc4f\n\ud835\udc50 \ud835\udc51\n]\ufe02\nis invertible if and only if \ud835\udc4e\ud835\udc51 \u2212 \ud835\udc4f\ud835\udc50 \u0338= 0.\nThus, the invertibility of a 1\u00d71 or 2\u00d72 matrix can be completely determined by examining\na number formed using the entries of the matrix. We give this number a name.\nDefinition 6.1.1\nDeterminant of a\n1 \u00d7 1 and 2 \u00d7 2\nMatrix\nIf \ud835\udc34 =\n[\ufe00\n\ud835\udc4e11\n]\ufe00\nis in \ud835\udc401\u00d71(F), then the determinant of \ud835\udc34, denoted by det(\ud835\udc34), is:\ndet(\ud835\udc34) = \ud835\udc4e11.\nIf \ud835\udc34 =\n[\ufe02\ud835\udc4e11 \ud835\udc4e12\n\ud835\udc4e21 \ud835\udc4e22\n]\ufe02\nis in \ud835\udc402\u00d72(F), then the determinant of \ud835\udc34, denoted by det(\ud835\udc34), is:\ndet(\ud835\udc34) = \ud835\udc4e11\ud835\udc4e22 \u2212 \ud835\udc4e12\ud835\udc4e21.\nExample 6.1.2\nLet \ud835\udc34 =\n[\ufe00\n4 \u2212 \ud835\udc56\n]\ufe00\n. Then det(\ud835\udc34) = 4 \u2212 \ud835\udc56.\nExample 6.1.3\nLet \ud835\udc35 =\n[\ufe02 6 8\n\u22123 2\n]\ufe02\n. Then det(\ud835\udc35) = 6(2) \u2212 8(\u22123) = 36.\nIn the remainder of this section, we will generalize the above and define the determinant of\nan \ud835\udc5b \u00d7 \ud835\udc5b matrix. One of our main results will be that an \ud835\udc5b \u00d7 \ud835\udc5b matrix is invertible if and\nonly if its determinant is non-zero, but it will take some time to get there (see Theorem\n6.3.1 (Invertible iff the Determinant is Non-Zero)).\nWe will need some preliminary definitions.\n147148\nChapter 6\nThe Determinant\nDefinition 6.1.4\n(\ud835\udc56, \ud835\udc57)\ud835\udc61\u210e Submatrix,\n(\ud835\udc56, \ud835\udc57)\ud835\udc61\u210e Minor\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F). The (\ud835\udc56, \ud835\udc57)\ud835\udc61\u210e submatrix of \ud835\udc34, denoted by \ud835\udc40\ud835\udc56\ud835\udc57(\ud835\udc34), is the (\ud835\udc5b \u2212 1) \u00d7\n(\ud835\udc5b \u2212 1) matrix obtained from \ud835\udc34 by removing the \ud835\udc56\ud835\udc61\u210e row and the \ud835\udc57\ud835\udc61\u210e column from \ud835\udc34. The\ndeterminant of \ud835\udc40\ud835\udc56\ud835\udc57(\ud835\udc34) is known as the (\ud835\udc56, \ud835\udc57)\ud835\udc61\u210e minor of \ud835\udc34.\nExample 6.1.5\nIf \ud835\udc34 =\n\u23a1\n\u23a3\n4 6 8\n6 \u22123 2\n5 7 9\n\u23a4\n\u23a6 then \ud835\udc4022(\ud835\udc34) =\n[\ufe024 8\n5 9\n]\ufe02\nand \ud835\udc4031(\ud835\udc34) =\n[\ufe02 6 8\n\u22123 2\n]\ufe02\n.\nDefinition 6.1.6\nDeterminant of an\n\ud835\udc5b \u00d7 \ud835\udc5b matrix\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) for \ud835\udc5b \u2265 2. We define the determinant function, det : \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) \u2192 F,\nby\ndet(\ud835\udc34) =\n\ud835\udc5b\n\u2211\ufe01\n\ud835\udc57=1\n\ud835\udc4e1\ud835\udc57(\u22121)1+\ud835\udc57 det(\ud835\udc401\ud835\udc57(\ud835\udc34)).\nExample 6.1.7\nIf \ud835\udc5b = 2, so that \ud835\udc34 =\n[\ufe02\ud835\udc4e11 \ud835\udc4e12\n\ud835\udc4e21 \ud835\udc4e22\n]\ufe02\n, the above definition gives\ndet(\ud835\udc34) = \ud835\udc4e11(\u22121)1+1 det(\n[\ufe00\n\ud835\udc4e22\n]\ufe00\n) + \ud835\udc4e12(\u22121)1+2 det(\n[\ufe00\n\ud835\udc4e21\n]\ufe00\n) = \ud835\udc4e11\ud835\udc4e22 \u2212 \ud835\udc4e12\ud835\udc4e21.\nThus, we recover the same expression given in Definition 6.1.1.\nThe expression for det(\ud835\udc34) in Definition 6.1.6 is called the expansion along the first row\nof the determinant. It is recursive in nature: we must multiply the entries in the first row\nof the matrix \ud835\udc34 by \u00b11 and then by the determinant of an (\ud835\udc56, \ud835\udc57) submatrix.\nFor a 3 \u00d7 3 matrix, this process will involve the evaluation of three determinants of 2 \u00d7 2\nmatrices.\nFor a 4 \u00d7 4 matrix, this process will involve the evaluation of four determinants of 3 \u00d7 3\nmatrices, each of which involve the evaluation of three determinants of 2 \u00d7 2 matrices.\nThis pattern continues as we increase \ud835\udc5b.\nIn the next section we will learn techniques that will permit us to occasionally avoid too\nmany tedious computations.\nExample 6.1.8\nFind the determinant of the matrix \ud835\udc34 =\n\u23a1\n\u23a3\n1 2 3\n4 5 6\n7 8 10\n\u23a4\n\u23a6.Section 6.1\nThe Definition of the Determinant\n149\nSolution: Using the definition, we have\ndet(\ud835\udc34) =\n3\n\u2211\ufe01\n\ud835\udc57=1\n\ud835\udc4e1\ud835\udc57(\u22121)1+\ud835\udc57 det(\ud835\udc401\ud835\udc57(\ud835\udc34))\n= \ud835\udc4e11(\u22121)1+1 det(\ud835\udc4011(\ud835\udc34)) + \ud835\udc4e12(\u22121)1+2 det(\ud835\udc4012(\ud835\udc34)) + \ud835\udc4e13(\u22121)1+3 det(\ud835\udc4013(\ud835\udc34))\n= (1)(1) det\n(\ufe02[\ufe025 6\n8 10\n]\ufe02)\ufe02\n+ (2)(\u22121) det\n(\ufe02[\ufe024 6\n7 10\n]\ufe02)\ufe02\n+ (3)(1) det\n(\ufe02[\ufe024 5\n7 8\n]\ufe02)\ufe02\n= 1(50 \u2212 48) \u2212 2(40 \u2212 42) + 3(32 \u2212 35) = \u22123.\nExample 6.1.9\nFind the determinant of the matrix \ud835\udc35 =\n\u23a1\n\u23a3\n1\n2\ud835\udc56\n3\n4 \u2212 \ud835\udc56 5 + 2\ud835\udc56 6\n7 + 3\ud835\udc56 8 \u2212 2\ud835\udc56 10\n\u23a4\n\u23a6 .\nSolution: Using the definition, we have\ndet(\ud835\udc35) =\n\ud835\udc5b\n\u2211\ufe01\n\ud835\udc57=1\n\ud835\udc4f1\ud835\udc57(\u22121)1+\ud835\udc57 det(\ud835\udc401\ud835\udc57(\ud835\udc35))\n= \ud835\udc5011(\u22121)1+1 det(\ud835\udc4011(\ud835\udc36)) + \ud835\udc5012(\u22121)1+2 det(\ud835\udc4012(\ud835\udc36)) + \ud835\udc5013(\u22121)1+3 det(\ud835\udc4013(\ud835\udc36))\n= (1)(1) det\n(\ufe02[\ufe025 + 2\ud835\udc56 6\n8 \u2212 2\ud835\udc56 10\n]\ufe02)\ufe02\n+ (2\ud835\udc56)(\u22121) det\n(\ufe02[\ufe02 4 \u2212 \ud835\udc56\n6\n7 + 3\ud835\udc56 10\n]\ufe02)\ufe02\n+ (3)(1) det\n(\ufe02[\ufe02 4 \u2212 \ud835\udc56 5 + 2\ud835\udc56\n7 + 3\ud835\udc56 8 \u2212 2\ud835\udc56\n]\ufe02)\ufe02\n= 1(50 + 20\ud835\udc56 \u2212 (48 \u2212 12\ud835\udc56)) \u2212 2\ud835\udc56(40 \u2212 10\ud835\udc56 \u2212 (42 + 18\ud835\udc56)) + 3(30 \u2212 16\ud835\udc56 \u2212 (29 + 29\ud835\udc56))\n= \u221251 \u2212 99\ud835\udc56.\nOne of the remarkable features of the determinant is that it may be evaluated by performing\nan expansion along any row, not just the first row. We state this result below. The proof\nof this result is quite lengthy and is omitted.\nProposition 6.1.10\n(\ud835\udc56\ud835\udc61\u210e Row Expansion of the Determinant)\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) with \ud835\udc5b \u2265 2 and let \ud835\udc56 \u2208 {1, . . . , \ud835\udc5b}. Then\ndet(\ud835\udc34) =\n\ud835\udc5b\n\u2211\ufe01\n\ud835\udc57=1\n\ud835\udc4e\ud835\udc56\ud835\udc57(\u22121)\ud835\udc56+\ud835\udc57 det(\ud835\udc40\ud835\udc56\ud835\udc57(\ud835\udc34)).\nNotice that if \ud835\udc56 = 1 then the above expression reduces to the definition of det(\ud835\udc34).150\nChapter 6\nThe Determinant\nExample 6.1.11\nEvaluate the determinant of the matrix \ud835\udc34 =\n\u23a1\n\u23a3\n1 2 3\n4 5 6\n7 8 10\n\u23a4\n\u23a6 using an expansion along the second\nrow.\nSolution: We have\ndet(\ud835\udc34) =\n\ud835\udc5b\n\u2211\ufe01\n\ud835\udc57=1\n\ud835\udc4e2\ud835\udc57(\u22121)2+\ud835\udc57 det(\ud835\udc402\ud835\udc57(\ud835\udc34))\n= \ud835\udc4e21(\u22121)2+1 det(\ud835\udc4021(\ud835\udc34)) + \ud835\udc4e22(\u22121)2+2 det(\ud835\udc4022(\ud835\udc34)) + \ud835\udc4e23(\u22121)2+3 det(\ud835\udc4023(\ud835\udc34))\n= (4)(\u22121) det\n(\ufe02[\ufe022 3\n8 10\n]\ufe02)\ufe02\n+ (5)(1) det\n(\ufe02[\ufe021 3\n7 10\n]\ufe02)\ufe02\n+ (6)(\u22121) det\n(\ufe02[\ufe021 2\n7 8\n]\ufe02)\ufe02\n= \u22124(20 \u2212 24) + 5(10 \u2212 21) \u2212 6(8 \u2212 14) = \u22123,\njust as we found in Example 6.1.8.\nA further remarkable feature of the determinant is that it may also be evaluated by ex-\npanding along any column.\nProposition 6.1.12\n(\ud835\udc57\ud835\udc61\u210e Column Expansion of the Determinant)\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) with \ud835\udc5b \u2265 2 and let \ud835\udc57 \u2208 {1, . . . , \ud835\udc5b}. Then\ndet(\ud835\udc34) =\n\ud835\udc5b\n\u2211\ufe01\n\ud835\udc56=1\n\ud835\udc4e\ud835\udc56\ud835\udc57(\u22121)\ud835\udc56+\ud835\udc57 det(\ud835\udc40\ud835\udc56\ud835\udc57(\ud835\udc34)).\nExample 6.1.13\nEvaluate the determinant of the matrix \ud835\udc34 =\n\u23a1\n\u23a3\n1 2 3\n4 5 6\n7 8 10\n\u23a4\n\u23a6 using an expansion along the third\ncolumn.\nSolution: We have\ndet(\ud835\udc34) =\n3\n\u2211\ufe01\n\ud835\udc56=1\n\ud835\udc4e\ud835\udc563(\u22121)\ud835\udc56+3 det(\ud835\udc40\ud835\udc563(\ud835\udc34))\n= \ud835\udc4e13(\u22121)1+3 det(\ud835\udc4013(\ud835\udc34)) + \ud835\udc4e23(\u22121)2+3 det(\ud835\udc4023(\ud835\udc34)) + \ud835\udc4e33(\u22121)3+3 det(\ud835\udc4033(\ud835\udc34))\n= (3)(1) det\n(\ufe02[\ufe024 5\n7 8\n]\ufe02)\ufe02\n+ (6)(\u22121) det\n(\ufe02[\ufe021 2\n7 8\n]\ufe02)\ufe02\n+ (10)(1) det\n(\ufe02[\ufe021 2\n4 5\n]\ufe02)\ufe02\n= 3(32 \u2212 35) \u2212 6(8 \u2212 14) + 10(5 \u2212 8) = \u22123.\nThus, you may evaluate the determinant by expanding along any row or column of your\nchoice. In practice, it is usually easier to choose a row or column with many zeros, since\nthis will reduce the number determinants of submatrices that need to be computed.Section 6.1\nThe Definition of the Determinant\n151\nExample 6.1.14\nEvaluate the determinant of \ud835\udc34 =\n\u23a1\n\u23a2\u23a2\u23a3\n1\n0\n0\n5\n3\n2\n0\n7\n567 234 14 235\n4\n5\n0\n3\n\u23a4\n\u23a5\u23a5\u23a6 .\nSolution: We perform an expansion along the third column.\ndet(\ud835\udc34) =\n4\n\u2211\ufe01\n\ud835\udc56=1\n\ud835\udc4e\ud835\udc563(\u22121)\ud835\udc56+3 det(\ud835\udc40\ud835\udc563(\ud835\udc34))\n= 0(1) det(\ud835\udc4013(\ud835\udc34)) + 0(\u22121) det(\ud835\udc4023(\ud835\udc34)) + 14(1) det(\ud835\udc4033(\ud835\udc34)) + 0(\u22121) det(\ud835\udc4043(\ud835\udc34))\n= 14 det\n\u239b\n\u239d\n\u23a1\n\u23a3\n1 0 5\n3 2 7\n4 5 3\n\u23a4\n\u23a6\n\u239e\n\u23a0 .\nFrom here, we need to proceed with another expansion along a row or column. Row 1 now\nlooks \u201cideal\u201d with the most zeroes of any row. Doing so, we continue our calculation below:\ndet(\ud835\udc34) = 14 det\n\u239b\n\u239d\n\u23a1\n\u23a3\n1 0 5\n3 2 7\n4 5 3\n\u23a4\n\u23a6\n\u239e\n\u23a0\n= 14\n[\ufe02\n(1) det\n(\ufe02[\ufe022 7\n5 3\n]\ufe02)\ufe02\n+ (5) det\n(\ufe02[\ufe023 2\n4 5\n]\ufe02)\ufe02]\ufe02\n= 14 [(6 \u2212 35) + 5(15 \u2212 8)]\n= 14 [\u221229 + 35] = 14(6) = 84.\nThe recursive definition of the determinant makes its direct application tedious. There are,\nhowever, certain situations where the determinant is relatively easy to compute.\nProposition 6.1.15\n(Easy Determinants)\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) be a square matrix.\n(a) If \ud835\udc34 has a row consisting only of zeros, then det \ud835\udc34 = 0.\n(b) If \ud835\udc34 has a column consisting only of zeros, then det \ud835\udc34 = 0.\n(c) If \ud835\udc34 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a2\u23a3\n\ud835\udc4e11\n*\n* \u00b7 \u00b7 \u00b7\n*\n0 \ud835\udc4e22\n* \u00b7 \u00b7 \u00b7\n*\n0\n0 \ud835\udc4e33 \u00b7 \u00b7 \u00b7\n*\n...\n...\n... ...\n...\n0\n0 \u00b7 \u00b7 \u00b7\n0 \ud835\udc4e\ud835\udc5b\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a5\u23a6\nis upper triangular, then det \ud835\udc34 = \ud835\udc4e11\ud835\udc4e22 \u00b7 \u00b7 \u00b7 \ud835\udc4e\ud835\udc5b\ud835\udc5b.\nProof: For parts (a) and (b), simply perform the expansion along the row/column consist-\ning of 0s.152\nChapter 6\nThe Determinant\nTo prove part (c), we will proceed by induction on \ud835\udc5b. If \ud835\udc5b = 1, then the result follows\nimmediately from the definition of the determinant of a 1 \u00d7 1 matrix. For the inductive\nstep, we will assume that the result is true when \ud835\udc5b = \ud835\udc58 and consider a (\ud835\udc58 + 1) \u00d7 (\ud835\udc58 + 1)\nupper triangular matrix\n\ud835\udc34 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a2\u23a3\n\ud835\udc4e11\n*\n* \u00b7 \u00b7 \u00b7\n*\n0 \ud835\udc4e22\n* \u00b7 \u00b7 \u00b7\n*\n0\n0 \ud835\udc4e33 \u00b7 \u00b7 \u00b7\n*\n...\n...\n... ...\n...\n0\n0 \u00b7 \u00b7 \u00b7\n0 \ud835\udc4e\ud835\udc58+1,\ud835\udc58+1\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a5\u23a6\n.\nUsing an expansion along the first column, we obtain\ndet(\ud835\udc34) = \ud835\udc4e11 det(\ud835\udc4011(\ud835\udc34)) = \ud835\udc4e11 det\n\u239b\n\u239c\n\u239c\n\u239c\n\u239d\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc4e22\n* \u00b7 \u00b7 \u00b7\n*\n0 \ud835\udc4e44 \u00b7 \u00b7 \u00b7\n*\n...\n... ...\n...\n0 \u00b7 \u00b7 \u00b7\n0 \ud835\udc4e\ud835\udc58+1,\ud835\udc58+1\n\u23a4\n\u23a5\u23a5\u23a5\u23a6\n\u239e\n\u239f\n\u239f\n\u239f\n\u23a0 .\nSince \ud835\udc4011(\ud835\udc34) is an \ud835\udc58 \u00d7 \ud835\udc58 matrix, we may apply the inductive hypothesis to conclude that\ndet \ud835\udc4011(\ud835\udc34) = \ud835\udc4e22 \u00b7 \u00b7 \u00b7 \ud835\udc4e\ud835\udc58+1,\ud835\udc58+1. It follows that det(\ud835\udc34) = \ud835\udc4e11\ud835\udc4e22 \u00b7 \u00b7 \u00b7 \ud835\udc4e\ud835\udc58+1,\ud835\udc58+1, as required.\nCorollary 6.1.16\nThe determinant of the \ud835\udc5b \u00d7 \ud835\udc5b identity matrix is 1, that is, det(\ud835\udc3c\ud835\udc5b) = 1.\nProof: This follows from part (c) of the previous Proposition.\nThe determinant of a lower triangular square matrix is also the product of its diagonal\nentries. This follows at once from the following result and Proposition 6.1.15 (Easy Deter-\nminants).\nProposition 6.1.17\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F). Then det(\ud835\udc34) = det(\ud835\udc34\ud835\udc47 ).\nProof: We proceed by induction on \ud835\udc5b. If \ud835\udc5b = 1, then \ud835\udc34 = \ud835\udc34\ud835\udc47 and there is nothing to\nprove. Thus, assume that the result is true for \ud835\udc5b = \ud835\udc58 and consider a (\ud835\udc58 +1)\u00d7(\ud835\udc58 +1) matrix\n\ud835\udc34. Let \ud835\udc35 = \ud835\udc34\ud835\udc47 . Notice that \ud835\udc4f\ud835\udc56\ud835\udc57 = \ud835\udc4e\ud835\udc57\ud835\udc56 and that \ud835\udc40\ud835\udc56\ud835\udc57(\ud835\udc35) = (\ud835\udc40\ud835\udc57\ud835\udc56(\ud835\udc34))\ud835\udc47 . Consequently, using\nan expansion along the first row of \ud835\udc35, we have\ndet(\ud835\udc35) =\n\ud835\udc58+1\n\u2211\ufe01\n\ud835\udc57=1\n\ud835\udc4f1\ud835\udc57(\u22121)1+\ud835\udc57 det(\ud835\udc401\ud835\udc57(\ud835\udc35)) =\n\ud835\udc58+1\n\u2211\ufe01\n\ud835\udc57=1\n\ud835\udc4e\ud835\udc571(\u22121)1+\ud835\udc57 det((\ud835\udc40\ud835\udc571(\ud835\udc34))\ud835\udc47 ).\nNow since \ud835\udc40\ud835\udc571(\ud835\udc34) is a \ud835\udc58 \u00d7 \ud835\udc58 matrix, we have det((\ud835\udc40\ud835\udc571(\ud835\udc34))\ud835\udc47 ) = det(\ud835\udc40\ud835\udc571(\ud835\udc34)), by the\ninductive hypothesis. So, the above expression for det(\ud835\udc35) = det(\ud835\udc34\ud835\udc47 ) becomes\ndet(\ud835\udc34\ud835\udc47 ) =\n\ud835\udc58+1\n\u2211\ufe01\n\ud835\udc57=1\n\ud835\udc4e\ud835\udc571(\u22121)1+\ud835\udc57 det(\ud835\udc40\ud835\udc571(\ud835\udc34)).\nThe right-side is the determinant expansion along the first column of \ud835\udc34, that is, it is equal\nto det(\ud835\udc34). Thus, det(\ud835\udc34\ud835\udc47 ) = det(\ud835\udc34).Section 6.2", "Computing the Determinant in Practice: EROs\n153\n6.2\nComputing the Determinant in Practice: EROs\nWe will now outline a practical method for computing the determinant of a general square\nmatrix \ud835\udc34. The basic idea is to perform EROs on \ud835\udc34, thereby reducing it to a matrix \ud835\udc35, whose\ndeterminant is more easily computed\u2014for instance, \ud835\udc35 could have a lot of 0 entries. Since\nEROs will turn out to have a well-understood effect on the determinant (as we describe\nbelow), we can obtain det(\ud835\udc34) from det(\ud835\udc35).\nTheorem 6.2.1\n(Effect of EROs on the Determinant)\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F).\n(a) (Row swap) If \ud835\udc35 is obtained from \ud835\udc34 by interchanging two rows, then det(\ud835\udc35) = \u2212 det(\ud835\udc34).\n(b) (Row scale) If \ud835\udc35 is obtained from \ud835\udc34 by multiplying a row by \ud835\udc5a \u0338= 0, then\ndet(\ud835\udc35) = \ud835\udc5a det(\ud835\udc34).\n(c) (Row addition) If \ud835\udc35 is obtained from \ud835\udc34 by adding a non-zero multiple of one row to\nanother row, then det(\ud835\udc35) = det(\ud835\udc34).\nREMARK\nSince det(\ud835\udc34) = det(\ud835\udc34\ud835\udc47 ), the previous Theorem remains true if we replace every instance of\nthe word \u201crow\u201d with the word \u201ccolumn\u201d.\nWARNING: Do not use such \u201ccolumn operations\u201d when performing calculations other\nthan a determinant, as column operations disrupt many properties of a matrix.\nExample 6.2.2\nLet \ud835\udc34 =\n\u23a1\n\u23a3\n2 \u22121 0\n0 \u22123 1\n0 0 3\n\u23a4\n\u23a6. Since \ud835\udc34 is upper triangular, we have that det(\ud835\udc34) = (2)(\u22123)(3) = \u221218.\nLet \ud835\udc35 =\n\u23a1\n\u23a3\n2 \u22121 0\n0 \u22123 1\n0 \u22126 5\n\u23a4\n\u23a6. Notice that \ud835\udc35 may be obtained from \ud835\udc34 by adding a multiple of 2 times\nthe second row of \ud835\udc34 to the third row of \ud835\udc34. Thus, det(\ud835\udc35) = det(\ud835\udc34) = \u221218.\nLet \ud835\udc36 =\n\u23a1\n\u23a3\n4 \u22122 0\n0 \u22123 1\n0 \u22126 5\n\u23a4\n\u23a6. Notice that \ud835\udc36 may be obtained from \ud835\udc35 by multiplying the first row\nby 2. Thus, det(\ud835\udc36) = 2 det(\ud835\udc35) = \u221236.\nFinally, let \ud835\udc37 =\n\u23a1\n\u23a3\n4 \u22122 0\n0 \u22126 5\n0 \u22123 1\n\u23a4\n\u23a6, which is obtained from \ud835\udc36 by interchanging the second and\nthird rows. Thus, det(\ud835\udc37) = \u2212 det(\ud835\udc36) = 36.\nThe proof of Theorem 6.2.1 (Effect of EROs on the Determinant) involves lengthy (but\nstraightforward) computations. We will not give it in this course. Instead, we will extract\nfrom the Theorem some useful corollaries.154\nChapter 6\nThe Determinant\nCorollary 6.2.3\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F). If \ud835\udc34 has two identical rows (or two identical columns), then det(\ud835\udc34) = 0.\nProof: If \ud835\udc34 has two identical rows, we can use a row operation to subtract one of these rows\nfrom the other. The resulting matrix \ud835\udc35 will have a row of zeros. Consequently, det(\ud835\udc35) = 0\nby Proposition 6.1.15 (Easy Determinants). From Theorem 6.2.1 (Effect of EROs on the\nDeterminant), we know that row addition EROs do not change the determinant. Thus, we\nconclude that det(\ud835\udc34) = det(\ud835\udc35) = 0.\nIf \ud835\udc34 has two identical columns, we can apply the previous argument to \ud835\udc34\ud835\udc47 .\nCorollary 6.2.4\n(Determinants of Elementary Matrices)\nFor each part below, let \ud835\udc38 be an elementary matrix of the indicated type.\n(a) (Row swap) det(\ud835\udc38) = \u22121.\n(b) (Row scale) det(\ud835\udc38) = \ud835\udc5a (if \ud835\udc38 is obtained from \ud835\udc3c\ud835\udc5b by multiplying a row by \ud835\udc5a \u0338= 0).\n(c) (Row addition) det(\ud835\udc38) = 1.\nProof: Combine the fact that det(\ud835\udc3c\ud835\udc5b) = 1 with Theorem 6.2.1 (Effect of EROs on the\nDeterminant).\nCorollary 6.2.5\n(Determinant After One ERO)\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) and suppose we perform a single ERO on \ud835\udc34 to produce the matrix \ud835\udc35.\nAssume that the corresponding elementary matrix is \ud835\udc38. Then\ndet(\ud835\udc35) = det(\ud835\udc38) det(\ud835\udc34).\nProof: Combine Theorem 6.2.1 (Effect of EROs on the Determinant) and Corollary 6.2.4\n(Determinants of Elementary Matrices).\nCorollary 6.2.6\n(Determinant After \ud835\udc58 EROs)\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) and suppose we perform a sequence of \ud835\udc58 EROs on the matrix \ud835\udc34 to obtain\nthe matrix \ud835\udc35.\nSuppose that the elementary matrix corresponding to the \ud835\udc56th ERO is \ud835\udc38\ud835\udc56, so that\n\ud835\udc35 = \ud835\udc38\ud835\udc58 \u00b7 \u00b7 \u00b7 \ud835\udc382\ud835\udc381\ud835\udc34.\nThen\ndet(\ud835\udc35) = det(\ud835\udc38\ud835\udc58 \u00b7 \u00b7 \u00b7 \ud835\udc382\ud835\udc381\ud835\udc34) = det(\ud835\udc38\ud835\udc58) \u00b7 \u00b7 \u00b7 det(\ud835\udc382) det(\ud835\udc381) det(\ud835\udc34).Section 6.2\nComputing the Determinant in Practice: EROs\n155\nProof: We proceed by induction on \ud835\udc58.\nIf \ud835\udc58 = 1, this is the previous Corollary.\nNow\nassume that the result is true for \ud835\udc58 = \u2113 and consider the case where \ud835\udc58 = \u2113 + 1. We then\nhave \ud835\udc35 = \ud835\udc38\u2113+1\ud835\udc38\u2113 \u00b7 \u00b7 \u00b7 \ud835\udc381\ud835\udc34, and therefore,\ndet(\ud835\udc35) = det(\ud835\udc38\u2113+1) det(\ud835\udc38\u2113 \u00b7 \u00b7 \u00b7 \ud835\udc381\ud835\udc34)\n(Corollary 6.2.5)\n= det(\ud835\udc38\u2113+1) det(\ud835\udc38\u2113) \u00b7 \u00b7 \u00b7 det(\ud835\udc381) det(\ud835\udc34)\n(inductive hypothesis).\nThe result now follows.\nWe will give an example that illustrates how to use the preceding results to obtain the\ndeterminant of an arbitrary matrix. We will attempt to apply EROs to simplify \ud835\udc34, keeping\ntrack of what EROs are being applied. Then we can relate det(\ud835\udc34) to det(\ud835\udc35) using Corollary\n6.2.6 (Determinant After \ud835\udc58 EROs).\nNotice that row addition EROs do not change the\ndeterminant, so we need only keep track of row swap and row scale EROs.\nExample 6.2.7\nEvaluate the determinant of \ud835\udc34 =\n\u23a1\n\u23a3\n1 2 3\n4 5 6\n7 8 10\n\u23a4\n\u23a6.\nSolution: We have\ndet(\ud835\udc34) = det\n\u239b\n\u239d\n\u23a1\n\u23a3\n1 2\n3\n0 \u22123 \u22126\n0 \u22126 \u221211\n\u23a4\n\u23a6\n\u239e\n\u23a0\n(\ufe03\nperform\n\ud835\udc452 \u2192 \u22124\ud835\udc451 + \ud835\udc452\n\ud835\udc453 \u2192 \u22127\ud835\udc451 + \ud835\udc453\n, determinant unchanged\n)\ufe03\n= det\n\u239b\n\u239d\n\u23a1\n\u23a3\n1 2\n3\n0 \u22123 \u22126\n0 0\n1\n\u23a4\n\u23a6\n\u239e\n\u23a0\n(perform \ud835\udc453 \u2192 \u22122\ud835\udc452 + \ud835\udc453, determinant unchanged)\n= (1)(\u22123)(1)\n(determinant of an upper triangular matrix)\n= \u22123.\nThe previous example used only row addition EROs. Our next example will use all three\ntypes. Notice that if we apply a row scale ERO to \ud835\udc34 to obtain \ud835\udc35, then det(\ud835\udc35) = \ud835\udc5a det(\ud835\udc34).\nThus, det(\ud835\udc34) = 1\n\ud835\udc5a det(\ud835\udc35).\nExample 6.2.8\nEvaluate the determinant of \ud835\udc34 =\n\u23a1\n\u23a3\n2 \u22122 4\n5 \u22125 1\n3 6 5\n\u23a4\n\u23a6.\nSolution: We have\ndet(\ud835\udc34) = 2 det\n\u239b\n\u239d\n\u23a1\n\u23a3\n1 \u22121 2\n5 \u22125 1\n3 6 5\n\u23a4\n\u23a6\n\u239e\n\u23a0\n(\ufe01\nperform \ud835\udc451 \u2192 1\n2\ud835\udc451, determinant scaled by\n1\n1/2 = 2\n)\ufe01\n= 2 det\n\u239b\n\u239d\n\u23a1\n\u23a3\n1 \u22121 2\n0 0 \u22129\n0 9 \u22121\n\u23a4\n\u23a6\n\u239e\n\u23a0\n(\ufe03\nperform \ud835\udc452 \u2192 \u22125\ud835\udc451 + \ud835\udc452\n\ud835\udc453 \u2192 \u22123\ud835\udc451 + \ud835\udc453\n, determinant unchanged\n)\ufe03\n= \u22122 det\n\u239b\n\u239d\n\u23a1\n\u23a3\n1 \u22121 2\n0 9 \u22121\n0 0 \u22129\n\u23a4\n\u23a6\n\u239e\n\u23a0\n(perform \ud835\udc452 \u2194 \ud835\udc453, sign of determinant changed)156\nChapter 6\nThe Determinant\n= (\u22122)(1)(9)(\u22129)\n(determinant of an upper triangular matrix)\n= 162.\n6.3", "The Determinant and Invertibility\nIn this section, we will use our results on the relationship between EROs and the determinant\nto prove the following fundamental result.\nTheorem 6.3.1\n(Invertible iff the Determinant is Non-Zero)\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F). Then \ud835\udc34 is invertible if and only if det(\ud835\udc34) \u0338= 0.\nProof: Let \ud835\udc45 = RREF(\ud835\udc34). Suppose we obtain \ud835\udc45 from \ud835\udc34 by applying \ud835\udc58 EROs. Thus,\n\ud835\udc45 = \ud835\udc38\ud835\udc58 \u00b7 \u00b7 \u00b7 \ud835\udc381\ud835\udc34,\nwhere \ud835\udc38\ud835\udc56 is the elementary matrix corresponding to the \ud835\udc56th ERO. Corollary 6.2.6 (Deter-\nminant After \ud835\udc58 EROs) then implies that\ndet(\ud835\udc45) = det(\ud835\udc38\ud835\udc58) \u00b7 \u00b7 \u00b7 det(\ud835\udc381) det(\ud835\udc34).\nBy Corollary 6.2.4 (Determinants of Elementary Matrices), since det(\ud835\udc38\ud835\udc56) \u0338= 0 for all \ud835\udc56, it\nfollows that det(\ud835\udc45) \u0338= 0 if and only if det(\ud835\udc34) \u0338= 0.\nNow, if \ud835\udc34 is invertible, then \ud835\udc45 = \ud835\udc3c\ud835\udc5b, and therefore det(\ud835\udc45) = 1 \u0338= 0. So det(\ud835\udc34) \u0338= 0.\nConversely, if \ud835\udc34 is not invertible, then \ud835\udc45 must have a zero row, and therefore det(\ud835\udc45) = 0.\nSo det(\ud835\udc34) = 0 in this case. This completes the proof.\nExample 6.3.2\nFor what value(s) of the constant \ud835\udc58 is the matrix \ud835\udc34 =\n\u23a1\n\u23a3\n3 5 7\n6 \ud835\udc58 14\n2 4 6\n\u23a4\n\u23a6 invertible?\nSolution: Let us evaluate the determinant of \ud835\udc34.\ndet(\ud835\udc34) = det\n\u239b\n\u239d\n\u23a1\n\u23a3\n3\n5\n7\n0 \ud835\udc58 \u2212 10 0\n2\n4\n6\n\u23a4\n\u23a6\n\u239e\n\u23a0\n(\ud835\udc452 \u2192 \u22122\ud835\udc451 + \ud835\udc452)\n= 2 det\n\u239b\n\u239d\n\u23a1\n\u23a3\n3\n5\n7\n0 \ud835\udc58 \u2212 10 0\n1\n2\n3\n\u23a4\n\u23a6\n\u239e\n\u23a0\n(\ud835\udc453 \u2192 1\n2\ud835\udc453)\n= 2 det\n\u239b\n\u239d\n\u23a1\n\u23a3\n0\n\u22121\n\u22122\n0 \ud835\udc58 \u2212 10 0\n1\n2\n3\n\u23a4\n\u23a6\n\u239e\n\u23a0\n(\ud835\udc451 \u2192 \u22123\ud835\udc453 + \ud835\udc451)\n= 4(\ud835\udc58 \u2212 10)\n(expansion along the second row).\nThus, det(\ud835\udc34) = 0 if and only if \ud835\udc58 = 10. We conclude that the matrix \ud835\udc34 is invertible if and\nonly if \ud835\udc58 \u0338= 10.Section 6.3\nThe Determinant and Invertibility\n157\nThe following result is one of the most important properties of the determinant.\nProposition 6.3.3\n(Determinant of a Product)\nLet \ud835\udc34, \ud835\udc35 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F). Then det(\ud835\udc34\ud835\udc35) = det(\ud835\udc34) det(\ud835\udc35).\nProof: As in the proof of Theorem 6.3.1 (Invertible iff the Determinant is Non-Zero), we\nmay write \ud835\udc34 as\n\ud835\udc34 = \ud835\udc38\ud835\udc58 \u00b7 \u00b7 \u00b7 \ud835\udc381\ud835\udc45\nwhere \ud835\udc45 = RREF(\ud835\udc34) and the \ud835\udc38\ud835\udc56 are elementary matrices that correspond to the EROs\nneeded to operate on \ud835\udc45 to produce \ud835\udc34. Then Corollary 6.2.6 (Determinant After \ud835\udc58 EROs)\ngives\ndet(\ud835\udc34) = det(\ud835\udc38\ud835\udc58) \u00b7 \u00b7 \u00b7 det(\ud835\udc381) det(\ud835\udc45).\nNow, suppose \ud835\udc34 is invertible, so that \ud835\udc45 = \ud835\udc3c\ud835\udc5b. On the one hand,\ndet(\ud835\udc34) = det(\ud835\udc38\ud835\udc58) \u00b7 \u00b7 \u00b7 det(\ud835\udc381),\nwhile on the other hand, \ud835\udc34\ud835\udc35 = (\ud835\udc38\ud835\udc58 \u00b7 \u00b7 \u00b7 \ud835\udc381\ud835\udc45)\ud835\udc35 = \ud835\udc38\ud835\udc58 \u00b7 \u00b7 \u00b7 \ud835\udc381\ud835\udc35 (as \ud835\udc45 = \ud835\udc3c\ud835\udc5b) so that\ndet(\ud835\udc34\ud835\udc35) = det(\ud835\udc38\ud835\udc58) \u00b7 \u00b7 \u00b7 det(\ud835\udc381) det(\ud835\udc35),\nagain by Corollary 6.2.6. The right-side is det(\ud835\udc34) det(\ud835\udc35). Thus, the Proposition is true if\n\ud835\udc34 is invertible.\nIf \ud835\udc34 is not invertible, then \ud835\udc45 has a zero row, and therefore so does \ud835\udc45\ud835\udc35. Since\n\ud835\udc34\ud835\udc35 = \ud835\udc38\ud835\udc58 \u00b7 \u00b7 \u00b7 \ud835\udc381(\ud835\udc45\ud835\udc35)\nwe can apply Corollary 6.2.6 (Determinant After \ud835\udc58 EROs) once more to find that\ndet(\ud835\udc34\ud835\udc35) = det(\ud835\udc38\ud835\udc58) \u00b7 \u00b7 \u00b7 det(\ud835\udc381) det(\ud835\udc45\ud835\udc35) = 0.\nSince det(\ud835\udc34) is 0 in this case too, we have that det(\ud835\udc34\ud835\udc35) = det(\ud835\udc34) det(\ud835\udc35).\nREMARK\nIt is not true that det(\ud835\udc34 + \ud835\udc35) = det(\ud835\udc34) + det(\ud835\udc35) in general. For example, if\n\ud835\udc34 =\n[\ufe021 0\n0 0\n]\ufe02\nand\n\ud835\udc35 =\n[\ufe020 0\n0 1\n]\ufe02\nthen det(\ud835\udc34) = det(\ud835\udc35) = 0 so that det(\ud835\udc34) + det(\ud835\udc35) = 0. On the other hand, \ud835\udc34 + \ud835\udc35 = \ud835\udc3c2, so\ndet(\ud835\udc34 + \ud835\udc35) = 1. Thus, det(\ud835\udc34 + \ud835\udc35) \u0338= det(\ud835\udc34) + det(\ud835\udc35) in this case.158\nChapter 6\nThe Determinant\nExample 6.3.4\nLet \ud835\udc34, \ud835\udc35 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F). Prove that \ud835\udc34\ud835\udc35 is invertible if and only if \ud835\udc35\ud835\udc34 is invertible.\nSolution:\n\ud835\udc34\ud835\udc35 is invertible iff det(\ud835\udc34\ud835\udc35) \u0338= 0\n(Theorem 6.3.1 (Invertible iff the Determinant is Non-Zero))\niff det(\ud835\udc34) det(\ud835\udc35) \u0338= 0\n(Proposition 6.3.3 (Determinant of a Product))\niff det(\ud835\udc35) det(\ud835\udc34) \u0338= 0\niff det(\ud835\udc35\ud835\udc34) \u0338= 0\n(Proposition 6.3.3)\niff \ud835\udc35\ud835\udc34 is invertible.\n(Theorem 6.3.1)\nThe previous example implicitly contains the following useful observation.\nCorollary 6.3.5\nLet \ud835\udc34, \ud835\udc35 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F). Then det(\ud835\udc34\ud835\udc35) = det(\ud835\udc35\ud835\udc34).\nHere is another useful observation that can be proved using similar ideas.\nCorollary 6.3.6\n(Determinant of Inverse)\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) be invertible. Then det(\ud835\udc34\u22121) =\n1\ndet(\ud835\udc34).\nProof: We have \ud835\udc34\u22121\ud835\udc34 = \ud835\udc3c\ud835\udc5b. Using Proposition 6.3.3 (Determinant of a Product) and\ntaking determinants of both sides, we get det(\ud835\udc34\u22121) det(\ud835\udc34) = 1. Since \ud835\udc34 is invertible, we\nhave that det(\ud835\udc34) \u0338= 0, so we may divide through by det(\ud835\udc34) to obtain det(\ud835\udc34\u22121) = 1/ det(\ud835\udc34),\nas desired.\nExample 6.3.7\nProve that \ud835\udc34 =\n\u23a1\n\u23a3\n1 2 3\n4 5 6\n7 8 10\n\u23a4\n\u23a6 is invertible and find det(\ud835\udc34\u22121).\nSolution: We saw in Example 6.2.7 that det(\ud835\udc34) = \u22123, so Theorem 6.3.1 (Invertible iff the\nDeterminant is Non-Zero)) tells us that \ud835\udc34 is invertible.\nWe get that det(\ud835\udc34\u22121) = \u22121\n3 by Corollary 6.3.6 (Determinant of Inverse).\n6.4", "An Expression for \ud835\udc34\u22121\nWe saw that a 2 \u00d7 2 matrix \ud835\udc34 is invertible if and only if det(\ud835\udc34) \u0338= 0 in Proposition 4.6.\n13 (Inverse of a 2 \u00d7 2 Matrix).\nIn the previous sections, we generalized the notion of\nthe determinant to \ud835\udc5b \u00d7 \ud835\udc5b matrices and obtained the analogous result: an \ud835\udc5b \u00d7 \ud835\udc5b matrix is\ninvertible if and only if det(\ud835\udc34) \u0338= 0 (Theorem 6.3.1).Section 6.4\nAn Expression for \ud835\udc34\u22121\n159\nProposition 4.6.13 contains one additional result: in the case where det(\ud835\udc34) \u0338= 0, an expres-\nsion for the inverse of \ud835\udc34 is given, namely\n\ud835\udc34\u22121 =\n1\ndet(\ud835\udc34)\n[\ufe02 \ud835\udc51 \u2212\ud835\udc4f\n\u2212\ud835\udc50 \ud835\udc4e\n]\ufe02\n.\nIn this section, we will show that there is a similar result for an \ud835\udc5b \u00d7 \ud835\udc5b matrix (see Corollary\n6.4.6 (Inverse by Adjugate)).\nWe will need some preliminary notation and terminology.\nDefinition 6.4.1\nCofactor\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F). The (\ud835\udc56, \ud835\udc57)\ud835\udc61\u210e cofactor of \ud835\udc34, denoted by \ud835\udc36\ud835\udc56\ud835\udc57(\ud835\udc34), is defined by\n\ud835\udc36\ud835\udc56\ud835\udc57(\ud835\udc34) = (\u22121)\ud835\udc56+\ud835\udc57 det(\ud835\udc40\ud835\udc56\ud835\udc57(\ud835\udc34)).\nNote that we can write the determinant of \ud835\udc34 in terms of cofactors as either:\ndet(\ud835\udc34) =\n\ud835\udc5b\n\u2211\ufe01\n\ud835\udc57=1\n\ud835\udc4e\ud835\udc56\ud835\udc57\ud835\udc36\ud835\udc56\ud835\udc57(\ud835\udc34)\n(expansion along the \ud835\udc56\ud835\udc61\u210e row)\nor\ndet(\ud835\udc34) =\n\ud835\udc5b\n\u2211\ufe01\n\ud835\udc56=1\n\ud835\udc4e\ud835\udc56\ud835\udc57\ud835\udc36\ud835\udc56\ud835\udc57(\ud835\udc34)\n(expansion along the \ud835\udc57\ud835\udc61\u210e column).\nDefinition 6.4.2\nAdjugate of a\nMatrix\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F). The adjugate of \ud835\udc34, denoted by adj(\ud835\udc34), is the \ud835\udc5b \u00d7 \ud835\udc5b matrix whose\n(\ud835\udc56, \ud835\udc57)\ud835\udc61\u210e entry is\n(adj(\ud835\udc34))\ud835\udc56\ud835\udc57 = \ud835\udc36\ud835\udc57\ud835\udc56(\ud835\udc34).\nThat is, the adjugate of \ud835\udc34 is the transpose of the matrix of cofactors of \ud835\udc34.\nExample 6.4.3\nIf \ud835\udc34 =\n[\ufe02\ud835\udc4e \ud835\udc4f\n\ud835\udc50 \ud835\udc51\n]\ufe02\n, then the cofactors of \ud835\udc34 are\n\ud835\udc3611(\ud835\udc34) = (\u22121)1+1\ud835\udc51 = \ud835\udc51,\n\ud835\udc3612(\ud835\udc34) = (\u22121)1+2\ud835\udc50 = \u2212\ud835\udc50,\n\ud835\udc3621(\ud835\udc34) = (\u22121)2+1\ud835\udc4f = \u2212\ud835\udc4f,\n\ud835\udc3622(\ud835\udc34) = (\u22121)2+2\ud835\udc4e = \ud835\udc4e.\nHence\nadj(\ud835\udc34) =\n[\ufe02 \ud835\udc51 \u2212\ud835\udc50\n\u2212\ud835\udc4f \ud835\udc4e\n]\ufe02\ud835\udc47\n=\n[\ufe02 \ud835\udc51 \u2212\ud835\udc4f\n\u2212\ud835\udc50 \ud835\udc4e\n]\ufe02\n.\nNotice that this is the matrix that appeared in the expression for \ud835\udc34\u22121 in Proposition 4.6.\n13 (Inverse of a 2 \u00d7 2 Matrix).160\nChapter 6\nThe Determinant\nExample 6.4.4\nFind the adjugate of \ud835\udc34 =\n\u23a1\n\u23a3\n1 2 3\n4 5 6\n7 8 10\n\u23a4\n\u23a6 .\nSolution:\nThe cofactors of \ud835\udc34 are given below. (We will write \ud835\udc40\ud835\udc56\ud835\udc57 and \ud835\udc36\ud835\udc56\ud835\udc57 instead of \ud835\udc40\ud835\udc56\ud835\udc57(\ud835\udc34) and\n\ud835\udc36\ud835\udc56\ud835\udc57(\ud835\udc34).)\n\ud835\udc4011 =\n[\ufe025 6\n8 10\n]\ufe02\n\ud835\udc3611 = 2\n\ud835\udc4012 =\n[\ufe024 6\n7 10\n]\ufe02\n\ud835\udc3612 = 2\n\ud835\udc4013 =\n[\ufe024 5\n7 8\n]\ufe02\n\ud835\udc3613 = \u22123\n\ud835\udc4021 =\n[\ufe022 3\n8 10\n]\ufe02\n\ud835\udc3621 = 4\n\ud835\udc4022 =\n[\ufe021 3\n7 10\n]\ufe02\n\ud835\udc3622 = \u221211\n\ud835\udc4023 =\n[\ufe021 2\n7 8\n]\ufe02\n\ud835\udc3623 = 6\n\ud835\udc4031 =\n[\ufe022 3\n5 6\n]\ufe02\n\ud835\udc3631 = \u22123\n\ud835\udc4032 =\n[\ufe021 3\n4 6\n]\ufe02\n\ud835\udc3632 = 6\n\ud835\udc4033 =\n[\ufe021 2\n4 5\n]\ufe02\n\ud835\udc3633 = \u22123\nConsequently,\nadj(\ud835\udc34) =\n\u23a1\n\u23a3\n2\n2\n\u22123\n4 \u221211 6\n\u22123\n6\n\u22123\n\u23a4\n\u23a6\n\ud835\udc47\n=\n\u23a1\n\u23a3\n2\n4\n\u22123\n2 \u221211 6\n\u22123\n6\n\u22123\n\u23a4\n\u23a6 .\nHere is the key result concerning the adjugate matrix, which we state without proof.\nTheorem 6.4.5\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F). Then\n\ud835\udc34 adj(\ud835\udc34) = adj(\ud835\udc34) \ud835\udc34 = det(\ud835\udc34)\ud835\udc3c\ud835\udc5b.\nCorollary 6.4.6\n(Inverse by Adjugate)\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F). If det(\ud835\udc34) \u0338= 0, then\n\ud835\udc34\u22121 =\n1\ndet(\ud835\udc34) adj(\ud835\udc34).\nProof: From Theorem 6.4.5, we know that\nadj(\ud835\udc34)\ud835\udc34 = det(\ud835\udc34)\ud835\udc3c\ud835\udc5b.\nDividing this equation by det(\ud835\udc34), we obtain\n(\ufe02\n1\ndet(\ud835\udc34) adj(\ud835\udc34)\n)\ufe02\n\ud835\udc34 = \ud835\udc3c\ud835\udc5b.Section 6.5", "Cramer\u2019s Rule\n161\nTherefore,\n1\ndet(\ud835\udc34) adj(\ud835\udc34) = \ud835\udc34\u22121.\nExample 6.4.7\nIf \ud835\udc34 =\n[\ufe02\ud835\udc4e \ud835\udc4f\n\ud835\udc50 \ud835\udc51\n]\ufe02\nand det(\ud835\udc34) \u0338= 0, then by Example 6.4.3 and Corollary 6.4.6 (Inverse by\nAdjugate),\n\ud835\udc34\u22121 =\n1\ndet(\ud835\udc34)\n[\ufe02 \ud835\udc51 \u2212\ud835\udc4f\n\u2212\ud835\udc50 \ud835\udc4e\n]\ufe02\n=\n1\n\ud835\udc4e\ud835\udc51 \u2212 \ud835\udc4f\ud835\udc50\n[\ufe02 \ud835\udc51 \u2212\ud835\udc4f\n\u2212\ud835\udc50 \ud835\udc4e\n]\ufe02\n,\nexactly as in Proposition 4.6.13 (Inverse of a 2 \u00d7 2 Matrix).\nExample 6.4.8\nLet \ud835\udc34 =\n\u23a1\n\u23a3\n1 2 3\n4 5 6\n7 8 10\n\u23a4\n\u23a6 . Determine \ud835\udc34\u22121, if it exists.\nSolution: From Example 6.2.7, we know\ndet(\ud835\udc34) = det\n\u23a1\n\u23a3\n1 2\n3\n0 \u22123 \u22126\n0 \u22126 \u221211\n\u23a4\n\u23a6 = 33 \u2212 36 = \u22123 \u0338= 0,\nso we have that \ud835\udc34 is invertible. Having computed in Example 6.4.4 that\nadj(\ud835\udc34) =\n\u23a1\n\u23a3\n2\n4\n\u22123\n2 \u221211 6\n\u22123\n6\n\u22123\n\u23a4\n\u23a6 ,\nwe conclude that\n\ud835\udc34\u22121 = \u22121\n3\n\u23a1\n\u23a3\n2\n4\n\u22123\n2 \u221211 6\n\u22123\n6\n\u22123\n\u23a4\n\u23a6 .\nREMARK\nWe do not recommend this method as a way of determining the inverse of a matrix. However,\nit may be useful for checking that one or two entries are correct.\nIn practice, it will usually be more efficient to use the Algorithm involving EROs given in\nProposition 4.6.8 (Algorithm for Checking Invertibility and Finding the Inverse).\n6.5\nCramer\u2019s Rule\nCramer\u2019s Rule provides a method for solving systems of \ud835\udc5b linear equations in \ud835\udc5b unknowns\nby making use of determinants. It is not usually efficient from a computational point of\nview, since calculating determinants is generally computationally intensive.\nHowever, Cramer\u2019s Rule is particularly useful if one is only interested in a single component\nof the solution.162\nChapter 6\nThe Determinant\nProposition 6.5.1\n(Cramer\u2019s Rule)\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) and consider the equation \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f , where #\u00bb\ud835\udc4f \u2208 F\ud835\udc5b and det(\ud835\udc34) \u0338= 0.\nIf we construct \ud835\udc35\ud835\udc57 from \ud835\udc34 by replacing the \ud835\udc57\ud835\udc61\u210e column of \ud835\udc34 by the column vector #\u00bb\ud835\udc4f , then\nthe solution #\u00bb\ud835\udc65 to the equation\n\ud835\udc34#\u00bb\ud835\udc65 = #\u00bb\ud835\udc4f\nis given by\n\ud835\udc65\ud835\udc57 = det(\ud835\udc35\ud835\udc57)\ndet(\ud835\udc34) ,\nfor all \ud835\udc57 = 1, . . . , \ud835\udc5b.\nProof: Since det(\ud835\udc34) \u0338= 0, we have that \ud835\udc34 is invertible and\n\ud835\udc34\u22121 =\n1\ndet(\ud835\udc34) adj(\ud835\udc34).\nThus,\n#\u00bb\ud835\udc65 = \ud835\udc34\u22121 #\u00bb\ud835\udc4f =\n1\ndet \ud835\udc34 adj(\ud835\udc34) #\u00bb\ud835\udc4f ,\nand so\n\ud835\udc65\ud835\udc57 =\n1\ndet(\ud835\udc34)\n\ud835\udc5b\n\u2211\ufe01\n\ud835\udc58=1\n(adj(\ud835\udc34))\ud835\udc57\ud835\udc58 \ud835\udc4f\ud835\udc58;\nthat is,\n\ud835\udc65\ud835\udc57 =\n1\ndet(\ud835\udc34)\n\ud835\udc5b\n\u2211\ufe01\n\ud835\udc58=1\n\ud835\udc36\ud835\udc58\ud835\udc57(\ud835\udc34) \ud835\udc4f\ud835\udc58.\nWe will show that\n\ud835\udc5b\n\u2211\ufe01\n\ud835\udc58=1\n\ud835\udc36\ud835\udc58\ud835\udc57(\ud835\udc34) \ud835\udc4f\ud835\udc58 = det(\ud835\udc35\ud835\udc57),\nand then Cramer\u2019s Rule will be proven.\nWe evaluate det(\ud835\udc35\ud835\udc57) by expanding the determinant along the \ud835\udc57\ud835\udc61\u210e column of \ud835\udc35\ud835\udc57,\ndet(\ud835\udc35\ud835\udc57) =\n\ud835\udc58\n\u2211\ufe01\n\ud835\udc56=1\n(\ud835\udc35\ud835\udc57)\ud835\udc58\ud835\udc57 (\ud835\udc36(\ud835\udc35\ud835\udc57))\ud835\udc58\ud835\udc57.\nRecall that (\ud835\udc35\ud835\udc57)\ud835\udc58\ud835\udc57 = \ud835\udc4f\ud835\udc58, since the \ud835\udc57\ud835\udc61\u210e column of \ud835\udc35\ud835\udc57 is just #\u00bb\ud835\udc4f .\nSince the matrices \ud835\udc34 and \ud835\udc35 only differ (at most) in the \ud835\udc57\ud835\udc61\u210e column, we conclude that\n(\ud835\udc36(\ud835\udc35\ud835\udc57))\ud835\udc58\ud835\udc57 = (\ud835\udc36(\ud835\udc34))\ud835\udc58\ud835\udc57.\nThus,\ndet(\ud835\udc35\ud835\udc57) =\n\ud835\udc5b\n\u2211\ufe01\n\ud835\udc58=1\n\ud835\udc36\ud835\udc58\ud835\udc57(\ud835\udc34) \ud835\udc4f\ud835\udc58,\nas required.Section 6.6", "The Determinant and Geometry\n163\nExample 6.5.2\nLet \ud835\udc34 =\n\u23a1\n\u23a3\n1 2 3\n4 5 6\n7 8 10\n\u23a4\n\u23a6. Use Cramer\u2019s Rule to solve\n\u23a1\n\u23a3\n1 2 3\n4 5 6\n7 8 10\n\u23a4\n\u23a6 #\u00bb\ud835\udc65 =\n\u23a1\n\u23a3\n\u22122\n3\n\u22124\n\u23a4\n\u23a6 .\nSolution: We saw in Example 6.2.7 that\ndet\n\u239b\n\u239d\n\u23a1\n\u23a3\n1 2 3\n4 5 6\n7 8 10\n\u23a4\n\u23a6\n\u239e\n\u23a0 = \u22123.\nNow, let us evaluate the determinants of the matrices\n\ud835\udc351 =\n\u23a1\n\u23a3\n\u22122 2 3\n3 5 6\n\u22124 8 10\n\u23a4\n\u23a6 ,\n\ud835\udc352 =\n\u23a1\n\u23a3\n1 \u22122 3\n4 3\n6\n7 \u22124 10\n\u23a4\n\u23a6 ,\n\ud835\udc353 =\n\u23a1\n\u23a3\n1 2 \u22122\n4 5 3\n7 8 \u22124\n\u23a4\n\u23a6 .\nWe evaluate the determinants of \ud835\udc351, \ud835\udc352 and \ud835\udc353 using the indicated EROs:\ndet(\ud835\udc351) = det\n\u23a1\n\u23a3\n\u22122 2 3\n3 5 6\n\u22124 8 10\n\u23a4\n\u23a6 = det\n\u23a1\n\u23a3\n\u22122 2 3\n0 8 21\n2\n0 4 4\n\u23a4\n\u23a6\n= 20.\n\u23a7\n\u23a8\n\u23a9\n\ud835\udc452 \u2192 3\n2\ud835\udc451 + \ud835\udc452\n\ud835\udc453 \u2192 \u22122\ud835\udc451 + \ud835\udc453\ndet(\ud835\udc352) = det\n\u23a1\n\u23a3\n1 \u22122 3\n4 3\n6\n7 \u22124 10\n\u23a4\n\u23a6 = det\n\u23a1\n\u23a3\n1 \u22122\n3\n0 11 \u22126\n0 10 \u221211\n\u23a4\n\u23a6 = \u221261.\n\u23a7\n\u23a8\n\u23a9\n\ud835\udc452 \u2192 \u22124\ud835\udc451 + \ud835\udc452\n\ud835\udc453 \u2192 \u22127\ud835\udc451 + \ud835\udc453\ndet(\ud835\udc353) = det\n\u23a1\n\u23a3\n1 2 \u22122\n4 5 3\n7 8 \u22124\n\u23a4\n\u23a6 = det\n\u23a1\n\u23a3\n1 2 \u22122\n0 \u22123 11\n0 \u22126 10\n\u23a4\n\u23a6 = 36.\n\u23a7\n\u23a8\n\u23a9\n\ud835\udc452 \u2192 \u22124\ud835\udc451 + \ud835\udc452\n\ud835\udc453 \u2192 \u22127\ud835\udc451 + \ud835\udc453\nThus,\n#\u00bb\ud835\udc65 = \u22121\n3\n\u23a1\n\u23a3\n20\n\u221261\n36\n\u23a4\n\u23a6 .\n6.6\nThe Determinant and Geometry\nIn this section, we will give a geometric interpretation of the determinant.\nIn R2, the\nunderlying idea is the relationship between the determinant and areas of parallelograms,\nwhich we can calculate using the cross product. Here is the key result.164\nChapter 6\nThe Determinant\nProposition 6.6.1\n(Area of Parallelogram)\nLet #\u00bb\ud835\udc63 =\n[\ufe02\ud835\udc631\n\ud835\udc632\n]\ufe02\nand #\u00bb\ud835\udc64 =\n[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02\nbe vectors in R2.\nThe area of the parallelogram with sides #\u00bb\ud835\udc63 and #\u00bb\ud835\udc64 is\n\u20d2\u20d2\u20d2\u20d2det\n(\ufe02[\ufe02\ud835\udc631 \ud835\udc641\n\ud835\udc632 \ud835\udc642\n]\ufe02)\ufe02\u20d2\u20d2\u20d2\u20d2 .\nProof: We shall consider the analogous vectors #\u00bb\ud835\udc63 1 and #\u00bb\ud835\udc641 in R3 with a third component\nof zero. That is, we let\n#\u00bb\ud835\udc63 1 =\n\u23a1\n\u23a3\n\ud835\udc631\n\ud835\udc632\n0\n\u23a4\n\u23a6 and #\u00bb\ud835\udc641 =\n\u23a1\n\u23a3\n\ud835\udc641\n\ud835\udc642\n0\n\u23a4\n\u23a6 .\nAs we saw in the Remark (Parallelogram Area via Cross Product) in Section 1.9, the area\nof the parallelogram with sides #\u00bb\ud835\udc63 and #\u00bb\ud835\udc64 is given by\n\u2016#\u00bb\ud835\udc63 1 \u00d7 #\u00bb\ud835\udc641\u2016 =\n\u20e6\u20e6\u20e6\u20e6\u20e6\u20e6\n\u23a1\n\u23a3\n\ud835\udc631\n\ud835\udc632\n0\n\u23a4\n\u23a6 \u00d7\n\u23a1\n\u23a3\n\ud835\udc641\n\ud835\udc642\n0\n\u23a4\n\u23a6\n\u20e6\u20e6\u20e6\u20e6\u20e6\u20e6\n=\n\u20e6\u20e6\u20e6\u20e6\u20e6\u20e6\n\u23a1\n\u23a3\n0\n0\n\ud835\udc631\ud835\udc642 \u2212 \ud835\udc641\ud835\udc632\n\u23a4\n\u23a6\n\u20e6\u20e6\u20e6\u20e6\u20e6\u20e6\n= |\ud835\udc631\ud835\udc642 \u2212 \ud835\udc641\ud835\udc632|.\nThe expression on the right is equal to\n\u20d2\u20d2\u20d2\u20d2det\n(\ufe02[\ufe02\ud835\udc631 \ud835\udc641\n\ud835\udc632 \ud835\udc642\n]\ufe02)\ufe02\u20d2\u20d2\u20d2\u20d2, as required.\nExample 6.6.2\nDetermine the area of the parallelogram in R2 with the vectors #\u00bb\ud835\udc63 =\n[\ufe00\n2 5\n]\ufe00\ud835\udc47 and #\u00bb\ud835\udc64 =\n[\ufe00\n4 1\n]\ufe00\ud835\udc47\nas its sides.\nSolution: The area is\n\u20d2\u20d2\u20d2\u20d2det\n(\ufe02[\ufe022 4\n5 1\n]\ufe02)\ufe02\u20d2\u20d2\u20d2\u20d2 = | \u2212 18| = 18 units2.\nNotice that it is important to include the absolute value signs in the expression given by\nProposition 6.6.1 (Area of Parallelogram).\nREMARK\nIf we study the proof of Proposition 6.6.1 (Area of Parallelogram), we can obtain a useful\ntrick that helps us compute cross products. Namely, suppose we wish to compute the cross\nproduct #\u00bb\ud835\udc62 \u00d7 #\u00bb\ud835\udc63 of #\u00bb\ud835\udc62 =\n\u23a1\n\u23a3\n\ud835\udc621\n\ud835\udc622\n\ud835\udc623\n\u23a4\n\u23a6 and #\u00bb\ud835\udc63 =\n\u23a1\n\u23a3\n\ud835\udc631\n\ud835\udc632\n\ud835\udc633\n\u23a4\n\u23a6. Consider the matrix\n\u23a1\n\u23a3\n#\u00bb\ud835\udc52 1 #\u00bb\ud835\udc52 2 #\u00bb\ud835\udc52 3\n\ud835\udc621 \ud835\udc622 \ud835\udc623\n\ud835\udc631 \ud835\udc632 \ud835\udc633\n\u23a4\n\u23a6\nwhose first row consists of the standard basis vectors #\u00bb\ud835\udc52 1, #\u00bb\ud835\udc52 2, #\u00bb\ud835\udc52 3 (treated as formal sym-\nbols!), and whose second and third rows are the entries of #\u00bb\ud835\udc62 and #\u00bb\ud835\udc63 , respectively. Then ifSection 6.6\nThe Determinant and Geometry\n165\nwe expand along the first row, we obtain\ndet\n\u23a1\n\u23a3\n#\u00bb\ud835\udc52 1 #\u00bb\ud835\udc52 2 #\u00bb\ud835\udc52 3\n\ud835\udc621 \ud835\udc622 \ud835\udc623\n\ud835\udc631 \ud835\udc632 \ud835\udc633\n\u23a4\n\u23a6 = (\ud835\udc622\ud835\udc633 \u2212 \ud835\udc623\ud835\udc632)#\u00bb\ud835\udc52 1 \u2212 (\ud835\udc621\ud835\udc633 \u2212 \ud835\udc623\ud835\udc631)#\u00bb\ud835\udc52 2 + (\ud835\udc621\ud835\udc632 \u2212 \ud835\udc622\ud835\udc631)#\u00bb\ud835\udc52 3\n=\n\u23a1\n\u23a3\n\ud835\udc622\ud835\udc633 \u2212 \ud835\udc623\ud835\udc632\n\u2212(\ud835\udc621\ud835\udc633 \u2212 \ud835\udc623\ud835\udc631)\n\ud835\udc621\ud835\udc632 \u2212 \ud835\udc622\ud835\udc631\n\u23a4\n\u23a6 .\nWe recognize this last expression as #\u00bb\ud835\udc62 \u00d7 #\u00bb\ud835\udc63 .\nWe must emphasize however that this is simply a trick that helps us remember the formula\nfor #\u00bb\ud835\udc62 \u00d7 #\u00bb\ud835\udc63 . We are abusing notation by treating #\u00bb\ud835\udc52 1, #\u00bb\ud835\udc52 2, #\u00bb\ud835\udc52 3 as symbols in the left-side of\nthe equation, but as vectors in the right-side of the equation.\nExample 6.6.3\nCompute\n\u23a1\n\u23a3\n2\n\u22123\n5\n\u23a4\n\u23a6 \u00d7\n\u23a1\n\u23a3\n\u22122\n1\n4\n\u23a4\n\u23a6.\nSolution:\nUsing the trick above, we have\n\u23a1\n\u23a3\n2\n\u22123\n5\n\u23a4\n\u23a6 \u00d7\n\u23a1\n\u23a3\n\u22122\n1\n4\n\u23a4\n\u23a6 = det\n\u23a1\n\u23a3\n#\u00bb\ud835\udc52 1 #\u00bb\ud835\udc52 2 #\u00bb\ud835\udc52 3\n2 \u22123 5\n\u22122 1\n4\n\u23a4\n\u23a6\n= (\u221217)#\u00bb\ud835\udc52 1 \u2212 (18)#\u00bb\ud835\udc52 2 + (\u22124)#\u00bb\ud835\udc52 3\n=\n\u23a1\n\u23a3\n\u221217\n\u221218\n\u22124\n\u23a4\n\u23a6 ,\njust as we had computed in Example 1.9.2.\nHere is another useful re-interpretation of Proposition 6.6.1 (Area of Parallelogram). Let\n\ud835\udc34 \u2208 \ud835\udc402\u00d72(R) and consider the unit square in R2. Multiply the sides #\u00bb\n\ud835\udc521 and #\u00bb\n\ud835\udc522 of the unit\nsquare by \ud835\udc34 to obtain the vectors \ud835\udc34#\u00bb\n\ud835\udc521 and \ud835\udc34#\u00bb\n\ud835\udc522. In this way, we may view \ud835\udc34 as having\ntransformed the unit square into a parallelogram with sides \ud835\udc34#\u00bb\n\ud835\udc521 and \ud835\udc34#\u00bb\n\ud835\udc522.\nSince \ud835\udc34#\u00bb\n\ud835\udc521 and \ud835\udc34#\u00bb\n\ud835\udc522 are the columns of \ud835\udc34 (by Lemma 4.2.2 (Column Extraction)), Proposition\n6.6.1 tells us that the area of the resulting parallelogram is | det(\ud835\udc34)|. Since the area of the\nunit square is 1, we conclude \ud835\udc34 has scaled the area of the unit square by a factor of | det(\ud835\udc34)|.\nThe determinant of a 2 \u00d7 2 real matrix may thus be interpreted as a (signed) scaling factor\nof areas. In particular, notice that if the determinant is 0, then the area gets scaled by 0.\nThis intuitively aligns with the fact that such a matrix is not invertible, since such a scaling\ncannot be reversed.\nIt is possible to give a similar interpretation of the \ud835\udc5b \u00d7 \ud835\udc5b determinant of a real matrix as\na (signed) scaling factor of volumes in R\ud835\udc5b, but we will not pursue this idea further in this\ncourse.166\nChapter 6\nThe Determinant\nFigure 6.6.1: Effect of \ud835\udc34 on the unit square.Chapter 7\nEigenvalues and Diagonalization\n7.1", "What is an Eigenpair?\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(R) be the standard matrix for the linear transformation \ud835\udc47\ud835\udc34.\nWe want\nto consider the effect that multiplication by \ud835\udc34 has on the vector #\u00bb\ud835\udc65 \u2208 R\ud835\udc5b; that is, we\nwill compare the length and the direction of an input vector #\u00bb\ud835\udc65 \u2208 R\ud835\udc5b to its image vector\n#\u00bb\ud835\udc66 = \ud835\udc34#\u00bb\ud835\udc65 \u2208 R\ud835\udc5b.\nUsually, when #\u00bb\ud835\udc65 is multiplied by matrix \ud835\udc34 to produce #\u00bb\ud835\udc66 = \ud835\udc34#\u00bb\ud835\udc65, there will be changes to\nboth the length and the direction. Exceptions to this pattern turn out to be particularly\ninteresting, and will become the focus of the majority of this chapter.\nExample 7.1.1\nLet \ud835\udc34 =\n[\ufe021 3\n3 1\n]\ufe02\nand #\u00bb\ud835\udc54 =\n[\ufe021\n0\n]\ufe02\n. Then\n#\u00bb\u210e = \ud835\udc47\ud835\udc34(#\u00bb\ud835\udc65) = \ud835\udc34#\u00bb\ud835\udc54 =\n[\ufe021 3\n3 1\n]\ufe02 [\ufe021\n0\n]\ufe02\n=\n[\ufe021\n3\n]\ufe02\n.\nSince \u2016#\u00bb\ud835\udc54 \u2016 = 1 and the length of the image is \u2016#\u00bb\u210e\u2016 =\n\u221a\n10,\nthe image #\u00bb\u210e has been scaled by a factor of\n\u221a\n10 relative to\nthe length of the input vector #\u00bb\ud835\udc54 .\nThe image #\u00bb\u210e has a different direction than the input #\u00bb\ud835\udc54 ;\nthe angle between #\u00bb\ud835\udc54 and #\u00bb\u210e is\n\ud835\udf03 = arccos\n(\ufe01\n#\u00bb\ud835\udc54 \u00b7 #\u00bb\u210e\n\u2016 #\u00bb\ud835\udc54 \u2016 \u2016 #\u00bb\u210e \u2016\n)\ufe01\n= arccos\n(\ufe01\n1\n\u221a\n10\n)\ufe01\n\u2248 1.249 radians\ncounter-clockwise.\nExample 7.1.2\nKeeping \ud835\udc34 =\n[\ufe021 3\n3 1\n]\ufe02\nfrom the previous example with a new input vector #\u00bb\ud835\udc62 =\n[\ufe02 2\n\u22121\n]\ufe02\n, then\n167168\nChapter 7\nEigenvalues and Diagonalization\n#\u00bb\ud835\udc63 = \ud835\udc47\ud835\udc34(#\u00bb\ud835\udc62) = \ud835\udc34 #\u00bb\ud835\udc62 =\n[\ufe021 3\n3 1\n]\ufe02 [\ufe02 2\n\u22121\n]\ufe02\n=\n[\ufe02\u22121\n5\n]\ufe02\n.\nSince \u2016#\u00bb\ud835\udc62\u2016 =\n\u221a\n5 and the length of the image is \u2016#\u00bb\ud835\udc63 \u2016 =\n\u221a\n26,\nthe image #\u00bb\ud835\udc63 has been scaled by a factor of\n\u221a\ufe01\n26\n5 relative to\nthe length of the input vector #\u00bb\ud835\udc62.\nThe image #\u00bb\ud835\udc63 has a different direction than the input #\u00bb\ud835\udc62;\nthe angle between #\u00bb\ud835\udc62 and #\u00bb\ud835\udc63 is \ud835\udf03 = arccos\n(\ufe01\n#\u00bb\ud835\udc62 \u00b7 #\u00bb\ud835\udc63\n\u2016 #\u00bb\ud835\udc62 \u2016 \u2016 #\u00bb\ud835\udc63 \u2016\n)\ufe01\n=\narccos\n(\ufe01\n\u22127\n\u221a\n5\n\u221a\n26\n)\ufe01\n\u2248 2.232 radians counter-clockwise.\nWe now ask, for a given matrix \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F), are there any input vectors whose direction\nis not changed when they are multiplied by \ud835\udc34?\nExample 7.1.3\nKeeping \ud835\udc34 =\n[\ufe021 3\n3 1\n]\ufe02\nfrom the previous examples with a new input vector #\u00bb\ud835\udc67 =\n[\ufe021\n1\n]\ufe02\n, then\n#\u00bb\ud835\udc64 = \ud835\udc47\ud835\udc34(#\u00bb\ud835\udc67 ) = \ud835\udc34#\u00bb\ud835\udc67 =\n[\ufe021 3\n3 1\n]\ufe02 [\ufe021\n1\n]\ufe02\n=\n[\ufe024\n4\n]\ufe02\n= 4\n[\ufe021\n1\n]\ufe02\n= 4#\u00bb\ud835\udc67 .\nThe image #\u00bb\ud835\udc64 has been scaled by a factor of 4 relative to the length of the input vector #\u00bb\ud835\udc67 .\nThe image #\u00bb\ud835\udc64 has the same direction as the original vector #\u00bb\ud835\udc67 ; that is, multiplying \ud835\udc34 by #\u00bb\ud835\udc67\ndid not change the direction.\nWe include within our scope of interest image vectors that are in the opposite direction of\nthe input vector.\nExample 7.1.4\nKeeping \ud835\udc34 =\n[\ufe021 3\n3 1\n]\ufe02\nfrom the previous examples with a new input vector #\u00bb\ud835\udc65 =\n[\ufe02 1\n\u22121\n]\ufe02\n,\n#\u00bb\ud835\udc66 = \ud835\udc47\ud835\udc34(#\u00bb\ud835\udc65) = \ud835\udc34#\u00bb\ud835\udc65 =\n[\ufe021 3\n3 1\n]\ufe02 [\ufe02 1\n\u22121\n]\ufe02\n=\n[\ufe02\u22122\n2\n]\ufe02\n= \u22122\n[\ufe02 1\n\u22121\n]\ufe02\n= \u22122#\u00bb\ud835\udc65.\nThe image #\u00bb\ud835\udc66 has been scaled by a factor of \u22122 relative to the length of the input vector #\u00bb\ud835\udc65.\nThe image #\u00bb\ud835\udc66 has the opposite direction as the original vector #\u00bb\ud835\udc65.\nIn the previous two examples, we found vectors #\u00bb\ud835\udc67 =\n[\ufe021\n1\n]\ufe02\nand #\u00bb\ud835\udc65 =\n[\ufe02 1\n\u22121\n]\ufe02\nthat \u201cfit\u201d with\nthe matrix \ud835\udc34 =\n[\ufe021 3\n3 1\n]\ufe02\nin a special way, such that \ud835\udc34#\u00bb\ud835\udc67 and \ud835\udc34#\u00bb\ud835\udc65 are scalar multiples of #\u00bb\ud835\udc67\nand #\u00bb\ud835\udc65 respectively.Section 7.2", "The Characteristic Polynomial and Finding Eigenvalues\n169\nREMARK\nGiven any matrix \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F), we will seek vectors #\u00bb\ud835\udc65 such that \ud835\udc34#\u00bb\ud835\udc65 is a scalar multiple\nof #\u00bb\ud835\udc65. For any such matrix \ud835\udc34, #\u00bb\ud835\udc65 = #\u00bb0 is such a vector because \ud835\udc34 #\u00bb0 = #\u00bb0 = \ud835\udc50#\u00bb0 for any\nconstant \ud835\udc50; that is, \ud835\udc34#\u00bb0 is always a scalar multiple of #\u00bb0 . This fact is so trivial that we focus\nour attention on vectors #\u00bb\ud835\udc65 \u0338= #\u00bb0 such that \ud835\udc34#\u00bb\ud835\udc65 is a scalar multiple of #\u00bb\ud835\udc65.\nWe now arrive at our main definitions.\nDefinition 7.1.5\nEigenvector,\nEigenvalue and\nEigenpair\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F). A non-zero vector #\u00bb\ud835\udc65 is an eigenvector of \ud835\udc34 over F if there exists a\nscalar \ud835\udf06 \u2208 F such that\n\ud835\udc34 #\u00bb\ud835\udc65 = \ud835\udf06 #\u00bb\ud835\udc65.\nThe scalar \ud835\udf06 is then called an eigenvalue of \ud835\udc34 over F, and the pair (\ud835\udf06, #\u00bb\ud835\udc65) is an eigenpair\nof \ud835\udc34 over F.\nExample 7.1.6\nIn Examples 7.1.3 and 7.1.4, we saw that \ud835\udc34 =\n[\ufe021 3\n3 1\n]\ufe02\nhas eigenpairs\n(\ufe02\n4,\n[\ufe021\n1\n]\ufe02)\ufe02\nand\n(\ufe02\n\u22122,\n[\ufe02 1\n\u22121\n]\ufe02)\ufe02\nover R.\nInterestingly enough, a square matrix with real entries may have eigenpairs with non-real\neigenvalues.\nExample 7.1.7\nIf \ud835\udc35 =\n[\ufe020 \u22121\n1 0\n]\ufe02\n, then (\ud835\udf06, #\u00bb\ud835\udc65) =\n(\ufe02\n\ud835\udc56,\n[\ufe02 \ud835\udc56\n1\n]\ufe02)\ufe02\nis an eigenpair of \ud835\udc35 over C, because\n\ud835\udc35 #\u00bb\ud835\udc65 =\n[\ufe020 \u22121\n1 0\n]\ufe02 [\ufe02 \ud835\udc56\n1\n]\ufe02\n=\n[\ufe02\u22121\n\ud835\udc56\n]\ufe02\n= \ud835\udc56\n[\ufe02 \ud835\udc56\n1\n]\ufe02\n= \ud835\udf06#\u00bb\ud835\udc65.\nYou can verify that\n(\ufe02\n\u2212\ud835\udc56,\n[\ufe02\u2212\ud835\udc56\n1\n]\ufe02)\ufe02\nis an eigenpair of \ud835\udc35 over C in a similar way. With the\ntechniques that will be developed in this chapter you will be able to show that, even though\n\ud835\udc35 has entries in R, it does not have any eigenpairs over R.\n7.2\nThe Characteristic Polynomial and Finding Eigenvalues\nWhen looking for eigenpairs of a matrix \ud835\udc34 over F, consider this list of equivalent equations\nwhich we solve over F for both #\u00bb\ud835\udc65 and \ud835\udf06. We denote \ud835\udc3c\ud835\udc5b by \ud835\udc3c.\n\ud835\udc34#\u00bb\ud835\udc65 = \ud835\udf06#\u00bb\ud835\udc65\n\u21d4\n\ud835\udc34#\u00bb\ud835\udc65 \u2212 \ud835\udf06#\u00bb\ud835\udc65 = #\u00bb0\n\u21d4\n\ud835\udc34#\u00bb\ud835\udc65 \u2212 \ud835\udf06\ud835\udc3c #\u00bb\ud835\udc65 = #\u00bb0\n\u21d4\n(\ud835\udc34 \u2212 \ud835\udf06\ud835\udc3c)#\u00bb\ud835\udc65 = #\u00bb0170\nChapter 7\nEigenvalues and Diagonalization\nThus, solving the equation \ud835\udc34#\u00bb\ud835\udc65 = \ud835\udf06#\u00bb\ud835\udc65 is equivalent to solving (\ud835\udc34 \u2212 \ud835\udf06\ud835\udc3c)#\u00bb\ud835\udc65 = #\u00bb0 .\nDefinition 7.2.1\nEigenvalue\nEquation or\nEigenvalue\nProblem\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F). We refer to the equation\n\ud835\udc34 #\u00bb\ud835\udc65 = \ud835\udf06 #\u00bb\ud835\udc65\nor\n(\ud835\udc34 \u2212 \ud835\udf06\ud835\udc3c) #\u00bb\ud835\udc65 = #\u00bb0\nas the eigenvalue equation for the matrix \ud835\udc34 over F. It is also sometimes referred to\nas the eigenvalue problem.\nREMARKS\n\u2022 This is an unusual equation to solve since we want to solve it for both the vector\n#\u00bb\ud835\udc65 \u2208 F\ud835\udc5b and the scalar \ud835\udf06 \u2208 F. We will approach the problem by first identifying\neligible values of \ud835\udf06. We can then determine corresponding sets of vectors #\u00bb\ud835\udc65 that solve\nthe equation for each \ud835\udf06 we identify.\n\u2022 As mentioned in the Remark following Example 7.1.4, a trivial solution to this equa-\ntion is #\u00bb\ud835\udc65 = #\u00bb0 . We seek to obtain a non-trivial (#\u00bb\ud835\udc65 \u0338= #\u00bb0 ) solution to the eigenvalue\nequation. This is possible if and only if the RREF of matrix \ud835\udc34 \u2212 \ud835\udf06\ud835\udc3c has fewer than\n\ud835\udc5b pivots, which occurs if and only if \ud835\udc34 \u2212 \ud835\udf06\ud835\udc3c is not invertible; that is, if and only if\ndet(\ud835\udc34 \u2212 \ud835\udf06\ud835\udc3c) = 0.\n\u2022 Computing det(\ud835\udc34\u2212\ud835\udf06\ud835\udc3c) = det\n\u239b\n\u239c\n\u239c\n\u239c\n\u239d\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc4e11 \u2212 \ud835\udf06\n\ud835\udc4e12\n. . .\n\ud835\udc4e1\ud835\udc5b\n\ud835\udc4e21\n\ud835\udc4e22 \u2212 \ud835\udf06 . . .\n\ud835\udc4e2\ud835\udc5b\n...\n...\n...\n...\n\ud835\udc4e\ud835\udc5b1\n\ud835\udc4e\ud835\udc5b2\n. . . \ud835\udc4e\ud835\udc5b\ud835\udc5b \u2212 \ud835\udf06\n\u23a4\n\u23a5\u23a5\u23a5\u23a6\n\u239e\n\u239f\n\u239f\n\u239f\n\u23a0 by expanding along\nthe first row, we sum up \ud835\udc5b terms, each of which is the product of entries in \ud835\udc34 \u2212 \ud835\udf06\ud835\udc3c.\nSince each entry is either a constant or a linear term in the variable \ud835\udf06, and all products\npresent in the expanded determinant calculation contain \ud835\udc5b terms, we can infer that\ndet(\ud835\udc34 \u2212 \ud835\udf06\ud835\udc3c) is a polynomial in \ud835\udf06 of degree \ud835\udc5b. See Proposition 7.3.4 (Features of the\nCharacteristic Polynomial) for a more precise statement and justification.\nDefinition 7.2.2\nCharacteristic\nPolynomial and\nCharacteristic\nEquation\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) and \ud835\udf06 \u2208 F. The characteristic polynomial of \ud835\udc34, denoted by \ud835\udc36\ud835\udc34(\ud835\udf06), is\n\ud835\udc36\ud835\udc34(\ud835\udf06) = det(\ud835\udc34 \u2212 \ud835\udf06\ud835\udc3c).\nThe characteristic equation of \ud835\udc34 is\n\ud835\udc36\ud835\udc34(\ud835\udf06) = 0.\nREMARK\nThe eigenvalues of \ud835\udc34 over F are the roots of the characteristic polynomial of \ud835\udc34 in F.Section 7.2\nThe Characteristic Polynomial and Finding Eigenvalues\n171\nExample 7.2.3\nFind the eigenvalues of \ud835\udc34 =\n[\ufe021 2\n2 1\n]\ufe02\nover R.\nSolution: Since \ud835\udc34 \u2212 \ud835\udf06\ud835\udc3c =\n[\ufe021 \u2212 \ud835\udf06\n2\n2\n1 \u2212 \ud835\udf06\n]\ufe02\n, the characteristic polynomial of \ud835\udc34 is\n\ud835\udc36\ud835\udc34(\ud835\udf06) = det\n(\ufe02[\ufe021 \u2212 \ud835\udf06\n2\n2\n1 \u2212 \ud835\udf06\n]\ufe02)\ufe02\n= (1 \u2212 \ud835\udf06)2 \u2212 22 = \ud835\udf062 \u2212 2\ud835\udf06 \u2212 3\nand the characteristic equation of \ud835\udc34 is\n\ud835\udc36\ud835\udc34(\ud835\udf06) = \ud835\udf062 \u2212 2\ud835\udf06 \u2212 3 = (\ud835\udf06 \u2212 3)(\ud835\udf06 + 1) = 0.\nThe eigenvalues of \ud835\udc34 over R are the real roots of \ud835\udc36\ud835\udc34(\ud835\udf06), that is, \ud835\udf061 = 3 and \ud835\udf062 = \u22121.\nExample 7.2.4\nFind the eigenvalues of \ud835\udc35 =\n[\ufe020 \u22121\n1 0\n]\ufe02\nover R.\nSolution: Since \ud835\udc35 \u2212 \ud835\udf06\ud835\udc3c =\n[\ufe02\u2212\ud835\udf06 \u22121\n1 \u2212\ud835\udf06\n]\ufe02\n, the characteristic polynomial of \ud835\udc35 is\n\ud835\udc36\ud835\udc35(\ud835\udf06) = det\n(\ufe02[\ufe02\u2212\ud835\udf06 \u22121\n1 \u2212\ud835\udf06\n]\ufe02)\ufe02\n= \ud835\udf062 + 1\nand the characteristic equation of \ud835\udc35 is\n\ud835\udc36\ud835\udc35(\ud835\udf06) = \ud835\udf062 + 1 = 0.\nSince \ud835\udc36\ud835\udc35(\ud835\udf06) has no real roots, \ud835\udc35 has no eigenvalues and no eigenpairs over R.\nREMARK\nNote that we can interpret \ud835\udc35 geometrically by observing that\n[\ufe020 \u22121\n1 0\n]\ufe02\n=\n[\ufe02cos \ud835\udf03 \u2212 sin \ud835\udf03\nsin \ud835\udf03\ncos \ud835\udf03\n]\ufe02\nfor\n\ud835\udf03 = \ud835\udf0b\n2 .\nTherefore, from a geometric perspective, \ud835\udc35 is the matrix which performs a rotation by \ud835\udf0b\n2\nradians counter-clockwise. Since \ud835\udc35 #\u00bb\ud835\udc65 can never be a scalar multiple of a nonzero vector\n#\u00bb\ud835\udc65 \u2208 R2 (because the transformation will always change the vector\u2019s direction), it makes\nsense that \ud835\udc35 would have no real eigenvalues nor eigenvectors.\nExample 7.2.5\nKeeping \ud835\udc35 =\n[\ufe020 \u22121\n1 0\n]\ufe02\nfrom the previous example, find the eigenvalues of \ud835\udc35 over C.\nSolution: As in the previous example, \ud835\udc35 \u2212 \ud835\udf06\ud835\udc3c =\n[\ufe02\u2212\ud835\udf06 \u22121\n1 \u2212\ud835\udf06\n]\ufe02\nand\n\ud835\udc36\ud835\udc35(\ud835\udf06) = det\n(\ufe02[\ufe02\u2212\ud835\udf06 \u22121\n1 \u2212\ud835\udf06\n]\ufe02)\ufe02\n= \ud835\udf062 + 1.172\nChapter 7\nEigenvalues and Diagonalization\nWe can factor \ud835\udc36\ud835\udc35(\ud835\udf06) fully because we are now working in C; thus the characteristic equation\nof \ud835\udc35 is\n\ud835\udc36\ud835\udc35(\ud835\udf06) = \ud835\udf062 + 1 = (\ud835\udf06 \u2212 \ud835\udc56)(\ud835\udf06 + \ud835\udc56) = 0.\nThe complex roots of \ud835\udc36\ud835\udc35(\ud835\udf06) are the eigenvalues of \ud835\udc35 over C. Thus, \ud835\udf061 = \ud835\udc56 and \ud835\udf062 = \u2212\ud835\udc56.\nExample 7.2.6\nFind the eigenvalues of \ud835\udc3a =\n[\ufe023\ud835\udc56 \u22124\n2\n\ud835\udc56\n]\ufe02\nover C.\nSolution: Since \ud835\udc3a \u2212 \ud835\udf06\ud835\udc3c =\n[\ufe023\ud835\udc56 \u2212 \ud835\udf06\n\u22124\n2\n\ud835\udc56 \u2212 \ud835\udf06\n]\ufe02\n, the characteristic polynomial of \ud835\udc3a is\n\ud835\udc36\ud835\udc3a(\ud835\udf06) = det\n(\ufe02[\ufe023\ud835\udc56 \u2212 \ud835\udf06\n\u22124\n2\n\ud835\udc56 \u2212 \ud835\udf06\n]\ufe02)\ufe02\n= (3\ud835\udc56 \u2212 \ud835\udf06)(\ud835\udc56 \u2212 \ud835\udf06) + 8 = \ud835\udf062 \u2212 4\ud835\udc56\ud835\udf06 + 5\nand the characteristic equation is\n\ud835\udc36\ud835\udc3a(\ud835\udf06) = \ud835\udf062 \u2212 4\ud835\udc56\ud835\udf06 + 5 = (\ud835\udf06 \u2212 5\ud835\udc56)(\ud835\udf06 + \ud835\udc56) = 0.\nThe complex roots of \ud835\udc36\ud835\udc3a(\ud835\udf06) are the eigenvalues of \ud835\udc3a over C. Thus, \ud835\udf061 = 5\ud835\udc56 and \ud835\udf062 = \u2212\ud835\udc56.\nExample 7.2.7\nFind the eigenvalues of \ud835\udc3b =\n\u23a1\n\u23a3\n4\n2 \u22126\n1 \u22122 1\n\u22126 2\n4\n\u23a4\n\u23a6 over R.\nSolution: We find the characteristic polynomial of \ud835\udc3b by calculating the determinant of\n\ud835\udc3b \u2212 \ud835\udf06\ud835\udc3c =\n\u23a1\n\u23a3\n4 \u2212 \ud835\udf06\n2\n\u22126\n1\n\u22122 \u2212 \ud835\udf06\n1\n\u22126\n2\n4 \u2212 \ud835\udf06\n\u23a4\n\u23a6 , using an expansion along the first row:\n\ud835\udc36\ud835\udc3b(\ud835\udf06) = det\n\u239b\n\u239d\n\u23a1\n\u23a3\n4 \u2212 \ud835\udf06\n2\n\u22126\n1\n\u22122 \u2212 \ud835\udf06\n1\n\u22126\n2\n4 \u2212 \ud835\udf06\n\u23a4\n\u23a6\n\u239e\n\u23a0\n= (4 \u2212 \ud835\udf06)[(\u22122 \u2212 \ud835\udf06)(4 \u2212 \ud835\udf06) \u2212 2] \u2212 2[1(4 \u2212 \ud835\udf06) \u2212 1(\u22126)] \u2212 6[1(2) \u2212 (\u22122 \u2212 \ud835\udf06)(\u22126)]\n= \u2212\ud835\udf063 + 6\ud835\udf062 + 40\ud835\udf06.\nThe characteristic equation is\n\ud835\udc36\ud835\udc3b(\ud835\udf06) = \u2212\ud835\udf063 + 6\ud835\udf062 + 40\ud835\udf06 = \u2212\ud835\udf06(\ud835\udf062 \u2212 6\ud835\udf06 \u2212 40) = \u2212\ud835\udf06(\ud835\udf06 \u2212 10)(\ud835\udf06 + 4) = 0.\nThe real roots are the eigenvalues of \ud835\udc3b over R. Thus, \ud835\udf061 = 10, \ud835\udf062 = 0 and \ud835\udf063 = \u22124.\n7.3", "Properties of the Characteristic Polynomial\nThere is a lot of arithmetic involved in finding eigenpairs and it is wise to make sure that\nour characteristic polynomial is actually correct before we begin factoring it. This section\nexplores properties of the characteristic polynomial that will allow us to verify our work.\nWe begin with the following result.Section 7.3\nProperties of the Characteristic Polynomial\n173\nProposition 7.3.1\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F). Then \ud835\udc34 is invertible if and only if \ud835\udf06 = 0 is not an eigenvalue of \ud835\udc34.\nProof:\n\ud835\udc34 is invertible iff det(\ud835\udc34) \u0338= 0.\niff det(\ud835\udc34 \u2212 0 \ud835\udc3c\ud835\udc5b) \u0338= 0\niff 0 is not a root of the characteristic polynomial\niff 0 is not an eigenvalue of the matrix A.\nDefinition 7.3.2\nTrace\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F). We define the trace of \ud835\udc34 by\ntr(\ud835\udc34) =\n\ud835\udc5b\n\u2211\ufe01\n\ud835\udc56=1\n\ud835\udc4e\ud835\udc56\ud835\udc56.\nThat is, the trace of a square matrix is the sum of its diagonal entries.\nExample 7.3.3\nLet \ud835\udc34 =\n\u23a1\n\u23a3\n1 2 7\n3 4 \u22125\n4 0 6\n\u23a4\n\u23a6. Then tr(\ud835\udc34) = 1 + 4 + 6 = 11.\nProposition 7.3.4\n(Features of the Characteristic Polynomial)\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) have characteristic polynomial \ud835\udc36\ud835\udc34(\ud835\udf06) = det(\ud835\udc34 \u2212 \ud835\udf06\ud835\udc3c). Then \ud835\udc36\ud835\udc34(\ud835\udf06) is a\ndegree \ud835\udc5b polynomial in \ud835\udf06 of the form\n\ud835\udc36\ud835\udc34(\ud835\udf06) = \ud835\udc50\ud835\udc5b\ud835\udf06\ud835\udc5b + \ud835\udc50\ud835\udc5b\u22121\ud835\udf06(\ud835\udc5b\u22121) + \u00b7 \u00b7 \u00b7 + \ud835\udc501\ud835\udf06 + \ud835\udc500,\nwhere\n(a) \ud835\udc50\ud835\udc5b = (\u22121)\ud835\udc5b,\n(b) \ud835\udc50\ud835\udc5b\u22121 = (\u22121)(\ud835\udc5b\u22121) tr(\ud835\udc34), and\n(c) \ud835\udc500 = det(\ud835\udc34).\nProof: By performing cofactor expansion along the first row of \ud835\udc34 and along the first row\nof every subsequent (1, 1)-submatrix, we obtain an expression of the form\n\ud835\udc36\ud835\udc34(\ud835\udf06) = det(\ud835\udc34 \u2212 \ud835\udf06\ud835\udc3c) = (\ud835\udc4e11 \u2212 \ud835\udf06)(\ud835\udc4e22 \u2212 \ud835\udf06) \u00b7 \u00b7 \u00b7 (\ud835\udc4e\ud835\udc5b\ud835\udc5b \u2212 \ud835\udf06) + \ud835\udc53(\ud835\udf06),\nwhere \ud835\udc53 is the polynomial that is the sum of the other terms of the determinant. In the\nabove, we have singled out the contribution of the product of the diagonal entries, and have\ngrouped together all other terms. This latter grouping \ud835\udc53(\ud835\udf06) is a polynomial of degree at\nmost \ud835\udc5b \u2212 2. To see this, note that unless the cofactor calculation is done with respect to\na diagonal entry, it will use an entry (\ud835\udc56, \ud835\udc57) that corresponds to deleting the entry (\ud835\udc4e\ud835\udc56\ud835\udc56 \u2212 \ud835\udf06)174\nChapter 7\nEigenvalues and Diagonalization\nFigure 7.3.1: Visualization of taking the (1, 2)-submatrix of \ud835\udc34 \u2212 \ud835\udf06\ud835\udc3c\nfrom the \ud835\udc56\ud835\udc61\u210e row and the entry (\ud835\udc4e\ud835\udc57\ud835\udc57 \u2212 \ud835\udf06) from the \ud835\udc57\ud835\udc61\u210e column. This leaves us with at most\n\ud835\udc5b\u22122 entries that contain a \ud835\udf06. We illustrate this below using the (1, 2)-entry as an example.\nReturning to our expression for \ud835\udc36\ud835\udc34(\ud835\udf06), we can expand out the first term in the expression\nto obtain\n\ud835\udc36\ud835\udc34(\ud835\udf06) = \ud835\udc4e11 \u00b7 \u00b7 \u00b7 \ud835\udc4e\ud835\udc5b\ud835\udc5b + \u00b7 \u00b7 \u00b7 + (\u22121)\ud835\udc5b\u22121(\ud835\udc4e11 + \u00b7 \u00b7 \u00b7 + \ud835\udc4e\ud835\udc5b\ud835\udc5b)\ud835\udf06\ud835\udc5b\u22121 + (\u22121)\ud835\udc5b\ud835\udf06\ud835\udc5b + \ud835\udc53(\ud835\udf06).\nFrom this we see that \ud835\udc36\ud835\udc34(\ud835\udf06) is a polynomial of degree \ud835\udc5b in \ud835\udf06 (because we\u2019ve shown that this\ndegree is not exceeded by the polynomial \ud835\udc53, which is of degree at most \ud835\udc5b \u2212 2). Moreover,\nwe obtain the following results:\n(a) The coefficient of \ud835\udf06\ud835\udc5b is \ud835\udc50\ud835\udc5b = (\u22121)\ud835\udc5b.\n(b) The coefficient of \ud835\udf06\ud835\udc5b\u22121 is\n\ud835\udc50\ud835\udc5b\u22121 = (\u22121)\ud835\udc5b\u22121(\ud835\udc4e11 + \u00b7 \u00b7 \u00b7 + \ud835\udc4e\ud835\udc5b\ud835\udc5b) = (\u22121)\ud835\udc5b\u22121 tr(\ud835\udc34).\n(c) From the definition of \ud835\udc36\ud835\udc34(\ud835\udf06), we immediately have that the constant term is\n\ud835\udc500 = \ud835\udc36\ud835\udc34(0) = det(\ud835\udc34 \u2212 0\ud835\udc3c) = det(\ud835\udc34).\nExample 7.3.5\nDetermine the characteristic polynomial of \ud835\udc34 =\n\u23a1\n\u23a3\n1 2 3\n4 5 6\n7 8 10\n\u23a4\n\u23a6 and verify the properties outlined\nin Proposition 7.3.4 (Features of the Characteristic Polynomial).\nSolution: The characteristic polynomial of \ud835\udc34 is\n\ud835\udc36\ud835\udc34(\ud835\udf06) = det\n\u23a1\n\u23a3\n1 \u2212 \ud835\udf06\n2\n3\n4\n5 \u2212 \ud835\udf06\n6\n7\n8\n10 \u2212 \ud835\udf06\n\u23a4\n\u23a6\n= (1 \u2212 \ud835\udf06) [(5 \u2212 \ud835\udf06)(10 \u2212 \ud835\udf06) \u2212 48] \u2212 2 [4(10 \u2212 \ud835\udf06) \u2212 42] + 3 [32 \u2212 7(5 \u2212 \ud835\udf06)]\n= \u2212\ud835\udf063 + 16\ud835\udf062 + 12\ud835\udf06 \u2212 3.\nObserve that \ud835\udc36\ud835\udc34(\ud835\udf06) has degree 3, that tr(\ud835\udc34) = 1 + 5 + 10 = 16 and that det(\ud835\udc34) = \u22123 as\nwe determined in Example 6.1.8.\nWe now verify our calculation of \ud835\udc36\ud835\udc34(\ud835\udf06) using each part of Proposition 7.3.4 (Features of\nthe Characteristic Polynomial):Section 7.3\nProperties of the Characteristic Polynomial\n175\n(a) The coefficient of \ud835\udf063 is \ud835\udc503 = \u22121 = (\u22121)3.\n(b) The coefficient of \ud835\udf062 is \ud835\udc502 = 16 = (\u22121)2 tr(\ud835\udc34).\n(c) The constant term is \ud835\udc500 = \u22123 = det(\ud835\udc34).\nWe can now be more confident that our characteristic polynomial was computed correctly.\nNote that this does not prove that our calculation was correct; this is simply a nice check\nfor \u201cred flags\u201d.\nThe characteristic polynomial \ud835\udc36\ud835\udc34(\ud835\udf06) of an \ud835\udc5b \u00d7 \ud835\udc5b matrix \ud835\udc34 is a degree \ud835\udc5b polynomial. By\nthe Fundamental Theorem of Algebra, the characteristic polynomial \ud835\udc36\ud835\udc34(\ud835\udf06) is guaranteed\nto have \ud835\udc5b complex roots (though some may be repeated) as we assume F \u2286 C. Therefore,\n\ud835\udc34 is guaranteed to have \ud835\udc5b eigenvalues in C. Some of these eigenvalues may be repeated, in\nwhich case we list each eigenvalue as many times as its corresponding linear factor appears\nin the characteristic polynomial \ud835\udc36\ud835\udc34(\ud835\udf06); Example 7.3.12 will address the case of repeated\neigenvalues.\nThe following result establishes a connection between the characteristic polynomial of a\nmatrix and its \ud835\udc5b complex eigenvalues over C.\nProposition 7.3.6\n(Characteristic Polynomial and Eigenvalues over C)\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) have characteristic polynomial\n\ud835\udc36\ud835\udc34(\ud835\udf06) = \ud835\udc50\ud835\udc5b\ud835\udf06\ud835\udc5b + \ud835\udc50\ud835\udc5b\u22121\ud835\udf06\ud835\udc5b\u22121 + \u00b7 \u00b7 \u00b7 + \ud835\udc501\ud835\udf06 + \ud835\udc500,\nand \ud835\udc5b eigenvalues \ud835\udf061, \ud835\udf062, . . . , \ud835\udf06\ud835\udc5b (possibly repeated) in C. Then\n(a) \ud835\udc50\ud835\udc5b\u22121 = (\u22121)(\ud835\udc5b\u22121)\n\ud835\udc5b\n\u2211\ufe01\n\ud835\udc56=1\n\ud835\udf06\ud835\udc56, and\n(b) \ud835\udc500 =\n\ud835\udc5b\n\u220f\ufe01\n\ud835\udc56=1\n\ud835\udf06\ud835\udc56.\nNote that if \ud835\udc34 has repeated eigenvalues over C, then we include each eigenvalue in the list\n\ud835\udf061, \ud835\udf062, ..., \ud835\udf06\ud835\udc5b as many times as its corresponding linear factor appears in the characteristic\npolynomial \ud835\udc36\ud835\udc34(\ud835\udf06).\nProof: The eigenvalues of \ud835\udc34 over C are the \ud835\udc5b complex roots of the characteristic polyno-\nmial, so its characteristic polynomial has the form\n\ud835\udc36\ud835\udc34(\ud835\udf06) = \ud835\udc58(\ud835\udf06 \u2212 \ud835\udf061)(\ud835\udf06 \u2212 \ud835\udf062) \u00b7 \u00b7 \u00b7 (\ud835\udf06 \u2212 \ud835\udf06\ud835\udc5b) for some \ud835\udc58 \u2208 C.\nBy Parts (a) and (b) of Proposition 7.3.4 (Features of the Characteristic Polynomial), the\ncoefficient of \ud835\udf06\ud835\udc5b is\n\ud835\udc50\ud835\udc5b = (\u22121)\ud835\udc5b. It must be that \ud835\udc58 = (\u22121)\ud835\udc5b, so\n\ud835\udc36\ud835\udc34(\ud835\udf06) = (\u22121)\ud835\udc5b(\ud835\udf06 \u2212 \ud835\udf061)(\ud835\udf06 \u2212 \ud835\udf062) \u00b7 \u00b7 \u00b7 (\ud835\udf06 \u2212 \ud835\udf06\ud835\udc5b).176\nChapter 7\nEigenvalues and Diagonalization\n(a) Consider \ud835\udc50\ud835\udc5b\u22121, the coefficient of \ud835\udf06\ud835\udc5b\u22121 in \ud835\udc36\ud835\udc34(\ud835\udf06). By expanding out the expression for\n\ud835\udc36\ud835\udc34(\ud835\udf06), we find that there are \ud835\udc5b terms involving \ud835\udf06\ud835\udc5b\u22121, each of which is the product of\n(\u22121)\ud835\udc5b with one of the constants \u2212\ud835\udf061, \u2212\ud835\udf062, . . . , \u2212\ud835\udf06\ud835\udc5b and with \ud835\udf06 from each of the other\n\ud835\udc5b \u2212 1 linear factors. By taking the sum of these terms, we find that\n\ud835\udc50\ud835\udc5b\u22121\ud835\udf06\ud835\udc5b\u22121 = (\u22121)\ud835\udc5b[\u2212\ud835\udf061 (\ud835\udf06)\ud835\udc5b\u22121 \u2212 \ud835\udf062 (\ud835\udf06)\ud835\udc5b\u22121 \u2212 \u00b7 \u00b7 \u00b7 \u2212 \ud835\udf06\ud835\udc5b (\ud835\udf06)\ud835\udc5b\u22121]\n=\n(\ufe03\n(\u22121)(\ud835\udc5b\u22121)\n\ud835\udc5b\n\u2211\ufe01\n\ud835\udc56=1\n\ud835\udf06\ud835\udc56\n)\ufe03\n\ud835\udf06\ud835\udc5b\u22121\nthat is, \ud835\udc50\ud835\udc5b\u22121 = (\u22121)(\ud835\udc5b\u22121)\n\ud835\udc5b\n\u2211\ufe01\n\ud835\udc56=1\n\ud835\udf06\ud835\udc56.\n(b) Expanding the terms of \ud835\udc36\ud835\udc34(\ud835\udf06), its constant term must be (\u22121)\ud835\udc5b times the product\nof the constant terms in each of the \ud835\udc5b linear factors, which are \u2212\ud835\udf061, \u2212\ud835\udf062, . . . , \u2212\ud835\udf06\ud835\udc5b.\nTherefore,\n\ud835\udc500 = (\u22121)\ud835\udc5b\n\ud835\udc5b\n\u220f\ufe01\n\ud835\udc56=1\n(\u2212\ud835\udf06\ud835\udc56) = (\u22121)2\ud835\udc5b\n\ud835\udc5b\n\u220f\ufe01\n\ud835\udc56=1\n\ud835\udf06\ud835\udc56 =\n\ud835\udc5b\n\u220f\ufe01\n\ud835\udc56=1\n\ud835\udf06\ud835\udc56.\nPropositions 7.3.4 and 7.3.6 combine to form the following corollary, the proof of which we\nleave as an exercise.\nCorollary 7.3.7\n(Eigenvalues and Trace/Determinant)\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) have \ud835\udc5b eigenvalues \ud835\udf061, \ud835\udf062, . . . , \ud835\udf06\ud835\udc5b (possibly repeated) in C. Show that:\n(a)\n\ud835\udc5b\n\u2211\ufe01\n\ud835\udc56=1\n\ud835\udf06\ud835\udc56 = tr(\ud835\udc34).\n(b)\n\ud835\udc5b\n\u220f\ufe01\n\ud835\udc56=1\n\ud835\udf06\ud835\udc56 = det(\ud835\udc34).\nIn the following examples, we confirm our previous calculations using Proposition 7.3.6\n(Characteristic Polynomial and Eigenvalues over C).\nExample 7.3.8\nIn Example 7.2.5, the eigenvalues of \ud835\udc35 =\n[\ufe020 \u22121\n1 0\n]\ufe02\nover C are \ud835\udf061 = \ud835\udc56 and \ud835\udf062 = \u2212\ud835\udc56, and\n\ud835\udc36\ud835\udc35(\ud835\udf06) = \ud835\udf062 + 1 is a quadratic (degree 2) polynomial. Proposition 7.3.6 and Corollary 7.3.7\nconfirm that\n(a) the coefficient of \ud835\udf06 is (\u22121)1\n2\n\u2211\ufe01\n\ud835\udc56=1\n\ud835\udf06\ud835\udc56 = \u2212(\ud835\udf061 + \ud835\udf062) = \u2212(\ud835\udc56 \u2212 \ud835\udc56) = 0 = \ud835\udc501 and tr(\ud835\udc35) =\n\ud835\udf061 + \ud835\udf062 = 0.\n(b) the constant term is\n2\n\u220f\ufe01\n\ud835\udc56=1\n\ud835\udf06\ud835\udc56 = \ud835\udf061\ud835\udf062 = (\ud835\udc56)(\u2212\ud835\udc56) = \u2212\ud835\udc562 = 1 = \ud835\udc500 and 1 = det(\ud835\udc35).Section 7.3\nProperties of the Characteristic Polynomial\n177\nExample 7.3.9\nIn Example 7.2.6, the eigenvalues of \ud835\udc3a =\n[\ufe023\ud835\udc56 \u22124\n2\n\ud835\udc56\n]\ufe02\nover C are \ud835\udf061 = 5\ud835\udc56 and \ud835\udf062 = \u2212\ud835\udc56 and\n\ud835\udc36\ud835\udc3a(\ud835\udf06) = \ud835\udf062 \u22124\ud835\udc56\ud835\udf06+5 is a degree 2 polynomial. hyperref[prop:complex-eigenvals-coeffs-char-\npoly]Proposition 7.3.6 and Corollary 7.3.7 confirm that\n(a) the coefficient of \ud835\udf06 is (\u22121)1\n2\n\u2211\ufe01\n\ud835\udc56=1\n\ud835\udf06\ud835\udc56 = \u2212(\ud835\udf061 + \ud835\udf062) = \u2212(5\ud835\udc56 \u2212 \ud835\udc56) = \u2212(4\ud835\udc56) = \ud835\udc501 and tr(\ud835\udc3a) =\n\ud835\udf061 + \ud835\udf062 = 4\ud835\udc56.\n(b) the constant term is\n2\n\u220f\ufe01\n\ud835\udc56=1\n\ud835\udf06\ud835\udc56 = \ud835\udf061\ud835\udf062 = 5\ud835\udc56(\u2212\ud835\udc56) = 5 = \ud835\udc500 and 5 = det(\ud835\udc3a).\nIn the next two examples, we will look at the eigenvalues of a matrix \ud835\udc34 over R, which\nare the real roots of the characteristic polynomial. Since R is a subset of C, any real root\nof a polynomial can also be considered as a complex root of the polynomial; thus, any\nreal eigenvalue of a matrix \ud835\udc34 can be considered to be a complex eigenvalue. As a result,\nProposition 7.3.6 (Characteristic Polynomial and Eigenvalues over C) applies in these cases.\nExample 7.3.10\nIn Example 7.2.3, \ud835\udc34 =\n[\ufe021 2\n2 1\n]\ufe02\nhas a degree two characteristic polynomial\n\ud835\udc36\ud835\udc34(\ud835\udf06) = \ud835\udf062 \u2212 2\ud835\udf06 \u2212 3 = (\ud835\udf06 \u2212 3)(\ud835\udf06 + 1), with two real roots \ud835\udf061 = 3 and \ud835\udf062 = \u22121. These are\nthe eigenvalues of \ud835\udc34 over C (as well as over R). Proposition 7.3.6 confirms that\n(a) the coefficient of \ud835\udf06 is (\u22121)1\n2\n\u2211\ufe01\n\ud835\udc56=1\n\ud835\udf06\ud835\udc56 = \u2212(\ud835\udf061 + \ud835\udf062) = \u2212(3 \u2212 1) = \u22122 = \ud835\udc501.\n(b) the constant term is\n2\n\u220f\ufe01\n\ud835\udc56=1\n\ud835\udf06\ud835\udc56 = \ud835\udf061\ud835\udf062 = (3)(\u22121) = \u22123 = \ud835\udc500.\nBe careful to note that a matrix \ud835\udc34 can have both real and non-real eigenvalues. In applying\nProposition 7.3.6, we must use all of the eigenvalues of \ud835\udc34.\nExample 7.3.11\nThe characteristic polynomial of \ud835\udc3d =\n\u23a1\n\u23a3\n\u22124 0 0\n0\n0 4\n0 \u22124 0\n\u23a4\n\u23a6 is\n\ud835\udc36\ud835\udc3d(\ud835\udf06) = det\n\u239b\n\u239d\n\u23a1\n\u23a3\n\u22124 \u2212 \ud835\udf06 0\n0\n0\n\u2212\ud835\udf06 4\n0\n\u22124 \u2212\ud835\udf06\n\u23a4\n\u23a6\n\u239e\n\u23a0 = \u2212(\ud835\udf06 + 4)(\ud835\udf062 + 16) = \u2212\ud835\udf063 \u2212 4\ud835\udf062 \u2212 16\ud835\udf06 \u2212 64.\nIts degree is 3, and it has one real root \ud835\udf061 = \u22124 and two non-real complex roots \ud835\udf062 = 4\ud835\udc56\nand \ud835\udf063 = \u22124\ud835\udc56. These are the eigenvalues of \ud835\udc3d over C. Proposition 7.3.6 confirms that178\nChapter 7\nEigenvalues and Diagonalization\n(a) the coefficient of \ud835\udf062 is (\u22121)2\n3\n\u2211\ufe01\n\ud835\udc56=1\n\ud835\udf06\ud835\udc56 = \ud835\udf061 + \ud835\udf062 + \ud835\udf063 = \u22124 + 4\ud835\udc56 \u2212 4\ud835\udc56 = \u22124 = \ud835\udc502.\n(b) the constant term is\n3\n\u220f\ufe01\n\ud835\udc56=1\n\ud835\udf06\ud835\udc56 = \ud835\udf061\ud835\udf062\ud835\udf063 = (\u22124)(4\ud835\udc56)(\u22124\ud835\udc56) = \u221264 = \ud835\udc500.\nFor our following example, the characteristic polynomial includes a repeated linear factor.\nIn order to use Proposition 7.3.6 (Characteristic Polynomial and Eigenvalues over C), we\ninclude each eigenvalue in our list \ud835\udf061, \ud835\udf062, ..., \ud835\udf06\ud835\udc5b as many times as its corresponding linear\nfactor appears in the characteristic polynomial \ud835\udc36\ud835\udc34(\ud835\udf06). We will address this concept later\nin terms of multiplicity.\nExample 7.3.12\nThe characteristic polynomial of \ud835\udc4d =\n\u23a1\n\u23a3\n3 1 1\n1 3 1\n1 1 3\n\u23a4\n\u23a6 is\n\ud835\udc36\ud835\udc4d(\ud835\udf06) = det\n\u239b\n\u239d\n\u23a1\n\u23a3\n3 \u2212 \ud835\udf06\n1\n1\n1\n3 \u2212 \ud835\udf06\n1\n1\n1\n3 \u2212 \ud835\udf06\n\u23a4\n\u23a6\n\u239e\n\u23a0\n= (3 \u2212 \ud835\udf06)[(3 \u2212 \ud835\udf06)2 \u2212 1] \u2212 1[(3 \u2212 \ud835\udf06) \u2212 1] + 1[1 \u2212 (3 \u2212 \ud835\udf06)]\n= \u2212\ud835\udf063 + 9\ud835\udf062 \u2212 24\ud835\udf06 + 20\n= \u2212(\ud835\udf06 \u2212 5)(\ud835\udf06 \u2212 2)2.\nSince \ud835\udc5b = 3, we must carefully write down the three eigenvalues corresponding to the roots\nof \ud835\udc36\ud835\udc4d(\ud835\udf06), allowing repeats. Since the linear factor \ud835\udf06 \u2212 2 occurs twice in \ud835\udc36\ud835\udc4d(\ud835\udf06), we list the\neigenvalues as \ud835\udf061 = 5, \ud835\udf062 = 2, and \ud835\udf063 = 2. Proposition 7.3.6 confirms that\n(a) the coefficient of \ud835\udf062 is (\u22121)2\n3\n\u2211\ufe01\n\ud835\udc56=1\n\ud835\udf06\ud835\udc56 = \ud835\udf061 + \ud835\udf062 + \ud835\udf063 = 5 + 2 + 2 = 9 = \ud835\udc502.\n(b) the constant term is\n3\n\u220f\ufe01\n\ud835\udc56=1\n\ud835\udf06\ud835\udc56 = \ud835\udf061\ud835\udf062\ud835\udf063 = 5(2)(2) = 20 = \ud835\udc500.\n7.4", "Finding Eigenvectors\nOnce we have found an eigenvalue \ud835\udf06 of a matrix \ud835\udc34 over F, we can examine the eigenvalue\nequation in the form (\ud835\udc34 \u2212 \ud835\udf06\ud835\udc3c)#\u00bb\ud835\udc65 = #\u00bb0 in order to obtain a corresponding eigenvector #\u00bb\ud835\udc65.\nExample 7.4.1\nFor each eigenvalue of \ud835\udc34 =\n[\ufe021 2\n2 1\n]\ufe02\nover R, find a corresponding eigenpair.Section 7.4\nFinding Eigenvectors\n179\nSolution: From Example 7.2.3, the eigenvalues of \ud835\udc34 over R are \ud835\udf061 = 3 and \ud835\udf062 = \u22121.\nFor each eigenvalue \ud835\udf06\ud835\udc56, we examine the eigenvalue equation to determine an eigenvector.\n\u2022 When \ud835\udf061 = 3, we examine (\ud835\udc34 \u2212 3\ud835\udc3c)#\u00bb\ud835\udc65 = #\u00bb0 which is equivalent to\n[\ufe02\u22122 2\n2 \u22122\n]\ufe02 [\ufe02\ud835\udc651\n\ud835\udc652\n]\ufe02\n= #\u00bb0\nand row-reduces to\n[\ufe021 \u22121\n0 0\n]\ufe02 [\ufe02\ud835\udc651\n\ud835\udc652\n]\ufe02\n= #\u00bb0 .\nThe general solution is\n{\ufe02\n\ud835\udc60\n[\ufe021\n1\n]\ufe02\n: \ud835\udc60 \u2208 R\n}\ufe02\nand an eigenpair is\n(\ufe02\n3,\n[\ufe021\n1\n]\ufe02)\ufe02\n.\n\u2022 When \ud835\udf062 = \u22121, we examine (\ud835\udc34 \u2212 (\u22121)\ud835\udc3c)#\u00bb\ud835\udc65 = #\u00bb0 which is equivalent to\n[\ufe022 2\n2 2\n]\ufe02 [\ufe02\ud835\udc651\n\ud835\udc652\n]\ufe02\n= #\u00bb0\nand row-reduces to\n[\ufe021 1\n0 0\n]\ufe02 [\ufe02\ud835\udc651\n\ud835\udc652\n]\ufe02\n= #\u00bb0 .\nThe general solution is\n{\ufe02\n\ud835\udc61\n[\ufe02 1\n\u22121\n]\ufe02\n: \ud835\udc61 \u2208 R\n}\ufe02\nand an eigenpair is\n(\ufe02\n\u22121,\n[\ufe02 1\n\u22121\n]\ufe02)\ufe02\n.\nChecking these eigenpairs, we have that\n\ud835\udc34\n[\ufe021\n1\n]\ufe02\n=\n[\ufe021 2\n2 1\n]\ufe02 [\ufe021\n1\n]\ufe02\n=\n[\ufe023\n3\n]\ufe02\n= 3\n[\ufe021\n1\n]\ufe02\nand\n\ud835\udc34\n[\ufe02 1\n\u22121\n]\ufe02\n=\n[\ufe021 2\n2 1\n]\ufe02 [\ufe02 1\n\u22121\n]\ufe02\n=\n[\ufe02\u22121\n1\n]\ufe02\n= \u22121\n[\ufe02 1\n\u22121\n]\ufe02\n.\nREMARK\nWhile\n(\ufe02\n3,\n[\ufe021\n1\n]\ufe02)\ufe02\nis an eigenpair of \ud835\udc34, we can get other eigenpairs by pairing non-zero scalar\nmultiples of the eigenvector\n[\ufe021\n1\n]\ufe02\nwith the eigenvalue \ud835\udf06 = 3. For example,\n(\ufe02\n3,\n[\ufe022\n2\n]\ufe02)\ufe02\nand\n(\ufe02\n3,\n[\ufe02\u22124\n\u22124\n]\ufe02)\ufe02\nare eigenpairs of \ud835\udc34 over R, since\n\ud835\udc34\n[\ufe022\n2\n]\ufe02\n=\n[\ufe021 2\n2 1\n]\ufe02 [\ufe022\n2\n]\ufe02\n=\n[\ufe026\n6\n]\ufe02\n= 3\n[\ufe022\n2\n]\ufe02\nand\n\ud835\udc34\n[\ufe02\u22124\n\u22124\n]\ufe02\n=\n[\ufe021 2\n2 1\n]\ufe02 [\ufe02\u22124\n\u22124\n]\ufe02\n=\n[\ufe02\u221212\n\u221212\n]\ufe02\n= 3\n[\ufe02\u22124\n\u22124\n]\ufe02\n.180\nChapter 7\nEigenvalues and Diagonalization\nWe formalize this idea later in Proposition 7.5.1 (Linear Combinations of Eigenvectors).\nExample 7.4.2\nFor each eigenvalue of \ud835\udc35 =\n[\ufe020 \u22121\n1 0\n]\ufe02\nover C, find a corresponding eigenpair.\nSolution: From Example 7.2.4, the eigenvalues of \ud835\udc35 over C are \ud835\udf061 = \ud835\udc56 and \ud835\udf062 = \u2212\ud835\udc56.\nFor each eigenvalue \ud835\udf06\ud835\udc56, we examine the eigenvalue equation to determine an eigenvector.\n\u2022 When \ud835\udf061 = \ud835\udc56, we examine (\ud835\udc35 \u2212 \ud835\udc56\ud835\udc3c)#\u00bb\ud835\udc65 = #\u00bb0 which is equivalent to\n[\ufe02\u2212\ud835\udc56 \u22121\n1 \u2212\ud835\udc56\n]\ufe02 [\ufe02\ud835\udc651\n\ud835\udc652\n]\ufe02\n= #\u00bb0\nand row-reduces to\n[\ufe021 \u2212\ud835\udc56\n0 0\n]\ufe02 [\ufe02\ud835\udc651\n\ud835\udc652\n]\ufe02\n= #\u00bb0 .\nThe general solution is\n{\ufe02\n\ud835\udc60\n[\ufe02 \ud835\udc56\n1\n]\ufe02\n: \ud835\udc60 \u2208 C\n}\ufe02\nand an eigenpair is\n(\ufe02\n\ud835\udc56,\n[\ufe02 \ud835\udc56\n1\n]\ufe02)\ufe02\n.\n\u2022 When \ud835\udf062 = \u2212\ud835\udc56, we examine (\ud835\udc35 \u2212 (\u2212\ud835\udc56)\ud835\udc3c) #\u00bb\ud835\udc65 = #\u00bb0 which is equivalent to\n[\ufe02 \ud835\udc56 \u22121\n1\n\ud835\udc56\n]\ufe02 [\ufe02\ud835\udc651\n\ud835\udc652\n]\ufe02\n= #\u00bb0\nand row-reduces to\n[\ufe021 \ud835\udc56\n0 0\n]\ufe02 [\ufe02\ud835\udc651\n\ud835\udc652\n]\ufe02\n= #\u00bb0 .\nThe general solution is\n{\ufe02\n\ud835\udc61\n[\ufe02\u2212\ud835\udc56\n1\n]\ufe02\n: \ud835\udc61 \u2208 C\n}\ufe02\nand an eigenpair is\n(\ufe02\n\u2212\ud835\udc56,\n[\ufe02\u2212\ud835\udc56\n1\n]\ufe02)\ufe02\n.\nChecking these eigenpairs, we have that\n\ud835\udc35\n[\ufe02 \ud835\udc56\n1\n]\ufe02\n=\n[\ufe020 \u22121\n1 0\n]\ufe02 [\ufe02 \ud835\udc56\n1\n]\ufe02\n=\n[\ufe02\u22121\n\ud835\udc56\n]\ufe02\n= \ud835\udc56\n[\ufe02 \ud835\udc56\n1\n]\ufe02\nand\n\ud835\udc35\n[\ufe02\u2212\ud835\udc56\n1\n]\ufe02\n=\n[\ufe020 \u22121\n1 0\n]\ufe02 [\ufe02\u2212\ud835\udc56\n1\n]\ufe02\n=\n[\ufe02\u22121\n\u2212\ud835\udc56\n]\ufe02\n= \u2212\ud835\udc56\n[\ufe02\u2212\ud835\udc56\n1\n]\ufe02\n.\nExample 7.4.3\nFor each eigenvalue of \ud835\udc4d =\n\u23a1\n\u23a3\n3 1 1\n1 3 1\n1 1 3\n\u23a4\n\u23a6 over R, find a corresponding eigenpair.\nSolution: From Example 7.3.12, the characteristic polynomial of \ud835\udc4d is\n\ud835\udc36\ud835\udc4d(\ud835\udf06) = \u2212(\ud835\udf06 \u2212 5)(\ud835\udf06 \u2212 2)2. Therefore, the eigenvalues of \ud835\udc4d over R are \ud835\udf061 = 5, \ud835\udf062 = 2 and\n\ud835\udf063 = 2. (Note that the eigenvalue 2 occurs twice.)Section 7.5", "Eigenspaces\n181\nFor each eigenvalue \ud835\udf06\ud835\udc56, we examine the eigenvalue equation to determine an eigenvector.\n\u2022 When \ud835\udf061 = 5, we solve the system (\ud835\udc4d \u2212 5\ud835\udc3c)#\u00bb\ud835\udc65 = #\u00bb0 which is equivalent to\n\u23a1\n\u23a3\n\u22122 1\n1\n1 \u22122 1\n1\n1 \u22122\n\u23a4\n\u23a6\n\u23a1\n\u23a3\n\ud835\udc651\n\ud835\udc652\n\ud835\udc653\n\u23a4\n\u23a6 = #\u00bb0\nand row-reduces to\n\u23a1\n\u23a3\n1 0 \u22121\n0 1 \u22121\n0 0 0\n\u23a4\n\u23a6\n\u23a1\n\u23a3\n\ud835\udc651\n\ud835\udc652\n\ud835\udc653\n\u23a4\n\u23a6 = #\u00bb0 .\nThe solution set is\n\u23a7\n\u23a8\n\u23a9\ud835\udc60\n\u23a1\n\u23a3\n1\n1\n1\n\u23a4\n\u23a6 : \ud835\udc60 \u2208 R\n\u23ab\n\u23ac\n\u23ad and an eigenpair is\n\u239b\n\u239d5,\n\u23a1\n\u23a3\n1\n1\n1\n\u23a4\n\u23a6\n\u239e\n\u23a0 .\n\u2022 When \ud835\udf062 = 2, we solve the system (\ud835\udc4d \u2212 2\ud835\udc3c)#\u00bb\ud835\udc65 = #\u00bb0 which is equivalent to\n\u23a1\n\u23a3\n1 1 1\n1 1 1\n1 1 1\n\u23a4\n\u23a6\n\u23a1\n\u23a3\n\ud835\udc651\n\ud835\udc652\n\ud835\udc653\n\u23a4\n\u23a6 = #\u00bb0\nand row-reduces to\n\u23a1\n\u23a3\n1 1 1\n0 0 0\n0 0 0\n\u23a4\n\u23a6\n\u23a1\n\u23a3\n\ud835\udc651\n\ud835\udc652\n\ud835\udc653\n\u23a4\n\u23a6 = #\u00bb0 .\nThe solution set is\n\u23a7\n\u23a8\n\u23a9\ud835\udc61\n\u23a1\n\u23a3\n\u22121\n1\n0\n\u23a4\n\u23a6 + \ud835\udc62\n\u23a1\n\u23a3\n\u22121\n0\n1\n\u23a4\n\u23a6 : \ud835\udc61, \ud835\udc62 \u2208 R\n\u23ab\n\u23ac\n\u23ad and an eigenpair is\n\u239b\n\u239d2,\n\u23a1\n\u23a3\n\u22121\n1\n0\n\u23a4\n\u23a6\n\u239e\n\u23a0 .\n\u2022 No new computation is needed for \ud835\udf063 = 2. However, note that we can obtain another\neigenpair\n\u239b\n\u239d2,\n\u23a1\n\u23a3\n\u22121\n0\n1\n\u23a4\n\u23a6\n\u239e\n\u23a0 where the eigenvector\n\u23a1\n\u23a3\n\u22121\n0\n1\n\u23a4\n\u23a6 is not a scalar multiple of the\neigenvector\n\u23a1\n\u23a3\n\u22121\n1\n0\n\u23a4\n\u23a6 obtained in the previous step. We are able to do this because the\nsolution set to the eigenvalue equation has two parameters in it. This feature of the\nsolution set is related to the fact that the eigenvalue \ud835\udf062 = \ud835\udf063 = 2 is a repeated root\nof the characteristic polynomial. We will study this phenomenon in more detail later.\n7.5\nEigenspaces\nAfter Example 7.2.3, we noted that \ud835\udc34 =\n[\ufe021 2\n2 1\n]\ufe02\nhas an eigenpair\n(\ufe02\n3,\n[\ufe021\n1\n]\ufe02)\ufe02\n. By taking\nscalar multiples of the eigenvector\n[\ufe021\n1\n]\ufe02\n, we generated\n(\ufe02\n3,\n[\ufe022\n2\n]\ufe02)\ufe02\nand\n(\ufe02\n3,\n[\ufe02\u22124\n\u22124\n]\ufe02)\ufe02\nthat are182\nChapter 7\nEigenvalues and", "Section 7.6\nDiagonalization\n183\nExample 7.5.4\nIn Example 7.4.1, we found that\n(\ufe02\n3,\n[\ufe021\n1\n]\ufe02)\ufe02\nand\n(\ufe02\n\u22121,\n[\ufe02 1\n\u22121\n]\ufe02)\ufe02\nare eigenpairs of \ud835\udc34 =\n[\ufe021 2\n2 1\n]\ufe02\nover R. Our work in that Example in fact shows that the eigenspaces of \ud835\udc34 are\n\ud835\udc383 = Span\n{\ufe02[\ufe021\n1\n]\ufe02}\ufe02\nand \ud835\udc38\u22121 = Span\n{\ufe02[\ufe02 1\n\u22121\n]\ufe02}\ufe02\n.\nExample 7.5.5\nOur work in Example 7.4.2 shows that the eigenspaces of \ud835\udc35 =\n[\ufe020 \u22121\n1 0\n]\ufe02\nover C are\n\ud835\udc38\ud835\udc56 = Span\n{\ufe02[\ufe02 \ud835\udc56\n1\n]\ufe02}\ufe02\nand \ud835\udc38\u2212\ud835\udc56 = Span\n{\ufe02[\ufe02\u2212\ud835\udc56\n1\n]\ufe02}\ufe02\n.\nExample 7.5.6\nIn Example 7.4.3, the eigenspaces of \ud835\udc4d =\n\u23a1\n\u23a3\n3 1 1\n1 3 1\n1 1 3\n\u23a4\n\u23a6 over R are\n\ud835\udc385 =\n\u23a7\n\u23a8\n\u23a9\ud835\udc60\n\u23a1\n\u23a3\n1\n1\n1\n\u23a4\n\u23a6 : \ud835\udc60 \u2208 R\n\u23ab\n\u23ac\n\u23ad = Span\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n1\n1\n1\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad\nand\n\ud835\udc382 =\n\u23a7\n\u23a8\n\u23a9\ud835\udc61\n\u23a1\n\u23a3\n\u22121\n1\n0\n\u23a4\n\u23a6 + \ud835\udc62\n\u23a1\n\u23a3\n\u22121\n0\n1\n\u23a4\n\u23a6 : \ud835\udc61, \ud835\udc62 \u2208 R\n\u23ab\n\u23ac\n\u23ad = Span\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n\u22121\n1\n0\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n\u22121\n0\n1\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad .\n7.6\nDiagonalization\nIn this section we will demonstrate one practical use of eigenvalues and eigenvectors. (There\nare many more that you can learn about in your future courses!)\nIn certain applications of linear algebra, it is necessary to compute powers \ud835\udc34\ud835\udc58 of a square\nmatrix \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) efficiently. It would be ideal if we could compute \ud835\udc34\ud835\udc58 without first\nhaving to compute each of \ud835\udc342, \ud835\udc343, \ud835\udc344, . . . , \ud835\udc34\ud835\udc58\u22121. In some special situations, this is possible.\nFor instance, if \ud835\udc34 is a diagonal matrix, then computing \ud835\udc34\ud835\udc58 is particularly straightforward:\nsimply take the \ud835\udc58\ud835\udc61\u210e powers of the diagonal entries.\nEXERCISE\nProve that if \ud835\udc37 = diag(\ud835\udc511, . . . , \ud835\udc51\ud835\udc5b) \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F), then \ud835\udc37\ud835\udc58 = diag(\ud835\udc51\ud835\udc58\n1, . . . , \ud835\udc51\ud835\udc58\n\ud835\udc5b) for all \ud835\udc58 \u2208 N.\nAs the following example demonstrates, computing powers of a matrix \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) is\nsimpler not only when \ud835\udc34 is diagonal, but also when \ud835\udc34 is of the form \ud835\udc34 = \ud835\udc43\ud835\udc37\ud835\udc43 \u22121, where \ud835\udc43\nis invertible and \ud835\udc37 is diagonal.184\nChapter 7\nEigenvalues and Diagonalization\nExample 7.6.1\nConsider the matrices \ud835\udc43 =\n[\ufe021 1\n1 \u22121\n]\ufe02\nand \ud835\udc37 =\n[\ufe023 0\n0 \u22121\n]\ufe02\n.\n(Observe that \ud835\udc37 is a diagonal\nmatrix.) Let \ud835\udc34 = \ud835\udc43\ud835\udc37\ud835\udc43 \u22121 =\n[\ufe021 2\n2 1\n]\ufe02\n. Then,\n\ud835\udc342 = \ud835\udc34\ud835\udc34 = (\ud835\udc43\ud835\udc37\ud835\udc43 \u22121)(\ud835\udc43\ud835\udc37\ud835\udc43 \u22121) = \ud835\udc43\ud835\udc37(\ud835\udc43 \u22121\ud835\udc43)\ud835\udc37\ud835\udc43 \u22121 = \ud835\udc43\ud835\udc372\ud835\udc43 \u22121,\nand therefore\n\ud835\udc343 = \ud835\udc34\ud835\udc342 = (\ud835\udc43\ud835\udc37\ud835\udc43 \u22121)(\ud835\udc43\ud835\udc372\ud835\udc43 \u22121) = \ud835\udc43\ud835\udc373\ud835\udc43 \u22121.\nOne can show using induction (exercise: do this!) that we have the following general formula\nfor \ud835\udc34\ud835\udc58:\n\ud835\udc34\ud835\udc58 = \ud835\udc43\ud835\udc37\ud835\udc58\ud835\udc43 \u22121 for all \ud835\udc58 \u2208 N.\nNow, the key observation is: since \ud835\udc37 is a diagonal matrix, we have\n\ud835\udc37\ud835\udc58 =\n[\ufe023\ud835\udc58\n0\n0 (\u22121)\ud835\udc58\n]\ufe02\n.\nConsequently,\n\ud835\udc34\ud835\udc58 = \ud835\udc43\ud835\udc37\ud835\udc58\ud835\udc43 \u22121 =\n[\ufe021 1\n1 \u22121\n]\ufe02 [\ufe023\ud835\udc58\n0\n0 (\u22121)\ud835\udc58\n]\ufe02 [\ufe021 1\n1 \u22121\n]\ufe02\u22121\n=\n[\ufe021 1\n1 \u22121\n]\ufe02 [\ufe023\ud835\udc58\n0\n0 (\u22121)\ud835\udc58\n]\ufe02 [\ufe02 1\n2\n1\n2\n1\n2 \u2212 1\n2\n]\ufe02\n= 1\n2\n[\ufe023\ud835\udc58 + (\u22121)\ud835\udc58\n3\ud835\udc58 \u2212 (\u22121)\ud835\udc58\n3\ud835\udc58 \u2212 (\u22121)\ud835\udc58\n3\ud835\udc58 + (\u22121)\ud835\udc58\n]\ufe02\n.\nIn the previous Example, the relationship between \ud835\udc34 and \ud835\udc37 given by the equation\n\ud835\udc34 = \ud835\udc43\ud835\udc37\ud835\udc43 \u22121 made the computation of \ud835\udc34\ud835\udc58 a rather straightforward matter.\nWe shall\ngive such a relationship a name. Of course, the key problem is how to find such a pair of\nmatrices \ud835\udc43 and \ud835\udc37 given a matrix \ud835\udc34, if this is even possible. We will return to this problem\nshortly.\nDefinition 7.6.2\nSimilar\nLet \ud835\udc34, \ud835\udc35 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F). We say that \ud835\udc34 is similar to \ud835\udc35 over F if there exists an invertible\nmatrix \ud835\udc43 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) such that \ud835\udc34 = \ud835\udc43\ud835\udc35\ud835\udc43 \u22121.\nREMARKS\n\u2022 Notice that if \ud835\udc34 = \ud835\udc43\ud835\udc35\ud835\udc43 \u22121 then multiplying this equation on the left by \ud835\udc43 \u22121 and\non the right by \ud835\udc43 gives \ud835\udc43 \u22121\ud835\udc34\ud835\udc43 = \ud835\udc35, or equivalently, \ud835\udc44\ud835\udc34\ud835\udc44\u22121 = \ud835\udc35 where \ud835\udc44 = \ud835\udc43 \u22121.\nThus if \ud835\udc34 is similar to \ud835\udc35, then \ud835\udc35 is similar to \ud835\udc34 and we can just say that \ud835\udc34 and \ud835\udc35\nare similar to each other.Section 7.6\nDiagonalization\n185\n\u2022 The choice of \u201csimilar\u201d as terminology for the relationship in Definition 7.6.2 might\nseem strange at first sight. There is in fact good reason for this choice, as we will\nlater learn. (See the Remark on page 234.) In the Exercise below, you are asked to\nshow that similar matrices share a variety of features. Specifically, they have the same\ndeterminant, trace, eigenvalues and characteristic polynomial.\nExample 7.6.3\nExample 7.6.1 shows that \ud835\udc34 =\n[\ufe021 2\n2 1\n]\ufe02\nis similar to \ud835\udc37 =\n[\ufe023 0\n0 \u22121\n]\ufe02\nover R.\nExample 7.6.4\nLet \ud835\udc34 =\n[\ufe021 2\n3 4\n]\ufe02\n. Consider \ud835\udc43 =\n[\ufe021 2\n4 6\n]\ufe02\n, with \ud835\udc43 \u22121 = \u22121\n2\n[\ufe02 6 \u22122\n\u22124 1\n]\ufe02\n, and let\n\ud835\udc35 = \ud835\udc43 \u22121\ud835\udc34\ud835\udc43 =\n[\ufe021 2\n4 6\n]\ufe02\u22121 [\ufe021 2\n3 4\n]\ufe02 [\ufe021 2\n4 6\n]\ufe02\n= 1\n2\n[\ufe02 16\n24\n\u221217 \u221226\n]\ufe02\n.\nThen \ud835\udc34 =\n[\ufe021 2\n3 4\n]\ufe02\nis similar to \ud835\udc35 = 1\n2\n[\ufe02 16\n24\n\u221217 \u221226\n]\ufe02\nover R.\nEXERCISE\nLet \ud835\udc34, \ud835\udc35, \ud835\udc36 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F). Show that:\n(a) \ud835\udc34 is similar to \ud835\udc34 over F.\n(b) If \ud835\udc34 is similar to \ud835\udc35 over F and \ud835\udc35 is similar to \ud835\udc36 over F, then \ud835\udc34 is similar to \ud835\udc36 over F.\nEXERCISE\nLet \ud835\udc34, \ud835\udc35 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F). Show that if \ud835\udc34 is similar to \ud835\udc35 over F, then:\n(a) For all \ud835\udc58 \u2208 N, \ud835\udc34\ud835\udc58 is similar to \ud835\udc35\ud835\udc58 over F.\n(b) \ud835\udc36\ud835\udc34(\ud835\udf06) = \ud835\udc36\ud835\udc35(\ud835\udf06).\n(c) \ud835\udc34 and \ud835\udc35 have the same eigenvalues.\n(d) tr(\ud835\udc34) = tr(\ud835\udc35) and det(\ud835\udc34) = det(\ud835\udc35).\nLet us return to the problem of computing \ud835\udc34\ud835\udc58. In view of Example 7.6.1, the problem\nbecomes much easier if we can show that \ud835\udc34 is similar to a diagonal matrix \ud835\udc37. We will\nsingle out such matrices.186\nChapter 7\nEigenvalues and Diagonalization\nDefinition 7.6.5\nDiagonalizable\nMatrix\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F). We say that \ud835\udc34 is diagonalizable over F if it is similar over F to a\ndiagonal matrix \ud835\udc37 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F); that is, if there exists an invertible matrix \ud835\udc43 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F)\nsuch that \ud835\udc43 \u22121\ud835\udc34\ud835\udc43 = \ud835\udc37. We say that the matrix \ud835\udc43 diagonalizes \ud835\udc34.\nREMARKS\n\u2022 Although we have motivated the above Definition by considering the problem of com-\nputing powers of matrices, the notion of diagonalizablity is fundamental for several\nother reasons, both theoretical and practical. We will see some of them in due course.\n\u2022 It is important to pay attention to what field F we are working over. It is possible\nfor a matrix \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(R) to be diagonalizable over C but not over R. (See Example\n9.4.1.)\nExample 7.6.6\nExample 7.6.1 shows that \ud835\udc34 =\n[\ufe021 2\n2 1\n]\ufe02\nis diagonalizable over R.\nThe problem we must now address is: determine if a given matrix \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) is diago-\nnalizable over F, and if it is, find the matrix \ud835\udc43 that diagonalizes it.\nWe will eventually be able to completely solve this problem. For now, we will give a partial\nsolution.\nProposition 7.6.7\n(\ud835\udc5b Distinct Eigenvalues =\u21d2 Diagonalizable)\nIf \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) has \ud835\udc5b distinct eigenvalues \ud835\udf061, \ud835\udf062, . . . , \ud835\udf06\ud835\udc5b in F, then \ud835\udc34 is diagonalizable over\nF.\nMore specifically, if we let (\ud835\udf061, #\u00bb\n\ud835\udc631), (\ud835\udf062, #\u00bb\n\ud835\udc632), . . . , (\ud835\udf06\ud835\udc5b, # \u00bb\n\ud835\udc63\ud835\udc5b) be eigenpairs of \ud835\udc34 over F, and if we\nlet \ud835\udc43 = [#\u00bb\n\ud835\udc631 #\u00bb\n\ud835\udc632 \u00b7 \u00b7 \u00b7 # \u00bb\n\ud835\udc63\ud835\udc5b] be the matrix whose columns are eigenvectors corresponding to the\ndistinct eigenvalues, then\n(a) \ud835\udc43 is invertible, and\n(b) \ud835\udc43 \u22121\ud835\udc34\ud835\udc43 = \ud835\udc37 = diag(\ud835\udf061, \ud835\udf062, \u00b7 \u00b7 \u00b7 , \ud835\udf06\ud835\udc5b).\nREMARKS\n\u2022 WARNING: The converse of the above Proposition is false. That is, if \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F)\nis diagonalizable over F, then it is not necessarily true that \ud835\udc34 has \ud835\udc5b distinct eigenval-\nues. Consider, for instance, \ud835\udcaa2\u00d72 = diag(0, 0) which is diagonalizable (it is diagonal!)\nwith two repeated eigenvalues \ud835\udf061 = \ud835\udf062 = 0.Section 7.6\nDiagonalization\n187\n\u2022 We will generalize this result in Chapter 9, and we will address precisely what happens\nwhen \ud835\udc34 does not have \ud835\udc5b distinct eigenvalues. We will prove the generalized result at\nthat time. (See page 242 for the proof of Proposition 7.6.7.)\n\u2022 Notice that the columns of \ud835\udc43 are eigenvectors of \ud835\udc34 and the diagonal entries of \ud835\udc37\nare eigenvalues of \ud835\udc34. Moreover, the order of the eigenvalues down the diagonal of\n\ud835\udc37 corresponds to the order the eigenvectors occur as columns in \ud835\udc43. That is, the\n\ud835\udc56\ud835\udc61\u210e diagonal entry in \ud835\udc37 is the eigenvalue corresponding to the \ud835\udc56\ud835\udc61\u210e column of \ud835\udc43. The\nProposition remains true if we list the eigenvectors as columns in \ud835\udc43 in any order we\nwant, provided we adjust the diagonal entries of \ud835\udc37 accordingly.\nAlthough we do not have a general proof of Proposition 7.6.7 at this time, we can directly\nverify that it works in specific examples as we illustrate below.\nExample 7.6.8\nFrom Example 7.4.1, \ud835\udc34 =\n[\ufe021 2\n2 1\n]\ufe02\nhas eigenpairs\n(\ufe02\n3,\n[\ufe021\n1\n]\ufe02)\ufe02\nand\n(\ufe02\n\u22121,\n[\ufe02 1\n\u22121\n]\ufe02)\ufe02\nover R.\nWe construct \ud835\udc43 =\n[\ufe021 1\n1 \u22121\n]\ufe02\nfrom the eigenvectors, with inverse \ud835\udc43 \u22121 = \u2212 1\n2\n[\ufe02\u22121 \u22121\n\u22121 1\n]\ufe02\n.\nNow, if we compute\n\ud835\udc37 = \ud835\udc43 \u22121\ud835\udc34\ud835\udc43 = \u22121\n2\n[\ufe02\u22121 \u22121\n\u22121 1\n]\ufe02 [\ufe021 2\n2 1\n]\ufe02 [\ufe021 1\n1 \u22121\n]\ufe02\n= \u22121\n2\n[\ufe02\u22121 \u22121\n\u22121 1\n]\ufe02 [\ufe023 \u22121\n3 1\n]\ufe02\n=\n[\ufe023 0\n0 \u22121\n]\ufe02\n= diag(3, \u22121),\nwe find that it is a diagonal matrix whose diagonal entries are the eigenvalues of \ud835\udc34, exactly\nas asserted by Proposition 7.6.7.\nExample 7.6.9\nFrom Example 7.4.2, \ud835\udc35 =\n[\ufe020 \u22121\n1 0\n]\ufe02\nhas eigenpairs\n(\ufe02\n\ud835\udc56,\n[\ufe02 \ud835\udc56\n1\n]\ufe02)\ufe02\nand\n(\ufe02\n\u2212\ud835\udc56,\n[\ufe02\u2212\ud835\udc56\n1\n]\ufe02)\ufe02\nover C. We\nconstruct \ud835\udc43 =\n[\ufe02 \ud835\udc56 \u2212\ud835\udc56\n1 1\n]\ufe02\nfrom the eigenvectors, with inverse \ud835\udc43 \u22121 = 1\n2\n[\ufe02\u2212\ud835\udc56 1\n\ud835\udc56 1\n]\ufe02\n.\nThen\n\ud835\udc37 = \ud835\udc43 \u22121\ud835\udc35\ud835\udc43\n= 1\n2\n[\ufe02\u2212\ud835\udc56 1\n\ud835\udc56 1\n]\ufe02 [\ufe020 \u22121\n1 0\n]\ufe02 [\ufe02 \ud835\udc56 \u2212\ud835\udc56\n1 1\n]\ufe02\n= 1\n2\n[\ufe02\u2212\ud835\udc56 1\n\ud835\udc56 1\n]\ufe02 [\ufe02\u22121 \u22121\n\ud835\udc56\n\u2212\ud835\udc56\n]\ufe02\n=\n[\ufe02 \ud835\udc56 0\n0 \u2212\ud835\udc56\n]\ufe02188\nChapter 7\nEigenvalues and Diagonalization\n= diag(\ud835\udc56, \u2212\ud835\udc56).\nExample 7.6.10\nFrom Example 7.2.7, \ud835\udc3b =\n\u23a1\n\u23a3\n4\n2 \u22126\n1 \u22122 1\n\u22126 2\n4\n\u23a4\n\u23a6 has eigenalues \ud835\udf061 = 10, \ud835\udf062 = 0 and \ud835\udf063 = \u22124.\nWe leave it as an exercise to verify that\n\u239b\n\u239d10,\n\u23a1\n\u23a3\n1\n0\n\u22121\n\u23a4\n\u23a6\n\u239e\n\u23a0 ,\n\u239b\n\u239d0,\n\u23a1\n\u23a3\n1\n1\n1\n\u23a4\n\u23a6\n\u239e\n\u23a0 and\n\u239b\n\u239d\u22124,\n\u23a1\n\u23a3\n1\n\u22121\n1\n\u23a4\n\u23a6\n\u239e\n\u23a0 are\neigenpairs over R.\nWe construct \ud835\udc43 =\n\u23a1\n\u23a3\n1 1 1\n0 1 \u22121\n\u22121 1 1\n\u23a4\n\u23a6 from the eigenvectors, with inverse\n\ud835\udc43 \u22121 = 1\n4\n\u23a1\n\u23a3\n2 0 \u22122\n1 2\n1\n1 \u22122 1\n\u23a4\n\u23a6 .\nThen\n\ud835\udc37 = \ud835\udc43 \u22121\ud835\udc3b\ud835\udc43 = 1\n4\n\u23a1\n\u23a3\n2 0 \u22122\n1 2\n1\n1 \u22122 1\n\u23a4\n\u23a6\n\u23a1\n\u23a3\n4\n2 \u22126\n1 \u22122 1\n\u22126 2\n4\n\u23a4\n\u23a6\n\u23a1\n\u23a3\n1 1 1\n0 1 \u22121\n\u22121 1 1\n\u23a4\n\u23a6\n= 1\n4\n\u23a1\n\u23a3\n2 0 \u22122\n1 2\n1\n1 \u22122 1\n\u23a4\n\u23a6\n\u23a1\n\u23a3\n10 0 \u22124\n0\n0 4\n\u221210 0 \u22124\n\u23a4\n\u23a6\n=\n\u23a1\n\u23a3\n10 0 0\n0 0 0\n0 0 \u22124\n\u23a4\n\u23a6\n= diag(10, 0, \u22124).\nEXERCISE\nThe matrix \ud835\udc34 =\n\u23a1\n\u23a3\n3 \u22125 0\n2 \u22123 0\n\u22122 3 \u22121\n\u23a4\n\u23a6 has the following eigenpairs:\n\u239b\n\u239d\u22121,\n\u23a1\n\u23a3\n0\n0\n1\n\u23a4\n\u23a6\n\u239e\n\u23a0 ,\n\u239b\n\u239d\ud835\udc56,\n\u23a1\n\u23a3\n2 \u2212 \ud835\udc56\n1 \u2212 \ud835\udc56\n\u22121\n\u23a4\n\u23a6\n\u239e\n\u23a0 , and\n\u239b\n\u239d\u2212\ud835\udc56,\n\u23a1\n\u23a3\n2 + \ud835\udc56\n1 + \ud835\udc56\n\u22121\n\u23a4\n\u23a6\n\u239e\n\u23a0 .\nFind an invertible matrix \ud835\udc43 and a diagonal matrix \ud835\udc37 such that \ud835\udc34 = \ud835\udc43\ud835\udc37\ud835\udc43 \u22121.\nWe close this Chapter with an example of a quick computation of powers of a diagonalizable\nmatrix.Section 7.6\nDiagonalization\n189\nExample 7.6.11\nLet \ud835\udc3b =\n\u23a1\n\u23a3\n4\n2 \u22126\n1 \u22122 1\n\u22126 2\n4\n\u23a4\n\u23a6. Find \ud835\udc3b10.\nSolution:\nIn the previous Example we found matrices \ud835\udc43 and \ud835\udc37 so that \ud835\udc3b = \ud835\udc43\ud835\udc37\ud835\udc43 \u22121. By what we\nhave learned from Example 7.6.1 (see also the Exercise below), we find that for all \ud835\udc58 \u2208 N\n\ud835\udc3b\ud835\udc58 = (\ud835\udc43\ud835\udc37\ud835\udc43 \u22121)\ud835\udc58 = \ud835\udc43\ud835\udc37\ud835\udc58\ud835\udc43 \u22121\n=\n\u23a1\n\u23a3\n1 1 1\n0 1 \u22121\n\u22121 1 1\n\u23a4\n\u23a6\n\u23a1\n\u23a3\n10 0 0\n0 0 0\n0 0 \u22124\n\u23a4\n\u23a6\n\ud835\udc58\n1\n4\n\u23a1\n\u23a3\n2 0 \u22122\n1 2\n1\n1 \u22122 1\n\u23a4\n\u23a6\n=\n\u23a1\n\u23a3\n1 1 1\n0 1 \u22121\n\u22121 1 1\n\u23a4\n\u23a6\n\u23a1\n\u23a3\n10\ud835\udc58 0\n0\n0\n0\ud835\udc58\n0\n0\n0 (\u22124)\ud835\udc58\n\u23a4\n\u23a6 1\n4\n\u23a1\n\u23a3\n2 0 \u22122\n1 2\n1\n1 \u22122 1\n\u23a4\n\u23a6\n= 1\n4\n\u23a1\n\u23a3\n2 \u00b7 10\ud835\udc58 + (\u22124)\ud835\udc58\n\u22122(\u22124)\ud835\udc58\n\u22122(10\ud835\udc58)\n\u2212(\u22124)\ud835\udc58\n2(\u22124)\ud835\udc58\n\u2212(\u22124)\ud835\udc58\n\u22122(10\ud835\udc58) + (\u22124)\ud835\udc58\n\u22122(\u22124)\ud835\udc58\n2(10\ud835\udc58) + (\u22124)\ud835\udc58\n\u23a4\n\u23a6 .\nIf we plug in \ud835\udc58 = 10 and simplify, we arrive at\n\ud835\udc3b10 = 512\n\u23a1\n\u23a3\n9766137 \u22121024 \u2212976513\n\u2212512\n1024\n\u2212512\n\u22129765113 \u22121024 9766137\n\u23a4\n\u23a6 .Chapter 8", "Subspaces and Bases\n8.1\nSubspaces\nThroughout this course we have been dealing with a variety of subsets of F\ud835\udc5b\u2014for example,\nsolutions sets of systems of equations, lines and planes in R3, and ranges of linear trans-\nformations. Many of these subsets have a special structure that makes them particularly\ninteresting from the point of view of linear algebra.\nThe next definition identifies the key features of this structure.\nDefinition 8.1.1\nSubspace\nA subset \ud835\udc49 of F\ud835\udc5b is called a subspace of F\ud835\udc5b if the following properties are all satisfied.\n1. #\u00bb0 \u2208 \ud835\udc49 .\n2. For all #\u00bb\ud835\udc65, #\u00bb\ud835\udc66 \u2208 \ud835\udc49, #\u00bb\ud835\udc65 + #\u00bb\ud835\udc66 \u2208 \ud835\udc49 (closure under addition).\n3. For all #\u00bb\ud835\udc65 \u2208 \ud835\udc49 and \ud835\udc50 \u2208 F, \ud835\udc50#\u00bb\ud835\udc65 \u2208 \ud835\udc49 (closure under scalar multiplication).\nHere are some important examples of subspaces.\nProposition 8.1.2\n(Examples of Subspaces)\n(a) {#\u00bb0 } and F\ud835\udc5b are subspaces of F\ud835\udc5b.\n(b) If {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58} is a subset of F\ud835\udc5b, then Span{#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58} is a subspace of F\ud835\udc5b.\n(c) If \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F), then the solution set to the homogeneous system \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb0 is a\nsubspace of F\ud835\udc5b. (Equivalently, Null(\ud835\udc34) is a subspace of F\ud835\udc5b.)\nProof: (a) This is immediate from the definition.\n190Section 8.1\nSubspaces\n191\n(b) We have #\u00bb0 = 0#\u00bb\n\ud835\udc631 + \u00b7 \u00b7 \u00b7 + 0#\u00bb\n\ud835\udc63\ud835\udc58, so #\u00bb0 \u2208 Span{#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58}.\nNext, we consider #\u00bb\ud835\udc65, #\u00bb\ud835\udc66 \u2208 Span{#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58} and \ud835\udc50 \u2208 F. Then there exist scalars\n\ud835\udc4e1, \ud835\udc4e2, . . . , \ud835\udc4e\ud835\udc58 \u2208 F such that #\u00bb\ud835\udc65 = \ud835\udc4e1 #\u00bb\n\ud835\udc631 + \ud835\udc4e2 #\u00bb\n\ud835\udc632 + \u00b7 \u00b7 \u00b7 + \ud835\udc4e\ud835\udc58 #\u00bb\n\ud835\udc63\ud835\udc58, and there exist scalars\n\ud835\udc4f1, \ud835\udc4f2, . . . , \ud835\udc4f\ud835\udc58 \u2208 F such that #\u00bb\ud835\udc66 = \ud835\udc4f1 #\u00bb\n\ud835\udc631 + \ud835\udc4f2 #\u00bb\n\ud835\udc632 + . . . + \ud835\udc4f\ud835\udc58 #\u00bb\n\ud835\udc63\ud835\udc58. We have\n#\u00bb\ud835\udc65 + #\u00bb\ud835\udc66 = (\ud835\udc4e1 #\u00bb\n\ud835\udc631 + \ud835\udc4e2 #\u00bb\n\ud835\udc632 + \u00b7 \u00b7 \u00b7 + \ud835\udc4e\ud835\udc58 #\u00bb\n\ud835\udc63\ud835\udc58) + (\ud835\udc4f1 #\u00bb\n\ud835\udc631 + \ud835\udc4f2 #\u00bb\n\ud835\udc632 + \u00b7 \u00b7 \u00b7 + \ud835\udc4f\ud835\udc58 #\u00bb\n\ud835\udc63\ud835\udc58)\n= (\ud835\udc4e1 + \ud835\udc4f1)#\u00bb\n\ud835\udc631 + (\ud835\udc4e2 + \ud835\udc4f2)#\u00bb\n\ud835\udc632 + \u00b7 \u00b7 \u00b7 + (\ud835\udc4e\ud835\udc58 + \ud835\udc4f\ud835\udc58)#\u00bb\n\ud835\udc63\ud835\udc58.\nThis shows that #\u00bb\ud835\udc65 + #\u00bb\ud835\udc66 is an element of Span{#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58}. Similarly, since\n\ud835\udc50#\u00bb\ud835\udc65 = \ud835\udc50(\ud835\udc4e1 #\u00bb\n\ud835\udc631 + \ud835\udc4e2 #\u00bb\n\ud835\udc632 + \u00b7 \u00b7 \u00b7 + \ud835\udc4e\ud835\udc58 #\u00bb\n\ud835\udc63\ud835\udc58) = \ud835\udc50\ud835\udc4e1 #\u00bb\n\ud835\udc631 + \ud835\udc50\ud835\udc4e2 #\u00bb\n\ud835\udc632 + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc4e\ud835\udc58 #\u00bb\n\ud835\udc63\ud835\udc58\nwe also have that \ud835\udc50#\u00bb\ud835\udc65 \u2208 Span{#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58}. This proves that Span{#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58} is a\nsubspace of F\ud835\udc5b.\n(c) Let \ud835\udc46 = {#\u00bb\ud835\udc65 \u2208 F\ud835\udc5b : \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb0 }. We must show that \ud835\udc46 is a subspace of F\ud835\udc5b. As \ud835\udc34#\u00bb0 = #\u00bb0 ,\nwe know that #\u00bb0 \u2208 \ud835\udc46. Next, let #\u00bb\ud835\udc65, #\u00bb\ud835\udc66 \u2208 \ud835\udc46 and \ud835\udc50 \u2208 F. Then since\n\ud835\udc34(#\u00bb\ud835\udc65 + #\u00bb\ud835\udc66 ) = \ud835\udc34#\u00bb\ud835\udc65 + \ud835\udc34#\u00bb\ud835\udc66 = #\u00bb0 + #\u00bb0 = #\u00bb0 ,\nwe have that #\u00bb\ud835\udc65 + #\u00bb\ud835\udc66 \u2208 \ud835\udc46. And since \ud835\udc34(\ud835\udc50#\u00bb\ud835\udc65) = \ud835\udc50(\ud835\udc34#\u00bb\ud835\udc65) = \ud835\udc50#\u00bb0 = #\u00bb0 , we have that \ud835\udc50#\u00bb\ud835\udc65 \u2208 \ud835\udc46.\nThis proves that \ud835\udc46 is a subspace of F\ud835\udc5b.\nMany commonly encountered sets in linear algebra can be shown to be subspaces by realizing\nthat they are either of the form Span \ud835\udc46, for some finite subset \ud835\udc46 of F\ud835\udc5b, or realizing that\nthey are the solution set of a homogeneous linear system of equations, and then appealing\nto Proposition 8.1.2 above. Here are some key examples of this.\nProposition 8.1.3\n(More Examples of Subspaces)\n(a) If \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F), then Col(\ud835\udc34) is a subspace of F\ud835\udc5a.\n(b) If \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5a is a linear transformation, then the range of \ud835\udc47, Range(\ud835\udc47), is a subspace\nof F\ud835\udc5a.\n(c) If \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5a is a linear transformation, then the kernel of \ud835\udc47, Ker(\ud835\udc47), is a subspace\nof F\ud835\udc5b.\n(d) If \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) and if \ud835\udf06 \u2208 F, then the eigenspace \ud835\udc38\ud835\udf06 is a subspace of F\ud835\udc5b.\nProof: (a) Col(\ud835\udc34) = Span{#\u00bb\n\ud835\udc4e1, #\u00bb\n\ud835\udc4e2, . . . , # \u00bb\n\ud835\udc4e\ud835\udc5b}, where #\u00bb\n\ud835\udc4e\ud835\udc56 is the \ud835\udc56\ud835\udc61\u210e column of \ud835\udc34, so this is a\nspecial case of Proposition 8.1.2 (b).\n(b) Range(\ud835\udc47) = Col([\ud835\udc47]\u2130), so this is a special case of Part (a).\n(c) Null(\ud835\udc47) is equal to the solution set of the homogeneous linear system [\ud835\udc47]\u2130 #\u00bb\ud835\udc65 = #\u00bb0 , so\nthis follows from Proposition 8.1.2 (c).192\nChapter 8\nSubspaces and Bases\n(d) \ud835\udc38\ud835\udf06 is the solution set of the homogeneous system (\ud835\udc34 \u2212 \ud835\udf06\ud835\udc3c)#\u00bb\ud835\udc65 = #\u00bb0 , so this is a special\ncase of Proposition 8.1.2 (c).\nThe following proposition can simplify the process needed to check if a subset of F\ud835\udc5b is a\nsubspace.\nProposition 8.1.4\n(Subspace Test)\nLet \ud835\udc49 be a subset of F\ud835\udc5b. Then \ud835\udc49 is a subspace of F\ud835\udc5b if and only if\n(a) \ud835\udc49 is non-empty, and\n(b) for all #\u00bb\ud835\udc65, #\u00bb\ud835\udc66 \u2208 \ud835\udc49 and \ud835\udc50 \u2208 F, \ud835\udc50 #\u00bb\ud835\udc65 + #\u00bb\ud835\udc66 \u2208 \ud835\udc49 .\nProof: (\u21d2):\nAssume \ud835\udc49 is a subspace of F\ud835\udc5b. Then #\u00bb0 \u2208 \ud835\udc49 , so \ud835\udc49 is non-empty. Also for all #\u00bb\ud835\udc65 \u2208 \ud835\udc49 and\n\ud835\udc50 \u2208 F, \ud835\udc50 #\u00bb\ud835\udc65 \u2208 \ud835\udc49 , since \ud835\udc49 is closed under scalar multiplication. But then, for all #\u00bb\ud835\udc66 \u2208 \ud835\udc49 ,\n\ud835\udc50#\u00bb\ud835\udc65 + #\u00bb\ud835\udc66 is also in \ud835\udc49 , since \ud835\udc49 is closed under addition. So \ud835\udc49 satisfies (a) and (b).\n(\u21d0):\nConversely, assume that \ud835\udc49 is a subset of F\ud835\udc5b that satisfies (a) and (b). By (a), there exists\nan #\u00bb\ud835\udc65 \u2208 \ud835\udc49 . Then, by (b) with \ud835\udc50 = \u22121 and #\u00bb\ud835\udc66 = #\u00bb\ud835\udc65, we find that #\u00bb0 = \u2212#\u00bb\ud835\udc65 + #\u00bb\ud835\udc65 is in \ud835\udc49 . Also,\nwith \ud835\udc50 = 1, and any #\u00bb\ud835\udc65 and #\u00bb\ud835\udc66 in \ud835\udc49 , we find that #\u00bb\ud835\udc65 + #\u00bb\ud835\udc66 \u2208 \ud835\udc49 , so \ud835\udc49 is closed under addition.\nFinally, since we have shown that \ud835\udc49 contains #\u00bb0 , then (b) with #\u00bb\ud835\udc66 = #\u00bb0 shows that \ud835\udc49 is\nclosed under scalar multiplication. So \ud835\udc49 is a subspace of F\ud835\udc5b.\nEXERCISE\nEstablish that the examples referred to in Propositions 8.1.2 and 8.1.3 above are subspaces\nusing Proposition 8.1.4 (Subspace Test).\nExample 8.1.5\nLet \ud835\udc4a1 = {[\ud835\udc65 \ud835\udc66 \ud835\udc67]\ud835\udc47 \u2208 R3 : \ud835\udc65 + 2\ud835\udc66 + 3\ud835\udc67 = 4} and \ud835\udc4a2 = {[\ud835\udc65 \ud835\udc66 \ud835\udc67]\ud835\udc47 \u2208 R3 : \ud835\udc652 \u2212 \ud835\udc672 = 0} be\nsubsets of R3. Determine whether either of them is a subspace of R3.\nSolution:\n\ud835\udc4a1 is not a subspace of R3, since [0 0 0]\ud835\udc47 /\u2208 \ud835\udc4a1.\nAlthough [0 0 0]\ud835\udc47 \u2208 \ud835\udc4a2, this subset does not look \u201clinear.\u201d Let us check closure under\naddition.\nNotice that [2 0 2]\ud835\udc47 \u2208 \ud835\udc4a2, as 22 \u2212 22 = 0, and [\u22122 0 2]\ud835\udc47 \u2208 \ud835\udc4a2, as (\u221222) \u2212 22 = 0. However,\nif we add these two vectors together, we get [2 0 2]\ud835\udc47 + [\u22122 0 2]\ud835\udc47 = [0 0 4]\ud835\udc47 , and since\n(02) \u2212 42 = \u221216 \u0338= 0, then [0 0 4]\ud835\udc47 /\u2208 \ud835\udc4a2.\nThis means that \ud835\udc4a2 is not closed under addition and is therefore not a subspace of R3.Section 8.2", "Linear Dependence and the Notion of a Basis of a Subspace\n193\nREMARK\nThe preceding example illustrates a useful check: solution sets to non-homogeneous systems\n(such as \ud835\udc4a1) are never subspaces, since they do not contain #\u00bb0 . Likewise, solution sets\nto nonlinear systems (such as \ud835\udc4a2) tend to not be subspaces, since they are usually not\nclosed under addition or scalar multiplication (or both). On the other hand, we have from\nProposition 8.1.2 (Examples of Subspaces) that solution sets to homogeneous linear systems\nare always subspaces.\n8.2\nLinear Dependence and the Notion of a Basis of a Sub-\nspace\nWe will now tackle the issue of how to describe a subspace in an efficient way. We have\nalready seen in Proposition 8.1.2 (Examples of Subspaces) that, given any finite subset \ud835\udc46 of\nvectors in F\ud835\udc5b, their span Span \ud835\udc46 is a subspace of F\ud835\udc5b. We will eventually see that, conversely,\nevery subspace \ud835\udc49 of F\ud835\udc5b may be expressed in the form of \ud835\udc49 = Span \ud835\udc46 where \ud835\udc46 is a finite\nsubset of vectors in \ud835\udc49 .\nAn important matter here is that this set \ud835\udc46 is not uniquely determined by \ud835\udc49 , in the sense\nthat a given subspace \ud835\udc49 may be expressed as the spanning set of many different subsets \ud835\udc46.\nExample 8.2.1\nWe have\nR2 = Span\n{\ufe02[\ufe021\n0\n]\ufe02\n,\n[\ufe020\n1\n]\ufe02}\ufe02\n= Span\n{\ufe02[\ufe021\n0\n]\ufe02\n,\n[\ufe020\n1\n]\ufe02\n,\n[\ufe021\n2\n]\ufe02}\ufe02\n= Span\n{\ufe02[\ufe021\n0\n]\ufe02\n,\n[\ufe020\n1\n]\ufe02\n,\n[\ufe021\n2\n]\ufe02\n,\n[\ufe02\u22121\n\u22121\n]\ufe02}\ufe02\n,\nas for\n[\ufe02\ud835\udc65\n\ud835\udc66\n]\ufe02\n\u2208 R2, we can express this as\n[\ufe02\ud835\udc65\n\ud835\udc66\n]\ufe02\n= \ud835\udc65\n[\ufe021\n0\n]\ufe02\n+ \ud835\udc66\n[\ufe020\n1\n]\ufe02\n= \ud835\udc65\n[\ufe021\n0\n]\ufe02\n+ \ud835\udc66\n[\ufe020\n1\n]\ufe02\n+ 0\n[\ufe021\n2\n]\ufe02\n= \ud835\udc65\n[\ufe021\n0\n]\ufe02\n+ \ud835\udc66\n[\ufe020\n1\n]\ufe02\n+ 0\n[\ufe021\n2\n]\ufe02\n+ 0\n[\ufe02\u22121\n\u22121\n]\ufe02\n.\nIn the preceding example, it is apparent that the second and third spanning sets contain\nsome redundancies. Our goal in this section is to be able to mathematically quantify this\ntype of redundancy and demonstrate that sets without such redundancies are preferable.\nBelow is a more involved example to illustrate this point.\nExample 8.2.2\nConsider the following subset of R3:\n\ud835\udc46 =\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n2\n2\n2\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n2\n\u22123\n4\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n0\n5\n\u22122\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n\u22122\n13\n\u22128\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n1\n1\n1\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad .\nLet \ud835\udc49 = Span (\ud835\udc46). At this point we cannot say much about \ud835\udc49 . For instance, it could be the\nentirety of R3, or it could be some smaller subspace, such as a line or a plane through the194\nChapter 8\nSubspaces and Bases\norigin. We can at least be sure that \ud835\udc49 cannot be a line through the origin, since \ud835\udc46 contains\ntwo non-zero, non-parallel vectors. (We will see below that \ud835\udc49 is in fact a plane.)\nTo get a better understanding of \ud835\udc49 , we would like to remove any \u201credundant\u201d vectors from\n\ud835\udc46 and provide a smaller subset, let us call it \ud835\udc461, such that \ud835\udc49 = Span (\ud835\udc461) . How do we\nknow which vectors are redundant and ought to be removed from \ud835\udc46? This leads us to the\nimportant idea of linear dependence.\nInformally, we say that the vectors #\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58 are linearly dependent if at least one of\nthem, #\u00bb\n\ud835\udc63\ud835\udc57 say, can be written as a linear combination of some of the other vectors. Thus, the\nvector #\u00bb\n\ud835\udc63\ud835\udc57 depends linearly on the other vectors. (The formal definition is given in Definition\n8.2.3 below.)\nFor example, the vectors in the set \ud835\udc46 above are linearly dependent because\n\u23a1\n\u23a3\n\u22122\n13\n\u22128\n\u23a4\n\u23a6 = 2\n\u23a1\n\u23a3\n2\n2\n2\n\u23a4\n\u23a6 \u2212 3\n\u23a1\n\u23a3\n2\n\u22123\n4\n\u23a4\n\u23a6 .\nThus, we can remove the vector\n[\ufe00\n\u22122 13 \u22128\n]\ufe00\ud835\udc47 from \ud835\udc46 and obtain a more efficient description\nof \ud835\udc49 :\n\ud835\udc49 = Span\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n2\n2\n2\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n2\n\u22123\n4\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n0\n5\n\u22122\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n\u22122\n13\n\u22128\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n1\n1\n1\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad\n= Span\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n2\n2\n2\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n2\n\u22123\n4\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n0\n5\n\u22122\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n1\n1\n1\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad .\nHowever, note that the choice of singling out the vector\n[\ufe00\n\u22122 13 \u22128\n]\ufe00\ud835\udc47 is somewhat arbitrary.\nFor example, we could also write\n\u23a1\n\u23a3\n2\n2\n2\n\u23a4\n\u23a6 = 1\n2\n\u23a1\n\u23a3\n\u22122\n13\n\u22128\n\u23a4\n\u23a6 + 3\n2\n\u23a1\n\u23a3\n2\n\u22123\n4\n\u23a4\n\u23a6\nor\n\u23a1\n\u23a3\n2\n\u22123\n4\n\u23a4\n\u23a6 = 2\n3\n\u23a1\n\u23a3\n2\n2\n2\n\u23a4\n\u23a6 \u2212 1\n3\n\u23a1\n\u23a3\n\u22122\n13\n\u22128\n\u23a4\n\u23a6\nand then remove one of these vectors instead.\nIt is therefore more reasonable and balanced if we put everything on one side of our depen-\ndence equation and re-write it as\n\u23a1\n\u23a3\n\u22122\n13\n\u22128\n\u23a4\n\u23a6 \u2212 2\n\u23a1\n\u23a3\n2\n2\n2\n\u23a4\n\u23a6 + 3\n\u23a1\n\u23a3\n2\n\u22123\n4\n\u23a4\n\u23a6 =\n\u23a1\n\u23a3\n0\n0\n0\n\u23a4\n\u23a6 .\nThe point is that the redundancy in the set \ud835\udc46 is identified by the feature that we can take\nsome linear combination of some of the vectors in \ud835\udc46 to produce the zero vector.Section 8.2\nLinear Dependence and the Notion of a Basis of a Subspace\n195\nWe can always form the zero vector by taking a trivial linear combination (that is, one\nwhere all the scalar coefficients are 0). For example,\n0\n\u23a1\n\u23a3\n\u22122\n13\n\u22128\n\u23a4\n\u23a6 + 0\n\u23a1\n\u23a3\n2\n2\n2\n\u23a4\n\u23a6 + 0\n\u23a1\n\u23a3\n2\n\u22123\n4\n\u23a4\n\u23a6 =\n\u23a1\n\u23a3\n0\n0\n0\n\u23a4\n\u23a6 .\nIt is worth noting the scenarios where this is the only linear combination that can pro-\nduce the zero vector, which forms the premise of our definitions of linear dependence and\nindependence below.\nDefinition 8.2.3\nLinear Dependence\nWe say that the vectors #\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58 \u2208 F\ud835\udc5b are linearly dependent if there exist scalars\n\ud835\udc501, \ud835\udc502, . . . , \ud835\udc50\ud835\udc58 \u2208 F, not all zero, such that \ud835\udc501 #\u00bb\n\ud835\udc631 + \ud835\udc502 #\u00bb\n\ud835\udc632 + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc58 #\u00bb\n\ud835\udc63\ud835\udc58 = #\u00bb0 .\nIf \ud835\udc48 = {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58}, then we say that the set \ud835\udc48 is a linearly dependent set (or\nsimply that \ud835\udc48 is linearly dependent) to mean that the vectors #\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58 are linearly\ndependent.\nIf a list or set of vectors is not linearly dependent, we will say that it is linearly independent.\nHere is the formal definition.\nDefinition 8.2.4\nLinear\nIndependence,\nTrivial Solution\nWe say that the vectors #\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58 \u2208 F\ud835\udc5b are linearly independent if there do not exist\nscalars \ud835\udc501, \ud835\udc502, . . . , \ud835\udc50\ud835\udc58 \u2208 F, not all zero, such that \ud835\udc501 #\u00bb\n\ud835\udc631 + \ud835\udc502 #\u00bb\n\ud835\udc632 + . . . + \ud835\udc50\ud835\udc58 #\u00bb\n\ud835\udc63\ud835\udc58 = #\u00bb0 .\nEquivalently we say that #\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58 \u2208 F\ud835\udc5b are linearly independent if the only solution\nto the equation\n\ud835\udc501 #\u00bb\n\ud835\udc631 + \ud835\udc502 #\u00bb\n\ud835\udc632 + . . . + \ud835\udc50\ud835\udc58 #\u00bb\n\ud835\udc63\ud835\udc58 = #\u00bb0\nis the trivial solution \ud835\udc501 = \ud835\udc502 = \u00b7 \u00b7 \u00b7 = \ud835\udc50\ud835\udc58 = 0.\nIf \ud835\udc48 = {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58}, then we say that the set \ud835\udc48 is a linearly independent set (or\nsimply that \ud835\udc48 is linearly independent) to mean that the vectors #\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58 are\nlinearly independent.\nREMARK\nAs a matter of convention, the empty set \u2205 is considered to be linearly independent. We\nconsider the condition for linear independence in the above definition to be vacuously sat-\nisfied by \u2205.\nThe notion of linear dependence and independence is one of the most important ideas in\nlinear algebra. We will examine it more deeply in the following sections. For now, let\u2019s\nreturn to the previous example.196\nChapter 8\nSubspaces and Bases\nExample 8.2.5\nWe have as before the set\n\ud835\udc49 = Span (\ud835\udc46) = Span\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n2\n2\n2\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n2\n\u22123\n4\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n0\n5\n\u22122\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n\u22122\n13\n\u22128\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n1\n1\n1\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad\nwhich is a subspace of R3. We have shown that \ud835\udc46 is linearly dependent, and specifically\nthat [\u22122 13 \u2212 8]\ud835\udc47 can be written as a linear combination of [2 2 2]\ud835\udc47 and [2 \u2212 3 4]\ud835\udc47 . We\nchoose to remove the vector [\u22122 13 \u2212 8]\ud835\udc47 from \ud835\udc46 to produce the set \ud835\udc461. Then\n\ud835\udc49 = Span (\ud835\udc461) = Span\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n2\n2\n2\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n2\n\u22123\n4\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n0\n5\n\u22122\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n1\n1\n1\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad .\nHowever \ud835\udc461 is linearly dependent. For example,\n\u23a1\n\u23a3\n2\n2\n2\n\u23a4\n\u23a6 \u2212 2\n\u23a1\n\u23a3\n1\n1\n1\n\u23a4\n\u23a6 =\n\u23a1\n\u23a3\n0\n0\n0\n\u23a4\n\u23a6 .\nWe choose to remove the vector [2 2 2]\ud835\udc47 from \ud835\udc461 to produce the set \ud835\udc462. Then\n\ud835\udc49 = Span (\ud835\udc462) = Span\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n2\n\u22123\n4\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n0\n5\n\u22122\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n1\n1\n1\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad .\nThe set \ud835\udc462 is still linearly dependent! For example,\n2\n\u23a1\n\u23a3\n1\n1\n1\n\u23a4\n\u23a6 \u2212\n\u23a1\n\u23a3\n2\n\u22123\n4\n\u23a4\n\u23a6 \u2212\n\u23a1\n\u23a3\n0\n5\n\u22122\n\u23a4\n\u23a6 =\n\u23a1\n\u23a3\n0\n0\n0\n\u23a4\n\u23a6 .\nWe choose to remove the vector [0 5 \u2212 2]\ud835\udc47 from \ud835\udc462 to produce the set \ud835\udc463. Then\n\ud835\udc49 = Span (\ud835\udc463) = Span\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n2\n\u22123\n4\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n1\n1\n1\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad .\nThe set \ud835\udc463, however, is linearly independent. Indeed, if we have a linear combination\n\ud835\udc501\n\u23a1\n\u23a3\n2\n\u22123\n4\n\u23a4\n\u23a6 + \ud835\udc502\n\u23a1\n\u23a3\n1\n1\n1\n\u23a4\n\u23a6 =\n\u23a1\n\u23a3\n0\n0\n0\n\u23a4\n\u23a6 ,\nthen \ud835\udc502 = \u22122\ud835\udc501 and \ud835\udc502 = 3\ud835\udc501, so \u22122\ud835\udc501 = 3\ud835\udc501. Therefore, \ud835\udc501 = 0 and consequently \ud835\udc502 = 0.\nThat is, we cannot form the zero vector as a non-trivial linear combination of vectors in \ud835\udc463.\nThe set \ud835\udc463 is an optimal way of producing the subspace \ud835\udc49 . This optimal set incidentally\nshows that \ud835\udc49 is equal to the span of two non-parallel vectors in R3, and so it is a plane\nthrough the origin.Section 8.3", "Detecting Linear Dependence and Independence\n197\nThe previous example illustrates an important phenomenon. Given a subspace \ud835\udc49 of F\ud835\udc5b, say\none of the form \ud835\udc49 = Span (\ud835\udc46) for some finite set \ud835\udc46 (we will later see that all subspaces are\nof this form), it will be desirable to remove any redundant vectors from \ud835\udc46, reducing it to\na smaller linearly independent subset \u212c such that \ud835\udc49 = Span(\u212c). Such a set \u212c is, in some\nsense, a basic set of building blocks for the construction of \ud835\udc49 .\nDefinition 8.2.6\nBasis\nLet \ud835\udc49 be a subspace of F\ud835\udc5b and let \u212c = {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58} be a finite set of vectors contained\nin \ud835\udc49 . We say that \u212c is a basis for \ud835\udc49 if\n1. \u212c is linearly independent, and\n2. \ud835\udc49 = Span(\u212c).\nREMARK\nWe shall adopt the convention that the empty set \u2205 is a basis for the zero subspace\n\ud835\udc49 =\n{\ufe01#\u00bb0\n}\ufe01\n. Recall that we had earlier adopted the convention of considering the empty\nset to be linearly independent. (See the remark following Definition 8.2.4.) The statement\nSpan (\u2205) =\n{\ufe01#\u00bb0\n}\ufe01\ncan be made plausible if we agree that a \u201clinear combination of no vectors\u201d\ngives the zero vector.\nThe notion of a basis is central to much of what follows in the course. We will spend the\nnext two sections carefully examining both conditions (1) (linear independence) and (2)\n(spanning) in the above definition.\nExample 8.2.7\nOur work in the previous example shows that \u212c =\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n2\n\u22123\n4\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n1\n1\n1\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad is a basis for\n\ud835\udc49 = Span\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n2\n2\n2\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n2\n\u22123\n4\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n0\n5\n\u22122\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n\u22122\n13\n\u22128\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n1\n1\n1\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad .\n8.3\nDetecting Linear Dependence and Independence\nWe begin by recalling the definitions of linear dependence and independence given in Defi-\nnitions 8.2.3 and 8.2.4. A set of vectors {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58} is said to be linearly dependent\nif there exist scalars \ud835\udc501, \ud835\udc502, . . . , \ud835\udc50\ud835\udc58, not all zero, such that \ud835\udc501 #\u00bb\n\ud835\udc631 + \ud835\udc502 #\u00bb\n\ud835\udc632 + . . . + \ud835\udc50\ud835\udc58 #\u00bb\n\ud835\udc63\ud835\udc58 = #\u00bb0 ; if\nnot, the set is said to be linearly independent.\nThe next proposition offers reformulations of these definitions that can be easier to use in\npractice.198\nChapter 8\nSubspaces and Bases\nProposition 8.3.1\n(Linear Dependence Check)\n(a) The vectors #\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58 are linearly dependent if and only if one of the vectors can be\nwritten as a linear combination of some of the other vectors.\n(b) The vectors #\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58 are linearly independent if and only if\n\ud835\udc501 #\u00bb\n\ud835\udc631 + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc58 #\u00bb\n\ud835\udc63\ud835\udc58 = #\u00bb0\n(\ud835\udc50\ud835\udc56 \u2208 F)\nimplies\n\ud835\udc501 = \u00b7 \u00b7 \u00b7 = \ud835\udc50\ud835\udc58 = 0.\nProof: (a) Suppose that #\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58 are linearly dependent.\nThen there exist scalars\n\ud835\udc501, . . . , \ud835\udc50\ud835\udc58, not all zero, such that \ud835\udc501 #\u00bb\n\ud835\udc631 + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc58 #\u00bb\n\ud835\udc63\ud835\udc58 = #\u00bb0 . Suppose that \ud835\udc50\ud835\udc57 is nonzero.\nThen by moving the \ud835\udc50\ud835\udc57 #\u00bb\n\ud835\udc63\ud835\udc57 term to the right side of the previous equation, we get\n\u2212\ud835\udc50\ud835\udc57 #\u00bb\n\ud835\udc63\ud835\udc57 =\n\u2211\ufe01\n\ud835\udc56\u0338=\ud835\udc57\n\ud835\udc50\ud835\udc56 #\u00bb\ud835\udc63 \ud835\udc56.\nDividing through by \u2212\ud835\udc50\ud835\udc57 (which is permissible, since \ud835\udc50\ud835\udc57 \u0338= 0), we get\n#\u00bb\n\ud835\udc63\ud835\udc57 =\n\u2211\ufe01\n\ud835\udc56\u0338=\ud835\udc57\n\ud835\udc50\ud835\udc56\n\u2212\ud835\udc50\ud835\udc57\n#\u00bb\ud835\udc63 \ud835\udc56.\nThus, we have expressed #\u00bb\n\ud835\udc63\ud835\udc57 as a linear combination of the other vectors.\nConversely, if #\u00bb\n\ud835\udc63\ud835\udc57 is a linear combination of the other vectors, say\n#\u00bb\n\ud835\udc63\ud835\udc57 =\n\u2211\ufe01\n\ud835\udc56\u0338=\ud835\udc57\n\ud835\udc4e\ud835\udc56 #\u00bb\ud835\udc63 \ud835\udc56,\nthen\n(\u22121)#\u00bb\n\ud835\udc63\ud835\udc57 +\n\u2211\ufe01\n\ud835\udc56\u0338=\ud835\udc57\n\ud835\udc4e\ud835\udc56 #\u00bb\ud835\udc63 \ud835\udc56 = #\u00bb0\nis an expression of #\u00bb0 as a nontrivial linear combination of the vectors #\u00bb\n\ud835\udc631, . . . , #\u00bb\n\ud835\udc63\ud835\udc58 (non-\ntrivial because the coefficient of #\u00bb\n\ud835\udc63\ud835\udc57 is nonzero). This proves that #\u00bb\n\ud835\udc631, . . . , #\u00bb\n\ud835\udc63\ud835\udc58 are linearly\ndependent.\n(b) This result is a rephrasing of the equivalent condition for linear independence in Def-\ninition 8.2.4. Indeed, the contrapositive of the given statement is: A list of vectors\n#\u00bb\n\ud835\udc631, . . . , #\u00bb\n\ud835\udc63\ud835\udc58 is linearly dependent if and only if there exists scalars \ud835\udc501, . . . , \ud835\udc50\ud835\udc58 not all zero\nsuch that \ud835\udc501 #\u00bb\n\ud835\udc631 + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc58 #\u00bb\n\ud835\udc63\ud835\udc58 = #\u00bb0 . This is the definition of linear dependence. So the\nstatement given in (b) must be true as well.\nNow we turn to the problem of determining whether a given set is or is not linearly depen-\ndent. When the set contains at most two vectors, this is particularly straightforward.\nProposition 8.3.2\nLet \ud835\udc46 \u2286 F\ud835\udc5b.\n(a) If #\u00bb0 \u2208 \ud835\udc46, then \ud835\udc46 is linearly dependent.Section 8.3\nDetecting Linear Dependence and Independence\n199\n(b) If \ud835\udc46 = {#\u00bb\ud835\udc65} contains only one vector, then \ud835\udc46 is linearly dependent if and only if #\u00bb\ud835\udc65 = #\u00bb0 .\n(c) If \ud835\udc46 = {#\u00bb\ud835\udc65, #\u00bb\ud835\udc66 } contains only two vectors, then \ud835\udc46 is linearly dependent if and only if\none of the vectors is a scalar multiple of the other.\nProof:\n(a) Since 1 is a non-zero scalar, and 1(#\u00bb0 ) = #\u00bb0 , we can thus take a non-trivial\nlinear combination of some vectors (in this case, only one vector) in \ud835\udc46 to produce the\nzero vector.\n(b) We know from (a) that if #\u00bb\ud835\udc65 = #\u00bb0 , then \ud835\udc46 is linearly dependent.\nConversely, we know from the properties of the zero vector that if \ud835\udc50#\u00bb\ud835\udc65 = #\u00bb0 , then either\n#\u00bb\ud835\udc65 = #\u00bb0 or \ud835\udc50 = 0.\nSo if #\u00bb\ud835\udc65 \u0338= #\u00bb0 and \ud835\udc50 #\u00bb\ud835\udc65 = #\u00bb0 , then \ud835\udc50 must be zero. That is, only the trivial combination\nof #\u00bb\ud835\udc65 \u0338= #\u00bb0 will produce the zero vector. Thus, \ud835\udc46 is linearly independent.\n(c) If one of the vectors is a multiple of the other, we may assume without loss of generality\nthat #\u00bb\ud835\udc66 = \ud835\udc5a#\u00bb\ud835\udc65 for some \ud835\udc5a \u2208 F. Then\n#\u00bb\ud835\udc66 \u2212 \ud835\udc5a #\u00bb\ud835\udc65 = #\u00bb0 .\nSince the coefficient of #\u00bb\ud835\udc66 is 1 \u0338= 0, we have demonstrated linear dependence.\nConversely, if \ud835\udc46 = {#\u00bb\ud835\udc65, #\u00bb\ud835\udc66 } is linearly dependent, then there exist \ud835\udc4e, \ud835\udc4f \u2208 F, not both\nzero, such that \ud835\udc4e #\u00bb\ud835\udc66 + \ud835\udc4f #\u00bb\ud835\udc65 = #\u00bb0 . We may assume without loss of generality that \ud835\udc4e \u0338= 0.\nWe then have that\n#\u00bb\ud835\udc66 + \ud835\udc4f\n\ud835\udc4e\n#\u00bb\ud835\udc65 = #\u00bb0 ,\nwhich gives\n#\u00bb\ud835\udc66 = \u2212 \ud835\udc4f\n\ud835\udc4e\n#\u00bb\ud835\udc65.\nThus, one of the vectors, #\u00bb\ud835\udc66 , is a multiple of the other, #\u00bb\ud835\udc65.\nExample 8.3.3\nIs \ud835\udc46 =\n{\ufe02[\ufe02 2\n\u22124\n]\ufe02\n,\n[\ufe02 6\n\u221212\n]\ufe02}\ufe02\nlinearly dependent?\nSolution:\nYes, as\n[\ufe02 6\n\u221212\n]\ufe02\n= 3\n[\ufe02 2\n\u22124\n]\ufe02\n.\nExample 8.3.4\nIs \ud835\udc46 =\n{\ufe02[\ufe02 2\n\u22124\n]\ufe02\n,\n[\ufe02 6\n\u221214\n]\ufe02}\ufe02\nlinearly dependent?\nSolution:\nNo. The second vector is not a multiple of the first (and the first is not a multiple of the\nsecond). Looking at the first components, 6 is 3 times 2; however, looking at the second\ncomponents, \u221214 is not 3 times \u22124.200\nChapter 8\nSubspaces and Bases\nExample 8.3.5\nIs \ud835\udc46 = {#\u00bb\n\ud835\udc671, #\u00bb\n\ud835\udc672} , with #\u00bb\n\ud835\udc671 =\n[\ufe022 + 3\ud835\udc56\n4 + \ud835\udc56\n]\ufe02\nand #\u00bb\n\ud835\udc672 =\n[\ufe0212 + 5\ud835\udc56\n14 \u2212 5\ud835\udc56\n]\ufe02\n, linearly dependent?\nSolution:\nBecause we are working over C, the answer to this question is not so obvious.\nWe will use Proposition 8.3.2 (b). Consider the equation \ud835\udc501 #\u00bb\n\ud835\udc671 + \ud835\udc502 #\u00bb\n\ud835\udc672 = #\u00bb0 . The Proposition\nstates that {#\u00bb\n\ud835\udc671, #\u00bb\n\ud835\udc672} is linearly independent precisely when this equation has only the trivial\nsolution \ud835\udc501 = \ud835\udc502 = 0.\nThe corresponding coefficient matrix of this equation is\n[\ufe022 + 3\ud835\udc56 12 + 5\ud835\udc56\n4 + \ud835\udc56 14 \u2212 5\ud835\udc56\n]\ufe02\nwhich row reduces to\n[\ufe021 3 \u2212 2\ud835\udc56\n0\n0\n]\ufe02\n.\nWe deduce from this reduced matrix that there are (infinitely many) non-trivial solutions\nto the system of equations. One solution is \ud835\udc501 = \u22123 + 2\ud835\udc56 and \ud835\udc502 = 1.\nThus, the set \ud835\udc46 is linearly dependent.\nHow do we deal with a set that contains more than two vectors? The ideas in the previous\nexamples can be expanded as follows. Let \ud835\udc46 = {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58} be a set of \ud835\udc58 vectors in F\ud835\udc5b.\nConsider the following questions about \ud835\udc46:\n1. Is #\u00bb0 \u2208 \ud835\udc46?\n2. Is one vector in \ud835\udc46 a scalar multiple of another vector in \ud835\udc46?\n3. Can we easily observe that we can write one of the vectors in \ud835\udc46 as a linear combination\nof some of the other vectors in \ud835\udc46?\nIf the answer to any of these questions is \u201cyes\u201d, then the set \ud835\udc46 is linearly dependent.\nIn particular, (2) and (3) above essentially ask \u201cis it obvious that this set is linearly\ndependent?\u201d\nIf the answer to all of them is \u201cno\u201d, we cannot immediately conclude whether the set is\nlinearly independent or dependent. Therefore, we must examine the expression\n\ud835\udc501 #\u00bb\n\ud835\udc631 + \ud835\udc502 #\u00bb\n\ud835\udc632 + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc58 #\u00bb\n\ud835\udc63\ud835\udc58 = #\u00bb0 .\nThis is a homogeneous linear system of \ud835\udc5b equations (obtained by equating the entries of the\nvectors on both sides of the above expression in \ud835\udc58 unknowns (the coefficients \ud835\udc50\ud835\udc56). Since it\nis a homogeneous system, we have that one solution is the trivial solution, and we wish to\nknow whether or not there are any other solutions. We know that \ud835\udc46 is linearly dependent\nif and only if there are non-trivial solutions from Proposition 8.3.1 (Linear Dependence\nCheck).\nThis is all succinctly captured by the rank of the coefficient matrix of the system associated\nwith the expression above.Section 8.3\nDetecting Linear Dependence and Independence\n201\nProposition 8.3.6\n(Pivots and Linear Independence)\nLet \ud835\udc46 = {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58} be a set of \ud835\udc58 vectors in F\ud835\udc5b. Let \ud835\udc34 =\n[\ufe00 #\u00bb\n\ud835\udc631 #\u00bb\n\ud835\udc632 \u00b7 \u00b7 \u00b7 #\u00bb\n\ud835\udc63\ud835\udc58\n]\ufe00\nbe the \ud835\udc5b \u00d7 \ud835\udc58\nmatrix whose columns are the vectors in \ud835\udc46.\nSuppose that rank(\ud835\udc34) = \ud835\udc5f and \ud835\udc34 has pivots in columns \ud835\udc5e1, \ud835\udc5e2, . . . , \ud835\udc5e\ud835\udc5f.\nLet \ud835\udc48 = {#  \u00bb\n\ud835\udc63\ud835\udc5e1, #  \u00bb\n\ud835\udc63\ud835\udc5e2, . . . , #  \u00bb\n\ud835\udc63\ud835\udc5e\ud835\udc5f}, the set of columns of \ud835\udc34 that correspond to the pivot columns\nlabelled above. Then\n(a) \ud835\udc46 is linearly independent if and only if \ud835\udc5f = \ud835\udc58.\n(b) \ud835\udc48 is linearly independent.\n(c) If #\u00bb\ud835\udc63 is in \ud835\udc46 but not in \ud835\udc48 then the set {#  \u00bb\n\ud835\udc63\ud835\udc5e1, ..., #  \u00bb\n\ud835\udc63\ud835\udc5e\ud835\udc5f, #\u00bb\ud835\udc63 } is linearly dependent.\n(d) Span (\ud835\udc48) = Span (\ud835\udc46).\nREMARK\nThis proposition makes the identification of linear dependence/independence relatively\nstraightforward. Additionally, it identifies \u201credundant\u201d vectors in a given set that may be\nremoved to obtain a linearly independent subset whose span is the same as the span of the\noriginal set. This gives a framework for the ad-hoc process carried out in Proposition 8.1.2.\nProof: (a) The matrix \ud835\udc34 is the coefficient matrix for the homogeneous system of linear\nequations\n\ud835\udc501 #\u00bb\n\ud835\udc631 + \ud835\udc502 #\u00bb\n\ud835\udc632 + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc58 #\u00bb\n\ud835\udc63\ud835\udc58 = #\u00bb0 .\nThere will be no parameters in the solution set if and only if there is a pivot in each of\nthe columns of \ud835\udc34, that is, if and only if \ud835\udc5f = \ud835\udc58. So \ud835\udc46 is linearly independent if and only\nif \ud835\udc5f = \ud835\udc58.\n(b) We must examine the linear dependence of the vectors #  \u00bb\n\ud835\udc63\ud835\udc5e1, #  \u00bb\n\ud835\udc63\ud835\udc5e2, . . . , #  \u00bb\n\ud835\udc63\ud835\udc5e\ud835\udc5f corresponding\nto the pivot columns in \ud835\udc34. Thus, we must consider the homogeneous system of linear\nequations\n\ud835\udc511 #  \u00bb\n\ud835\udc63\ud835\udc5e1 + \ud835\udc512 #  \u00bb\n\ud835\udc63\ud835\udc5e2 + \u00b7 \u00b7 \u00b7 + \ud835\udc51\ud835\udc5f #  \u00bb\n\ud835\udc63\ud835\udc5e\ud835\udc5f = #\u00bb0 .\nThis system is a system of \ud835\udc5f equations in \ud835\udc5f unknowns. Its coefficient matrix has rank\n\ud835\udc5f because it consists of the pivot columns in \ud835\udc34. Thus, the only solution to this system\nis the trivial solution. Consequently, \ud835\udc48 must be linearly independent.\n(c) Suppose that \ud835\udc5f < \ud835\udc58, so that there is at least one non-pivot column in \ud835\udc34 \u2014 the \ud835\udc57th\ncolumn, say. Add the vector #\u00bb\n\ud835\udc63\ud835\udc57 to \ud835\udc48 and check this new set for linear dependence. This\namounts to examining the system\n\ud835\udc511 #  \u00bb\n\ud835\udc63\ud835\udc5e1 + \ud835\udc512 #  \u00bb\n\ud835\udc63\ud835\udc5e2 + \u00b7 \u00b7 \u00b7 + \ud835\udc51\ud835\udc5f #  \u00bb\n\ud835\udc63\ud835\udc5e\ud835\udc5f + \ud835\udefc #\u00bb\n\ud835\udc63\ud835\udc57 = #\u00bb0 .\nBy construction, the coefficient matrix of this system has \ud835\udc5f + 1 columns and rank \ud835\udc5f.\nThus, there must be \ud835\udc5f +1\u2212\ud835\udc5f = 1 free parameter in its solution set, and therefore, there\nare nontrivial solutions. It follows that {#  \u00bb\n\ud835\udc63\ud835\udc5e1, #  \u00bb\n\ud835\udc63\ud835\udc5e2, . . . , #  \u00bb\n\ud835\udc63\ud835\udc5e\ud835\udc5f, #\u00bb\n\ud835\udc63\ud835\udc57} is linearly dependent.202\nChapter 8\nSubspaces and Bases\n(d) Note that \ud835\udc48 \u2286 \ud835\udc46, so Span (\ud835\udc48) \u2286 Span (\ud835\udc46). We will prove that Span (\ud835\udc46) \u2286 Span (\ud835\udc48).\nIf \ud835\udc48 = \ud835\udc46, there is nothing to prove. So assume that \ud835\udc46 \u0338= \ud835\udc48, and let #\u00bb\n\ud835\udc63\ud835\udc57 be a vector in \ud835\udc46,\nbut not in \ud835\udc48. Our proof in part (3) shows that the system\n\ud835\udc511 #  \u00bb\n\ud835\udc63\ud835\udc5e1 + \ud835\udc512 #  \u00bb\n\ud835\udc63\ud835\udc5e2 + \u00b7 \u00b7 \u00b7 + \ud835\udc51\ud835\udc5f #  \u00bb\n\ud835\udc63\ud835\udc5e\ud835\udc5f + \ud835\udefc #\u00bb\n\ud835\udc63\ud835\udc57 = #\u00bb0\nhas a nontrivial solution. Such a solution must have \ud835\udefc \u0338= 0, because of the following\nargument. If \ud835\udefc = 0, then\n\ud835\udc511 #  \u00bb\n\ud835\udc63\ud835\udc5e1 + \ud835\udc512 #  \u00bb\n\ud835\udc63\ud835\udc5e2 + \u00b7 \u00b7 \u00b7 + \ud835\udc51\ud835\udc5f #  \u00bb\n\ud835\udc63\ud835\udc5e\ud835\udc5f = #\u00bb0 ,\nand consequently \ud835\udc511 = . . . = \ud835\udc51\ud835\udc5f = 0 by part (b) above and by Part (b) of Proposition\n8.3.1 (Linear Dependence Check). So, if \ud835\udefc = 0, we get the trivial solution, which implies\nthat this set of vectors is linearly independent and this contradicts (c).\nTherefore, since \ud835\udefc \u0338= 0, we can write #\u00bb\n\ud835\udc63\ud835\udc57 as a linear combination of the vectors in \ud835\udc48,\nnamely\n#\u00bb\n\ud835\udc63\ud835\udc57 = \ud835\udc511\n\u2212\ud835\udefc\n#  \u00bb\n\ud835\udc63\ud835\udc5e1 + \ud835\udc512\n\u2212\ud835\udefc\n#  \u00bb\n\ud835\udc63\ud835\udc5e2 + \u00b7 \u00b7 \u00b7 + \ud835\udc51\ud835\udc5f\n\u2212\ud835\udefc\n#  \u00bb\n\ud835\udc63\ud835\udc5e\ud835\udc5f.\nThis shows that #\u00bb\n\ud835\udc63\ud835\udc57 \u2208 Span (\ud835\udc48). Since #\u00bb\n\ud835\udc63\ud835\udc57 was an arbitrary vector in \ud835\udc46 but not in \ud835\udc48, it\nfollows that Span (\ud835\udc46) \u2286 Span (\ud835\udc48), as desired.\nHere is a very useful application of the previous Proposition.\nCorollary 8.3.7\n(Bound on Number of Linearly Independent Vectors)\nLet \ud835\udc46 = {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58} be a set of \ud835\udc58 vectors in F\ud835\udc5b. If \ud835\udc5b < \ud835\udc58, then \ud835\udc46 is linearly dependent.\nProof: As in Proposition 8.3.6 (Pivots and Linear Independence), let \ud835\udc34 be the matrix\nwhose columns are the vectors in \ud835\udc46, and let \ud835\udc5f = rank(\ud835\udc34). Then \ud835\udc5f \u2264 \ud835\udc5b, since \ud835\udc34 has \ud835\udc5b rows.\nHence if \ud835\udc5b < \ud835\udc58, it follows that \ud835\udc5f \u2264 \ud835\udc5b < \ud835\udc58. Therefore, \ud835\udc46 is linearly dependent, by Proposition\n8.3.6 (a).\nWe now turn to some computational applications of Proposition 8.3.6 (Pivots and Linear\nIndependence).\nExample 8.3.8\nConsider the following vectors in R6:\n#\u00bb\n\ud835\udc631 =\n[\ufe00\n1 \u22122 3 \u22124 5 \u22126\n]\ufe00\ud835\udc47 ,\n#\u00bb\n\ud835\udc632 =\n[\ufe00\n3 4 5 6 7 8\n]\ufe00\ud835\udc47 ,\n#\u00bb\n\ud835\udc633 =\n[\ufe00\n\u22125 \u221210 \u22127 \u221216 \u22129 \u221222\n]\ufe00\ud835\udc47 ,\n#\u00bb\n\ud835\udc634 =\n[\ufe00\n\u22126 \u22124 \u22122 0 2 4\n]\ufe00\ud835\udc47 ,\n#\u00bb\n\ud835\udc635 =\n[\ufe00\n1 1 1 1 1 1\n]\ufe00\ud835\udc47 ,\n#\u00bb\n\ud835\udc636 =\n[\ufe00\n\u22123 3 \u22125 5 \u22121 1\n]\ufe00\ud835\udc47 .\nLet \ud835\udc46 = {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, #\u00bb\n\ud835\udc633, #\u00bb\n\ud835\udc634, #\u00bb\n\ud835\udc635, #\u00bb\n\ud835\udc636} and \ud835\udc49 = Span \ud835\udc46.\n(a) Show that \ud835\udc46 is linearly dependent.\n(b) Find a subset of \ud835\udc46 that is a basis for \ud835\udc49 .Section 8.3\nDetecting Linear Dependence and Independence\n203\nSolution: (a) Form matrix \ud835\udc34, which has the vectors in \ud835\udc46 as its columns.\n\ud835\udc34 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a2\u23a2\u23a3\n1\n3\n\u22125\n\u22126\n1\n\u22123\n\u22122\n4\n\u221210\n\u22124\n1\n3\n3\n5\n\u22127\n\u22122\n1\n\u22125\n\u22124\n6\n\u221216\n0\n1\n5\n5\n7\n\u22129\n2\n1\n\u22121\n\u22126\n8\n\u221222\n4\n1\n1\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a5\u23a5\u23a6\nAn REF of \ud835\udc34 is\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a2\u23a2\u23a2\u23a2\u23a3\n1 3 \u22125 \u22126 1 \u22123\n0 1 \u22122 \u22128\n5\n3\n10\n\u22123\n10\n0 0 0\n1\n\u22121\n12\n7\n24\n0 0 0\n0\n0\n1\n0 0 0\n0\n0\n0\n0 0 0\n0\n0\n0\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a5\u23a5\u23a5\u23a5\u23a6\n.\nWe find that \ud835\udc34 has rank 4 with pivots in columns 1, 2, 4, and 6. Since 4 < 6, we conclude that\n\ud835\udc46 is linearly dependent (by Part (a) of Proposition 8.3.6 (Pivots and Linear Independence)).\n(b) Parts (b) and (d) of Proposition 8.3.6 (Pivots and Linear Independence) tell us that the\nvectors #\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, #\u00bb\n\ud835\udc634 and #\u00bb\n\ud835\udc636 are linearly independent, and that\nSpan{#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, #\u00bb\n\ud835\udc634, #\u00bb\n\ud835\udc636} = Span \ud835\udc46 = \ud835\udc49.\nWe conclude that {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, #\u00bb\n\ud835\udc634, #\u00bb\n\ud835\udc636} is a basis for \ud835\udc49 .\nExample 8.3.9\nConsider the following vectors in C5 :\n#\u00bb\ud835\udc63 1\n= [1 + \ud835\udc56, \u22122 + \ud835\udc56, 3, \u22124 \u2212 \ud835\udc56, 5\ud835\udc56]\ud835\udc47 ,\n#\u00bb\ud835\udc63 2\n= [\u22121 + 5\ud835\udc56, \u22127 \u2212 4\ud835\udc56, 6 + 9\ud835\udc56, \u22125 \u2212 14\ud835\udc56, \u221215 + 10\ud835\udc56]\ud835\udc47 ,\n#\u00bb\ud835\udc63 3\n= [3\ud835\udc56, 4 + 2\ud835\udc56, 5 + 2\ud835\udc56, 6 \u2212 4\ud835\udc56, 7 \u2212 2\ud835\udc56]\ud835\udc47 ,\n#\u00bb\ud835\udc63 4\n= [\u22121 + 2\ud835\udc56, \u22123 \u2212 6\ud835\udc56, 11 + 9\ud835\udc56, 1 \u2212 18\ud835\udc56, \u22128 + 10\ud835\udc56]\ud835\udc47 ,\n#\u00bb\ud835\udc63 5\n= [\u22126\ud835\udc56, \u22124\ud835\udc56, \u22122\ud835\udc56, 0, 2\ud835\udc56]\ud835\udc47 .\nLet \ud835\udc46 = {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, #\u00bb\n\ud835\udc633, #\u00bb\n\ud835\udc634, #\u00bb\n\ud835\udc635} and \ud835\udc49 = Span \ud835\udc46.\n(a) Show that \ud835\udc46 is linearly dependent.\n(b) Find a subset of \ud835\udc46 that is a basis for \ud835\udc49 .\nSolution: (a) Form matrix \ud835\udc34, which has the vectors in \ud835\udc46 as its columns.\n\ud835\udc34 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n1 + \ud835\udc56\n\u22121 + 5\ud835\udc56\n3\ud835\udc56\n\u22121 + 2\ud835\udc56\n\u22126\ud835\udc56\n\u22122 + \ud835\udc56\n\u22127 \u2212 4\ud835\udc56\n4 + 2\ud835\udc56\n\u22123 \u2212 6\ud835\udc56\n\u22124\ud835\udc56\n3\n6 + 9\ud835\udc56\n5 + 2\ud835\udc56\n11 + 9\ud835\udc56\n\u22122\ud835\udc56\n\u22124 \u2212 \ud835\udc56\n\u22125 \u2212 14\ud835\udc56\n6 \u2212 4\ud835\udc56\n1 \u2212 18\ud835\udc56\n0\n5\ud835\udc56\n\u221215 + 10\ud835\udc56\n7 \u2212 2\ud835\udc56\n\u22128 + 10\ud835\udc56\n2\ud835\udc56\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\n.204\nChapter 8\nSubspaces and Bases\nThe RREF of \ud835\udc34 is\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n1 2 + 3\ud835\udc56 0 0 \u22122 \u2212 3\ud835\udc56\n0\n0\n1 0\n\u22121\n0\n0\n0 1\n1\n0\n0\n0 0\n0\n0\n0\n0 0\n0\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\n.\nWe find that \ud835\udc34 has rank 3 with pivots in columns 1, 3 and 4. Since 3 < 5, we conclude that\n\ud835\udc46 is linearly dependent (by Part (a) of Proposition 8.3.6 (Pivots and Linear Independence)).\n(b) Parts (b) and (d) of Proposition 8.3.6 (Pivots and Linear Independence) tell us that the\nvectors #\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc633, and #\u00bb\n\ud835\udc634 are linearly independent, and that\nSpan{#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, #\u00bb\n\ud835\udc634} = Span \ud835\udc46 = \ud835\udc49.\nWe conclude that {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, #\u00bb\n\ud835\udc634} is a basis for \ud835\udc49 .\n8.4", "Spanning Sets\nThe problem we wish to tackle in this section is the following: given a subspace \ud835\udc49 of F\ud835\udc5b,\nfind a finite set \ud835\udc46 = {#\u00bb\n\ud835\udc631, . . . , #\u00bb\n\ud835\udc63\ud835\udc58} of vectors in \ud835\udc49 such that \ud835\udc49 = Span{#\u00bb\n\ud835\udc631, . . . , #\u00bb\n\ud835\udc63\ud835\udc58}. We begin\nby showing that this is always possible.\nTheorem 8.4.1\n(Every Subspace Has a Spanning Set)\nLet \ud835\udc49 be a subspace of F\ud835\udc5b. Then there exist vectors #\u00bb\n\ud835\udc631, . . . , #\u00bb\n\ud835\udc63\ud835\udc58 \u2208 \ud835\udc49 such that\n\ud835\udc49 = Span{#\u00bb\n\ud835\udc631, . . . , #\u00bb\n\ud835\udc63\ud835\udc58}.\nProof: If \ud835\udc49 = {#\u00bb0 }, then \ud835\udc49 = Span{#\u00bb0 }. So we may assume that \ud835\udc49 \u0338= {#\u00bb0 }. Therefore,\nthere must be some nonzero vector #\u00bb\ud835\udc63 1 in \ud835\udc49 .\nIf \ud835\udc49 = Span{#\u00bb\n\ud835\udc631}, we are done. Otherwise, there exists a #\u00bb\n\ud835\udc632 \u2208 \ud835\udc49 that is not in Span{#\u00bb\n\ud835\udc631}. By\nPart (a) of Proposition 8.3.1 (Linear Dependence Check), the set {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632} must be linearly\nindependent.\nIf \ud835\udc49 = Span{#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632}, we are done. Otherwise, by continuously repeating this process, we\ngenerate a set {#\u00bb\n\ud835\udc631, . . . , #\u00bb\n\ud835\udc63\ud835\udc58} of \ud835\udc58 linearly independent vectors in \ud835\udc49 . By Corollary 8.3.7 (Bound\non Number of Linearly Independent Vectors), we must have \ud835\udc58 \u2264 \ud835\udc5b. Thus, the process must\nterminate after at most \ud835\udc5b steps, at which point we have \ud835\udc49 = Span{#\u00bb\n\ud835\udc631, . . . , #\u00bb\n\ud835\udc63\ud835\udc58}.\nREMARK\nThe above proof actually shows more than is stated in the Theorem. It shows that if \ud835\udc49 is\na nonzero subspace of F\ud835\udc5b, then we can find a linearly independent spanning set (that is, a\nbasis!) for \ud835\udc49 . Moreover, we can find a basis with at most \ud835\udc5b elements. We will return toSection 8.4\nSpanning Sets\n205\nthese points in Theorem 8.5.1 (Every Subspace Has a", "208\nChapter 8\nSubspaces and Bases\nSolution:\n(a) Span (\ud835\udc461) \u0338= R4, since we need at least four vectors to span R4.\n(b) There are at least four vectors in \ud835\udc462, so perhaps it spans R4. Let us place the vectors\nin a matrix \ud835\udc34 and check if rank(\ud835\udc34) = 4. We have\n\ud835\udc34 =\n\u23a1\n\u23a2\u23a2\u23a3\n1 2 2 5\n1 \u22122 4 3\n1 3 6 10\n1 \u22123 8 6\n\u23a4\n\u23a5\u23a5\u23a6\nwith\nRREF(\ud835\udc34) =\n\u23a1\n\u23a2\u23a2\u23a3\n1 0 0 1\n0 1 0 1\n0 0 1 1\n0 0 0 0\n\u23a4\n\u23a5\u23a5\u23a6 .\nThus rank(\ud835\udc34) = 3 \u0338= 4. So Span (\ud835\udc462) \u0338= R4.\n(c) We again have at least four vectors. Let\n\ud835\udc34 =\n\u23a1\n\u23a2\u23a2\u23a3\n1 2 2 5\n3\n1 \u22122 4 3\n5\n1 3 6 10 6\n1 \u22123 8 6 10\n\u23a4\n\u23a5\u23a5\u23a6 .\nThen\nRREF(\ud835\udc34) =\n\u23a1\n\u23a2\u23a2\u23a3\n1 0 0 1 0\n0 1 0 1 0\n0 0 1 1 0\n0 0 0 0 1\n\u23a4\n\u23a5\u23a5\u23a6 .\nThus rank(\ud835\udc34) = 4, and so in this case Span (\ud835\udc463) = R4.\n8.5\nBasis\nIn Definition 8.2.6, we defined a basis for a subspace \ud835\udc49 of F\ud835\udc5b to be a subset \u212c \u2286 \ud835\udc49 that is\nlinearly independent and spans \ud835\udc49 ; that is, Span (\u212c) = \ud835\udc49 . In the previous two sections, we\nexamined both aspects of this definition. In this section and the next, we will put everything\ntogether to showcase the utility of bases.\nWe begin with the following result which we had already noted in passing.\nTheorem 8.5.1\n(Every Subspace Has a Basis)\nLet \ud835\udc49 be a subspace of F\ud835\udc5b. Then \ud835\udc49 has a basis.Section 8.5\nBasis\n209\nProof: If \ud835\udc49 is not the zero subspace, then the result is given by the proof of Theorem 8.4.1\n(Every Subspace Has a Spanning Set). As discussed immediately following Definition 8.2.6,\nwe know that \u2205 is a basis of the trivial subspace\n{\ufe01#\u00bb0\n}\ufe01\n.\nTheorem 8.5.1 (Every Subspace Has a Basis), as it is stated, is merely an existence result. It\ndoes not supply us with a method for obtaining a basis for \ud835\udc49 . (Although, as mentioned in\nthe previous section, the proof of Theorem 8.4.1 (Every Subspace Has a Spanning Set) can\nbe refined into an algorithm.) Nonetheless, in some cases it\u2019s possible to explicitly exhibit\nexamples of bases. Here is a special\u2014but very important\u2014example.\nDefinition 8.5.2\nStandard Basis for\nF\ud835\udc5b\nIn F\ud835\udc5b, let #\u00bb\ud835\udc52 \ud835\udc56 represent the vector whose \ud835\udc56\ud835\udc61\u210e component is 1 with all other components 0.\nThe set \u2130 = {#\u00bb\n\ud835\udc521, #\u00bb\n\ud835\udc522, ..., #\u00bb\n\ud835\udc52\ud835\udc5b} is called the standard basis for F\ud835\udc5b.\nUsing Proposition 8.3.6 (Pivots and Linear Independence), we can verify that the standard\nbasis \u2130 is linearly independent. It also spans F\ud835\udc5b. Indeed, if #\u00bb\ud835\udc65 \u2208 F\ud835\udc5b, then\n#\u00bb\ud835\udc65 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc651\n\ud835\udc652\n...\n\ud835\udc65\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 = \ud835\udc651\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n1\n0\n...\n0\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 + \ud835\udc652\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n0\n1\n...\n0\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 + \u00b7 \u00b7 \u00b7 + \ud835\udc65\ud835\udc5b\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n0\n0\n...\n1\n\u23a4\n\u23a5\u23a5\u23a5\u23a6\n= \ud835\udc651 #\u00bb\n\ud835\udc521 + \ud835\udc652 #\u00bb\n\ud835\udc522 + \u00b7 \u00b7 \u00b7 \ud835\udc65\ud835\udc5b #\u00bb\n\ud835\udc52\ud835\udc5b.\nTherefore, #\u00bb\ud835\udc65 \u2208 Span (\u2130). Thus, \u2130 is a basis for F\ud835\udc5b.\nIn general, determining if a set \ud835\udc46 is a basis for F\ud835\udc5b is a straightforward matter, as the next\ntwo propositions show.\nProposition 8.5.3\n(Size of Basis for F\ud835\udc5b)\nLet \ud835\udc46 = {#\u00bb\n\ud835\udc631, . . . , #\u00bb\n\ud835\udc63\ud835\udc58} be a set of \ud835\udc58 vectors in F\ud835\udc5b. If \ud835\udc46 is a basis for F\ud835\udc5b, then \ud835\udc58 = \ud835\udc5b.\nProof: For a subset \ud835\udc46 of F\ud835\udc5b to be a basis of F\ud835\udc5b, we must have that\n1. Span (\ud835\udc46) = F\ud835\udc5b, which by Proposition 8.4.6 (Spans F\ud835\udc5b iff rank is \ud835\udc5b) means that \ud835\udc58 \u2265 \ud835\udc5b,\nand\n2. \ud835\udc46 is linearly independent, which by Corollary 8.3.7 (Bound on Number of Linearly\nIndependent Vectors) means that \ud835\udc58 \u2264 \ud835\udc5b.\nWe conclude that \ud835\udc58 = \ud835\udc5b.\nThus, if a subset \ud835\udc46 of F\ud835\udc5b contains fewer than \ud835\udc5b vectors, it does not contain enough vectors\nto span F\ud835\udc5b and is thus not a spanning set of F\ud835\udc5b. On the other hand, if \ud835\udc46 contains more\nthan \ud835\udc5b vectors in F\ud835\udc5b, then it must be linearly dependent.\nIf \ud835\udc46 contains exactly \ud835\udc5b vectors, then it may or may not be a basis for F\ud835\udc5b. We still have to\ncheck that \ud835\udc46 is linearly independent and that it spans F\ud835\udc5b. In fact, as the next result shows,\nwe only need to check one of these conditions!210\nChapter 8\nSubspaces and Bases\nProposition 8.5.4\n(\ud835\udc5b Vectors in F\ud835\udc5b Span iff Independent)\nLet \ud835\udc46 = {#\u00bb\n\ud835\udc631, . . . , # \u00bb\n\ud835\udc63\ud835\udc5b} be a set of \ud835\udc5b vectors in F\ud835\udc5b. Then \ud835\udc46 is linearly independent if and only if\nSpan (\ud835\udc46) = F\ud835\udc5b.\nProof: Let \ud835\udc34 =\n[\ufe00 #\u00bb\n\ud835\udc631 \u00b7 \u00b7 \u00b7 # \u00bb\n\ud835\udc63\ud835\udc5b\n]\ufe00\nbe the \ud835\udc5b \u00d7 \ud835\udc5b matrix whose columns are the vectors in \ud835\udc46. By\nPart (a) of Proposition 8.3.6 (Pivots and Linear Independence), \ud835\udc46 is linearly independent\nif and only if rank(\ud835\udc34) = \ud835\udc5b.\nOn the other hand, from Proposition 8.4.6 (Spans F\ud835\udc5b iff rank is \ud835\udc5b) we have that Span (\ud835\udc46) =\nF\ud835\udc5b if and only if rank(\ud835\udc34) = \ud835\udc5b.\nCombining both of these results completes the proof.\nThus, when we are checking to see whether or not a subset \ud835\udc46 of F\ud835\udc5b is a basis of F\ud835\udc5b, below\nare three options to check this:\n1. Check \ud835\udc46 for linear independence and check \ud835\udc46 for spanning, or\n2. Count the vectors in \ud835\udc46 and, if \ud835\udc46 contains exactly \ud835\udc5b vectors, then check \ud835\udc46 for spanning\nusing Proposition 8.4.6 (Spans F\ud835\udc5b iff rank is \ud835\udc5b), or\n3. Count the vectors in \ud835\udc46 and, if \ud835\udc46 contains exactly \ud835\udc5b vectors, then check \ud835\udc46 for linear\nindependence using Proposition 8.3.6 (Pivots and Linear Independence).\nIn practice, the last option above is usually the quickest.\nExample 8.5.5\nLet #\u00bb\n\ud835\udc631 =\n\u23a1\n\u23a2\u23a2\u23a3\n1\n2\n3\n4\n\u23a4\n\u23a5\u23a5\u23a6 , #\u00bb\n\ud835\udc632 =\n\u23a1\n\u23a2\u23a2\u23a3\n\u22121\n2\n\u22123\n4\n\u23a4\n\u23a5\u23a5\u23a6 , #\u00bb\n\ud835\udc633 =\n\u23a1\n\u23a2\u23a2\u23a3\n4\n3\n2\n1\n\u23a4\n\u23a5\u23a5\u23a6 , #\u00bb\n\ud835\udc634 =\n\u23a1\n\u23a2\u23a2\u23a3\n1\n1\n1\n1\n\u23a4\n\u23a5\u23a5\u23a6 , #\u00bb\n\ud835\udc635 =\n\u23a1\n\u23a2\u23a2\u23a3\n4\n\u22123\n2\n\u22121\n\u23a4\n\u23a5\u23a5\u23a6 .\nWhich of the following subsets of R4 is a basis for R4?\n\ud835\udc461 = {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, #\u00bb\n\ud835\udc633} ,\n\ud835\udc462 = {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, #\u00bb\n\ud835\udc633, #\u00bb\n\ud835\udc634, #\u00bb\n\ud835\udc635} ,\n\ud835\udc463 = {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, #\u00bb\ud835\udc63 3, #\u00bb\n\ud835\udc634} ,\n\ud835\udc464 = {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, #\u00bb\n\ud835\udc633, #\u00bb\n\ud835\udc635} .\nSolution: Sets \ud835\udc461 and \ud835\udc462 fail immediately as they have the wrong number of vectors in\nthem.\nSets \ud835\udc463 and \ud835\udc464 have the correct number of vectors in them so we need to investigate them\nfurther. Let us check whether they are linear independent.\nThe matrix whose columns are the vectors in \ud835\udc463 is\n\ud835\udc34 =\n\u23a1\n\u23a2\u23a2\u23a3\n1 \u22121 4 1\n2 2 3 1\n3 \u22123 2 1\n4 4 1 1\n\u23a4\n\u23a5\u23a5\u23a6 ,Section 8.5\nBasis\n211\nwhich row reduces to\n\u23a1\n\u23a2\u23a2\u23a3\n1 0 0 1\n5\n0 1 0 0\n0 0 1 1\n5\n0 0 0 0\n\u23a4\n\u23a5\u23a5\u23a6 .\nThus, rank(\ud835\udc34) = 3. Since rank(\ud835\udc34) \u0338= 4, \ud835\udc463 is not linearly independent. Consequently, it is\nnot a basis either.\nFor set \ud835\udc464, we consider the matrix\n\ud835\udc35 =\n\u23a1\n\u23a2\u23a2\u23a3\n1 \u22121 4 4\n2 2 3 \u22123\n3 \u22123 2 2\n4 4 1 \u22121\n\u23a4\n\u23a5\u23a5\u23a6 ,\nwhich row reduces to\n\u23a1\n\u23a2\u23a2\u23a3\n1 0 0 0\n0 1 0 0\n0 0 1 0\n0 0 0 1\n\u23a4\n\u23a5\u23a5\u23a6 .\nSince rank(\ud835\udc35) = 4, it must be the case that \ud835\udc464 is linearly independent. Since \ud835\udc464 contains\nexactly four elements, it is a basis for R4 by Proposition 8.5.4 (\ud835\udc5b Vectors in F\ud835\udc5b Span iff\nIndependent).\nREMARK\nThere are two problems we might encounter when trying to obtain a basis for F\ud835\udc5b:\n(a) We might have a set of vectors \ud835\udc46 \u2286 F\ud835\udc5b with the property that Span (\ud835\udc46) = F\ud835\udc5b, but the\nset contains more than \ud835\udc5b vectors, which is too many to be a basis. In this case, \ud835\udc46 will be\nlinearly dependent. We may apply Proposition 8.3.6 (Pivots and Linear Independence)\nto produce a subset of \ud835\udc46 that is linearly independent, but still spans F\ud835\udc5b. This subset\nwill be a basis for F\ud835\udc5b.\n(b) We might have a set of vectors \ud835\udc46 \u2286 F\ud835\udc5b that is linearly independent, but that contains\nfewer than \ud835\udc5b vectors, which is too few to be a basis. In this case, Span (\ud835\udc46) \u0338= F\ud835\udc5b. The\nproblem here is to figure out which vectors to add to \ud835\udc46 to make it span F\ud835\udc5b. One possible\napproach is to add all \ud835\udc5b standard basis vectors to \ud835\udc46, obtaining a larger set \ud835\udc46\u2032. Then\ncertainly Span (\ud835\udc46\u2032) = F\ud835\udc5b, but now \ud835\udc46\u2032 is too large to be a basis. This brings us back to\n(a).\nWe summarize observations stated in the above remark in Theorem 8.5.6.\nTheorem 8.5.6\n(Basis From a Spanning Set or Linearly Independent Set)\nLet \ud835\udc46 = {#\u00bb\ud835\udc63 1, . . . , #\u00bb\ud835\udc63 \ud835\udc58} be a subset of F\ud835\udc5b.212\nChapter 8\nSubspaces and Bases\n(a) If Span(\ud835\udc46) = F\ud835\udc5b, then there exists a subset \u212c of \ud835\udc46 which is a basis for F\ud835\udc5b.\n(b) If Span(\ud835\udc46) \u0338= F\ud835\udc5b and \ud835\udc46 is linearly independent, then there exist vectors #\u00bb\ud835\udc63 \ud835\udc58+1, . . . , #\u00bb\ud835\udc63 \ud835\udc5b\nin F\ud835\udc5b such that \u212c = {#\u00bb\ud835\udc63 1, . . . , #\u00bb\ud835\udc63 \ud835\udc58, #\u00bb\ud835\udc63 \ud835\udc58+1, . . . , #\u00bb\ud835\udc63 \ud835\udc5b} is a basis for F\ud835\udc5b.\nExample 8.5.7\nFind a basis \u212c of R3 that contains the set\n\ud835\udc46 =\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n1\n2\n3\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n\u22123\n\u22124\n\u22126\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad .\nSolution: Notice that \ud835\udc46 is linearly independent, since the two vectors it contains are not\nmultiples of one another. We would like to extend \ud835\udc46 to a basis for R3. We begin by adding\nthe standard basis vectors to the set to obtain the set\n\ud835\udc46\u2032 =\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n1\n2\n3\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n\u22123\n\u22124\n\u22126\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n1\n0\n0\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n0\n1\n0\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n0\n0\n1\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad .\nNow Span \ud835\udc46\u2032 = R3 and we would like to extract a linearly independent subset from \ud835\udc46\u2032 using\nthe method of Proposition 8.3.6 (Pivots and Linear Independence).\nThe matrix whose\ncolumns are the vectors in \ud835\udc46\u2032 is\n\ud835\udc34 =\n\u23a1\n\u23a3\n1 \u22123 1 0 0\n2 \u22124 0 1 0\n3 \u22126 0 0 1\n\u23a4\n\u23a6 ,\nwhich row reduces to\n\u23a1\n\u23a3\n1 0 \u22122 0\n1\n0 1 \u22121 0\n1\n3\n0 0 0 1 \u2212 2\n3\n\u23a4\n\u23a6 .\nThere are pivots in columns 1, 2 and 4. Thus, columns 1, 2 and 4 of \ud835\udc34 are a basis for R3:\n\u212c =\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n1\n2\n3\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n\u22123\n\u22124\n\u22126\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n0\n1\n0\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad .\nIn the above, we only considered bases for the whole space F\ud835\udc5b. In the next section we will\ndiscuss examples of bases for special subspaces of F\ud835\udc5b. In Chapter 9 we will look at bases\nfor eigenspaces and we will discover a connection to the problem of diagonalizability that\nwe had met in Section 7.6.\n8.6", "Bases for Col(\ud835\udc34) and Null(\ud835\udc34)\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F). In Propositions 8.1.3 and 8.1.2, we saw that Col(\ud835\udc34) is a subspace of F\ud835\udc5a\nand that Null(\ud835\udc34) is a subspace of F\ud835\udc5b.Section 8.6\nBases for Col(\ud835\udc34) and Null(\ud835\udc34)\n213\nProposition 8.6.1\n(Basis for Col(\ud835\udc34))\nLet \ud835\udc34 =\n[\ufe00 #\u00bb\n\ud835\udc4e1 \u00b7 \u00b7 \u00b7 # \u00bb\n\ud835\udc4e\ud835\udc5b\n]\ufe00\n\u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F) and suppose that RREF(\ud835\udc34) has pivots in columns\n\ud835\udc5e1, . . . , \ud835\udc5e\ud835\udc5f, where \ud835\udc5f = rank(\ud835\udc34). Then {#  \u00bb\n\ud835\udc4e\ud835\udc5e1, . . . , #  \u00bb\n\ud835\udc4e\ud835\udc5e\ud835\udc5f} is a basis for Col(\ud835\udc34).\nProof: This follows from Proposition 8.3.6 (Pivots and Linear Independence).\nREMARK\nIt is important to note that the columns of \ud835\udc34\u2014and not those of RREF(\ud835\udc34)\u2014are the elements\nof the basis given in the previous proposition. In general, the columns in RREF(\ud835\udc34) are not\nnecessarily in Col(\ud835\udc34).\nExample 8.6.2\nLet \ud835\udc34 =\n\u23a1\n\u23a2\u23a2\u23a3\n1\n3\n3\n2 \u22129\n\u22122 \u22122 2 \u22128 2\n2\n3\n0\n7\n1\n3\n4 \u22121 11 \u22128\n\u23a4\n\u23a5\u23a5\u23a6. Find a basis for Col(\ud835\udc34).\nSolution: Row reduce \ud835\udc34 to\nRREF(\ud835\udc34) =\n\u23a1\n\u23a2\u23a2\u23a3\n1 0 \u22123 5 0\n0 1 2 \u22121 0\n0 0 0\n0 1\n0 0 0\n0 0\n\u23a4\n\u23a5\u23a5\u23a6 .\nSince there are pivots in columns 1, 2 and 5, we conclude that\n\u212c =\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n1\n\u22122\n2\n3\n\u23a4\n\u23a5\u23a5\u23a6 ,\n\u23a1\n\u23a2\u23a2\u23a3\n3\n\u22122\n3\n4\n\u23a4\n\u23a5\u23a5\u23a6 ,\n\u23a1\n\u23a2\u23a2\u23a3\n\u22129\n2\n1\n\u22128\n\u23a4\n\u23a5\u23a5\u23a6\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\nis a basis for Col(\ud835\udc34).\nNotice that in this example it would be incorrect to say that the set of pivot columns of\nRREF(\ud835\udc34) is a basis for Col(\ud835\udc34). Indeed, they all have 0 in the fourth component, so they\ncannot possibly span Col(\ud835\udc34). We can also show that\n\u23a1\n\u23a2\u23a2\u23a3\n0\n0\n1\n0\n\u23a4\n\u23a5\u23a5\u23a6 \u0338\u2208 Col(\ud835\udc34).\nNext we turn our attention to Null(\ud835\udc34). Recall that we can view this subspace as the solution\nset to the homogeneous system \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb0 . If we re-examine the Gauss\u2013Jordan Algorithm,\nwe find that it provides us with a basis for Null(\ud835\udc34). Indeed, the solutions corresponding to\nthe free parameters are by design a basis for Null(\ud835\udc34).214\nChapter 8\nSubspaces and Bases\nExample 8.6.3\nLet \ud835\udc34 =\n\u23a1\n\u23a3\n1 \u22122 \u22121 3\n2 \u22124 1\n0\n1 \u22122 2 \u22123\n\u23a4\n\u23a6. Find a basis for Null(\ud835\udc34).\nSolution: The matrix \ud835\udc34 is the coefficient matrix of the homogeneous system of linear\nequations\n\ud835\udc651\n\u22122\ud835\udc652\n\u2212\ud835\udc653\n+3\ud835\udc654\n=\n0\n2\ud835\udc651\n\u22124\ud835\udc652\n+\ud835\udc653\n=\n0\n\ud835\udc651\n\u22122\ud835\udc652\n+2\ud835\udc653\n\u22123\ud835\udc654\n=\n0\n.\nThus, Null(\ud835\udc34) is the solution set to this system. In Example 3.7.4, we applied the Gauss\u2013\nJordan Algorithm to find that the solution to this system is\nNull(\ud835\udc34) =\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n2\ud835\udc60 \u2212 \ud835\udc61\n\ud835\udc60\n2\ud835\udc61\n\ud835\udc61\n\u23a4\n\u23a5\u23a5\u23a6 : \ud835\udc60, \ud835\udc61 \u2208 F\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n=\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\ud835\udc60\n\u23a1\n\u23a2\u23a2\u23a3\n2\n1\n0\n0\n\u23a4\n\u23a5\u23a5\u23a6 + \ud835\udc61\n\u23a1\n\u23a2\u23a2\u23a3\n\u22121\n0\n2\n1\n\u23a4\n\u23a5\u23a5\u23a6 : \ud835\udc60, \ud835\udc61 \u2208 F\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n.\nNotice that the Gauss\u2013Jordan Algorithm immediately supplies us with the spanning set\n\u212c =\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n2\n1\n0\n0\n\u23a4\n\u23a5\u23a5\u23a6 ,\n\u23a1\n\u23a2\u23a2\u23a3\n\u22121\n0\n2\n1\n\u23a4\n\u23a5\u23a5\u23a6\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n.\nMoreover, observe that this spanning set is linearly independent since the two vectors it\ncontains are not multiples of each other. Thus, \u212c is a basis for Null(\ud835\udc34).\nDigging a bit deeper, the real reason the set \u212c in the previous example is linearly inde-\npendent is because it contains the solution vectors that were constructed using the free\nparameters \ud835\udc652 and \ud835\udc654. (Refer back to Example 3.7.4.) This forces the first vector in the\nspanning set to have a 1 in the second component and forces the second vector to have\na 0 in the second component. (It also forces the second vector to have a 1 in the fourth\ncomponent and the first vector to have a 0 in the fourth component.)\nExample 8.6.4\nLet \ud835\udc34 =\n\u23a1\n\u23a3\n\u22121 \u22121 \u22122 3\n1\n\u22129 5 \u22124 \u22121 \u22125\n7 \u22125 2\n3\n5\n\u23a4\n\u23a6. Find a basis for Null(\ud835\udc34).\nSolution:\nThe matrix \ud835\udc34 is the coefficient matrix of the homogeneous system of linear equations\n\u2212\ud835\udc651\n\u22122\ud835\udc652\n\u22122\ud835\udc653\n+3\ud835\udc654\n+\ud835\udc655\n=\n0\n\u22129\ud835\udc651\n5\ud835\udc652\n\u22124\ud835\udc653\n\u2212\ud835\udc654\n\u22125\ud835\udc655\n=\n0\n7\ud835\udc651\n\u22125\ud835\udc652\n+2\ud835\udc653\n+3\ud835\udc654\n+5\ud835\udc655\n=\n0\n.\nThus, Null(\ud835\udc34) is the solution set to this system. We have\nRREF(\ud835\udc34) =\n\u23a1\n\u23a3\n1 0 1 \u22121 0\n0 1 1 \u22122 \u22121\n0 0 0 0\n0\n\u23a4\n\u23a6 .Section 8.6\nBases for Col(\ud835\udc34) and Null(\ud835\udc34)\n215\nThere are pivots in columns 1 and 2, so we may take \ud835\udc653 = \ud835\udc60, \ud835\udc654 = \ud835\udc61 and \ud835\udc655 = \ud835\udc5f as free\nparameters. Then \ud835\udc651 = \u2212\ud835\udc653 + \ud835\udc654 = \u2212\ud835\udc60 + \ud835\udc61 and \ud835\udc652 = \u2212\ud835\udc653 + 2\ud835\udc654 + \ud835\udc655 = \u2212\ud835\udc60 + 2\ud835\udc61 + \ud835\udc5f, and\ntherefore, the solution set is given by\nNull(\ud835\udc34) =\n\u23a7\n\u23aa\n\u23aa\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n\u2212\ud835\udc60 + \ud835\udc61\n\u2212\ud835\udc60 + 2\ud835\udc61 + \ud835\udc5f\n\ud835\udc60\n\ud835\udc61\n\ud835\udc5f\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\n: \ud835\udc60, \ud835\udc61, \ud835\udc5f \u2208 F\n\u23ab\n\u23aa\n\u23aa\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23aa\n\u23aa\n\u23ad\n=\n\u23a7\n\u23aa\n\u23aa\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23aa\n\u23aa\n\u23a9\n\ud835\udc60\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n\u22121\n\u22121\n1\n0\n0\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\n+ \ud835\udc61\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n1\n2\n0\n1\n0\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\n+ \ud835\udc5f\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n0\n1\n0\n0\n1\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\n: \ud835\udc60, \ud835\udc61, \ud835\udc5f \u2208 F\n\u23ab\n\u23aa\n\u23aa\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23aa\n\u23aa\n\u23ad\n.\nConsequently, the set\n\u212c =\n\u23a7\n\u23aa\n\u23aa\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n\u22121\n\u22121\n1\n0\n0\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\n,\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n1\n2\n0\n1\n0\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\n,\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n0\n1\n0\n0\n1\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\n\u23ab\n\u23aa\n\u23aa\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23aa\n\u23aa\n\u23ad\nis a spanning set for Null(\ud835\udc34). It is also linearly independent. Indeed, if some linear combi-\nnation of the vectors in the set is zero, that is,\n\ud835\udc60\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n\u22121\n\u22121\n1\n0\n0\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\n+ \ud835\udc61\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n1\n2\n0\n1\n0\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\n+ \ud835\udc5f\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n0\n1\n0\n0\n1\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\n=\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n0\n0\n0\n0\n0\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\n,\nthen\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n\u2212\ud835\udc60 + \ud835\udc61\n\u2212\ud835\udc60 + 2\ud835\udc61 + \ud835\udc5f\n\ud835\udc60\n\ud835\udc61\n\ud835\udc5f\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\n=\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n0\n0\n0\n0\n0\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\nand hence \ud835\udc60 = \ud835\udc61 = \ud835\udc5f = 0 by equating the third, fourth and fifth entries.\nSo the only\npossible such linear combination is the trivial linear combination. Therefore, \u212c is linearly\nindependent.\nNotice that the third, fourth and fifth entries correspond to the free parameters. This is no\ncoincidence. Indeed, in the set \u212c, each vector has a nonzero entry in the row corresponding\nto its free parameter while all other vectors in \u212c have a 0 in that same row.\nThe results in the previous two examples may be generalized as follows.\nProposition 8.6.5\n(Basis for Null(\ud835\udc34))\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F) and consider the homogeneous linear system \ud835\udc34#\u00bb\ud835\udc65 = #\u00bb0 . Suppose that,\nafter applying the Gauss\u2013Jordan Algorithm, we obtain \ud835\udc58 free parameters so that the solution\nset to this system is given by\nNull(\ud835\udc34) = {\ud835\udc611 # \u00bb\n\ud835\udc651 + \u00b7 \u00b7 \u00b7 + \ud835\udc61\ud835\udc58 # \u00bb\n\ud835\udc65\ud835\udc58 : \ud835\udc611, . . . , \ud835\udc61\ud835\udc58 \u2208 F}.216\nChapter 8\nSubspaces and Bases\nHere \ud835\udc58 = nullity(\ud835\udc34) = \ud835\udc5b \u2212 rank(\ud835\udc34) and the parameters \ud835\udc61\ud835\udc56 and the vectors #\u00bb\n\ud835\udc65\ud835\udc56 for 1 \u2264 \ud835\udc56 \u2264 \ud835\udc58\nare obtained using the method outlined in Section 3.7.\nThen {# \u00bb\n\ud835\udc651, . . . , # \u00bb\n\ud835\udc65\ud835\udc58} is a basis for Null(\ud835\udc34).\nProof: Since Null(\ud835\udc34) = {\ud835\udc611 # \u00bb\n\ud835\udc651 + \u00b7 \u00b7 \u00b7 + \ud835\udc61\ud835\udc58 # \u00bb\n\ud835\udc65\ud835\udc58 : \ud835\udc611, . . . , \ud835\udc61\ud835\udc58 \u2208 F}, we see that \u212c = {# \u00bb\n\ud835\udc651, . . . , # \u00bb\n\ud835\udc65\ud835\udc58} is\na spanning set. The fact that it is linearly independent follows from the way the solution\nvectors #\u00bb\n\ud835\udc65\ud835\udc56 were constructed such that only #\u00bb\n\ud835\udc65\ud835\udc56 has a nonzero entry in the row corresponding\nto the \ud835\udc56\ud835\udc61\u210e free variable. So if there are scalars \ud835\udc50\ud835\udc56 \u2208 F so that\n\ud835\udc501 # \u00bb\n\ud835\udc651 + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc58 # \u00bb\n\ud835\udc65\ud835\udc58 = #\u00bb0 ,\nthen by comparing \ud835\udc56\ud835\udc61\u210e coefficients of both sides of the equation, we get that \ud835\udc50\ud835\udc56 = 0 for all \ud835\udc56.\nThus, \u212c is a basis for Null(\ud835\udc34), as claimed.\n8.7", "Dimension\nA nonzero subspace \ud835\udc49 of F\ud835\udc5b will have infinitely many different bases. If \u212c = {#\u00bb\n\ud835\udc631, . . . , #\u00bb\n\ud835\udc63\ud835\udc58} is\na basis for \ud835\udc49 , then so is \u212c\u2032 = {\ud835\udc50#\u00bb\n\ud835\udc631, . . . , #\u00bb\n\ud835\udc63\ud835\udc58} for any nonzero scalar \ud835\udc50 \u2208 F. More drastically,\ntwo different bases can contain substantially different vectors, and not just ones that are\nscalar multiples of each other.\nExample 8.7.1\nIn Section 8.5, we saw two bases for R4: the standard basis\n\ud835\udcae = {#\u00bb\n\ud835\udc521, #\u00bb\n\ud835\udc522, #\u00bb\n\ud835\udc523, #\u00bb\n\ud835\udc524} =\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n1\n0\n0\n0\n\u23a4\n\u23a5\u23a5\u23a6 ,\n\u23a1\n\u23a2\u23a2\u23a3\n0\n1\n0\n0\n\u23a4\n\u23a5\u23a5\u23a6 ,\n\u23a1\n\u23a2\u23a2\u23a3\n0\n0\n1\n0\n\u23a4\n\u23a5\u23a5\u23a6 ,\n\u23a1\n\u23a2\u23a2\u23a3\n0\n0\n0\n1\n\u23a4\n\u23a5\u23a5\u23a6\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n,\nand the basis\n\ud835\udc464 =\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n1\n2\n3\n4\n\u23a4\n\u23a5\u23a5\u23a6 ,\n\u23a1\n\u23a2\u23a2\u23a3\n\u22121\n2\n\u22123\n4\n\u23a4\n\u23a5\u23a5\u23a6 ,\n\u23a1\n\u23a2\u23a2\u23a3\n4\n3\n2\n1\n\u23a4\n\u23a5\u23a5\u23a6 ,\n\u23a1\n\u23a2\u23a2\u23a3\n4\n\u22123\n2\n\u22121\n\u23a4\n\u23a5\u23a5\u23a6\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\ngiven in Example 8.5.5. From our work in Example 8.4.7(b), we can obtain yet another\nbasis:\n\ud835\udc462 =\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n1\n1\n1\n1\n\u23a4\n\u23a5\u23a5\u23a6 ,\n\u23a1\n\u23a2\u23a2\u23a3\n2\n\u22122\n3\n\u22123\n\u23a4\n\u23a5\u23a5\u23a6 ,\n\u23a1\n\u23a2\u23a2\u23a3\n2\n4\n6\n8\n\u23a4\n\u23a5\u23a5\u23a6 ,\n\u23a1\n\u23a2\u23a2\u23a3\n5\n3\n10\n6\n\u23a4\n\u23a5\u23a5\u23a6\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n.\nAlthough the three sets in the above example contain different vectors, they share one thing\nin common. They each contain precisely four vectors. This agrees with Proposition 8.5.3\n(Size of Basis for F\ud835\udc5b), which states that a basis for F\ud835\udc5b must contain precisely \ud835\udc5b vectors.\nThe same kind of result is true for a subspace \ud835\udc49 of F\ud835\udc5b. Even though \ud835\udc49 may have many\ndifferent bases, any two bases will have the same number of elements.Section 8.7\nDimension\n217\nTheorem 8.7.2\n(Dimension is Well-Defined)\nLet \ud835\udc49 be a subspace of F\ud835\udc5b. If \u212c = {#\u00bb\n\ud835\udc631, . . . , #\u00bb\n\ud835\udc63\ud835\udc58} and \ud835\udc9e = {# \u00bb\n\ud835\udc641, . . . , # \u00bb\n\ud835\udc64\u2113} are bases for \ud835\udc49 , then\n\ud835\udc58 = \u2113.\nProof: Since \u212c and \ud835\udc9e are bases for \ud835\udc49 , we have that \ud835\udc49 = Span (\u212c) = Span (\ud835\udc9e). This means,\nin particular, that # \u00bb\n\ud835\udc641 \u2208 Span (\u212c). Thus there are scalars \ud835\udc501, . . . , \ud835\udc50\ud835\udc58 such that\n# \u00bb\n\ud835\udc641 = \ud835\udc501 #\u00bb\n\ud835\udc631 + \ud835\udc502 #\u00bb\n\ud835\udc632 + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc58 #\u00bb\n\ud835\udc63\ud835\udc58.\nAt least one of these scalars must be nonzero, for if they were all zero then # \u00bb\n\ud835\udc641 would be\nequal to #\u00bb0 , which would contradict the fact that \ud835\udc9e is linearly independent (by Proposition\n8.3.2(a)).\nWe may assume, without loss of generality, that \ud835\udc501 \u0338= 0. Then we can write\n#\u00bb\n\ud835\udc631 = 1\n\ud835\udc501\n(# \u00bb\n\ud835\udc641 \u2212 \ud835\udc502 #\u00bb\n\ud835\udc632 \u2212 \u00b7 \u00b7 \u00b7 \u2212 \ud835\udc50\ud835\udc58 #\u00bb\n\ud835\udc63\ud835\udc58).\nThis shows that Span{#\u00bb\n\ud835\udc631, . . . , #\u00bb\n\ud835\udc63\ud835\udc58} = Span{# \u00bb\n\ud835\udc641, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58}. Thus, we have effectively replaced\n#\u00bb\n\ud835\udc631 with # \u00bb\n\ud835\udc641. By repeating this same argument with # \u00bb\n\ud835\udc641, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58 and # \u00bb\n\ud835\udc642, we can show\nthat we can replace some other #\u00bb\n\ud835\udc63\ud835\udc56, say without loss of generality #\u00bb\n\ud835\udc632, while still having\nSpan{#\u00bb\n\ud835\udc631, . . . , #\u00bb\n\ud835\udc63\ud835\udc58} = Span{# \u00bb\n\ud835\udc641, # \u00bb\n\ud835\udc642, #\u00bb\n\ud835\udc633, . . . , #\u00bb\n\ud835\udc63\ud835\udc58}. We can continue this replacement procedure\nfor each # \u00bb\n\ud835\udc64\ud835\udc56 in \ud835\udc9e. This is only possible if \u2113 \u2264 \ud835\udc58.\nUsing a similar argument where the roles of \u212c and \ud835\udc9e are swapped, we must also have that\n\ud835\udc58 \u2264 \u2113. Thus, \ud835\udc58 = \u2113.\nDefinition 8.7.3\nDimension\nThe number of elements in a basis for a subspace \ud835\udc49 of F\ud835\udc5b is called the dimension of \ud835\udc49 .\nWe denote this number by dim(\ud835\udc49 ).\nSince every subspace \ud835\udc49 of F\ud835\udc5b has a basis (by Theorem 8.5.1 (Every Subspace Has a Basis)),\nand since we just proved in Theorem 8.7.2 (Dimension is Well-Defined) that any two bases for\n\ud835\udc49 have the same number of elements, we see that dim(\ud835\udc49 ) is well-defined (or unambiguous).\nWe can evaluate dim(\ud835\udc49 ) by counting the number of vectors in any basis for \ud835\udc49 .\nExample 8.7.4\nThe standard basis \u2130 = {#\u00bb\n\ud835\udc521, . . . , #\u00bb\n\ud835\udc52\ud835\udc5b} of F\ud835\udc5b consist of \ud835\udc5b vectors. Thus, dim(F\ud835\udc5b) = \ud835\udc5b. This\naligns with our intuition of F\ud835\udc5b being \u201c\ud835\udc5b-dimensional\u201d.\nHow large can the dimension of a subspace of F\ud835\udc5b be?\nProposition 8.7.5\n(Bound on Dimension of Subspace)\nLet \ud835\udc49 be a subspace of F\ud835\udc5b. Then dim(\ud835\udc49 ) \u2264 \ud835\udc5b.\nProof: The proof of Theorem 8.4.1 (Every Subspace Has a Spanning Set) gave us that every\nsubspace has a basis, and established that the basis generated in the proof was guaranteed\nto have at most \ud835\udc5b elements.218\nChapter 8\nSubspaces and Bases\nEXERCISE\nLet \ud835\udc49 be a subspace of F\ud835\udc5b. Show that \ud835\udc49 = F\ud835\udc5b if and only if dim(\ud835\udc49 ) = \ud835\udc5b.\nExample 8.7.6\nLet \ud835\udc3f be the line through the origin in R\ud835\udc5b with direction vector #\u00bb\ud835\udc51 \u0338= #\u00bb0 . That is,\n\ud835\udc3f = {\ud835\udc61#\u00bb\ud835\udc51 : \ud835\udc61 \u2208 R} = Span\n{\ufe01#\u00bb\ud835\udc51\n}\ufe01\n.\nSince #\u00bb\ud835\udc51 \u0338= 0, the set\n{\ufe01#\u00bb\ud835\udc51\n}\ufe01\nis linearly independent, and by the above it spans \ud835\udc3f. Thus,\n\u212c =\n{\ufe01#\u00bb\ud835\udc51\n}\ufe01\nis a basis for \ud835\udc3f. Consequently, dim(\ud835\udc3f) = 1.\nThat is, lines through the origin are 1-dimensional subspaces of R\ud835\udc5b.\nExample 8.7.7\nLet \ud835\udc43 be the plane in R3 given by the scalar equation 2\ud835\udc65 \u2212 6\ud835\udc66 + 4\ud835\udc67 = 0. In Example 8.4.3,\nwe saw that\n\ud835\udc46 =\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n3\n1\n0\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n\u22122\n0\n1\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad\nis a basis for \ud835\udc43. Thus, dim(\ud835\udc43) = 2.\nMore generally, if \ud835\udc43 is any plane through the origin in R3, then we can show that any two\nlinearly independent vectors in \ud835\udc43 will form a basis for \ud835\udc43. Thus, dim(\ud835\udc43) = 2 in all cases.\nThat is, planes through the origin are 2-dimensional subspaces of R\ud835\udc5b.\nThe next two examples of dimension computations are important enough to warrant being\nput in a proposition.\nProposition 8.7.8\n(Rank and Nullity as Dimensions)\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F). Then\n(a) rank(\ud835\udc34) = dim(Col(\ud835\udc34)), and\n(b) nullity(\ud835\udc34) = dim(Null(\ud835\udc34)).\nProof: (a) follows from Proposition 8.6.1 (Basis for Col(\ud835\udc34)).\n(b) follows from Proposition 8.6.5 (Basis for Null(\ud835\udc34)).\nUsing the definition of nullity (Definition 3.6.8), we arrive at the following important result.Section 8.8", "Coordinates\n219\nTheorem 8.7.9\n(Rank\u2013Nullity Theorem)\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F). Then\n\ud835\udc5b = rank(\ud835\udc34) + nullity(\ud835\udc34)\n= dim(Col(\ud835\udc34)) + dim(Null(\ud835\udc34)).\nProof: This result follows immediately from the fact that nullity(\ud835\udc34) = \ud835\udc5b \u2212 rank(\ud835\udc34), to-\ngether with Proposition 8.7.8 (Rank and Nullity as Dimensions).\nThis relationship between rank and nullity is one of the central results of linear algebra.\nAlthough the above proof seems short, it contains a significant amount of content.\n8.8\nCoordinates\nIn this section, we discuss one of the most important results about a basis. This result will\nnaturally lead us to the idea of coordinates with respect to bases.\nTheorem 8.8.1\n(Unique Representation Theorem)\nLet \u212c = {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , # \u00bb\n\ud835\udc63\ud835\udc5b} be a basis for F\ud835\udc5b. Then, for every vector #\u00bb\ud835\udc63 \u2208 F\ud835\udc5b, there exist unique\nscalars \ud835\udc501, \ud835\udc502, . . . , \ud835\udc50\ud835\udc5b \u2208 F such that\n#\u00bb\ud835\udc63 = \ud835\udc501 #\u00bb\n\ud835\udc631 + \ud835\udc502 #\u00bb\n\ud835\udc632 + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc5b # \u00bb\n\ud835\udc63\ud835\udc5b.\nProof: First we prove that such scalars exist. Since \u212c is a basis for F\ud835\udc5b, Span (\u212c) = F\ud835\udc5b,\nand so each vector #\u00bb\ud835\udc63 can be written as a linear combination of elements of \u212c, that is, there\nexist scalars \ud835\udc501, \ud835\udc502, . . . , \ud835\udc50\ud835\udc5b \u2208 F such that #\u00bb\ud835\udc63 = \ud835\udc501 #\u00bb\n\ud835\udc631 + \ud835\udc502 #\u00bb\n\ud835\udc632 + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc5b # \u00bb\n\ud835\udc63\ud835\udc5b.\nNext, we show that the representation is unique. Suppose that we can also express #\u00bb\ud835\udc63 as\n#\u00bb\ud835\udc63 = \ud835\udc511 #\u00bb\n\ud835\udc631 + \ud835\udc512 #\u00bb\n\ud835\udc632 + \u00b7 \u00b7 \u00b7 + \ud835\udc51\ud835\udc5b # \u00bb\n\ud835\udc63\ud835\udc5b, for some scalars \ud835\udc511, \ud835\udc512, . . . , \ud835\udc51\ud835\udc5b \u2208 F.\nIf we subtract these two expressions for #\u00bb\ud835\udc63 , then we have\n#\u00bb0 = #\u00bb\ud835\udc63 \u2212 #\u00bb\ud835\udc63 = (\ud835\udc501 #\u00bb\n\ud835\udc631 + \ud835\udc502 #\u00bb\n\ud835\udc632 + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc5b # \u00bb\n\ud835\udc63\ud835\udc5b) \u2212 (\ud835\udc511 #\u00bb\n\ud835\udc631 + \ud835\udc512 #\u00bb\n\ud835\udc632 + \u00b7 \u00b7 \u00b7 + \ud835\udc51\ud835\udc5b # \u00bb\n\ud835\udc63\ud835\udc5b)\n= (\ud835\udc501 \u2212 \ud835\udc511)#\u00bb\n\ud835\udc631 + (\ud835\udc502 \u2212 \ud835\udc512)#\u00bb\n\ud835\udc632 + \u00b7 \u00b7 \u00b7 + (\ud835\udc50\ud835\udc5b \u2212 \ud835\udc51\ud835\udc5b)# \u00bb\n\ud835\udc63\ud835\udc5b.\nSince \u212c is linearly independent, we have that (\ud835\udc501 \u2212 \ud835\udc511) = 0, (\ud835\udc502 \u2212 \ud835\udc512) = 0, . . . , (\ud835\udc50\ud835\udc5b \u2212 \ud835\udc51\ud835\udc5b) = 0.\nThat is, \ud835\udc501 = \ud835\udc511, \ud835\udc502 = \ud835\udc512, . . . , \ud835\udc50\ud835\udc5b = \ud835\udc51\ud835\udc5b, and thus, the representation for #\u00bb\ud835\udc63 is unique.\nExample 8.8.2\nLet \u2130 = {#\u00bb\n\ud835\udc521, . . . , #\u00bb\n\ud835\udc52\ud835\udc5b} be the standard basis for F\ud835\udc5b. Given #\u00bb\ud835\udc65 =\n\u23a1\n\u23a2\u23a3\n\ud835\udc651\n...\n\ud835\udc65\ud835\udc5b\n\u23a4\n\u23a5\u23a6 \u2208 F\ud835\udc5b, we have\n#\u00bb\ud835\udc65 = \ud835\udc651 #\u00bb\n\ud835\udc521 + \u00b7 \u00b7 \u00b7 + \ud835\udc65\ud835\udc5b #\u00bb\n\ud835\udc52\ud835\udc5b.220\nChapter 8\nSubspaces and Bases\nThus, the unique scalars in the representation of #\u00bb\ud835\udc65 in terms of the standard basis are the\ncoordinates (or components) of #\u00bb\ud835\udc65.\nThe previous Example motivates our next definition.\nDefinition 8.8.3\nCoordinates and\nComponents\nLet \u212c = {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , # \u00bb\n\ud835\udc63\ud835\udc5b} be a basis for F\ud835\udc5b. Let the vector #\u00bb\ud835\udc63 \u2208 F\ud835\udc5b have representation\n#\u00bb\ud835\udc63 = \ud835\udc501 #\u00bb\n\ud835\udc631 + \ud835\udc502 #\u00bb\n\ud835\udc632 + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc5b # \u00bb\n\ud835\udc63\ud835\udc5b\n(\ud835\udc50\ud835\udc56 \u2208 F).\nWe call the scalars \ud835\udc501, \ud835\udc502, . . . , \ud835\udc50\ud835\udc5b the coordinates (or components) of #\u00bb\ud835\udc63 with respect\nto \u212c, or the \u212c-coordinates of #\u00bb\ud835\udc63 .\nWe would like to use this definition to create a column vector\n\u23a1\n\u23a2\u23a3\n\ud835\udc501\n...\n\ud835\udc50\ud835\udc5b\n\u23a4\n\u23a5\u23a6 using the coordinates\n\ud835\udc501, . . . , \ud835\udc50\ud835\udc5b of #\u00bb\ud835\udc63 with respect to \u212c. However, the ordering of the vectors in a basis (that\nis, the assignment of labels 1, 2, ..., \ud835\udc5b for #\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, ..., # \u00bb\n\ud835\udc63\ud835\udc5b) is arbitrary, and permutations of the\nordering result in the same basis. Unfortunately, each of these permutations can result in\ndifferent representations of the vector under \u212c, which could be a source of confusion.\nThe next definition helps us address this subtlety.\nDefinition 8.8.4\nOrdered Basis\nAn ordered basis for F\ud835\udc5b is a basis \u212c = {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , # \u00bb\n\ud835\udc63\ud835\udc5b} for F\ud835\udc5b together with a fixed\nordering.\nREMARK\nWhen we refer to the set {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , # \u00bb\n\ud835\udc63\ud835\udc5b} as being ordered, we are indicating that #\u00bb\n\ud835\udc631 is the\nfirst element in the ordering, that #\u00bb\n\ud835\udc632 is the second, and so on.\nThus even though {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632} and {#\u00bb\n\ud835\udc632, #\u00bb\n\ud835\udc631} are the same set, they are different from the point\nof view of orderings.\nA given basis {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , # \u00bb\n\ud835\udc63\ud835\udc5b} gives rise to \ud835\udc5b! ordered bases, one for each possible ordering\n(permutation) of the entries.\nExample 8.8.5\nThe set \u212c =\n{\ufe02[\ufe021\n2\n]\ufe02\n,\n[\ufe025\n6\n]\ufe02}\ufe02\nis a basis for R2. The two vectors in \u212c are not multiples of each\nother, so \u212c is linearly independent. Since \u212c contains precisely two vectors, it must also\nspan R2, by Proposition 8.5.4 (\ud835\udc5b Vectors in F\ud835\udc5b Span iff Independent). Hence \u212c is a basis\nfor R2.\nThe basis \u212c gives rise to two different ordered bases:\n{\ufe02[\ufe021\n2\n]\ufe02\n,\n[\ufe025\n6\n]\ufe02}\ufe02\nand\n{\ufe02[\ufe025\n6\n]\ufe02\n,\n[\ufe021\n2\n]\ufe02}\ufe02\n.Section 8.8\nCoordinates\n221\nDefinition 8.8.6\nCoordinate Vector\nLet \u212c = {#\u00bb\n\ud835\udc631, . . . , # \u00bb\n\ud835\udc63\ud835\udc5b} be an ordered basis for F\ud835\udc5b. Let #\u00bb\ud835\udc63 \u2208 F\ud835\udc5b have coordinates \ud835\udc501, . . . , \ud835\udc50\ud835\udc5b\nwith respect to \u212c, where the ordering of the scalars \ud835\udc50\ud835\udc56 matches the ordering in \u212c, that is,\n#\u00bb\ud835\udc63 =\n\ud835\udc5b\n\u2211\ufe01\n\ud835\udc56=1\n\ud835\udc50\ud835\udc56 #\u00bb\n\ud835\udc63\ud835\udc56.\nThen the coordinate vector of #\u00bb\ud835\udc63 with respect to \u212c (or the \u212c-coordinate vector of\n#\u00bb\ud835\udc63 ) is the column vector in F\ud835\udc5b\n[#\u00bb\ud835\udc63 ]\u212c =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc501\n\ud835\udc502\n...\n\ud835\udc50\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 .\nIf we choose a different ordering on the basis \u212c then the entries of [#\u00bb\ud835\udc63 ]\u212c will be permuted\naccordingly.\nExample 8.8.7\nConsider the ordered basis \u212c =\n{\ufe02[\ufe021\n2\n]\ufe02\n,\n[\ufe025\n6\n]\ufe02}\ufe02\nfor R2 and let #\u00bb\ud835\udc63 =\n[\ufe02 7\n10\n]\ufe02\n. By inspection, we\nhave\n#\u00bb\ud835\udc63 = (2)\n[\ufe021\n2\n]\ufe02\n+ (1)\n[\ufe025\n6\n]\ufe02\n.\nSo the \u212c-coordinates of #\u00bb\ud835\udc63 are 2 and 1. Therefore,\n[#\u00bb\ud835\udc63 ]\u212c =\n[\ufe022\n1\n]\ufe02\n.\nIf we instead use the ordered basis \ud835\udc9e =\n{\ufe02[\ufe025\n6\n]\ufe02\n,\n[\ufe021\n2\n]\ufe02}\ufe02\n, we would have\n[#\u00bb\ud835\udc63 ]\ud835\udc9e =\n[\ufe021\n2\n]\ufe02\n.\nIn using coordinates, it is therefore important to indicate clearly which ordered basis you\nare using.\nREMARK (Standard Ordering)\nLet \u2130 = {#\u00bb\n\ud835\udc521, . . . , #\u00bb\n\ud835\udc52\ud835\udc5b} be the standard basis for F\ud835\udc5b, ordered so that #\u00bb\n\ud835\udc52\ud835\udc56 is the \ud835\udc56th vector. We\ncall this the standard ordering. Unless explicitly stated otherwise, we always assume\nthat \u2130 is given the standard ordering.\nIn the early part of the course, we had been implicitly using coordinate vectors with respect222\nChapter 8\nSubspaces and Bases\nto \u2130. Indeed, whenever we had written\n#\u00bb\ud835\udc63 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc631\n\ud835\udc632\n...\n\ud835\udc63\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6\nwe were implicitly writing down [#\u00bb\ud835\udc63 ]\u2130.\nMoving forwards, when we attempt to describe some vector in F\ud835\udc5b, we still have to represent\nit somehow. Unless we have some other explicit arrangement, we will do this as above, i.e.,\nby making use of the standard basis (with its standard ordering). We will often suppress\nthe notation [#\u00bb\ud835\udc63 ]\u2130 when doing so, and instead simply write #\u00bb\ud835\udc63 as we have been doing so far.\nREMARK\nThe notation of [#\u00bb\ud835\udc63 ]\u2130 (and more generally [#\u00bb\ud835\udc63 ]\u212c) is reminiscent of the notation [\ud835\udc47]\u2130 for the\nstandard matrix representation of the linear transformation \ud835\udc47. In both cases, the notation\nconveys the idea that we are taking an object (a vector or linear transformation) and\nrepresenting it as an array of numbers (a column vector or matrix) by using a basis to\nobtain this representation.\nThere is another connection between these two pieces of notation, as we will see later.\nNote that for an ordered basis \u212c = {#\u00bb\n\ud835\udc631, . . . , # \u00bb\n\ud835\udc63\ud835\udc5b} of F\ud835\udc5b, the relationship between #\u00bb\ud835\udc63 and [#\u00bb\ud835\udc63 ]\u212c\nis a two-way relationship:\n#\u00bb\ud835\udc63 = \ud835\udc501 #\u00bb\n\ud835\udc631 + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc5b # \u00bb\n\ud835\udc63\ud835\udc5b \u21d0\u21d2 [#\u00bb\ud835\udc63 ]\u212c =\n\u23a1\n\u23a2\u23a3\n\ud835\udc501\n...\n\ud835\udc50\ud835\udc5b\n\u23a4\n\u23a5\u23a6 .\nThus, if we have #\u00bb\ud835\udc63 , we can obtain [#\u00bb\ud835\udc63 ]\u212c, and vice versa. We leave the proof of the following\nresult as an exercise.\nTheorem 8.8.8\n(Linearity of Taking Coordinates)\nLet \u212c = {#\u00bb\n\ud835\udc631, . . . , # \u00bb\n\ud835\udc63\ud835\udc5b} be an ordered basis for F\ud835\udc5b. Then the function [\n]\u212c : F\ud835\udc5b \u2192 F\ud835\udc5b defined\nby sending #\u00bb\ud835\udc63 to [#\u00bb\ud835\udc63 ]\u212c is linear:\n(a) For all #\u00bb\ud835\udc62, #\u00bb\ud835\udc63 \u2208 F\ud835\udc5b, [#\u00bb\ud835\udc62 + #\u00bb\ud835\udc63 ]\u212c = [#\u00bb\ud835\udc62]\u212c + [#\u00bb\ud835\udc63 ]\u212c.\n(b) For all #\u00bb\ud835\udc63 \u2208 F\ud835\udc5b and \ud835\udc50 \u2208 F, [\ud835\udc50#\u00bb\ud835\udc63 ]\u212c = \ud835\udc50[#\u00bb\ud835\udc63 ]\u212c.\nWe now provide some examples of computing coordinates with respect to bases for F\ud835\udc5b.Section 8.8\nCoordinates\n223\nExample 8.8.9\nConsider the ordered basis \u212c =\n{\ufe02[\ufe021\n2\n]\ufe02\n,\n[\ufe025\n6\n]\ufe02}\ufe02\nfor R2. Let #\u00bb\ud835\udc63 =\n[\ufe023\n4\n]\ufe02\n. (By this we mean [#\u00bb\ud835\udc63 ]\u2130,\nas explained at the end of the above remark on the standard ordering.)\n(a) Find [#\u00bb\ud835\udc63 ]\u212c.\n(b) If [#\u00bb\ud835\udc64]\u212c =\n[\ufe02\u22123\n2\n]\ufe02\n, find #\u00bb\ud835\udc64 (i.e., find [#\u00bb\ud835\udc64]\u2130).\nSolution:\n(a) To find [#\u00bb\ud835\udc63 ]\u212c, we need to find the coordinates of #\u00bb\ud835\udc63 with respect to \u212c. Thus, we want\nto find \ud835\udc4e, \ud835\udc4f \u2208 F so that\n\ud835\udc4e\n[\ufe021\n2\n]\ufe02\n+ \ud835\udc4f\n[\ufe025\n6\n]\ufe02\n=\n[\ufe023\n4\n]\ufe02\n.\nThis leads us to the system\n[\ufe021 5\n2 6\n]\ufe02 [\ufe02\ud835\udc4e\n\ud835\udc4f\n]\ufe02\n=\n[\ufe023\n4\n]\ufe02\nwith augmented matrix\n[\ufe02 1\n5\n3\n2\n6\n4\n]\ufe02\n,\nwhich reduces to\n[\ufe03\n1\n0\n1\n2\n0\n1\n1\n2\n]\ufe03\n.\nThus, \ud835\udc4e = 1\n2 and \ud835\udc4f = 1\n2. These are the coordinates of #\u00bb\ud835\udc63 with respect of \u212c. Therefore,\n[\ufe03\n3\n4\n]\ufe03\n\u212c\n=\n[\ufe03\n1\n2\n1\n2\n]\ufe03\n.\n(b) We are given that [#\u00bb\ud835\udc64]\u212c =\n[\ufe02\u22123\n2\n]\ufe02\n. This means that\n#\u00bb\ud835\udc64 = (\u22123)\n[\ufe021\n2\n]\ufe02\n+ 2\n[\ufe025\n6\n]\ufe02\n=\n[\ufe027\n6\n]\ufe02\n.\nThat is,\n[#\u00bb\ud835\udc64]\u2130 = #\u00bb\ud835\udc64 =\n[\ufe027\n6\n]\ufe02\n.\nExample 8.8.10\nLet \u212c =\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n1\n1\n1\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n1\n0\n3\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n1\n\u22122\n4\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad and let #\u00bb\ud835\udc63 =\n\u23a1\n\u23a3\n\u22123\n2\n\u22126\n\u23a4\n\u23a6.\n(a) Show that \u212c is a basis for R3.224\nChapter 8\nSubspaces and Bases\n(b) Viewing \u212c as an ordered basis in the given order, find [#\u00bb\ud835\udc63 ]\u212c.\n(c) If [#\u00bb\ud835\udc64]\u212c =\n\u23a1\n\u23a3\n3\n\u22124\n5\n\u23a4\n\u23a6, find [#\u00bb\ud835\udc64]\u2130.\nSolution:\n(a) By Proposition 8.5.4 (\ud835\udc5b Vectors in F\ud835\udc5b Span iff Independent), since we have three vectors\nin \u212c, it suffices to check that they span R3.\nBy Proposition 8.4.6 (Spans F\ud835\udc5b iff rank is \ud835\udc5b), this can be done by evaluating the rank\nof\n\ud835\udc34 =\n\u23a1\n\u23a3\n1 1 1\n1 0 \u22122\n1 3 4\n\u23a4\n\u23a6 .\nRow reduction yields the matrix \ud835\udc45 =\n\u23a1\n\u23a3\n1 1 1\n0 1 3\n0 0 3\n\u23a4\n\u23a6 , which has rank 3. Thus, we have a\nbasis.\n(b) We need to find \ud835\udc4e, \ud835\udc4f, \ud835\udc50 \u2208 R so that\n\ud835\udc4e\n\u23a1\n\u23a3\n1\n1\n1\n\u23a4\n\u23a6 + \ud835\udc4f\n\u23a1\n\u23a3\n1\n0\n3\n\u23a4\n\u23a6 + \ud835\udc50\n\u23a1\n\u23a3\n1\n\u22122\n4\n\u23a4\n\u23a6 =\n\u23a1\n\u23a3\n\u22123\n2\n\u22126\n\u23a4\n\u23a6 .\nConsider the system\n\u23a1\n\u23a3\n1 1 1\n1 0 \u22122\n1 3 4\n\u23a4\n\u23a6\n\u23a1\n\u23a3\n\ud835\udc4e\n\ud835\udc4f\n\ud835\udc50\n\u23a4\n\u23a6 =\n\u23a1\n\u23a3\n\u22123\n2\n\u22126\n\u23a4\n\u23a6 ,\nwhich has augmented matrix\n\u23a1\n\u23a3\n1\n1\n1\n\u22123\n1\n0\n\u22122\n2\n1\n3\n4\n\u22126\n\u23a4\n\u23a6 ,\nwhich reduces to\n\u23a1\n\u23a2\u23a3\n1\n0\n0\n\u22128\n3\n0\n1\n0\n2\n0\n0\n1\n\u22127\n3\n\u23a4\n\u23a5\u23a6 .\nThus, \ud835\udc4e = \u2212 8\n3, \ud835\udc4f = 2 and \ud835\udc50 = \u2212 7\n3, and we have\n[#\u00bb\ud835\udc63 ]\u212c =\n\u23a1\n\u23a2\u23a3\n\u2212 8\n3\n2\n\u2212 7\n3\n\u23a4\n\u23a5\u23a6 .Section 8.8\nCoordinates\n225\n(c) If\n[#\u00bb\ud835\udc64]\u212c =\n\u23a1\n\u23a3\n3\n\u22124\n5\n\u23a4\n\u23a6 ,\nthen\n#\u00bb\ud835\udc64 = (3)\n\u23a1\n\u23a3\n1\n1\n1\n\u23a4\n\u23a6 + (\u22124)\n\u23a1\n\u23a3\n1\n0\n3\n\u23a4\n\u23a6 + (5)\n\u23a1\n\u23a3\n1\n\u22122\n4\n\u23a4\n\u23a6 =\n\u23a1\n\u23a3\n4\n\u22127\n11\n\u23a4\n\u23a6 ,\nthat is,\n[#\u00bb\ud835\udc64]\u2130 = #\u00bb\ud835\udc64 =\n\u23a1\n\u23a3\n4\n\u22127\n11\n\u23a4\n\u23a6 .\nIn the previous two examples, we saw that in order to obtain the coordinate vector rep-\nresentation [#\u00bb\ud835\udc63 ]\u212c of a given vector #\u00bb\ud835\udc63 , we must solve a certain system of equations. Must\nwe do this each time we want to find coordinate vectors with respect to \u212c? The answer is\n\u201cno\u201d; there is a more efficient approach.\nExample 8.8.11\nLet us first consider the final calculation of Example 8.8.9 (b), where we had\n[#\u00bb\ud835\udc64]\u212c =\n[\ufe02\u22123\n2\n]\ufe02\n,\nand then\n[#\u00bb\ud835\udc64]\u2130 = #\u00bb\ud835\udc64 =\n[\ufe027\n6\n]\ufe02\n.\nThis was completed by performing the calculation\n(\u22123)\n[\ufe021\n2\n]\ufe02\n+ 2\n[\ufe025\n6\n]\ufe02\n= #\u00bb\ud835\udc64.\nThe system above can be expressed as\n[\ufe021 5\n2 6\n]\ufe02 [\ufe02\u22123\n2\n]\ufe02\n.\nThus, there is a matrix at work here, namely \ud835\udc40 =\n[\ufe021 5\n2 6\n]\ufe02\n, such that multiplication by \ud835\udc40\nallows us to go from the new coordinate system (with respect to the basis \u212c) to the standard\nsystem (basis \u2130).\nFor instance, if we are given a vector #\u00bb\ud835\udc67 with [#\u00bb\ud835\udc67 ]\u212c =\n[\ufe02 4\n\u22123\n]\ufe02\n, then\n[#\u00bb\ud835\udc67 ]\u2130 = \ud835\udc40[#\u00bb\ud835\udc67 ]\u212c =\n[\ufe021 5\n2 6\n]\ufe02 [\ufe02 4\n\u22123\n]\ufe02\n=\n[\ufe02\u221211\n\u221210\n]\ufe02\n.\nNotice that \ud835\udc40 is very special. Its columns are the coordinate vectors of \u212c expressed in the\nstandard basis.226\nChapter 8\nSubspaces and Bases\nWhat about going the other way, from \u2130 to \u212c? Let us re-examine what we did in Example\n8.8.9 (a). We wanted to obtain\n[\ufe023\n4\n]\ufe02\n\u212c\n, which we found amounted to solving the system\n[\ufe021 5\n2 6\n]\ufe02 [\ufe02\ud835\udc4e\n\ud835\udc4f\n]\ufe02\n=\n[\ufe023\n4\n]\ufe02\n.\nThe coefficient matrix here is the same \ud835\udc40 above.\nIt is invertible!\n(This is a general\nphenomenon, as we will soon see.) Thus,\n[\ufe02\ud835\udc4e\n\ud835\udc4f\n]\ufe02\n=\n[\ufe021 5\n2 6\n]\ufe02\u22121 [\ufe023\n4\n]\ufe02\n= \u22121\n4\n[\ufe02 6 \u22125\n\u22122 1\n]\ufe02 [\ufe023\n4\n]\ufe02\n=\n[\ufe03 1\n2\n1\n2\n]\ufe03\n.\nFrom this, we get\n[\ufe023\n4\n]\ufe02\n\u212c\n=\n\u23a1\n\u23a3\n1\n2\n1\n2\n\u23a4\n\u23a6 .\nOnce again there is a matrix at work here, namely \ud835\udc40\u22121 = \u2212 1\n4\n[\ufe02\n6\n\u22125\n\u22122\n1\n]\ufe02\n. It will change\ncoordinates from the standard system (basis \u2130) to the new system (basis \u212c), and it will do\nthis for any vector whose components we already have in \u2130.\nFor instance, given a vector #\u00bb\ud835\udc62 with [#\u00bb\ud835\udc62]\u2130 =\n[\ufe02\u22122\n5\n]\ufe02\n, then\n[#\u00bb\ud835\udc62]\u212c = \ud835\udc40\u22121[#\u00bb\ud835\udc62]\u2130 = \u22121\n4\n[\ufe02 6 \u22125\n\u22122 1\n]\ufe02 [\ufe02\u22122\n5\n]\ufe02\n= 1\n4\n[\ufe02 37\n\u22129\n]\ufe02\n.\nTo obtain \ud835\udc40\u22121, we invert the matrix whose columns are the coordinates of the new basis\nvector in \u212c expressed in the standard basis.\nWith some work, you can show that the columns of \ud835\udc40\u22121 are in fact the coordinate vectors\nof the standard basis vectors with respect to \u212c.\nThe idea of using a matrix like \ud835\udc40 above to change coordinates from one basis to another\nis in fact always possible, as we now explain.\nDefinition 8.8.12\nChange-of-Basis\nMatrix, Change-of-\nCoordinate\nMatrix\nLet \u212c = {#\u00bb\n\ud835\udc631, . . . , # \u00bb\n\ud835\udc63\ud835\udc5b} and \ud835\udc9e = {# \u00bb\n\ud835\udc641, . . . , #  \u00bb\n\ud835\udc64\ud835\udc5b} be ordered bases for F\ud835\udc5b.\nThe change-of-basis (or change-of-coordinates) matrix from \u212c-coordinates to \ud835\udc9e-\ncoordinates is the \ud835\udc5b \u00d7 \ud835\udc5b matrix\n\ud835\udc9e[\ud835\udc3c]\u212c =\n[\ufe00\n[#\u00bb\n\ud835\udc631]\ud835\udc9e . . . [# \u00bb\n\ud835\udc63\ud835\udc5b]\ud835\udc9e\n]\ufe00\nwhose columns are the \ud835\udc9e-coordinates of the vectors #\u00bb\n\ud835\udc63\ud835\udc56 in \u212c.\nSimilarly, the change-of-basis (or change-of-coordinates) matrix from \ud835\udc9e-coordinates\nto \u212c-coordinates is the \ud835\udc5b \u00d7 \ud835\udc5b matrix\n\u212c[\ud835\udc3c]\ud835\udc9e =\n[\ufe00\n[# \u00bb\n\ud835\udc641]\u212c . . . [#  \u00bb\n\ud835\udc64\ud835\udc5b]\u212c\n]\ufe00\nwhose columns are the \u212c-coordinates of the vectors # \u00bb\n\ud835\udc64\ud835\udc56 in \ud835\udc9e.Section 8.8\nCoordinates\n227\nREMARKS\n\u2022 The reason for the notation will become apparent later.\nThe resemblance to the\nnotation [\ud835\udc47]\u2130 for the standard matrix of the linear transformation \ud835\udc47 is intentional.\n\u2022 Other sources may notate \ud835\udc9e[\ud835\udc3c]\u212c as \ud835\udc9e\ud835\udc43\u212c or \ud835\udc43\ud835\udc9e\u2190\u212c.\nExample 8.8.13\nThe matrix \ud835\udc40 in Example 8.8.9 is none other than \u2130[\ud835\udc3c]\u212c, while the matrix \ud835\udc40\u22121 is \u212c[\ud835\udc3c]\u2130.\n(This is not a coincidence. See Corollary 8.8.16 (Inverse of Change-of-Basis Matrix).)\nThe role of the change-of-basis matrix is exactly as its name suggests. It changes coordinates\nfrom one basis to another.\nProposition 8.8.14\n(Changing a Basis)\nLet \u212c = {#\u00bb\n\ud835\udc631, . . . , # \u00bb\n\ud835\udc63\ud835\udc5b} and \ud835\udc9e = {# \u00bb\n\ud835\udc641, . . . , #  \u00bb\n\ud835\udc64\ud835\udc5b} be ordered bases for F\ud835\udc5b.\nThen [#\u00bb\ud835\udc65]\ud835\udc9e = \ud835\udc9e[\ud835\udc3c]\u212c [#\u00bb\ud835\udc65]\u212c and [#\u00bb\ud835\udc65]\u212c = \u212c[\ud835\udc3c]\ud835\udc9e [#\u00bb\ud835\udc65]\ud835\udc9e for all #\u00bb\ud835\udc65 \u2208 F\ud835\udc5b.\nProof: Suppose that [#\u00bb\ud835\udc65]\u212c =\n\u23a1\n\u23a2\u23a3\n\ud835\udc4e1\n...\n\ud835\udc4e\ud835\udc5b\n\u23a4\n\u23a5\u23a6 . Then #\u00bb\ud835\udc65 = \ud835\udc4e1 #\u00bb\n\ud835\udc631+\u00b7 \u00b7 \u00b7+\ud835\udc4e\ud835\udc5b # \u00bb\n\ud835\udc63\ud835\udc5b. As the coordinate vector\nmap is linear by Theorem 8.8.8 (Linearity of Taking Coordinates), we have\n[#\u00bb\ud835\udc65]\ud835\udc9e = [\ud835\udc4e1 #\u00bb\n\ud835\udc631 + \u00b7 \u00b7 \u00b7 + \ud835\udc4e\ud835\udc5b # \u00bb\n\ud835\udc63\ud835\udc5b]\ud835\udc9e\n= \ud835\udc4e1[#\u00bb\n\ud835\udc631]\ud835\udc9e + \u00b7 \u00b7 \u00b7 + \ud835\udc4e\ud835\udc5b[# \u00bb\n\ud835\udc63\ud835\udc5b]\ud835\udc9e\n=\n[\ufe00\n[#\u00bb\n\ud835\udc631]\ud835\udc9e [#\u00bb\n\ud835\udc632]\ud835\udc9e \u00b7 \u00b7 \u00b7 [# \u00bb\n\ud835\udc63\ud835\udc5b]\ud835\udc9e\n]\ufe00\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc4e1\n\ud835\udc4e2\n...\n\ud835\udc4e\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6\n= \ud835\udc9e[\ud835\udc3c]\u212c [#\u00bb\ud835\udc65]\u212c.\nThe proof going from \ud835\udc9e to \u212c is identical, with \ud835\udc9e switched with \u212c.\nCorollary 8.8.15\nLet #\u00bb\ud835\udc65 = [#\u00bb\ud835\udc65]\u2130 =\n\u23a1\n\u23a2\u23a3\n\ud835\udc651\n...\n\ud835\udc65\ud835\udc5b\n\u23a4\n\u23a5\u23a6 be a vector in F\ud835\udc5b, where \u2130 is the standard basis for F\ud835\udc5b. If \ud835\udc9e is any\nordered basis for F\ud835\udc5b, then\n[#\u00bb\ud835\udc65]\ud835\udc9e = \ud835\udc9e[\ud835\udc3c]\u2130 [#\u00bb\ud835\udc65]\u2130 .\nProof: Take \u212c = \u2130 in Proposition 8.8.14 (Changing a Basis).228\nChapter 8\nSubspaces and Bases\nThe matrix \u2130[\ud835\udc3c]\ud835\udc9e is relatively easily obtained by simply inserting the standard coordinates\nof the vectors in \ud835\udc9e into the columns of a matrix. However, we usually want to go the other\nway (as in the above Corollary), and thus, we would like to have \ud835\udc9e[\ud835\udc3c]\u2130.\nThe next result tells us that once we have one of these two matrices, then we can obtain\nthe other rather quickly as they are inverses of each other.\nCorollary 8.8.16\n(Inverse of Change-of-Basis Matrix)\nLet \u212c and \ud835\udc9e be two ordered bases of F\ud835\udc5b. Then\n\u212c[\ud835\udc3c]\ud835\udc9e \ud835\udc9e[\ud835\udc3c]\u212c = \ud835\udc3c\ud835\udc5b\nand\n\ud835\udc9e[\ud835\udc3c]\u212c \u212c[\ud835\udc3c]\ud835\udc9e = \ud835\udc3c\ud835\udc5b.\nIn other words, \u212c[\ud835\udc3c]\ud835\udc9e = ( \ud835\udc9e[\ud835\udc3c]\u212c )\u22121.\nProof: Suppose we change coordinates twice. We start using basis \u212c, then change the\nbasis to \ud835\udc9e, and then back to \u212c.\nWe then have, for any #\u00bb\ud835\udc65 \u2208 F\ud835\udc5b, [#\u00bb\ud835\udc65]\ud835\udc9e = \ud835\udc9e[\ud835\udc3c]\u212c [#\u00bb\ud835\udc65]\u212c and therefore,\n[#\u00bb\ud835\udc65]\u212c = \u212c[\ud835\udc3c]\ud835\udc9e [#\u00bb\ud835\udc65]\ud835\udc9e = \u212c[\ud835\udc3c]\ud835\udc9e \ud835\udc9e[\ud835\udc3c]\u212c [#\u00bb\ud835\udc65]\u212c.\nWe can write this as\n(\ufe00\n\ud835\udc3c\ud835\udc5b \u2212 \u212c[\ud835\udc3c]\ud835\udc9e \ud835\udc9e[\ud835\udc3c]\u212c\n)\ufe00\n[#\u00bb\ud835\udc65]\u212c = #\u00bb0 ,\nfor all #\u00bb\ud835\udc65 \u2208 F\ud835\udc5b.\nThus, by Theorem 4.2.3 (Equality of Matrices), we conclude that\n(\ud835\udc3c\ud835\udc5b \u2212\u212c [\ud835\udc3c]\ud835\udc9e \ud835\udc9e[\ud835\udc3c]\u212c) = \ud835\udcaa,\nwhere \ud835\udcaa is the \ud835\udc5b \u00d7 \ud835\udc5b zero matrix, and therefore \u212c[\ud835\udc3c]\ud835\udc9e \ud835\udc9e[\ud835\udc3c]\u212c = \ud835\udc3c\ud835\udc5b. So \u212c[\ud835\udc3c]\ud835\udc9e and \ud835\udc9e[\ud835\udc3c]\u212c are\ninverses of each other.\nExample 8.8.17\nIf we revisit Example 8.8.10 with this new notation and information, we find that\n\u2130[\ud835\udc3c]\u212c =\n\u23a1\n\u23a3\n1 1 1\n1 0 \u22122\n1 3 4\n\u23a4\n\u23a6 .\nThe inverse of this matrix is\n\u212c[\ud835\udc3c]\u2130 = 1\n3\n\u23a1\n\u23a3\n6 \u22121 \u22122\n\u22126 3\n3\n3 \u22122 \u22121\n\u23a4\n\u23a6\nand so\n\u23a1\n\u23a3\n\u22123\n2\n\u22126\n\u23a4\n\u23a6\n\u212c\n= 1\n3\n\u23a1\n\u23a3\n6 \u22121 \u22122\n\u22126 3\n3\n3 \u22122 \u22121\n\u23a4\n\u23a6\n\u23a1\n\u23a3\n\u22123\n2\n\u22126\n\u23a4\n\u23a6 = 1\n3\n\u23a1\n\u23a3\n\u22128\n6\n\u22127\n\u23a4\n\u23a6 ,\njust as we had computed.Section 8.8\nCoordinates\n229\nFurthermore, if we now want, for example,\n\u23a1\n\u23a3\n3\n5\n9\n\u23a4\n\u23a6\n\u212c\n, then we can quickly find it:\n\u23a1\n\u23a3\n3\n5\n9\n\u23a4\n\u23a6\n\u212c\n= 1\n3\n\u23a1\n\u23a3\n6 \u22121 \u22122\n\u22126 3\n3\n3 \u22122 \u22121\n\u23a4\n\u23a6\n\u23a1\n\u23a3\n3\n5\n9\n\u23a4\n\u23a6 = 1\n3\n\u23a1\n\u23a3\n\u22125\n24\n\u221210\n\u23a4\n\u23a6 .\nExample 8.8.18\nSuppose we are in C2 and we wish to work with the ordered basis \ud835\udc9e = {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632} , where\n#\u00bb\n\ud835\udc631 =\n[\ufe02 1 + 2\ud835\udc56\n\u22121 + \ud835\udc56\n]\ufe02\nand #\u00bb\n\ud835\udc632 =\n[\ufe021 + \ud835\udc56\n\ud835\udc56\n]\ufe02\n.\n(a) Let #\u00bb\ud835\udc67 =\n[\ufe0210 + \ud835\udc56\n2 + 6\ud835\udc56\n]\ufe02\n. Find [#\u00bb\ud835\udc67 ]\ud835\udc9e.\n(b) Consider the vector #\u00bb\ud835\udc64 \u2208 C2 with [#\u00bb\ud835\udc64]\ud835\udc9e =\n[\ufe02 2\n3\ud835\udc56\n]\ufe02\n. Find [#\u00bb\ud835\udc64]\u2130.\nSolution:\nNote that, as usual, all the vectors have been given with respect to the standard basis.\nWe have\n\u2130[\ud835\udc3c]\ud835\udc9e =\n[\ufe02 1 + 2\ud835\udc56 1 + \ud835\udc56\n\u22121 + \ud835\udc56\n\ud835\udc56\n]\ufe02\nand therefore, we can compute\n\ud835\udc9e[\ud835\udc3c]\u2130 =\n[\ufe02 1 + 2\ud835\udc56 1 + \ud835\udc56\n\u22121 + \ud835\udc56\n\ud835\udc56\n]\ufe02\u22121\n= 1\n\ud835\udc56\n[\ufe02\n\ud835\udc56\n\u22121 \u2212 \ud835\udc56\n1 \u2212 \ud835\udc56 1 + 2\ud835\udc56\n]\ufe02\n= \u2212\ud835\udc56\n[\ufe02\n\ud835\udc56\n\u22121 \u2212 \ud835\udc56\n1 \u2212 \ud835\udc56 1 + 2\ud835\udc56\n]\ufe02\n=\n[\ufe02\n1\n\u22121 + \ud835\udc56\n\u22121 \u2212 \ud835\udc56 2 \u2212 \ud835\udc56\n]\ufe02\n.\n(a) We can obtain [#\u00bb\ud835\udc67 ]\ud835\udc9e by\n[#\u00bb\ud835\udc67 ]\ud835\udc9e = \ud835\udc9e[\ud835\udc3c]\u2130 [#\u00bb\ud835\udc67 ]\u2130 =\n[\ufe02\n1\n\u22121 + \ud835\udc56\n\u22121 \u2212 \ud835\udc56 2 \u2212 \ud835\udc56\n]\ufe02 [\ufe0210 + \ud835\udc56\n2 + 6\ud835\udc56\n]\ufe02\n=\n[\ufe022 \u2212 3\ud835\udc56\n1 \u2212 \ud835\udc56\n]\ufe02\n.\n(b) We can obtain [#\u00bb\ud835\udc64]\u2130 by\n[#\u00bb\ud835\udc64]\u2130 = \u2130[\ud835\udc3c]\ud835\udc9e [#\u00bb\ud835\udc64]\ud835\udc9e =\n[\ufe02 1 + 2\ud835\udc56 1 + \ud835\udc56\n\u22121 + \ud835\udc56\n\ud835\udc56\n]\ufe02 [\ufe02 2\n3\ud835\udc56\n]\ufe02\n=\n[\ufe02\u22121 + 7\ud835\udc56\n\u22125 + 2\ud835\udc56\n]\ufe02\n.Chapter 9\nDiagonalization\n9.1", "Matrix Representation of a Linear Operator\nIn this chapter we will focus on linear transformations \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5b whose domain and\ncodomain are the same set. Among other notable properties, these transformations will\nhave the ability to be composed with themselves; that is, functions such as \ud835\udc47 \u2218 \ud835\udc47 will be\nwell-defined when the domain and codomain of \ud835\udc47 are the same.\nDefinition 9.1.1\nLinear Operator\nA linear transformation \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5a where \ud835\udc5b = \ud835\udc5a is called a linear operator.\nIn Section 5.5, we learned how to find the standard matrix [\ud835\udc47]\u2130 of a linear operator \ud835\udc47.\nIn this section we\u2019ll learn how to find matrix representations of a linear operator \ud835\udc47 with\nrespect to bases for F\ud835\udc5b other than the standard basis.\nDefinition 9.1.2\n\u212c-Matrix of T\nLet \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5b be a linear operator and let \u212c = {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , # \u00bb\n\ud835\udc63\ud835\udc5b} be an ordered basis for\nF\ud835\udc5b. We define the \u212c-matrix of \ud835\udc47 to be the matrix [\ud835\udc47]\u212c constructed as follows:\n[\ud835\udc47]\u212c =\n[\ufe01\n[\ud835\udc47(#\u00bb\n\ud835\udc631)]\u212c\n[\ud835\udc47(#\u00bb\n\ud835\udc632)]\u212c \u00b7 \u00b7 \u00b7 [\ud835\udc47(# \u00bb\n\ud835\udc63\ud835\udc5b)]\u212c\n]\ufe01\n.\nThat is, after applying the action of \ud835\udc47 to each member of \u212c, we take the \u212c-coordinate\nvectors of each of these images to create the columns of [\ud835\udc47]\u212c.\nSimilar to the way we used [\ud835\udc47]\u2130 to find the image of a vector in F\ud835\udc5b, we can use [\ud835\udc47]\u212c to\nfind the coordinate vector with respect to \u212c of the image of any vector in F\ud835\udc5b by performing\nmatrix\u2013vector multiplication.\nProposition 9.1.3\nLet \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5b be a linear operator and let \u212c = {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , # \u00bb\n\ud835\udc63\ud835\udc5b} be an ordered basis for\nF\ud835\udc5b. If #\u00bb\ud835\udc63 \u2208 F\ud835\udc5b, then\n[\ud835\udc47(#\u00bb\ud835\udc63 )]\u212c = [\ud835\udc47]\u212c [#\u00bb\ud835\udc63 ]\u212c.\n230Section 9.1\nMatrix Representation of a Linear Operator\n231\nProof: Since \u212c is a basis for F\ud835\udc5b and #\u00bb\ud835\udc63 \u2208 F\ud835\udc5b, then there exists \ud835\udc501, \ud835\udc502, . . . , \ud835\udc50\ud835\udc5b \u2208 F such that\n#\u00bb\ud835\udc63 = \ud835\udc501 #\u00bb\n\ud835\udc631 + \ud835\udc502 #\u00bb\n\ud835\udc632 + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc5b # \u00bb\n\ud835\udc63\ud835\udc5b.\nWe can use the linearity of \ud835\udc47 to expand \ud835\udc47(#\u00bb\ud835\udc63 ). We get\n\ud835\udc47(#\u00bb\ud835\udc63 ) = \ud835\udc47(\ud835\udc501 #\u00bb\n\ud835\udc631 + \ud835\udc502 #\u00bb\n\ud835\udc632 + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc5b # \u00bb\n\ud835\udc63\ud835\udc5b) = \ud835\udc501\ud835\udc47(#\u00bb\n\ud835\udc631) + \ud835\udc502\ud835\udc47(#\u00bb\n\ud835\udc632) + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc5b\ud835\udc47(# \u00bb\n\ud835\udc63\ud835\udc5b).\nTaking coordinates is a linear operation, so\n[\ud835\udc47(#\u00bb\ud835\udc63 )]\u212c = [\ud835\udc501 \ud835\udc47(#\u00bb\n\ud835\udc631) + \ud835\udc502 \ud835\udc47(#\u00bb\n\ud835\udc632) + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc5b \ud835\udc47(# \u00bb\n\ud835\udc63\ud835\udc5b)]\u212c\n= \ud835\udc501 [\ud835\udc47(#\u00bb\n\ud835\udc631)]\u212c + \ud835\udc502 [\ud835\udc47(#\u00bb\n\ud835\udc632)]\u212c + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc5b [\ud835\udc47(# \u00bb\n\ud835\udc63\ud835\udc5b)]\u212c\n=\n[\ufe01\n[\ud835\udc47(#\u00bb\n\ud835\udc631)]\u212c\n[\ud835\udc47(#\u00bb\n\ud835\udc632)]\u212c \u00b7 \u00b7 \u00b7 [\ud835\udc47(# \u00bb\n\ud835\udc63\ud835\udc5b)]\u212c\n]\ufe01\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\ud835\udc501\n\ud835\udc502\n...\n\ud835\udc50\ud835\udc5b\n\u23a4\n\u23a5\u23a5\u23a5\u23a6\n= [\ud835\udc47]\u212c [#\u00bb\ud835\udc63 ]\u212c,\nas required.\nThere are two important reasons why we may want to use another basis. The first is that\nwe may have some geometrically or physically preferred vectors that naturally arise in our\nproblem; for example, the direction vector of a line through which we are reflecting vectors.\nThe second is that we may wish to simplify the matrix representation; for example, it would\nsimplify things if [\ud835\udc47]\u212c were diagonal. These two reasons are often connected.\nWe will now revisit some of the linear transformations that we considered in Section 5.6.\nFor each transformation, we will choose a basis \u212c such that the \u212c-matrix will be particularly\nsimple: it will be diagonal.\nExample 9.1.4\nLet #\u00bb\ud835\udc64 =\n[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02\nbe a non-zero vector in R2.\nConsider the projection transformation\nproj #\u00bb\n\ud835\udc64 : R2 \u2192 R2. Find a basis \u212c such that [proj #\u00bb\n\ud835\udc64]\u212c is diagonal.\nSolution:\nConsider some vectors for which it is relatively easy to determine their images under proj #\u00bb\n\ud835\udc64.\nThe projection of #\u00bb\ud835\udc64 onto itself is itself. Therefore, proj #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc64) = #\u00bb\ud835\udc64. The vector\n[\ufe02 \ud835\udc642\n\u2212\ud835\udc641\n]\ufe02\nis\northogonal to #\u00bb\ud835\udc64. Therefore, proj #\u00bb\n\ud835\udc64\n(\ufe02[\ufe02 \ud835\udc642\n\u2212\ud835\udc641\n]\ufe02)\ufe02\n=\n[\ufe020\n0\n]\ufe02\n.\nLet \u212c =\n{\ufe02[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02\n,\n[\ufe02 \ud835\udc642\n\u2212\ud835\udc641\n]\ufe02}\ufe02\n. This set consists of two vectors that are not scalar multiples of\neach other, and therefore it is linearly independent. So \u212c is a basis for R2.\nWe have that\nproj #\u00bb\n\ud835\udc64\n(\ufe02[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02)\ufe02\n=\n[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02\n= 1\n[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02\n+ 0\n[\ufe02 \ud835\udc642\n\u2212\ud835\udc641\n]\ufe02\nand\nproj #\u00bb\n\ud835\udc64\n(\ufe02[\ufe02 \ud835\udc642\n\u2212\ud835\udc641\n]\ufe02)\ufe02\n=\n[\ufe020\n0\n]\ufe02\n= 0\n[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02\n+ 0\n[\ufe02 \ud835\udc642\n\u2212\ud835\udc641.\n]\ufe02232\nChapter 9\nDiagonalization\nConsequently,\n[proj #\u00bb\n\ud835\udc64]\u212c =\n[\ufe021 0\n0 0\n]\ufe02\n.\nNotice that this is a diagonal matrix.\nExample 9.1.5\nLet #\u00bb\ud835\udc64 =\n[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02\nbe a non-zero vector in R2.\nConsider the reflection transformation\nrefl #\u00bb\n\ud835\udc64 : R2 \u2192 R2, which reflects any vector in R2 about the line Span{#\u00bb\ud835\udc64}. Find a basis\n\u212c such that [refl #\u00bb\n\ud835\udc64]\u212c is diagonal.\nSolution: Consider some vectors for which it is relatively easy to determine their images\nunder refl #\u00bb\n\ud835\udc64. The reflection of #\u00bb\ud835\udc64 about itself is itself. Therefore, refl #\u00bb\n\ud835\udc64(#\u00bb\ud835\udc64) = #\u00bb\ud835\udc64. The vector\n[\ufe02 \ud835\udc642\n\u2212\ud835\udc641\n]\ufe02\nis orthogonal to #\u00bb\ud835\udc64 and so its reflection about #\u00bb\ud835\udc64 is its additive inverse. Therefore,\nrefl #\u00bb\n\ud835\udc64\n(\ufe02[\ufe02 \ud835\udc642\n\u2212\ud835\udc641\n]\ufe02)\ufe02\n=\n[\ufe02\u2212\ud835\udc642\n\ud835\udc641\n]\ufe02\n.\nLet \u212c =\n{\ufe02[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02\n,\n[\ufe02 \ud835\udc642\n\u2212\ud835\udc641\n]\ufe02}\ufe02\n. This set consists of two vectors that are not scalar multiples of\neach other, and therefore it is linearly independent. So \u212c is a basis for R2.\nWe have that\nrefl #\u00bb\n\ud835\udc64\n(\ufe02[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02)\ufe02\n=\n[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02\n= 1\n[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02\n+ 0\n[\ufe02 \ud835\udc642\n\u2212\ud835\udc641\n]\ufe02\nand\nrefl #\u00bb\n\ud835\udc64\n(\ufe02[\ufe02 \ud835\udc642\n\u2212\ud835\udc641\n]\ufe02)\ufe02\n=\n[\ufe02\u2212\ud835\udc642\n\ud835\udc641\n]\ufe02\n= 0\n[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02\n+ (\u22121)\n[\ufe02 \ud835\udc642\n\u2212\ud835\udc641.\n]\ufe02\nConsequently, we get the following diagonal matrix for [refl#\u00bb\n\ud835\udc64]\u212c:\n[refl #\u00bb\n\ud835\udc64]\u212c =\n[\ufe021 0\n0 \u22121\n]\ufe02\n.\nEXERCISE\nIn Examples 9.1.4 and 9.1.5, what happens to the matrices [proj#\u00bb\n\ud835\udc64]\u212c and [refl #\u00bb\n\ud835\udc64]\u212c if we\nreplace \u212c =\n{\ufe02[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02\n,\n[\ufe02 \ud835\udc642\n\u2212\ud835\udc641\n]\ufe02}\ufe02\nwith the ordered basis\n{\ufe02[\ufe02 \ud835\udc642\n\u2212\ud835\udc641\n]\ufe02\n,\n[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02}\ufe02\n?\nREMARK\nFinding a basis \u212c such that [\ud835\udc47]\u212c is diagonal is not usually done by inspection. Moreover,\nit is not always possible to choose a basis \u212c such that [\ud835\udc47]\u212c is diagonal. For example, the\noperator known as the \u201cshear operator\u201d \ud835\udc47 : R2 \u2192 R2, defined by \ud835\udc47\n(\ufe02[\ufe02\ud835\udc65\n\ud835\udc66\n]\ufe02)\ufe02\n=\n[\ufe02\ud835\udc65 + \ud835\udc66\n\ud835\udc66\n]\ufe02\n,\nis an example of a linear operator for which no basis \u212c exists such that [\ud835\udc47]\u212c is diagonal.\nThroughout this chapter we will develop criteria to determine whether or not we will be\nable to find such a basis.Section 9.1\nMatrix Representation of a Linear Operator\n233\nGiven a linear operator \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5b, we can create many matrices [\ud835\udc47]\u212c by choosing different\nbases \u212c for F\ud835\udc5b. A natural question to ask is: How are these various matrices related? The\nanswer is that they are similar (see Definition 7.6.2).\nProposition 9.1.6\n(Similarity of Matrix Representations)\nLet \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5b be a linear operator. Let \u212c and \ud835\udc9e be ordered bases for F\ud835\udc5b. Then\n[\ud835\udc47]\ud835\udc9e = \ud835\udc9e[\ud835\udc3c]\u212c [\ud835\udc47]\u212c \u212c[\ud835\udc3c]\ud835\udc9e = (\u212c[\ud835\udc3c]\ud835\udc9e)\u22121 [\ud835\udc47]\u212c \u212c[\ud835\udc3c]\ud835\udc9e\nand\n[\ud835\udc47]\u212c = \u212c[\ud835\udc3c]\ud835\udc9e [\ud835\udc47]\ud835\udc9e \ud835\udc9e[\ud835\udc3c]\u212c = (\ud835\udc9e[\ud835\udc3c]\u212c)\u22121 [\ud835\udc47]\ud835\udc9e \ud835\udc9e[\ud835\udc3c]\u212c.\nThat is, the matrices [\ud835\udc47]\u212c and [\ud835\udc47]\ud835\udc9e are similar over F.\nProof: Let \u212c = {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , # \u00bb\n\ud835\udc63\ud835\udc5b} and let \ud835\udc9e = {# \u00bb\n\ud835\udc641, # \u00bb\n\ud835\udc642, . . . , #  \u00bb\n\ud835\udc64\ud835\udc5b}. Then using the definition of\n[\ud835\udc47]\ud835\udc9e and Proposition 8.8.14 (Changing a Basis) gives\n[\ud835\udc47]\ud835\udc9e =\n[\ufe01\n[\ud835\udc47(# \u00bb\n\ud835\udc641)]\ud835\udc9e\n[\ud835\udc47(# \u00bb\n\ud835\udc642)]\ud835\udc9e \u00b7 \u00b7 \u00b7 [\ud835\udc47(#  \u00bb\n\ud835\udc64\ud835\udc5b)]\ud835\udc9e\n]\ufe01\n=\n[\ufe01\n\ud835\udc9e[\ud835\udc3c]\u212c [\ud835\udc47(# \u00bb\n\ud835\udc641)]\u212c\n\ud835\udc9e[\ud835\udc3c]\u212c [\ud835\udc47(# \u00bb\n\ud835\udc642)]\u212c \u00b7 \u00b7 \u00b7 \ud835\udc9e[\ud835\udc3c]\u212c [\ud835\udc47(#  \u00bb\n\ud835\udc64\ud835\udc5b)]\u212c\n]\ufe01\n.\nUsing the definition of matrix multiplication, we can write this matrix as the product\n[\ud835\udc47]\ud835\udc9e = \ud835\udc9e[\ud835\udc3c]\u212c\n[\ufe01\n[\ud835\udc47(# \u00bb\n\ud835\udc641)]\u212c\n[\ud835\udc47(# \u00bb\n\ud835\udc642)]\u212c \u00b7 \u00b7 \u00b7 [\ud835\udc47(#  \u00bb\n\ud835\udc64\ud835\udc5b)]\u212c\n]\ufe01\n.\nUsing Proposition 9.1.3, we get\n[\ud835\udc47]\ud835\udc9e = \ud835\udc9e[\ud835\udc3c]\u212c\n[\ufe01\n[\ud835\udc47]\u212c[# \u00bb\n\ud835\udc641]\u212c\n[\ud835\udc47]\u212c[# \u00bb\n\ud835\udc642]\u212c \u00b7 \u00b7 \u00b7 [\ud835\udc47]\u212c[#  \u00bb\n\ud835\udc64\ud835\udc5b]\u212c\n]\ufe01\n.\nAgain using the definition of matrix multiplication, we obtain\n[\ud835\udc47]\ud835\udc9e = \ud835\udc9e[\ud835\udc3c]\u212c [\ud835\udc47]\u212c\n[\ufe01\n[# \u00bb\n\ud835\udc641]\u212c\n[# \u00bb\n\ud835\udc642]\u212c \u00b7 \u00b7 \u00b7 [#  \u00bb\n\ud835\udc64\ud835\udc5b]\u212c\n]\ufe01\n.\nBy definition,\n\u212c[\ud835\udc3c]\ud835\udc9e =\n[\ufe01\n[# \u00bb\n\ud835\udc641]\u212c\n[# \u00bb\n\ud835\udc642]\u212c \u00b7 \u00b7 \u00b7 [#  \u00bb\n\ud835\udc64\ud835\udc5b]\u212c\n]\ufe01\n.\nSince\n\ud835\udc9e[\ud835\udc3c]\u212c = (\u212c[\ud835\udc3c]\ud835\udc9e)\u22121 ,\nso we obtain that\n[\ud835\udc47]\ud835\udc9e = (\u212c[\ud835\udc3c]\ud835\udc9e)\u22121 [\ud835\udc47]\u212c \u212c[\ud835\udc3c]\ud835\udc9e.\nBy swapping the roles played by \u212c and \ud835\udc9e in the above argument, we obtain that\n[\ud835\udc47]\u212c = \u212c[\ud835\udc3c]\ud835\udc9e [\ud835\udc47]\ud835\udc9e \ud835\udc9e[\ud835\udc3c]\u212c = (\ud835\udc9e[\ud835\udc3c]\u212c )\u22121 [\ud835\udc47]\ud835\udc9e\n\ud835\udc9e[\ud835\udc3c]\u212c.234\nChapter 9\nDiagonalization\nCorollary 9.1.7\n(Finding the Standard Matrix)\nLet \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5b be a linear operator. Let \u212c be a basis for F\ud835\udc5b and let \u2130 be the standard\nbasis for F\ud835\udc5b. Then\n[\ud835\udc47]\u2130 = \u2130[\ud835\udc3c]\u212c [\ud835\udc47]\u212c \u212c[\ud835\udc3c]\u2130 = (\u212c[\ud835\udc3c]\u2130)\u22121 [\ud835\udc47]\u212c \u212c[\ud835\udc3c]\u2130\nand\n[\ud835\udc47]\u212c = \u212c[\ud835\udc3c]\u2130 [\ud835\udc47]\u2130\n\u2130[\ud835\udc3c]\u212c = (\u2130[\ud835\udc3c]\u212c)\u22121 [\ud835\udc47]\u2130\n\u2130[\ud835\udc3c]\u212c.\nProof: This follows from the previous Proposition, with \ud835\udc9e replaced by \u2130.\nEXERCISE\nIn this exercise you will show that if \ud835\udc34 and \ud835\udc35 are similar matrices in \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F), then they\nare different representations of the same linear operator.\nLet \ud835\udc34, \ud835\udc35 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F). Suppose that \ud835\udc34 is similar to \ud835\udc35, say \ud835\udc34 = \ud835\udc43\ud835\udc35\ud835\udc43 \u22121 for some invertible\nmatrix \ud835\udc43 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F). Let \u212c be the ordered basis for F\ud835\udc5b consisting of the columns of \ud835\udc43\n(ordered in the way they appear in \ud835\udc43). Show that [\ud835\udc47\ud835\udc34]\u2130 = \ud835\udc34 and [\ud835\udc47\ud835\udc34]\u212c = \ud835\udc35.\nREMARK\nThe previous Exercise justifies the use of the word \u201csimilar\u201d to describe the relationship\nin Definition 7.6.2. If matrices \ud835\udc34, \ud835\udc35 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) are similar over F, then they are both\n\u212c-matrices of the same linear operator \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5b. That is, similar matrices are just\ndifferent representations of the same operator.\nExample 9.1.8\nLet #\u00bb\ud835\udc64 =\n[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02\nbe a non-zero vector in R2.\nConsider the projection transformation\nproj #\u00bb\n\ud835\udc64 : R2 \u2192 R2. Determine [proj #\u00bb\n\ud835\udc64]\u2130 using the solution to Example 9.1.4 and Corollary\n9.1.7 (Finding the Standard Matrix).\nSolution: In Example 9.1.4, we found the matrix representation [proj#\u00bb\n\ud835\udc64]\u212c =\n[\ufe021 0\n0 0\n]\ufe02\nwith\nrespect to the basis \u212c =\n{\ufe02[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02\n,\n[\ufe02 \ud835\udc642\n\u2212\ud835\udc641\n]\ufe02}\ufe02\n.\nWe also have that\n\u2130[\ud835\udc3c]\u212c =\n[\ufe02\ud835\udc641\n\ud835\udc642\n\ud835\udc642 \u2212\ud835\udc641\n]\ufe02\nand\n\u212c[\ud835\udc3c]\u2130 = (\u2130[\ud835\udc3c]\u212c)\u22121 =\n1\n\u2212\ud835\udc642\n1 \u2212 \ud835\udc642\n2\n[\ufe02\u2212\ud835\udc641 \u2212\ud835\udc642\n\u2212\ud835\udc642 \ud835\udc641\n]\ufe02\n=\n1\n\ud835\udc642\n1 + \ud835\udc642\n2\n[\ufe02\ud835\udc641\n\ud835\udc642\n\ud835\udc642 \u2212\ud835\udc641\n]\ufe02\n.Section 9.2", "Diagonalizability of Linear Operators\n235\nTherefore, using Corollary 9.1.7 (Finding the Standard Matrix), we have\n[proj #\u00bb\n\ud835\udc64]\u2130 = \u2130[\ud835\udc3c]\u212c [proj #\u00bb\n\ud835\udc64]\u212c \u212c[\ud835\udc3c]\u2130\n=\n[\ufe02\ud835\udc641\n\ud835\udc642\n\ud835\udc642 \u2212\ud835\udc641\n]\ufe02 [\ufe021 0\n0 0\n]\ufe02\n1\n\ud835\udc642\n1 + \ud835\udc642\n2\n[\ufe02\ud835\udc641\n\ud835\udc642\n\ud835\udc642 \u2212\ud835\udc641\n]\ufe02\n=\n1\n\ud835\udc642\n1 + \ud835\udc642\n2\n[\ufe02\ud835\udc641 0\n\ud835\udc642 0\n]\ufe02 [\ufe02\ud835\udc641 \ud835\udc642\n\ud835\udc642 \u2212\ud835\udc641\n]\ufe02\n=\n1\n\ud835\udc642\n1 + \ud835\udc642\n2\n[\ufe02 \ud835\udc642\n1\n\ud835\udc641\ud835\udc642\n\ud835\udc641\ud835\udc642\n\ud835\udc642\n2\n]\ufe02\n,\nwhich matches what we found in Example 5.6.1.\nExample 9.1.9\nLet #\u00bb\ud835\udc64 =\n[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02\nbe a non-zero vector in R2.\nConsider the reflection transformation\nrefl #\u00bb\n\ud835\udc64 : R2 \u2192 R2, which reflects any vector #\u00bb\ud835\udc63 \u2208 R2 about the line Span{#\u00bb\ud835\udc64}. Determine\n[refl #\u00bb\n\ud835\udc64]\u2130 using the solution to Example 9.1.5 and Corollary 9.1.7 (Finding the Standard\nMatrix).\nSolution: In Example 9.1.5, we found the matrix representation [refl#\u00bb\n\ud835\udc64]\u212c =\n[\ufe021 0\n0 \u22121\n]\ufe02\nwith\nrespect to the basis \u212c =\n{\ufe02[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02\n,\n[\ufe02 \ud835\udc642\n\u2212\ud835\udc641\n]\ufe02}\ufe02\n.\nWe also have that\n\u2130[\ud835\udc3c]\u212c =\n[\ufe02\ud835\udc641\n\ud835\udc642\n\ud835\udc642 \u2212\ud835\udc641\n]\ufe02\nand\n\u212c[\ud835\udc3c]\u2130 = (\u2130[\ud835\udc3c]\u212c)\u22121 =\n1\n\u2212\ud835\udc642\n1 \u2212 \ud835\udc642\n2\n[\ufe02\u2212\ud835\udc641 \u2212\ud835\udc642\n\u2212\ud835\udc642 \ud835\udc641\n]\ufe02\n=\n1\n\ud835\udc642\n1 + \ud835\udc642\n2\n[\ufe02\ud835\udc641\n\ud835\udc642\n\ud835\udc642 \u2212\ud835\udc641\n]\ufe02\n.\nTherefore, using Corollary 9.1.7 (Finding the Standard Matrix), we have\n[refl #\u00bb\n\ud835\udc64]\u2130 = \u2130[\ud835\udc3c]\u212c [refl #\u00bb\n\ud835\udc64]\u212c \u212c[\ud835\udc3c]\u2130\n=\n[\ufe02\ud835\udc641\n\ud835\udc642\n\ud835\udc642 \u2212\ud835\udc641\n]\ufe02 [\ufe021 0\n0 \u22121\n]\ufe02\n1\n\ud835\udc642\n1 + \ud835\udc642\n2\n[\ufe02\ud835\udc641 \ud835\udc642\n\ud835\udc642 \u2212\ud835\udc641\n]\ufe02\n=\n1\n\ud835\udc642\n1 + \ud835\udc642\n2\n[\ufe02\ud835\udc641 \u2212\ud835\udc642\n\ud835\udc642\n\ud835\udc641\n]\ufe02 [\ufe02\ud835\udc641\n\ud835\udc642\n\ud835\udc642 \u2212\ud835\udc641\n]\ufe02\n=\n1\n\ud835\udc642\n1 + \ud835\udc642\n2\n[\ufe02\ud835\udc642\n1 \u2212 \ud835\udc642\n2\n2\ud835\udc641\ud835\udc642\n2\ud835\udc641\ud835\udc642 \ud835\udc642\n2 \u2212 \ud835\udc642\n1\n]\ufe02\n,\nwhich matches what we found in Example 5.6.4.\n9.2\nDiagonalizability of Linear Operators\nOf all the \u212c-matrices of a fixed linear operator \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5b, some might be simpler than\nothers. For instance, in Examples 9.1.4 and 9.1.5, we were able to find an ordered basis\n\u212c for F\ud835\udc5b such that the \u212c-matrix of the given linear operator \ud835\udc47 was especially simple: it236\nChapter 9\nDiagonalization\nwas a diagonal matrix. This can allow us to perform computations with or make certain\nobservations about the nature of \ud835\udc47 in a more efficient manner.\nExample 9.2.1\nLet #\u00bb\ud835\udc64 =\n[\ufe021\n2\n]\ufe02\n\u2208 R2 and consider the linear operator \ud835\udc47 = refl #\u00bb\n\ud835\udc64. Then:\n1. Using the standard basis \u2130, we have [\ud835\udc47]\u2130 = 1\n5\n[\ufe02\u22123 4\n4 3\n]\ufe02\n.\n2. Using the basis \u212c =\n{\ufe02[\ufe021\n2\n]\ufe02\n,\n[\ufe02 2\n\u22121\n]\ufe02}\ufe02\nfrom Example 9.1.5, we have [\ud835\udc47]\u212c =\n[\ufe021 0\n0 \u22121\n]\ufe02\n.\n3. Using the basis \ud835\udc9e =\n{\ufe02[\ufe02 1\n\u22122\n]\ufe02 [\ufe022\n1\n]\ufe02}\ufe02\n, it can be shown that [\ud835\udc47]\ud835\udc9e = \u22121\n25\n[\ufe02 7\n24\n24 \u221225\n]\ufe02\n.\nWe can see immediately that the matrix [\ud835\udc47]\u212c is invertible. This is also true of the \u2130- and\n\ud835\udc9e-matrix representations, but it is not as obvious.\nMoreover, we can also see at once that ([\ud835\udc47]\u212c)2 = \ud835\udc3c2. This is a manifestation of the geometric\nfact that refl #\u00bb\n\ud835\udc64 \u2218 refl #\u00bb\n\ud835\udc64 is the identity transformation. You can check that ([\ud835\udc47]\u2130)2 and ([\ud835\udc47]\ud835\udc9e)2\nare also both equal to the 2 \u00d7 2 identity matrix, but this requires a bit of a computation.\nThis example demonstrates some of the ways in which a diagonal matrix representation,\nsuch as [\ud835\udc47]\u212c, can be superior to other matrix representations.\nDefinition 9.2.2\nDiagonalizable\nLet \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5b be a linear operator. We say that \ud835\udc47 is diagonalizable over F if there\nexists an ordered basis \u212c for F\ud835\udc5b such that [\ud835\udc47]\u212c is a diagonal matrix.\nLike matrices, not all linear operators are diagonalizable. We\u2019ll see this later as we explore\nthe connection between the diagonalizability of matrices and linear operators.\nExample 9.2.3\nLet #\u00bb\ud835\udc64 \u2208 R2 be a non-zero vector. Then Example 9.1.4 shows that \ud835\udc47 = proj #\u00bb\n\ud835\udc64 is a diagonal-\nizable operator and Example 9.1.5 shows that \ud835\udc47 = refl #\u00bb\n\ud835\udc64 is a diagonalizable operator.\nWe were able to accomplish this because we could choose basis vectors #\u00bb\n\ud835\udc631 and #\u00bb\n\ud835\udc632 such that\n\ud835\udc47(#\u00bb\n\ud835\udc63\ud835\udc56) is a scalar multiple of #\u00bb\n\ud835\udc63\ud835\udc56.\nThe observation at the end of the preceding Example is the key to diagonalizability. It also\nprompts the following (hopefully familiar!) definition.\nDefinition 9.2.4\nEigenvector,\nEigenvalue and\nEigenpair of a\nLinear Operator\nLet \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5b be a linear operator.\nWe say that the non-zero vector #\u00bb\ud835\udc65 \u2208 F\ud835\udc5b is an\neigenvector of \ud835\udc47 if there exists a scalar \ud835\udf06 \u2208 F such that\n\ud835\udc47(#\u00bb\ud835\udc65) = \ud835\udf06#\u00bb\ud835\udc65.\nThe scalar \ud835\udf06 is called an eigenvalue of \ud835\udc47 over F and the pair (\ud835\udf06, #\u00bb\ud835\udc65) is called an eigenpair\nof \ud835\udc47 over F.Section 9.2\nDiagonalizability of Linear Operators\n237\nThis should remind you of the analogous definitions for matrices (Definition 7.1.5). These\ndefinitions are connected as follows.\nProposition 9.2.5\n(Eigenpairs of \ud835\udc47 and [\ud835\udc47]\u212c)\nLet \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5b be a linear operator and let \u212c be an ordered basis for F\ud835\udc5b. Then (\ud835\udf06, #\u00bb\ud835\udc65) is\nan eigenpair of \ud835\udc47 if and only if (\ud835\udf06, [#\u00bb\ud835\udc65]\u212c) is an eigenpair of the matrix [\ud835\udc47]\u212c.\nProof: Take the coordinates of both sides with respect to \u212c of the eigenvalue problem and\nuse the fact that taking coordinates is a linear operation:\n\ud835\udc47(#\u00bb\ud835\udc65) = \ud835\udf06#\u00bb\ud835\udc65 \u21d4 [\ud835\udc47(#\u00bb\ud835\udc65)]\u212c = [\ud835\udf06#\u00bb\ud835\udc65]\u212c\n\u21d4 [\ud835\udc47]\u212c [#\u00bb\ud835\udc65]\u212c = \ud835\udf06 [#\u00bb\ud835\udc65]\u212c\nEXERCISE\nLet #\u00bb\ud835\udc64 =\n[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02\nbe a non-zero vector in R2.\nConsider the projection transformation\nproj #\u00bb\n\ud835\udc64 : R2 \u2192 R2. Find the eigenvalues of proj#\u00bb\n\ud835\udc64 and, for each eigenvalue, find a corre-\nsponding eigenvector.\n[Hint: The hard way is to use the standard basis and [proj#\u00bb\n\ud835\udc64]\u2130 which we computed in\nExample 5.6.1. The easy way is to use the basis \u212c from Example 9.1.4.]\nNow we can give a criterion for the diagonalizability of a linear operator \ud835\udc47.\nProposition 9.2.6\n(Eigenvector Basis Criterion for Diagonalizability)\nLet \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5b be a linear operator. Then \ud835\udc47 is diagonalizable over F if and only if there\nexists an ordered basis \u212c = {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , # \u00bb\n\ud835\udc63\ud835\udc5b} for F\ud835\udc5b consisting of eigenvectors of \ud835\udc47.\nProof: Begin with the forward direction. Assume that \ud835\udc47 is diagonalizable over F. Then\nthere exists an ordered basis \u212c = {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , # \u00bb\n\ud835\udc63\ud835\udc5b} of F\ud835\udc5b such that\n[\ud835\udc47]\u212c = diag(\ud835\udc511, \ud835\udc512, . . . , \ud835\udc51\ud835\udc5b).\nTherefore,\n[\ud835\udc47(#\u00bb\n\ud835\udc63\ud835\udc56)]\u212c = [\ud835\udc47]\u212c [#\u00bb\n\ud835\udc63\ud835\udc56]\u212c\n(by Proposition 9.1.3)\n= diag(\ud835\udc511, . . . , \ud835\udc51\ud835\udc5b)#\u00bb\n\ud835\udc52\ud835\udc56\n= the \ud835\udc56\ud835\udc61\u210e column of diag(\ud835\udc511, . . . , \ud835\udc51\ud835\udc5b)\n(by Lemma 4.2.2 (Column Extraction))\n= \ud835\udc51\ud835\udc56 #\u00bb\n\ud835\udc52\ud835\udc56\n= \ud835\udc51\ud835\udc56 [#\u00bb\n\ud835\udc63\ud835\udc56]\u212c .\nTherefore, for each \ud835\udc56 = 1, 2, . . . , \ud835\udc5b, #\u00bb\n\ud835\udc63\ud835\udc56 is an eigenvector of \ud835\udc47 with eigenvalue \ud835\udc51\ud835\udc56.\nFor the backward direction, assume that there exists an ordered basis \u212c = {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , # \u00bb\n\ud835\udc63\ud835\udc5b}\nfor F\ud835\udc5b consisting of eigenvectors of \ud835\udc47. Then, for all #\u00bb\n\ud835\udc63\ud835\udc56 \u2208 \u212c, \ud835\udc47(#\u00bb\n\ud835\udc63\ud835\udc56) = \ud835\udf06\ud835\udc56 #\u00bb\n\ud835\udc63\ud835\udc56 for some \ud835\udf06\ud835\udc56 \u2208 F.\nSo [\ud835\udc47]\u212c = diag(\ud835\udf061, \ud835\udf062, . . . , \ud835\udf06\ud835\udc5b), a diagonal matrix. Thus, \ud835\udc47 is diagonalizable over F.238\nChapter 9\nDiagonalization\nExample 9.2.7\nLet #\u00bb\ud835\udc64 =\n[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02\nbe a non-zero vector in R2. In Example 9.1.4, we essentially showed that\n\u212c =\n{\ufe02[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02\n,\n[\ufe02 \ud835\udc642\n\u2212\ud835\udc641\n]\ufe02}\ufe02\nis a basis for R2 consisting of eigenvectors of proj #\u00bb\n\ud835\udc64. So proj #\u00bb\n\ud835\udc64 is\ndiagonalizable over R by Proposition 9.2.6.\nMoreover, we showed that the eigenvalues corresponding to\n[\ufe02\ud835\udc641\n\ud835\udc642\n]\ufe02\nand\n[\ufe02 \ud835\udc642\n\u2212\ud835\udc641\n]\ufe02\nare 1 and\n0, respectively, so the proof of Proposition 9.2.6 asserts that [proj #\u00bb\ud835\udc64]\u212c = diag(1, 0). This is\nprecisely what we had found in Example 9.1.4.\nEXERCISE\nApply the same analysis to refl #\u00bb\n\ud835\udc64.\nThe previous Example and Exercise make use of eigenpairs that were determined through a\ngeometric argument. Not all transformations will have intuitive geometric interpretations,\nso this strategy won\u2019t always be practical. We will tackle this problem in the next two\nsections.\n9.3", "Diagonalizability of Matrices Revisited\nIn this section we will describe a strategy for determining when a linear operator is diag-\nonalizable while simultaneously connecting this notion of diagonalizability to the notion of\ndiagonalizability of matrices that we learned about in Section 7.6.\nProposition 9.3.1\n(\ud835\udc47 Diagonalizable iff [\ud835\udc47]\u212c Diagonalizable)\nLet \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5b be a linear operator and let \u212c be an ordered basis of F\ud835\udc5b. Then \ud835\udc47 is\ndiagonalizable over F if and only if the matrix [\ud835\udc47]\u212c is diagonalizable over F.\nProof: (\u21d2):\nAssume that \ud835\udc47 is diagonalizable over F. Then, by Proposition 9.2.6 (Eigenvector Basis Cri-\nterion for Diagonalizability), there exists an ordered basis \ud835\udc9e of F\ud835\udc5b consisting of eigenvectors\nof \ud835\udc47. In the proof of Proposition 9.2.6, we saw that [\ud835\udc47]\ud835\udc9e = diag(\ud835\udf061, \ud835\udf062, . . . , \ud835\udf06\ud835\udc5b), where the\n\ud835\udf06\ud835\udc56\u2019s are the eigenvalues of \ud835\udc47.\nBy Corollary 9.1.7 (Finding the Standard Matrix),\n[\ud835\udc47]\ud835\udc9e = \ud835\udc9e[\ud835\udc3c]\u212c [\ud835\udc47]\u212c \u212c[\ud835\udc3c]\ud835\udc9e = (\u212c[\ud835\udc3c]\ud835\udc9e)\u22121 [\ud835\udc47]\u212c \u212c[\ud835\udc3c]\ud835\udc9e.\nSince [\ud835\udc47]\ud835\udc9e is diagonal, then [\ud835\udc47]\u212c is diagonalizable over F and the matrix \ud835\udc43 = \u212c[\ud835\udc3c]\ud835\udc9e diago-\nnalizes [\ud835\udc47]\u212c.Section 9.3\nDiagonalizability of Matrices Revisited\n239\n(\u21d0):\nAssume that [\ud835\udc47]\u212c is diagonalizable over F.\nThen there exists an invertible matrix\n\ud835\udc43 =\n[\ufe00 #\u00bb\n\ud835\udc5d1 #\u00bb\n\ud835\udc5d2 \u00b7 \u00b7 \u00b7 # \u00bb\n\ud835\udc5d\ud835\udc5b\n]\ufe00\nsuch that\n\ud835\udc43 \u22121[\ud835\udc47]\u212c\ud835\udc43 = \ud835\udc37 = diag(\ud835\udc511, \ud835\udc512, . . . , \ud835\udc51\ud835\udc5b).\nWe define vectors #\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , # \u00bb\n\ud835\udc63\ud835\udc5b such that for \ud835\udc56 = 1, . . . , \ud835\udc5b, [#\u00bb\n\ud835\udc63\ud835\udc56]\u212c = #\u00bb\ud835\udc5d \ud835\udc56, the \ud835\udc56\ud835\udc61\u210e column of \ud835\udc43.\nWe see this is possible by defining #\u00bb\n\ud835\udc63\ud835\udc56 = \u2130[\ud835\udc3c]\u212c #\u00bb\n\ud835\udc5d\ud835\udc56, so that\n#\u00bb\n\ud835\udc5d\ud835\udc56 = (\u2130[\ud835\udc3c]\u212c)\u22121 #\u00bb\n\ud835\udc63\ud835\udc56 = \u212c[\ud835\udc3c]\u2130 #\u00bb\n\ud835\udc63\ud835\udc56 = [#\u00bb\n\ud835\udc63\ud835\udc56]\u212c.\nTherefore,\n\ud835\udc43 =\n[\ufe01\n[#\u00bb\n\ud835\udc631]\u212c [#\u00bb\n\ud835\udc632]\u212c \u00b7 \u00b7 \u00b7 [# \u00bb\n\ud835\udc63\ud835\udc5b]\u212c\n]\ufe01\n.\nWe will show that the set \ud835\udcae = {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , # \u00bb\n\ud835\udc63\ud835\udc5b} is a basis for F\ud835\udc5b. By Proposition 8.5.4 (\ud835\udc5b\nVectors in F\ud835\udc5b Span iff Independent), since it contains \ud835\udc5b vectors in F\ud835\udc5b, then it will be enough\nto show that the set \ud835\udcae is linearly independent. Consider the equation\n\ud835\udc501 #\u00bb\n\ud835\udc631 + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc5b # \u00bb\n\ud835\udc63\ud835\udc5b = #\u00bb0 .\nTaking the coordinates with respect to \u212c of both sides of the equation above, as finding\ncoordinates with respect to a basis is a linear process and [#\u00bb0 ]\u212c = #\u00bb0 , we obtain the equation\n\ud835\udc501[#\u00bb\n\ud835\udc631]\u212c + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc5b[# \u00bb\n\ud835\udc63\ud835\udc5b]\u212c = #\u00bb0 .\nThe set {[#\u00bb\n\ud835\udc631]\u212c, . . . , [# \u00bb\n\ud835\udc63\ud835\udc5b]\u212c} consists of the columns of \ud835\udc43.\nSince \ud835\udc43 is invertible, then by\nTheorem 4.6.7 (Invertibility Criteria \u2013 First Version), rank(\ud835\udc43) = \ud835\udc5b. It then follows from\nProposition 8.3.6 (Pivots and Linear Independence) that {[#\u00bb\n\ud835\udc631]\u212c, . . . , [# \u00bb\n\ud835\udc63\ud835\udc5b]\u212c} is linearly inde-\npendent. Therefore, \ud835\udc501 = \u00b7 \u00b7 \u00b7 = \ud835\udc50\ud835\udc5b = 0 and thus, \ud835\udcae is linearly independent and a basis for\nF\ud835\udc5b.\nNext, we will show that the vectors in \ud835\udcae are also eigenvectors of \ud835\udc47. Using the fact that\n\ud835\udc43 \u22121[\ud835\udc47]\u212c\ud835\udc43 = \ud835\udc37 = diag(\ud835\udc511, \ud835\udc512, . . . , \ud835\udc51\ud835\udc5b), we can multiply both sides by \ud835\udc43 to obtain that\n[\ud835\udc47]\u212c\ud835\udc43 = \ud835\udc43\ud835\udc37. Comparing the \ud835\udc56\ud835\udc61\u210e column of [\ud835\udc47]\u212c\ud835\udc43 with the \ud835\udc56\ud835\udc61\u210e column of \ud835\udc43\ud835\udc37 we obtain\nthe equation\n[\ud835\udc47]\u212c[#\u00bb\n\ud835\udc63\ud835\udc56]\u212c = \ud835\udc51\ud835\udc56[#\u00bb\n\ud835\udc63\ud835\udc56]\u212c.\nTherefore, by Proposition 9.1.3 and the linearity of finding coordinates,\n[\ud835\udc47(#\u00bb\n\ud835\udc63\ud835\udc56)]\u212c = [\ud835\udc51\ud835\udc56 #\u00bb\n\ud835\udc63\ud835\udc56]\u212c.\nThus, \ud835\udc47(#\u00bb\n\ud835\udc63\ud835\udc56) = \ud835\udc51\ud835\udc56 #\u00bb\n\ud835\udc63\ud835\udc56 by Theorem 8.8.1 (Unique Representation Theorem). We know that\n#\u00bb\n\ud835\udc63\ud835\udc56 \u0338= #\u00bb0 , since #\u00bb\n\ud835\udc63\ud835\udc56 belongs to a linearly independent set, and so #\u00bb\n\ud835\udc63\ud835\udc56 is an eigenvector of \ud835\udc47.\nConsequently, we conclude that \ud835\udcae is a basis of eigenvectors of \ud835\udc47, and \ud835\udc47 is diagonalizable\nover F by Proposition 9.2.6 (Eigenvector Basis Criterion for Diagonalizability).\nUsing this result, we can translate our criterion for diagonalizability of operators from\nProposition 9.2.6 (Eigenvector Basis Criterion for Diagonalizability) to a criterion for diag-\nonalizability of matrices.240\nChapter 9\nDiagonalization\nCorollary 9.3.2\n(Eigenvector Basis Criterion for Diagonalizability \u2013 Matrix Version)\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F). Then \ud835\udc34 is diagonalizable over F if and only if there exists a basis of F\ud835\udc5b\nconsisting of eigenvectors of \ud835\udc34.\nProof: Consider the linear operator \ud835\udc47\ud835\udc34 : F\ud835\udc5b \u2192 F\ud835\udc5b such that \ud835\udc47\ud835\udc34(#\u00bb\ud835\udc65) = \ud835\udc34#\u00bb\ud835\udc65. Then [\ud835\udc47\ud835\udc34]\u2130 = \ud835\udc34\nand\n\ud835\udc34 is diagonalizable over F\n\u21d0\u21d2 [\ud835\udc47\ud835\udc34]\u2130 is diagonalizable over F\n(because [\ud835\udc47\ud835\udc34]\u2130 = \ud835\udc34)\n\u21d0\u21d2 \ud835\udc47\ud835\udc34 is diagonalizable over F\n(by Proposition 9.3.1 (\ud835\udc47 Diagonalizable iff [\ud835\udc47]\u212c Diagonalizable))\n\u21d0\u21d2 There exists a basis \u212c of F\ud835\udc5b of eigenvectors of \ud835\udc47\ud835\udc34\n(by Proposition 9.2.6 (Eigenvector Basis Criterion for Diagonalizability))\nBy Proposition 9.2.5 (Eigenpairs of \ud835\udc47 and [\ud835\udc47]\u212c), #\u00bb\ud835\udc65 is an eigenvector of \ud835\udc47\ud835\udc34 if and only if #\u00bb\ud835\udc65\nis an eigenvector of [\ud835\udc47]\u2130 = \ud835\udc34. Therefore, there exists a basis \u212c of F\ud835\udc5b of eigenvectors of \ud835\udc47\ud835\udc34\nif and only if there exists a basis \u212c of F\ud835\udc5b of eigenvectors of \ud835\udc34.\nREMARKS\nThe previous two results contain several important pieces of information.\n1. To determine whether a linear operator \ud835\udc47 is diagonalizable over F, we can start by\nobtaining the matrix of \ud835\udc47 with respect to some basis \u212c for F\ud835\udc5b, and then test whether\nthis matrix is diagonalizable over F.\nThe most natural initial choice for \u212c is the\nstandard basis, \u2130. Thus, moving forward, we can focus our discussion on the\ndiagonalization of matrices.\n2. If \ud835\udc34 is diagonalizable over F and \ud835\udc43 \u22121\ud835\udc34\ud835\udc43 = \ud835\udc37 is a diagonal matrix, then\n(a) the entries of \ud835\udc37 are the eigenvalues of \ud835\udc34 in F,\n(b) the matrix \ud835\udc43 is the change of basis matrix from an ordered basis \u212c for F\ud835\udc5b\ncomprised of eigenvectors of \ud835\udc34 to the standard basis \u2130 for F\ud835\udc5b (so \ud835\udc43 = \u2130[\ud835\udc3c]\u212c),\nand\n(c) the columns of \ud835\udc43 are eigenvectors of \ud835\udc34.\nCorollary 9.3.2 (Eigenvector Basis Criterion for Diagonalizability \u2013 Matrix Version) tells us\nthat determining whether a matrix \ud835\udc34 is diagonalizable over F boils down to whether or not\nwe can find \ud835\udc5b linearly independent eigenvectors of \ud835\udc34 in F\ud835\udc5b.Section 9.3\nDiagonalizability of Matrices Revisited\n241\nExample 9.3.3\nLet \ud835\udc47 : R3 \u2192 R3 be a linear operator with [\ud835\udc47]\u2130 =\n\u23a1\n\u23a3\n3 4 \u22122\n3 8 \u22123\n6 14 \u22125\n\u23a4\n\u23a6 . We will show that \ud835\udc47 is\ndiagonalizable over R by finding three linearly independent eigenvectors of \ud835\udc34 = [\ud835\udc47]\u2130. In\norder to do this, let us begin by finding all the possible eigenvectors of \ud835\udc34.\nThe characteristic polynomial of \ud835\udc34 is\n\ud835\udc36\ud835\udc34(\ud835\udf06) = det\n\u239b\n\u239d\n\u23a1\n\u23a3\n3 \u2212 \ud835\udf06\n4\n\u22122\n3\n8 \u2212 \ud835\udf06\n\u22123\n6\n14\n\u22125 \u2212 \ud835\udf06\n\u23a4\n\u23a6\n\u239e\n\u23a0 = \u2212\ud835\udf063 + 6\ud835\udf062 \u2212 11\ud835\udf06 + 6 = \u2212(\ud835\udf06 \u2212 3)(\ud835\udf06 \u2212 2)(\ud835\udf06 \u2212 1).\nThe eigenvalues of \ud835\udc34 are thus \ud835\udf061 = 1, \ud835\udf062 = 2 and \ud835\udf063 = 3. We leave it as an exercise to show\nthat the corresponding eigenspaces are given by\n\ud835\udc381 = Span\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n1\n0\n1\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad , \ud835\udc382 = Span\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n0\n1\n2\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad and \ud835\udc383 = Span\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n1\n3\n6\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad .\nTherefore, there is an obvious choice for our desired three linearly independent eigenvectors:\n\u212c =\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n1\n0\n1\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n0\n1\n2\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n1\n3\n6\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad .\nOf course, we have to check that this set is in fact linearly independent. We can easily do\nthis using Proposition 8.3.6 (Pivots and Linear Independence), for instance. Thus \u212c is a\nbasis for R3 consisting of eigenvectors of \ud835\udc34.\nTherefore, \ud835\udc34 is diagonalizable over F, by Corollary 9.3.2 (Eigenvector Basis Criterion for\nDiagonalizability \u2013 Matrix Version), and hence \ud835\udc47 is diagonalizable over F too, by Proposition\n9.3.1 (\ud835\udc47 Diagonalizable iff [\ud835\udc47]\u212c Diagonalizable).\nIn the previous Example we could have invoked Proposition 7.6.7 (\ud835\udc5b Distinct Eigenvalues\n=\u21d2 Diagonalizable) to deduce that \ud835\udc34 is diagonalizable. Notice that Proposition 7.6.7 sug-\ngests the same strategy that we followed above: namely, take an eigenvector corresponding\nto each one of the eigenvalues of \ud835\udc34, and form a basis using these eigenvectors. For this strat-\negy to actually produce a basis, we need to be sure that the resulting set of eigenvectors is\nlinearly independent.\nProposition 9.3.4\n(Eigenvectors Corresponding to Distinct Eigenvalues are Linearly Inde-\npendent)\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) have eigenpairs (\ud835\udf061, #\u00bb\n\ud835\udc631), (\ud835\udf062, #\u00bb\n\ud835\udc632), . . . , (\ud835\udf06\ud835\udc58, #\u00bb\n\ud835\udc63\ud835\udc58) over F.\nIf the eigenvalues \ud835\udf061, \ud835\udf062, . . . , \ud835\udf06\ud835\udc58 are all distinct, then the set of eigenvectors {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58}\nis linearly independent.\nProof: Proceed by induction on \ud835\udc58. If \ud835\udc58 = 1, then since eigenvectors are non-zero we have\nthat {#\u00bb\n\ud835\udc631} is linearly independent.242\nChapter 9\nDiagonalization\nAssume the statement holds for \ud835\udc58 = \ud835\udc57, that is, we assume that the set {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc57} is\nlinearly independent.\nConsider the set {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc57, #      \u00bb\n\ud835\udc63\ud835\udc57+1}. We must show that this set is linearly independent\nand so we consider the equation\n\ud835\udc501 #\u00bb\n\ud835\udc631 + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc57+1 #      \u00bb\n\ud835\udc63\ud835\udc57+1 = #\u00bb0 .\n(*)\nWe\u2019ll manipulate (*) in two ways. First, multiply both sides of (*) through by \ud835\udc34 to obtain\n\ud835\udc501\ud835\udf061 #\u00bb\n\ud835\udc631 + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc57\ud835\udf06\ud835\udc57 #\u00bb\n\ud835\udc63\ud835\udc57 + \ud835\udc50\ud835\udc57+1\ud835\udf06\ud835\udc57+1 #      \u00bb\n\ud835\udc63\ud835\udc57+1 = #\u00bb0 .\n(**)\nNext, multiply both sides of (*) through by \ud835\udf06\ud835\udc57+1 to obtain\n\ud835\udc501\ud835\udf06\ud835\udc57+1 #\u00bb\n\ud835\udc631 + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc57\ud835\udf06\ud835\udc57+1 #\u00bb\n\ud835\udc63\ud835\udc57 + \ud835\udc50\ud835\udc57+1\ud835\udf06\ud835\udc57+1 #      \u00bb\n\ud835\udc63\ud835\udc57+1 = #\u00bb0 .\n(* * *)\nThen subtract (* * *) from (**) to get\n\ud835\udc501(\ud835\udf061 \u2212 \ud835\udf06\ud835\udc57+1)#\u00bb\n\ud835\udc631 + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc57(\ud835\udf06\ud835\udc57 \u2212 \ud835\udf06\ud835\udc57+1)#\u00bb\n\ud835\udc63\ud835\udc57 = #\u00bb0 .\nBy the inductive hypothesis, {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc57} is linearly independent so for all \ud835\udc56, 1 \u2264 \ud835\udc56 \u2264 \ud835\udc57,\n\ud835\udc50\ud835\udc56(\ud835\udf06\ud835\udc56 \u2212 \ud835\udf06\ud835\udc57+1) = 0.\nHowever, \ud835\udf06\ud835\udc56 \u0338= \ud835\udf06\ud835\udc57+1 and so \ud835\udc50\ud835\udc56 = 0. Thus, \ud835\udc501 = \u00b7 \u00b7 \u00b7 = \ud835\udc50\ud835\udc57 = 0 and our original equation (*)\nbecomes\n\ud835\udc50\ud835\udc57+1 #      \u00bb\n\ud835\udc63\ud835\udc57+1 = #\u00bb0 .\nThe vector #      \u00bb\n\ud835\udc63\ud835\udc57+1 is nonzero since it is an eigenvector, so we conclude that \ud835\udc50\ud835\udc57+1 = 0. Conse-\nquently, the set {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc57, #      \u00bb\n\ud835\udc63\ud835\udc57+1} is linearly independent. This establishes the inductive\nstep and completes the proof.\nWe can now provide a proof of Proposition 7.6.7 (\ud835\udc5b Distinct Eigenvalues =\u21d2 Diagonaliz-\nable) which states the following:\nIf \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) has \ud835\udc5b distinct eigenvalues \ud835\udf061, \ud835\udf062, . . . , \ud835\udf06\ud835\udc5b in F, then \ud835\udc34 is diagonalizable over\nF.\nMore specifically, if we let (\ud835\udf061, #\u00bb\n\ud835\udc631), . . . , (\ud835\udf06\ud835\udc5b, # \u00bb\n\ud835\udc63\ud835\udc5b) be eigenpairs of \ud835\udc34 over F, and if we let\n\ud835\udc43 = [#\u00bb\n\ud835\udc631 \u00b7 \u00b7 \u00b7 # \u00bb\n\ud835\udc63\ud835\udc5b] be the matrix whose columns are eigenvectors corresponding to the distinct\neigenvalues, then\n(a) \ud835\udc43 is invertible, and\n(b) \ud835\udc43 \u22121\ud835\udc34\ud835\udc43 = \ud835\udc37 = diag(\ud835\udf061, \ud835\udf062, \u00b7 \u00b7 \u00b7 , \ud835\udf06\ud835\udc5b).\nProof: Since we have \ud835\udc5b eigenvectors corresponding to \ud835\udc5b distinct eigenvalues, then the set\n{#\u00bb\n\ud835\udc631, . . . , # \u00bb\n\ud835\udc63\ud835\udc5b} is linearly independent by Proposition 9.3.4 (Eigenvectors Corresponding to\nDistinct Eigenvalues are Linearly Independent). Further, the set {#\u00bb\n\ud835\udc631, . . . , # \u00bb\n\ud835\udc63\ud835\udc5b} is a basis of\neigenvectors for F\ud835\udc5b. Therefore, \ud835\udc34 is diagonalizable over F by Proposition 9.2.6 (Eigenvector\nBasis Criterion for Diagonalizability).Section 9.3\nDiagonalizability of Matrices Revisited\n243\nLet \ud835\udc43 = [#\u00bb\n\ud835\udc631 \u00b7 \u00b7 \u00b7 # \u00bb\n\ud835\udc63\ud835\udc5b].\nSince {#\u00bb\n\ud835\udc631, . . . , # \u00bb\n\ud835\udc63\ud835\udc5b} is a basis, then it is linearly independent, and\nso rank(\ud835\udc43) = \ud835\udc5b by Proposition 8.3.6 (Pivots and Linear Independence).\nTherefore, by\nTheorem 4.6.7 (Invertibility Criteria \u2013 First Version), \ud835\udc43 is invertible. Now since #\u00bb\n\ud835\udc631, . . . , # \u00bb\n\ud835\udc63\ud835\udc5b\nare eigenvectors of \ud835\udc34, then using Lemma 4.2.2 (Column Extraction),\n\ud835\udc34\ud835\udc43 = \ud835\udc34[#\u00bb\n\ud835\udc631 \u00b7 \u00b7 \u00b7 # \u00bb\n\ud835\udc63\ud835\udc5b] = [\ud835\udc34#\u00bb\n\ud835\udc63\ud835\udc56 \u00b7 \u00b7 \u00b7 \ud835\udc34# \u00bb\n\ud835\udc63\ud835\udc5b] = [\ud835\udf061 #\u00bb\n\ud835\udc631 \u00b7 \u00b7 \u00b7 \ud835\udf06\ud835\udc5b # \u00bb\n\ud835\udc63\ud835\udc5b].\nLet \ud835\udc37 = diag(\ud835\udf061, \ud835\udf062, . . . , \ud835\udf06\ud835\udc5b) = [\ud835\udf061 #\u00bb\n\ud835\udc521 \u00b7 \u00b7 \u00b7 \ud835\udf06\ud835\udc5b #\u00bb\n\ud835\udc52\ud835\udc5b]. Therefore, using Lemma 4.2.2 again,\n\ud835\udc43\ud835\udc37 = \ud835\udc43[\ud835\udf061 #\u00bb\n\ud835\udc521 \u00b7 \u00b7 \u00b7 \ud835\udf06\ud835\udc5b #\u00bb\n\ud835\udc52\ud835\udc5b] = [\ud835\udf061\ud835\udc43 #\u00bb\n\ud835\udc521 \u00b7 \u00b7 \u00b7 \ud835\udf06\ud835\udc5b\ud835\udc43 #\u00bb\n\ud835\udc52\ud835\udc5b] = [\ud835\udf061 #\u00bb\n\ud835\udc631 \u00b7 \u00b7 \u00b7 \ud835\udf06\ud835\udc5b # \u00bb\n\ud835\udc63\ud835\udc5b].\nTherefore, \ud835\udc34\ud835\udc43 = \ud835\udc43\ud835\udc37 and so\n\ud835\udc43 \u22121\ud835\udc34\ud835\udc43 = \ud835\udc37 = diag(\ud835\udf061, \ud835\udf062, . . . , \ud835\udf06\ud835\udc5b).\nExample 9.3.5\nSuppose \ud835\udc47 : R3 \u2192 R3 is a linear operator with [\ud835\udc47]\u2130 =\n\u23a1\n\u23a3\n5 2 \u22121\n8 1 \u22122\n16 0 \u22123\n\u23a4\n\u23a6 .\n(a) Prove that \ud835\udc47 is diagonalizable over R.\n(b) Find a basis \u212c of R3 such that [\ud835\udc47]\u212c is a diagonal matrix.\n(c) Determine an invertible matrix \ud835\udc43 such that \ud835\udc43 \u22121 [\ud835\udc47]\u2130 \ud835\udc43 = [\ud835\udc47]\u212c.\nSolution:\n(a) By Proposition 9.3.1 (\ud835\udc47 Diagonalizable iff [\ud835\udc47]\u212c Diagonalizable), it suffices to prove that\n\ud835\udc34 = [\ud835\udc47]\u2130 is diagonalizable over R. The characteristic polynomial of \ud835\udc34 is\n\ud835\udc36\ud835\udc34(\ud835\udf06) = det\n\u239b\n\u239d\n\u23a1\n\u23a3\n5 \u2212 \ud835\udf06\n2\n\u22121\n8\n1 \u2212 \ud835\udf06\n\u22122\n16\n0\n\u22123 \u2212 \ud835\udf06\n\u23a4\n\u23a6\n\u239e\n\u23a0 = \u2212\ud835\udf063 + 3\ud835\udf062 + 13\ud835\udf06 \u2212 15.\nSince\n\u2212\ud835\udf063 + 3\ud835\udf062 + 13\ud835\udf06 \u2212 15 = \u2212(\ud835\udf06 \u2212 5)(\ud835\udf06 \u2212 1)(\ud835\udf06 + 3),\nthe eigenvalues of \ud835\udc47 are \ud835\udf061 = 5, \ud835\udf062 = 1, and \ud835\udf063 = \u22123. There are three distinct eigenval-\nues, and therefore \ud835\udc34 is diagonalizable over R by Proposition 7.6.7 (\ud835\udc5b Distinct Eigenvalues\n=\u21d2 Diagonalizable).\n(b) We want a basis \u212c for R3 consisting of eigenvectors of \ud835\udc34. Since we have three distinct\neigenvalues, we need to select one eigenvector from each eigenspace. We leave it as an\nexercise to determine that the eigenspaces of \ud835\udc34 are given by\n\ud835\udc385 = Span\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n1\n1\n2\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad , \ud835\udc381 = Span\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n1\n0\n4\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad and \ud835\udc38\u22123 = Span\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n0\n1\n2\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad .\nThus,\n\u212c =\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n1\n1\n2\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n1\n0\n4\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n0\n1\n2\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad\nis a basis for R3 for which [\ud835\udc47]\u212c = diag(5, 1, \u22123).244\nChapter 9\nDiagonalization\n(c) The columns of the desired matrix \ud835\udc43 are the eigenvectors in \u212c. Thus,\n\ud835\udc43 =\n\u23a1\n\u23a3\n1 1 0\n1 0 1\n2 4 2\n\u23a4\n\u23a6 .\nREMARK\nWe repeat for emphasis that the matrix \ud835\udc43 in part (c) that diagonalizes \ud835\udc34 is the change of\nbasis matrix from the basis of eigenvectors of \ud835\udc34 to the standard basis, \u2130[\ud835\udc3c]\u212c.\n9.4", "The Diagonalizability Test\nFor \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) to be diagonalizable over F, it must have \ud835\udc5b linearly independent eigen-\nvectors in F\ud835\udc5b. Let us consider some examples where \ud835\udc5b linearly independent eigenvectors do\nnot exist.\nExample 9.4.1\nLet \ud835\udc34 =\n[\ufe02 0 1\n\u22121 0\n]\ufe02\n. Then \ud835\udc36\ud835\udc34(\ud835\udf06) = \ud835\udf062 + 1. This matrix has no real eigenvalues and therefore\nno real eigenvectors. So \ud835\udc34 is not diagonalizable over R.\nHowever, we note that \ud835\udc34 does have two distinct complex eigenvalues, \ud835\udf061 = \ud835\udc56 and \ud835\udf062 = \u2212\ud835\udc56,\nand is therefore diagonalizable over C.\nExample 9.4.2\nLet \ud835\udc34 =\n\u23a1\n\u23a3\n2 0 0\n0 0 1\n0 \u22121 0\n\u23a4\n\u23a6 . Then \ud835\udc36\ud835\udc34(\ud835\udf06) = \u2212(\ud835\udf06 \u2212 2)(\ud835\udf062 + 1).\nThis matrix has only one real eigenvalue \ud835\udf061 = 2. We can show that all eigenvectors associated\nwith this eigenvalue are scalar multiples of\n[\ufe00\n1 0 0\n]\ufe00\ud835\udc47 . Therefore, \ud835\udc34 is not diagonalizable\nover R.\nHowever, we note that \ud835\udc34 does have three distinct complex eigenvalues, \ud835\udf061 = 2, \ud835\udf062 = \ud835\udc56, and\n\ud835\udf063 = \u2212\ud835\udc56, and is therefore diagonalizable over C.\nExample 9.4.3\nLet \ud835\udc34 =\n[\ufe020 1\n0 0\n]\ufe02\n. Then \ud835\udc36\ud835\udc34(\ud835\udf06) = \ud835\udf062 = (\ud835\udf06 \u2212 0)2.\nThis matrix has two real eigenvalues, but they are both 0. We can show that all eigenvec-\ntors associated with the eigenvalue 0 are scalar multiples of\n[\ufe00\n1 0\n]\ufe00\ud835\udc47 . Therefore, \ud835\udc34 is not\ndiagonalizable over R or C.\nWe will now introduce some theory that will help us determine exactly when a basis of\neigenvectors exists.Section 9.4\nThe Diagonalizability Test\n245\nDefinition 9.4.4\nAlgebraic\nMultiplicity\nLet \ud835\udf06\ud835\udc56 be an eigenvalue of \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F). The algebraic multiplicity of \ud835\udf06\ud835\udc56, denoted by\n\ud835\udc4e\ud835\udf06\ud835\udc56, is the largest positive integer such that (\ud835\udf06\u2212\ud835\udf06\ud835\udc56)\ud835\udc4e\ud835\udf06\ud835\udc56 divides the characteristic polynomial\n\ud835\udc36\ud835\udc34(\ud835\udf06).\nIn other words, \ud835\udc4e\ud835\udf06\ud835\udc56 gives the number of times that (\ud835\udf06\u2212\ud835\udf06\ud835\udc56) terms occur in the fully factorized\nform of \ud835\udc36\ud835\udc34(\ud835\udf06).\nExample 9.4.5\nLet \ud835\udc34 =\n\u23a1\n\u23a3\n1 2 2\n2 1 2\n2 2 1\n\u23a4\n\u23a6 . Then \ud835\udc36\ud835\udc34(\ud835\udf06) = \u2212(\ud835\udf06 \u2212 5)(\ud835\udf06 + 1)2.\nThe matrix \ud835\udc34 has two distinct eigenvalues: \ud835\udf061 = 5, with algebraic multiplicity \ud835\udc4e\ud835\udf061 = 1, and\n\ud835\udf062 = \u22121, with algebraic multiplicity \ud835\udc4e\ud835\udf062 = 2.\nWe can also say that \ud835\udc34 has three eigenvalues with one of them being repeated twice. So its\neigenvalues are 5, \u22121, and \u22121.\nDefinition 9.4.6\nGeometric\nMultiplicity\nLet \ud835\udf06\ud835\udc56 be an eigenvalue of \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F). The geometric multiplicity of \ud835\udf06\ud835\udc56, denoted by\n\ud835\udc54\ud835\udf06\ud835\udc56, is the dimension of the eigenspace \ud835\udc38\ud835\udf06\ud835\udc56. That is, \ud835\udc54\ud835\udf06\ud835\udc56 = dim(\ud835\udc38\ud835\udf06\ud835\udc56).\nExample 9.4.7\nLet \ud835\udc34 \u2208 \ud835\udc403\u00d73(R) with \ud835\udc34 =\n\u23a1\n\u23a3\n1 2 2\n2 1 2\n2 2 1\n\u23a4\n\u23a6 . Determine the geometric multiplicities of all eigen-\nvalues of \ud835\udc34.\nSolution:\nThe eigenvalues of \ud835\udc34 are \ud835\udf061 = 5 and \ud835\udf062 = \u22121.\nThe eigenspace \ud835\udc38\ud835\udf061 is the solution set to (\ud835\udc34 \u2212 5\ud835\udc3c)#\u00bb\ud835\udc65 = #\u00bb0 , which is equivalent to\n\u23a1\n\u23a3\n\u22124 2\n2\n2 \u22124 2\n2\n2 \u22124\n\u23a4\n\u23a6 #\u00bb\ud835\udc65 = #\u00bb0\nand row reduces to\n\u23a1\n\u23a3\n1 0 \u22121\n0 1 \u22121\n0 0 0\n\u23a4\n\u23a6 #\u00bb\ud835\udc65 = #\u00bb0 .\nA basis for \ud835\udc385 is thus\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n1\n1\n1\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad .\nTherefore, dim(\ud835\udc38\ud835\udf061) = 1 and so \ud835\udc54\ud835\udf061 = 1.\nThe eigenspace \ud835\udc38\ud835\udf062 is the solution set to (\ud835\udc34 + 1\ud835\udc3c)#\u00bb\ud835\udc65 = #\u00bb0 , which is equivalent to\n\u23a1\n\u23a3\n2 2 2\n2 2 2\n2 2 2\n\u23a4\n\u23a6 #\u00bb\ud835\udc65 = #\u00bb0246\nChapter 9\nDiagonalization\nand row reduces to\n\u23a1\n\u23a3\n1 1 1\n0 0 0\n0 0 0\n\u23a4\n\u23a6 #\u00bb\ud835\udc65 = #\u00bb0 .\nA basis for \ud835\udc38\ud835\udf062 is thus\n\u23a7\n\u23a8\n\u23a9\n\u23a1\n\u23a3\n1\n\u22121\n0\n\u23a4\n\u23a6 ,\n\u23a1\n\u23a3\n1\n0\n\u22121\n\u23a4\n\u23a6\n\u23ab\n\u23ac\n\u23ad .\nTherefore, dim(\ud835\udc38\ud835\udf062) = 2 and so \ud835\udc54\ud835\udf062 = 2.\nThe geometric multiplicity of an eigenvalue tells us the maximum number of linearly inde-\npendent eigenvectors we can obtain from the eigenspace corresponding to that eigenvalue.\nThe two multiplicities are connected through the following result.\nProposition 9.4.8\n(Geometric and Algebraic Multiplicities)\nLet \ud835\udf06\ud835\udc56 be an eigenvalue of the matrix \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F). Then\n1 \u2264 \ud835\udc54\ud835\udf06\ud835\udc56 \u2264 \ud835\udc4e\ud835\udf06\ud835\udc56.\nREMARK\nIn the proof below, we will describe a matrix by using what is called a block matrix; that\nis, denoting some or all parts of a matrix as matrices themselves.\nFor example, given the matrix\n\ud835\udc34 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a3\n1\n2\n5\n6\n7\n3\n4\n8\n9 10\n11 12 17 18 19\n13 14 20 21 22\n15 16 23 24 25\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a6\nwe can describe \ud835\udc34 as\n\ud835\udc34 =\n[\ufe02\ud835\udc341 \ud835\udc342\n\ud835\udc351 \ud835\udc352\n]\ufe02\nwhere\n\ud835\udc341 =\n[\ufe021 2\n3 4\n]\ufe02\n,\n\ud835\udc342 =\n[\ufe025 6 7\n8 9 10\n]\ufe02\n,\n\ud835\udc351 =\n\u23a1\n\u23a3\n11 12\n13 14\n15 16\n\u23a4\n\u23a6 ,\n\ud835\udc352 =\n\u23a1\n\u23a3\n17 18 19\n20 21 22\n23 24 25\n\u23a4\n\u23a6 .\nAlternatively, with \ud835\udc342, \ud835\udc351, and \ud835\udc352 defined as above, we can re-write our matrix \ud835\udc34 as\n\ud835\udc34 =\n\u23a1\n\u23a3\n1\n2\n3\n4\n\ud835\udc342\n\ud835\udc351\n\ud835\udc352\n\u23a4\n\u23a6 .\nOf course, there are many other ways we could slice \ud835\udc34 into blocks to give different block\nrepresentations of \ud835\udc34.Section 9.4\nThe Diagonalizability Test\n247\nProof: By definition, if \ud835\udf06\ud835\udc56 is an eigenvalue of \ud835\udc34, then there is a non-trivial solution to\n\ud835\udc34#\u00bb\ud835\udc63 = \ud835\udf06\ud835\udc56 #\u00bb\ud835\udc63 . Therefore, each eigenspace contains at least one non-zero vector and so its\ndimension will be at least one. Therefore, 1 \u2264 \ud835\udc54\ud835\udf06\ud835\udc56.\nSuppose that {#\u00bb\n\ud835\udc631, . . . , #\u00bb\n\ud835\udc63\ud835\udc58} is a basis for \ud835\udc38\ud835\udf06\ud835\udc56. Therefore, \ud835\udc54\ud835\udf06\ud835\udc56 = \ud835\udc58.\nWe can extend this basis for \ud835\udc38\ud835\udf06\ud835\udc56 to a basis \u212c for F\ud835\udc5b (for a demonstration of how this\ncan be done, see Example 8.5.7, as well as the remark preceding it).\nTherefore, \u212c =\n{#\u00bb\n\ud835\udc631, . . . , #\u00bb\n\ud835\udc63\ud835\udc58, #        \u00bb\n\ud835\udc64\ud835\udc58+1, . . . , #  \u00bb\n\ud835\udc64\ud835\udc5b} .\nWe let \ud835\udc47\ud835\udc34 : F\ud835\udc5b \u2192 F\ud835\udc5b be defined as \ud835\udc47\ud835\udc34(#\u00bb\ud835\udc63 ) = \ud835\udc34#\u00bb\ud835\udc63 .\nFor \ud835\udc57 = 1, . . . , \ud835\udc58, it is the case that #\u00bb\n\ud835\udc63\ud835\udc57 \u2208 \ud835\udc38\ud835\udf06\ud835\udc56 and therefore, \ud835\udc34#\u00bb\n\ud835\udc63\ud835\udc57 = \ud835\udf06\ud835\udc56 #\u00bb\n\ud835\udc63\ud835\udc57.\nTherefore,\n[\ud835\udc47\ud835\udc34(#\u00bb\n\ud835\udc63\ud835\udc57)]\u212c = \ud835\udf06\ud835\udc56 #\u00bb\n\ud835\udc52\ud835\udc57. For \ud835\udc57 = \ud835\udc58 + 1, . . . , \ud835\udc5b, [\ud835\udc47\ud835\udc34(# \u00bb\n\ud835\udc64\ud835\udc57)]\u212c will be some vector in F\ud835\udc5b. It now follows\nthat [\ud835\udc47\ud835\udc34]\u212c has the block structure\n[\ud835\udc47\ud835\udc34]\u212c =\n\u23a1\n\u23a2\u23a2\u23a2\u23a2\u23a2\u23a3\n\ud835\udf06\ud835\udc56\n0\n\u00b7 \u00b7 \u00b7\n0\n0\n\ud835\udf06\ud835\udc56\n\u00b7 \u00b7 \u00b7\n0\n...\n...\n...\n...\n0\n0\n\u00b7 \u00b7 \u00b7\n\ud835\udf06\ud835\udc56\n\ud835\udc401\n\ud835\udcaa(\ud835\udc5b\u2212\ud835\udc58)\u00d7\ud835\udc58\n\ud835\udc402\n\u23a4\n\u23a5\u23a5\u23a5\u23a5\u23a5\u23a6\nfor some \ud835\udc401 \u2208 \ud835\udc40\ud835\udc58\u00d7(\ud835\udc5b\u2212\ud835\udc58)(F) and some \ud835\udc402 \u2208 \ud835\udc40(\ud835\udc5b\u2212\ud835\udc58)\u00d7(\ud835\udc5b\u2212\ud835\udc58)(F).\nThe characteristic polynomial of \ud835\udc34 is equal to the characteristic polynomials of [\ud835\udc47\ud835\udc34]\u212c since\nthese two matrices are similar (exercise).\nIt can be shown by induction that\n\ud835\udc36\ud835\udc34(\ud835\udf06) = (\ud835\udf06\ud835\udc56 \u2212 \ud835\udf06)\ud835\udc58\ud835\udc36\ud835\udc402(\ud835\udf06) = (\ud835\udf06\ud835\udc56 \u2212 \ud835\udf06)\ud835\udc54\ud835\udf06\ud835\udc56\ud835\udc36\ud835\udc402(\ud835\udf06).\nSince \ud835\udc4e\ud835\udf06\ud835\udc56 is the largest positive integer such that (\ud835\udf06 \u2212 \ud835\udf06\ud835\udc56)\ud835\udc4e\ud835\udf06\ud835\udc56 divides \ud835\udc36\ud835\udc34(\ud835\udc61), it follows that\n\ud835\udc54\ud835\udf06\ud835\udc56 \u2264 \ud835\udc4e\ud835\udf06\ud835\udc56.\nWhat happens if we take the union of the bases of all the eigenspaces of a given matrix? It\nturns out that this set is linearly independent.\nProposition 9.4.9\nLet \ud835\udc34\n\u2208\n\ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) with distinct eigenvalues \ud835\udf061, \ud835\udf062, . . . , \ud835\udf06\ud835\udc58.\nIf their corresponding\neigenspaces, \ud835\udc38\ud835\udf061, \ud835\udc38\ud835\udf062, . . . , \ud835\udc38\ud835\udf06\ud835\udc58 have bases \u212c1, \u212c2, . . . , \u212c\ud835\udc58, then \u212c = \u212c1 \u222a \u212c2 \u222a \u00b7 \u00b7 \u00b7 \u222a \u212c\ud835\udc58 is\nlinearly independent.\nProof: To make things easier to read, let \ud835\udc54\ud835\udc56 = \ud835\udc54\ud835\udf06\ud835\udc56 for \ud835\udc56 = 1, . . . , \ud835\udc58.\nLet \u212c1 = {#   \u00bb\n\ud835\udc631 1, . . . , #     \u00bb\n\ud835\udc631 \ud835\udc541}, \u212c2 = {#   \u00bb\n\ud835\udc632 1, . . . , #     \u00bb\n\ud835\udc632 \ud835\udc542} and so on up to \u212c\ud835\udc58 = {#   \u00bb\n\ud835\udc63\ud835\udc58 1 . . . , #      \u00bb\n\ud835\udc63\ud835\udc58 \ud835\udc54\ud835\udc58}. Take\nnote of the double subscripts here, with the first subscript corresponding to the numbering\nof the basis (\u212c1, \u212c2, and so on) and the second subscript counting the vector\u2019s position\nwithin that basis.\nWe wish to perform the linear dependence check on \u212c = \u212c1 \u222a \u212c2 \u222a \u00b7 \u00b7 \u00b7 \u222a \u212c\ud835\udc58. We consider\nthe following equation with scalars in F:\n\ud835\udc541\n\u2211\ufe01\n\ud835\udc56=1\n\ud835\udc501\ud835\udc56 #  \u00bb\n\ud835\udc631 \ud835\udc56 +\n\ud835\udc542\n\u2211\ufe01\n\ud835\udc56=1\n\ud835\udc502\ud835\udc56 #  \u00bb\n\ud835\udc632 \ud835\udc56 + \u00b7 \u00b7 \u00b7 +\n\ud835\udc54\ud835\udc58\n\u2211\ufe01\n\ud835\udc56=1\n\ud835\udc50\ud835\udc58\ud835\udc56 #   \u00bb\n\ud835\udc63\ud835\udc58 \ud835\udc56 = #\u00bb0\n(*).248\nChapter 9\nDiagonalization\nLet # \u00bb\n\ud835\udc641 =\n\ud835\udc541\n\u2211\ufe00\n\ud835\udc56=1\n\ud835\udc501\ud835\udc56 #  \u00bb\n\ud835\udc631 \ud835\udc56, which is a vector from \ud835\udc38\ud835\udf061. Let # \u00bb\n\ud835\udc642 =\n\ud835\udc542\n\u2211\ufe00\n\ud835\udc56=1\n\ud835\udc502\ud835\udc56 #  \u00bb\n\ud835\udc632 \ud835\udc56, which is a vector from\n\ud835\udc38\ud835\udf062. Continuing in this manner, let #  \u00bb\n\ud835\udc64\ud835\udc58 =\n\ud835\udc54\ud835\udc58\n\u2211\ufe00\n\ud835\udc56=1\n\ud835\udc50\ud835\udc58\ud835\udc56 #   \u00bb\n\ud835\udc63\ud835\udc58 \ud835\udc56, which is a vector from \ud835\udc38\ud835\udf06\ud835\udc58.\nTherefore, our equation (*) has become\n# \u00bb\n\ud835\udc641 + # \u00bb\n\ud835\udc642 + \u00b7 \u00b7 \u00b7 + #  \u00bb\n\ud835\udc64\ud835\udc58 = #\u00bb0\n(**).\nEach of the # \u00bb\n\ud835\udc64\ud835\udc57 are from a different eigenspace.\nThe vectors in a given eigenspace are\neither eigenvectors or the zero vector. If any of the # \u00bb\n\ud835\udc64\ud835\udc57 are not the zero vector, then from\n(**) we get a non-trivial linear combination of eigenvectors each chosen from a different\neigenspace equalling to the zero vector. This contradicts Proposition 9.3.4 (Eigenvectors\nCorresponding to Distinct Eigenvalues are Linearly Independent), which tells us that a set\nof eigenvectors chosen in such a way that every eigenvector is from a different eigenspace is\nlinearly independent. Therefore, it must be the case that # \u00bb\n\ud835\udc641 = \u00b7 \u00b7 \u00b7 = #  \u00bb\n\ud835\udc64\ud835\udc58 = #\u00bb0 .\nBut # \u00bb\n\ud835\udc64\ud835\udc57 =\n\ud835\udc54\ud835\udc57\n\u2211\ufe00\n\ud835\udc56=1\n\ud835\udc50\ud835\udc57\ud835\udc56 #  \u00bb\n\ud835\udc63\ud835\udc57 \ud835\udc56 = #\u00bb0 implies that \ud835\udc50\ud835\udc571 = \u00b7 \u00b7 \u00b7 = \ud835\udc50\ud835\udc57\ud835\udc54\ud835\udf06\ud835\udc57 = 0 because \u212c\ud835\udc57 is a basis for \ud835\udc38\ud835\udf06\ud835\udc57.\nTherefore, all of the scalars in (*) are 0 and the set \u212c is linearly independent.\nWe have now reached the stage where we can give a test to determine whether a matrix is\ndiagonalizable over F.\nTheorem 9.4.10\n(Diagonalizability Test)\nLet \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F). Suppose that the complete factorization of the characteristic polynomial\nof \ud835\udc34 into irreducible factors over F is given by\n\ud835\udc36\ud835\udc34(\ud835\udf06) = (\ud835\udf06 \u2212 \ud835\udf061)\ud835\udc4e\ud835\udf061 \u00b7 \u00b7 \u00b7 (\ud835\udf06 \u2212 \ud835\udf06\ud835\udc58)\ud835\udc4e\ud835\udf06\ud835\udc58 \u210e(\ud835\udf06),\nwhere \ud835\udf061, . . . \ud835\udf06\ud835\udc58 are all of the distinct eigenvalues of \ud835\udc34 in F with corresponding algebraic\nmultiplicities \ud835\udc4e\ud835\udf061 . . . \ud835\udc4e\ud835\udf06\ud835\udc58 and \u210e(\ud835\udf06) is a polynomial in \ud835\udf06 that is irreducible over F. Then \ud835\udc34\nis diagonalizable over F if and only if \u210e(\ud835\udf06) is a constant polynomial and \ud835\udc4e\ud835\udf06\ud835\udc56 = \ud835\udc54\ud835\udf06\ud835\udc56, for each\n\ud835\udc56 = 1, . . . , \ud835\udc58.\nProof: We begin with the forward direction. Thus, assume that \ud835\udc34 is diagonalizable over\nF. Then, by Corollary 9.3.2 (Eigenvector Basis Criterion for Diagonalizability \u2013 Matrix\nVersion), \ud835\udc34 has \ud835\udc5b linearly independent eigenvectors in F\ud835\udc5b. Each of these eigenvectors must\nlie in one of the eigenspaces \ud835\udc38\ud835\udf06\ud835\udc56 of \ud835\udc34, and no eigenvector can lie in two different eigenspaces.\nSince there can be at most \ud835\udc54\ud835\udf06\ud835\udc56 linearly independent vectors in \ud835\udc38\ud835\udf06\ud835\udc56, we conclude that\n\ud835\udc5b \u2264 \ud835\udc54\ud835\udf06\ud835\udc56 + . . . + \ud835\udc54\ud835\udf06\ud835\udc58.\nOn the other hand, by Proposition 9.4.8 (Geometric and Algebraic Multiplicities), we know\nthat \ud835\udc54\ud835\udf06\ud835\udc56 \u2264 \ud835\udc4e\ud835\udf06\ud835\udc56, and so\n\ud835\udc54\ud835\udf061 + \u00b7 \u00b7 \u00b7 + \ud835\udc54\ud835\udf06\ud835\udc58 \u2264 \ud835\udc4e\ud835\udf061 + \u00b7 \u00b7 \u00b7 + \ud835\udc4e\ud835\udf06\ud835\udc58.\nWe also know that the sum of algebraic multiplicities \ud835\udc4e\ud835\udf06\ud835\udc56 + \u00b7 \u00b7 \u00b7 + \ud835\udc4e\ud835\udf06\ud835\udc58 is at most the degree\nof \ud835\udc36\ud835\udc34(\ud835\udf06), which is \ud835\udc5b by Proposition 7.3.4 (Features of the Characteristic Polynomial).\nTherefore,\n\ud835\udc5b \u2264 \ud835\udc54\ud835\udf06\ud835\udc56 + . . . + \ud835\udc54\ud835\udf06\ud835\udc58 \u2264 \ud835\udc4e\ud835\udf06\ud835\udc56 + \u00b7 \u00b7 \u00b7 + \ud835\udc4e\ud835\udf06\ud835\udc58 \u2264 \ud835\udc5b.Section 9.4\nThe Diagonalizability Test\n249\nThis implies that\n\ud835\udc54\ud835\udf06\ud835\udc56 + . . . + \ud835\udc54\ud835\udf06\ud835\udc58 = \ud835\udc4e\ud835\udf06\ud835\udc56 + \u00b7 \u00b7 \u00b7 + \ud835\udc4e\ud835\udf06\ud835\udc58 = \ud835\udc5b = deg(\ud835\udc36\ud835\udc34(\ud835\udf06)).\nFrom this we immediately conclude that deg(\u210e(\ud835\udf06)) = 0, i.e., that \u210e(\ud835\udf06) is a constant poly-\nnomial. Since \ud835\udc54\ud835\udf06\ud835\udc56 \u2264 \ud835\udc4e\ud835\udf06\ud835\udc56 for all \ud835\udc56 = 1, . . . , \ud835\udc58, we also conclude from this that \ud835\udc54\ud835\udf06\ud835\udc56 = \ud835\udc4e\ud835\udf06\ud835\udc56 for all\n\ud835\udc56 = 1, . . . , \ud835\udc58. This completes the proof of the forward direction.\nConversely, assume that \u210e(\ud835\udf06) is a constant polynomial and that \ud835\udc54\ud835\udf06\ud835\udc56 = \ud835\udc4e\ud835\udf06\ud835\udc56 for all \ud835\udc56 = 1, . . . , \ud835\udc58.\nThis implies that\n\ud835\udc54\ud835\udf06\ud835\udc56 + . . . + \ud835\udc54\ud835\udf06\ud835\udc58 = \ud835\udc4e\ud835\udf06\ud835\udc56 + \u00b7 \u00b7 \u00b7 + \ud835\udc4e\ud835\udf06\ud835\udc58 = \ud835\udc5b.\nThus if we let \u212c\ud835\udc58 be a basis for \ud835\udc38\ud835\udf06\ud835\udc58 for \ud835\udc56 = 1, . . . , \ud835\udc58, and if we let \u212c = \u212c1 \u222a \u00b7 \u00b7 \u00b7 \u222a \u212c\ud835\udc58 be\nthe union of these bases, then by Proposition 9.4.9, \u212c will linearly independent, and by the\nabove, \u212c will contain \ud835\udc54\ud835\udf06\ud835\udc56 + . . . + \ud835\udc54\ud835\udf06\ud835\udc58 = \ud835\udc5b eigenvectors. Thus \u212c is a linearly independent\nsubset of F\ud835\udc5b that contains \ud835\udc5b vectors, so \u212c must be a basis for F\ud835\udc5b. Therefore, we have\nfound a basis for F\ud835\udc5b consisting of eigenvectors of \ud835\udc34, so \ud835\udc34 must be diagonalizable over F, by\nCorollary 9.3.2 (Eigenvector Basis Criterion for Diagonalizability \u2013 Matrix Version).\nREMARK\nIf F = C, then the polynomial \u210e(\ud835\udf06) in Theorem 9.4.10 (Diagonalizability Test) is always\nconstant (in fact, it is equal to (\u22121)\ud835\udc5b.) This is because every degree \ud835\udc5b polynomial factors\nover C into linear factors. Therefore \u210e(\ud835\udf06) only matters if F = R. It measures the failure of\n\ud835\udc36\ud835\udc34(\ud835\udf06) to factor completely into linear factors, and so it measures, in a sense, a deficit of\nreal eigenvalues.\nExample 9.4.11\nConsider the matrix \ud835\udc34 =\n\u23a1\n\u23a3\n1 2 2\n2 1 2\n2 2 1\n\u23a4\n\u23a6 from Example 9.4.7. Determine whether \ud835\udc34 is diagonal-\nizable over R and/or C.\nSolution: In Example 9.4.7, we found the characteristic polynomial to be\n\ud835\udc36\ud835\udc34(\ud835\udf06) = \u2212(\ud835\udf06 \u2212 5)(\ud835\udf06 + 1)2.\nSo \u210e(\ud835\udf06) = \u22121, a constant polynomial. The eigenvalues are \ud835\udf061 = 5 and \ud835\udf062 = \u22121 and we\ndetermined that \ud835\udc4e\ud835\udf061 = \ud835\udc54\ud835\udf061 = 1 and \ud835\udc4e\ud835\udf062 = \ud835\udc54\ud835\udf062 = 2. Therefore, \ud835\udc34 is diagonalizable over both\nR and C, using Theorem 9.4.10 (Diagonalizability Test).\nExample 9.4.12\nDetermine whether \ud835\udc34 =\n\u23a1\n\u23a2\u23a2\u23a3\n1 2 0 0\n2 1 0 0\n0 0 1 2\n0 0 2 1\n\u23a4\n\u23a5\u23a5\u23a6 is diagonalizable over R and/or C.\nSolution: The characteristic polynomial is \ud835\udc36\ud835\udc34(\ud835\udf06) = (\ud835\udf06 \u2212 3)2(\ud835\udf06 + 1)2. Therefore, \u210e(\ud835\udf06) = 1,\na constant polynomial.250\nChapter 9\nDiagonalization\nThe eigenvalues are: \ud835\udf061 = 3, with \ud835\udc4e\ud835\udf061 = 2, and \ud835\udf062 = \u22121, with \ud835\udc4e\ud835\udf062 = 2.\nThe eigenspace \ud835\udc38\ud835\udf061 is the solution set to (\ud835\udc34 \u2212 3\ud835\udc3c)#\u00bb\ud835\udc63 = #\u00bb0 , which is equivalent to\n\u23a1\n\u23a2\u23a2\u23a3\n\u22122 2\n0\n0\n2 \u22122 0\n0\n0\n0 \u22122 2\n0\n0\n2 \u22122\n\u23a4\n\u23a5\u23a5\u23a6 #\u00bb\ud835\udc63 = #\u00bb0\nand row reduces to\n\u23a1\n\u23a2\u23a2\u23a3\n1 \u22121 0 0\n0 0 1 \u22121\n0 0 0 0\n0 0 0 0\n\u23a4\n\u23a5\u23a5\u23a6 #\u00bb\ud835\udc63 = #\u00bb0 .\nSince the rank of the coefficient matrix is 2, then there will be 4 \u2212 2 = 2 parameters in the\nsolution set. Therefore, \ud835\udc54\ud835\udf061 = dim(\ud835\udc38\ud835\udf061) = 2.\nThe eigenspace \ud835\udc38\ud835\udf062 is the solution set to (\ud835\udc34 + 1\ud835\udc3c)#\u00bb\ud835\udc63 = #\u00bb0 which is equivalent to\n\u23a1\n\u23a2\u23a2\u23a3\n2 2 0 0\n2 2 0 0\n0 0 2 2\n0 0 2 2\n\u23a4\n\u23a5\u23a5\u23a6 #\u00bb\ud835\udc63 = #\u00bb0\nand row reduces to\n\u23a1\n\u23a2\u23a2\u23a3\n1 1 0 0\n0 0 1 1\n0 0 0 0\n0 0 0 0\n\u23a4\n\u23a5\u23a5\u23a6 #\u00bb\ud835\udc63 = #\u00bb0 .\nSince the rank of the coefficient matrix is 2, then there will be 4 \u2212 2 = 2 parameters in the\nsolution set. Therefore, \ud835\udc54\ud835\udf062 = dim(\ud835\udc38\ud835\udf062) = 2.\nSince \ud835\udc4e\ud835\udf061 = \ud835\udc54\ud835\udf061 = 2, and \ud835\udc4e\ud835\udf062 = \ud835\udc54\ud835\udf062 = 2, \ud835\udc34 is diagonalizable over both R and C by Theorem\n9.4.10 (Diagonalizability Test).\nExample 9.4.13\nDetermine whether \ud835\udc34 =\n\u23a1\n\u23a2\u23a2\u23a3\n5 2 0\n1\n\u22122 1 0 \u22121\n4 4 3\n2\n16 0 \u22128 \u22125\n\u23a4\n\u23a5\u23a5\u23a6 is diagonalizable over R and/or C.\nSolution: The characteristic polynomial \ud835\udc36\ud835\udc34(\ud835\udf06) = (\ud835\udf06 \u2212 3)3(\ud835\udf06 + 5). Therefore, \u210e(\ud835\udf06) = 1, a\nconstant polynomial.\nThe eigenvalues are: \ud835\udf061 = 3, with \ud835\udc4e\ud835\udf061 = 3, and \ud835\udf062 = \u22125, with \ud835\udc4e\ud835\udf062 = 1.\nThe eigenspace \ud835\udc38\ud835\udf061 is the solution set to (\ud835\udc34 \u2212 3\ud835\udc3c)#\u00bb\ud835\udc63 = #\u00bb0 , which is equivalent to\n\u23a1\n\u23a2\u23a2\u23a3\n2\n2\n0\n1\n\u22122 \u22122 0 \u22121\n4\n4\n0\n2\n16\n0 \u22128 \u22128\n\u23a4\n\u23a5\u23a5\u23a6 #\u00bb\ud835\udc63 = #\u00bb0Section 9.4\nThe Diagonalizability Test\n251\nand row reduces to\n\u23a1\n\u23a2\u23a2\u23a3\n2 2 0 1\n0 2 1 2\n0 0 0 0\n0 0 0 0\n\u23a4\n\u23a5\u23a5\u23a6 #\u00bb\ud835\udc63 = #\u00bb0 .\nSince the rank of the coefficient matrix is 2, then there will be 4 \u2212 2 = 2 parameters in the\nsolution set. Therefore, dim(\ud835\udc38\ud835\udf061) = 2.\nSince \ud835\udc4e\ud835\udf061 = 3 and \ud835\udc54\ud835\udf061 = 2, \ud835\udc34 is not diagonalizable over R nor C, by Theorem 9.4.10\n(Diagonalizability Test).\nExample 9.4.14\nDetermine whether \ud835\udc34 =\n[\ufe021 \u22121\n1 1\n]\ufe02\nis diagonalizable over R and/or C.\nSolution: The characteristic polynomial \ud835\udc36\ud835\udc34(\ud835\udf06) = \ud835\udf062 \u22122\ud835\udf06+2 = (\ud835\udf06\u22121\u2212\ud835\udc56)(\ud835\udf06\u22121+\ud835\udc56). Over\nR, \u210e(\ud835\udf06) = \ud835\udf062\u22122\ud835\udf06+2 which is not a constant polynomial. Therefore, \ud835\udc34 is not diagonalizable\nover R, by Theorem 9.4.10 (Diagonalizability Test).\nHowever, over C, \u210e(\ud835\udf06) = 1, which is a constant polynomial.\nThe eigenvalues are: \ud835\udf061 = 1 + \ud835\udc56, with \ud835\udc4e\ud835\udf061 = 1 and \ud835\udf062 = 1 \u2212 \ud835\udc56, with \ud835\udc4e\ud835\udf062 = 1. Since\n\ud835\udc34 has two distinct eigenvalues, we can conclude that \ud835\udc34 is diagonalizable over C by\nProposition 7.6.7 (\ud835\udc5b Distinct Eigenvalues =\u21d2 Diagonalizable).\nIf we wanted to use Theorem 9.4.10, we could note that 1 \u2264 \ud835\udc54\ud835\udc56 \u2264 \ud835\udc4e\ud835\udc56 for any eigenvalue. In\nthis case, \ud835\udc4e\ud835\udf061 = \ud835\udc4e\ud835\udf062 = 1 and so \ud835\udc54\ud835\udf061 = \ud835\udc54\ud835\udf062 = 1. Therefore, by the Diagonalizability Test, \ud835\udc34\nis diagonalizable over C.\nTheorem 9.4.10 (Diagonalizability Test) is useful when we are determining whether a matrix\nis diagonalizable over F. However, if an \ud835\udc5b \u00d7 \ud835\udc5b matrix \ud835\udc34 is diagonalizable over F, we often\nwant to find an invertible matrix \ud835\udc43 \u2208 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) such \ud835\udc43 \u22121\ud835\udc34\ud835\udc43 = \ud835\udc37, where \ud835\udc37 is a diagonal\nmatrix.\nTheorem 9.4.10 and the proof of Proposition 9.4.9 give us that if \ud835\udc34 is diagonalizable over\nF, then the union of the bases of all of the eigenspaces of \ud835\udc34 will be a basis of eigenvectors of\n\ud835\udc34 for F\ud835\udc5b. Therefore, we let \ud835\udc43 be the matrix whose columns are this basis of eigenvectors.\nThe proof of Proposition 9.3.1 (\ud835\udc47 Diagonalizable iff [\ud835\udc47]\u212c Diagonalizable) gives us that\n\ud835\udc43 \u22121\ud835\udc34\ud835\udc43 = \ud835\udc37, where \ud835\udc37 is a diagonal matrix and the entries on the diagonal of \ud835\udc37 will be\nthe eigenvalues of \ud835\udc34 in the order corresponding to the order in which the eigenvectors are\nused as the columns of \ud835\udc43. We illustrate this with an example.\nExample 9.4.15\nWe know from Example 9.4.12 that matrix \ud835\udc34 =\n\u23a1\n\u23a2\u23a2\u23a3\n1 2 0 0\n2 1 0 0\n0 0 1 2\n0 0 2 1\n\u23a4\n\u23a5\u23a5\u23a6 is diagonalizable over R. De-\ntermine an invertible matrix \ud835\udc43 such that \ud835\udc43 \u22121\ud835\udc34\ud835\udc43 = \ud835\udc37, where \ud835\udc37 is a diagonal matrix.\nSolution: In Example 9.4.12, we determined that \ud835\udc34 had two eigenvalues, \ud835\udf061 = 3 and\n\ud835\udf062 = \u22121.252\nChapter 9\nDiagonalization\nWe determined that the eigenspace \ud835\udc38\ud835\udf061 was the solution set to\n\u23a1\n\u23a2\u23a2\u23a3\n1 \u22121 0 0\n0 0 1 \u22121\n0 0 0 0\n0 0 0 0\n\u23a4\n\u23a5\u23a5\u23a6 #\u00bb\ud835\udc63 = #\u00bb0 .\nA basis for \ud835\udc38\ud835\udf061 is\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n1\n1\n0\n0\n\u23a4\n\u23a5\u23a5\u23a6 ,\n\u23a1\n\u23a2\u23a2\u23a3\n0\n0\n1\n1\n\u23a4\n\u23a5\u23a5\u23a6\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n.\nWe determined that the eigenspace \ud835\udc38\ud835\udf062 was the solution set to\n\u23a1\n\u23a2\u23a2\u23a3\n1 1 0 0\n0 0 1 1\n0 0 0 0\n0 0 0 0\n\u23a4\n\u23a5\u23a5\u23a6 #\u00bb\ud835\udc63 = #\u00bb0 .\nA basis for \ud835\udc38\ud835\udf062 is\n\u23a7\n\u23aa\n\u23aa\n\u23a8\n\u23aa\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a2\u23a3\n\u22121\n1\n0\n0\n\u23a4\n\u23a5\u23a5\u23a6 ,\n\u23a1\n\u23a2\u23a2\u23a3\n0\n0\n\u22121\n1\n\u23a4\n\u23a5\u23a5\u23a6\n\u23ab\n\u23aa\n\u23aa\n\u23ac\n\u23aa\n\u23aa\n\u23ad\n.\nTherefore, we let\n\ud835\udc43 =\n\u23a1\n\u23a2\u23a2\u23a3\n1 0 \u22121 0\n1 0 1\n0\n0 1 0 \u22121\n0 1 0\n1\n\u23a4\n\u23a5\u23a5\u23a6 ,\nwhich will give us that\n\ud835\udc43 \u22121\ud835\udc34\ud835\udc43 = \ud835\udc37 =\n\u23a1\n\u23a2\u23a2\u23a3\n3 0 0\n0\n0 3 0\n0\n0 0 \u22121 0\n0 0 0 \u22121\n\u23a4\n\u23a5\u23a5\u23a6 .\nIf we reorder the columns of \ud835\udc43 such that\n\ud835\udc43 =\n\u23a1\n\u23a2\u23a2\u23a3\n1 \u22121 0 0\n1 1 0 0\n0 0 1 \u22121\n0 0 1 1\n\u23a4\n\u23a5\u23a5\u23a6 ,\nthen we will obtain\n\ud835\udc43 \u22121\ud835\udc34\ud835\udc43 = \ud835\udc37 =\n\u23a1\n\u23a2\u23a2\u23a3\n3 0 0 0\n0 \u22121 0 0\n0 0 3 0\n0 0 0 \u22121\n\u23a4\n\u23a5\u23a5\u23a6 .Section 9.4\nThe Diagonalizability Test\n253\nEXERCISE\nUsing Example 9.4.15, find all diagonal matrices which are similar to \ud835\udc34 =\n\u23a1\n\u23a2\u23a2\u23a3\n1 2 0 0\n2 1 0 0\n0 0 1 2\n0 0 2 1\n\u23a4\n\u23a5\u23a5\u23a6.Chapter 10\nVector Spaces\n10.1", "Definition of a Vector Space\nSo far, all of our discussion has taken place within R\ud835\udc5b and C\ud835\udc5b or within various subspaces\nof these spaces. An underlying fact that we have made use of is that these sets are closed\nunder addition and scalar multiplication.\nWe have taken it for granted that any linear\ncombination of vectors in R\ud835\udc5b (or C\ud835\udc5b) will produce a vector in R\ud835\udc5b (or C\ud835\udc5b). This assumption\nis fundamental to linear algebra.\nWe can consider other sets of objects along with two operations. One operation, called\naddition, combines two objects in the set to produce another object in the set. The other\noperation, called scalar multiplication, combines an object in the set and a scalar from\nthe field F to produce another object in the set. These operations may be defined in familiar\nways, like the addition and scalar multiplication of vectors in F\ud835\udc5b. However, they may also\nbe newly defined operations.\nExample 10.1.1\nConsider the set of all real polynomials of degree two or less, which we denote by \ud835\udc432(R):\n\ud835\udc432(R) =\n{\ufe00\n\ud835\udc5d0 + \ud835\udc5d1\ud835\udc65 + \ud835\udc5d2\ud835\udc652 : \ud835\udc5d0, \ud835\udc5d1, \ud835\udc5d2 \u2208 R\n}\ufe00\n.\nGiven two polynomials in this set,\n\ud835\udc5d(\ud835\udc65) = \ud835\udc5d0 + \ud835\udc5d1\ud835\udc65 + \ud835\udc5d2\ud835\udc652 and \ud835\udc5e(\ud835\udc65) = \ud835\udc5e0 + \ud835\udc5e1\ud835\udc65 + \ud835\udc5e2\ud835\udc652,\ntheir sum is\n\ud835\udc5d1(\ud835\udc65) + \ud835\udc5d2(\ud835\udc65) = \ud835\udc5d0 + \ud835\udc5d1\ud835\udc65 + \ud835\udc5d2\ud835\udc652 + \ud835\udc5e0 + \ud835\udc5e1\ud835\udc65 + \ud835\udc5e2\ud835\udc652 = \ud835\udc5f0 + \ud835\udc5f1\ud835\udc65 + \ud835\udc5f2\ud835\udc652,\nwhere \ud835\udc5f0 = \ud835\udc5d0 + \ud835\udc5e0, \ud835\udc5f1 = \ud835\udc5d1 + \ud835\udc5e1 and \ud835\udc5f2 = \ud835\udc5d2 + \ud835\udc5e2.\nThe resulting polynomial is another polynomial in \ud835\udc432(R), and thus we say that \ud835\udc432(R) is\nclosed under addition.\nIf we multiply \ud835\udc5d(\ud835\udc65) by \ud835\udc50 \u2208 R we get\n\ud835\udc50\ud835\udc5d(\ud835\udc65) = \ud835\udc50(\ud835\udc5d0 + \ud835\udc5d1\ud835\udc65 + \ud835\udc5d2\ud835\udc652) = \ud835\udc50\ud835\udc5d0 + \ud835\udc50\ud835\udc5d1\ud835\udc65 + \ud835\udc50\ud835\udc5d2\ud835\udc652 = \ud835\udc600 + \ud835\udc601\ud835\udc65 + \ud835\udc602\ud835\udc652,\nwhere \ud835\udc600 = \ud835\udc50\ud835\udc5d0, \ud835\udc601 = \ud835\udc50\ud835\udc5d1 and \ud835\udc602 = \ud835\udc50\ud835\udc5d2. The resulting polynomial is another polynomial in\n\ud835\udc432(R) and thus, we say that \ud835\udc432(R) is closed under scalar multiplication.\n254Section 10.1\nDefinition of a Vector Space\n255\nWe can think of linear algebra as operating in a world with four components:\n1. a non-empty set of objects V;\n2. a field F;\n3. an operation called addition, that combines two objects from V, which we denote by\n\u2295; and\n4. an operation called scalar multiplication, which combines an object from V and a\nscalar from F, which we denote by \u2299.\nNote that addition (\u2295) and scalar multiplication (\u2299) are used in place of + and \u00b7 to\ndenote that these operations may have definitions that differ from the \u201cstandard operations\u201d\nof addition/multiplication on scalars or coordinate vectors. Many other definitions of these\noperations are possible, as long as they satisfy the vector space axioms below.\nDefinition 10.1.2\nVector Space\nA non-empty set of objects, V, is a vector space over a field, F, under the operations\nof addition, \u2295, and scalar multiplication, \u2299, provided the following set of ten axioms\nare met.\nC1. For all #\u00bb\ud835\udc65, #\u00bb\ud835\udc66 \u2208 V, #\u00bb\ud835\udc65 \u2295 #\u00bb\ud835\udc66 \u2208 V.\n(Closure Under Addition)\nC2. For all #\u00bb\ud835\udc65 \u2208 V and all \ud835\udc50 \u2208 F, \ud835\udc50 \u2299 #\u00bb\ud835\udc65 \u2208 V.\n(Closure Under Scalar Multiplication)\nV1. For all #\u00bb\ud835\udc65, #\u00bb\ud835\udc66 \u2208 V, #\u00bb\ud835\udc65 \u2295 #\u00bb\ud835\udc66 = #\u00bb\ud835\udc66 \u2295 #\u00bb\ud835\udc65.\n(Addition is Commutative)\nV2. For all #\u00bb\ud835\udc65, #\u00bb\ud835\udc66 , #\u00bb\ud835\udc67 \u2208 V, (#\u00bb\ud835\udc65 \u2295 #\u00bb\ud835\udc66 ) \u2295 #\u00bb\ud835\udc67 = #\u00bb\ud835\udc65 \u2295 (#\u00bb\ud835\udc66 \u2295 #\u00bb\ud835\udc67 ) = #\u00bb\ud835\udc65 \u2295 #\u00bb\ud835\udc66 \u2295 #\u00bb\ud835\udc67 .\n(Addition is Associative)\nV3. There exists a vector #\u00bb0 \u2208 V such that for all #\u00bb\ud835\udc65 \u2208 V, #\u00bb\ud835\udc65 \u2295 #\u00bb0 = #\u00bb0 \u2295 #\u00bb\ud835\udc65 = #\u00bb\ud835\udc65.\n(Additive Identity)\nV4. For all #\u00bb\ud835\udc65 \u2208 V, there exists a vector \u2212#\u00bb\ud835\udc65 \u2208 V such that #\u00bb\ud835\udc65 \u2295 (\u2212#\u00bb\ud835\udc65) = (\u2212#\u00bb\ud835\udc65) \u2295 #\u00bb\ud835\udc65 = #\u00bb0 .\n(Additive Inverse)\nV5. For all #\u00bb\ud835\udc65, #\u00bb\ud835\udc66 \u2208 V and for all \ud835\udc50 \u2208 F, \ud835\udc50 \u2299 (#\u00bb\ud835\udc65 \u2295 #\u00bb\ud835\udc66 ) = (\ud835\udc50 \u2299 #\u00bb\ud835\udc65) \u2295 (\ud835\udc50 \u2299 #\u00bb\ud835\udc66 ).\n(Vector Addition Distributive Law)\nV6. For all #\u00bb\ud835\udc65 \u2208 V and for all \ud835\udc50, \ud835\udc51 \u2208 F, (\ud835\udc50 + \ud835\udc51) \u2299 #\u00bb\ud835\udc65 = (\ud835\udc50 \u2299 #\u00bb\ud835\udc65) \u2295 (\ud835\udc51 \u2299 #\u00bb\ud835\udc65).\n(Scalar Addition Distributive Law)\nV7. For all #\u00bb\ud835\udc65 \u2208 V and for all \ud835\udc50, \ud835\udc51 \u2208 F, (\ud835\udc50\ud835\udc51) \u2299 #\u00bb\ud835\udc65 = \ud835\udc50 \u2299 (\ud835\udc51 \u2299 #\u00bb\ud835\udc65).\n(Scalar Multiplication is Associative)\nV8. For all #\u00bb\ud835\udc65 \u2208 V, 1 \u2299 #\u00bb\ud835\udc65 = #\u00bb\ud835\udc65.\n(Multiplicative Identity)256\nChapter 10\nVector Spaces\nDefinition 10.1.3\nVector\nA vector is an element of a vector space.\nREMARKS\n1. The sum \ud835\udc50 + \ud835\udc51 in V6 (scalar addition distributive law) is the sum of scalars in F.\n2. The product \ud835\udc50\ud835\udc51 in V7 (scalar associativity) is the product of scalars in F.\n3. In Abstract Algebra, the combination of set, field, addition, and scalar multiplication\nis sometimes referenced as (V, F, \u2295, \u2299).\n4. If the \u201cstandard operations\u201d for a given vector space are being used, then we will\nusually default to the standard + symbol for addition and juxtaposition for scalar\nmultiplication.\n5. One of the defining properties of a field that we will use is the fact that every nonzero\n\ud835\udc4e \u2208 F has a multiplicative inverse, which we denote by \ud835\udc4e\u22121.\nThat is to say, for every nonzero \ud835\udc4e \u2208 F, there exists \ud835\udc4e\u22121 \u2208 F such that\n\ud835\udc4e\ud835\udc4e\u22121 = \ud835\udc4e\u22121\ud835\udc4e = 1.\nExample 10.1.4\nConsider R\ud835\udc5b over R and C\ud835\udc5b over C with the standard vector addition and standard scalar\nmultiplication, respectively. We can show that the ten vector space axioms are satisfied\nhere, so that both of these sets are vector spaces over their respective fields.\nPerhaps the most simple vector space V that one can think of is the vector space consisting\nof a single vector, namely the zero vector #\u00bb0 , with addition and scalar multiplication defined\nin an obvious way.\nExample 10.1.5\nConsider the set V = {#\u00bb0 } with the operations #\u00bb0 + #\u00bb0 = #\u00bb0 and \ud835\udc50#\u00bb0 = #\u00bb0 , where \ud835\udc50 \u2208 F. It\ncan be shown that these operations satisfy the ten vector space axioms. Thus, V = {#\u00bb0 } is\na vector space. It is called the zero vector space or the zero space.\nThe zero space is not the most interesting object to study. Here are two more interesting\nexamples of vector spaces.\nExample 10.1.6\nConsider \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F) over F equipped with the standard matrix addition and scalar multipli-\ncation, respectively. We can show that the ten vector space axioms are satisfied, with the\nzero vector in this space being the zero matrix. Therefore, \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F) is a vector space over\nF.Section 10.1\nDefinition of a Vector Space\n257\nExample 10.1.7\nThe set \ud835\udc43\ud835\udc5b(F) is the set of all polynomials of degree at most \ud835\udc5b with coefficients in F. Using\nthe field F, we define addition and scalar multiplication in the following way:\n(\ud835\udc4e0 + \ud835\udc4e1\ud835\udc65 + \u00b7 \u00b7 \u00b7 + \ud835\udc4e\ud835\udc5b\ud835\udc65\ud835\udc5b) + (\ud835\udc4f0 + \ud835\udc4f1\ud835\udc65 + \u00b7 \u00b7 \u00b7 + \ud835\udc4f\ud835\udc5b\ud835\udc65\ud835\udc5b) = (\ud835\udc4e0 + \ud835\udc4f0) + (\ud835\udc4e1 + \ud835\udc4f1)\ud835\udc65 + \u00b7 \u00b7 \u00b7 + (\ud835\udc4e\ud835\udc5b + \ud835\udc4f\ud835\udc5b)\ud835\udc65\ud835\udc5b,\n\ud835\udc50(\ud835\udc4e0 + \ud835\udc4e1\ud835\udc65 + \u00b7 \u00b7 \u00b7 + \ud835\udc4e\ud835\udc5b\ud835\udc65\ud835\udc5b) = (\ud835\udc50\ud835\udc4e0) + (\ud835\udc50\ud835\udc4e1)\ud835\udc65 + \u00b7 \u00b7 \u00b7 + (\ud835\udc50\ud835\udc4e\ud835\udc5b)\ud835\udc65\ud835\udc5b.\nWe can show that these operations satisfy the ten vector space axioms, with the zero vector\nbeing the zero polynomial in \ud835\udc43\ud835\udc5b(F), i.e.,\n\ud835\udc5d(\ud835\udc65) = 0 + 0\ud835\udc65 + \u00b7 \u00b7 \u00b7 + 0\ud835\udc65\ud835\udc5b.\nTherefore, this is a vector space over F. We give the formal definition below.\nNote that a vector in \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F) is by definition an \ud835\udc5a \u00d7 \ud835\udc5b matrix \ud835\udc34 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F). Likewise,\na vector in \ud835\udc43\ud835\udc5b(F) is a polynomial in \ud835\udc43\ud835\udc5b(F).\nDefinition 10.1.8\n\ud835\udc43\ud835\udc5b(F)\nWe use \ud835\udc43\ud835\udc5b(F) to denote the vector space over F comprised of the set of all polynomials of\ndegree at most \ud835\udc5b with coefficients in F, with addition and scalar multiplication defined as\nfollows:\n(\ud835\udc4e0 + \ud835\udc4e1\ud835\udc65 + \u00b7 \u00b7 \u00b7 + \ud835\udc4e\ud835\udc5b\ud835\udc65\ud835\udc5b) + (\ud835\udc4f0 + \ud835\udc4f1\ud835\udc65 + \u00b7 \u00b7 \u00b7 + \ud835\udc4f\ud835\udc5b\ud835\udc65\ud835\udc5b) = (\ud835\udc4e0 + \ud835\udc4f0) + (\ud835\udc4e1 + \ud835\udc4f1)\ud835\udc65 + \u00b7 \u00b7 \u00b7 + (\ud835\udc4e\ud835\udc5b + \ud835\udc4f\ud835\udc5b)\ud835\udc65\ud835\udc5b,\n\ud835\udc50(\ud835\udc4e0 + \ud835\udc4e1\ud835\udc65 + \u00b7 \u00b7 \u00b7 + \ud835\udc4e\ud835\udc5b\ud835\udc65\ud835\udc5b) = (\ud835\udc50\ud835\udc4e0) + (\ud835\udc50\ud835\udc4e1)\ud835\udc65 + \u00b7 \u00b7 \u00b7 + (\ud835\udc50\ud835\udc4e\ud835\udc5b)\ud835\udc65\ud835\udc5b.\nOf course, our discussion about vector spaces would not be complete without showing\nexamples of objects (V, F, \u2295, \u2299) that are not vector spaces. This happens when at least\none of the ten vector space axioms fails. In order to prove that (V, F, \u2295, \u2299) is not a vector\nspace, it suffices to disprove V4 by showing that V has no additive identity or to disprove\nany other vector space axiom by providing an explicit counterexample that violates it.\nExample 10.1.9\nFor a positive integer \ud835\udc5b, let\nV =\n\u23a7\n\u23aa\n\u23a8\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a3\n\ud835\udc651\n...\n\ud835\udc65\ud835\udc5b\n\u23a4\n\u23a5\u23a6 : \ud835\udc651 > 0, . . . , \ud835\udc65\ud835\udc5b > 0\n\u23ab\n\u23aa\n\u23ac\n\u23aa\n\u23ad\nbe a subset of R\ud835\udc5b, and consider V equipped with the standard operations of addition and\nscalar multiplication of vectors in R\ud835\udc5b. Show that V is not a vector space.\nSolution: Since V does not contain the zero vector, we see that the vector space axiom\nV4 is violated, which means that V is not a vector space.258\nChapter 10\nVector Spaces\nExample 10.1.10\nFor a positive integer \ud835\udc5b, let\nV =\n\u23a7\n\u23aa\n\u23a8\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a3\n\ud835\udc651\n...\n\ud835\udc65\ud835\udc5b\n\u23a4\n\u23a5\u23a6 : \ud835\udc651 \u2265 0, . . . , \ud835\udc65\ud835\udc5b \u2265 0\n\u23ab\n\u23aa\n\u23ac\n\u23aa\n\u23ad\nbe a subset of R\ud835\udc5b, and consider V equipped with the standard operations of addition and\nscalar multiplication of vectors in R\ud835\udc5b. Show that V is not a vector space over R.\nSolution: Unlike in the previous example, this time V does contain the zero vector, so\nthe axiom V4 is satisfied. Furthermore, one can verify that V is closed under addition,\nso the axiom C1 is satisfied. However, V is not closed under scalar multiplication. As a\ncounterexample, take the first standard basis vector #\u00bb\ud835\udc65 = #\u00bb\ud835\udc52 1 and \ud835\udc50 = \u22121. Then\n\ud835\udc50#\u00bb\ud835\udc65 = (\u22121) \u00b7\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n1\n0\n...\n0\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 =\n\u23a1\n\u23a2\u23a2\u23a2\u23a3\n\u22121\n0\n...\n0\n\u23a4\n\u23a5\u23a5\u23a5\u23a6 /\u2208 V,\nwhich means that the vector space axiom C2 is violated. This proves that V is not a vector\nspace over R. As an exercise try listing all vector space axioms that do and do not hold for\nV.\nEXERCISE\nLet\nV =\n\u23a7\n\u23aa\n\u23a8\n\u23aa\n\u23a9\n\u23a1\n\u23a2\u23a3\n\ud835\udc651\n...\n\ud835\udc65\ud835\udc5b\n\u23a4\n\u23a5\u23a6 : \ud835\udc651, . . . , \ud835\udc65\ud835\udc5b \u2208 R\n\u23ab\n\u23aa\n\u23ac\n\u23aa\n\u23ad\nbe a subset of C\ud835\udc5b, and consider V equipped with the standard operations of addition and\nscalar multiplication of vectors in C\ud835\udc5b. Show that V is not a vector space over C. List all\nvector space axioms that do and do not hold for V.\n10.2", "Span, Linear Independence and Basis\nJust like for F\ud835\udc5b, we can introduce the notions of a span, linear dependence, linear indepen-\ndence and basis for a vector space (V, F, + , \u00b7 ). In what follows, we will primarily be\ninterested in vector spaces \ud835\udc43\ud835\udc5b(F) and \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F).\nDefinition 10.2.1\nSpan\nLet #\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58 be vectors in V. We define the span of {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58} to be the set of all\nlinear combinations of #\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58. That is,\nSpan{#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58} = {\ud835\udc501 #\u00bb\n\ud835\udc631 + \ud835\udc502 #\u00bb\n\ud835\udc632 + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc58 #\u00bb\n\ud835\udc63\ud835\udc58 : \ud835\udc501, \ud835\udc502, . . . , \ud835\udc50\ud835\udc58 \u2208 F}.\nWe refer to {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58} as a spanning set for Span{#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58}. We also say that\nSpan{#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58} is spanned by {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58}.Section 10.2\nSpan, Linear Independence and Basis\n259\nWe have not yet developed an analogous result for Proposition 8.4.6 (Spans F\ud835\udc5b iff rank is\n\ud835\udc5b) in the general vector space context, so in order to show a set \u212c is a spanning set of\na vector space V we will need to apply a more \u201cfirst principles\u201d approach. To establish\nSpan(\u212c) = V, we will need to show Span(\u212c) \u2286 V and V \u2286 Span(\u212c).\nExample 10.2.2\nShow that the set\n\u212c =\n{\ufe02[\ufe021 0\n0 0\n]\ufe02\n,\n[\ufe020 0\n0 1\n]\ufe02\n,\n[\ufe020 1\n1 0\n]\ufe02\n,\n[\ufe02 0 1\n\u22121 0\n]\ufe02}\ufe02\nis a spanning set for \ud835\udc402\u00d72(F).\nSolution: Our goal is to show that\nSpan\n{\ufe02[\ufe021 0\n0 0\n]\ufe02\n,\n[\ufe020 0\n0 1\n]\ufe02\n,\n[\ufe020 1\n1 0\n]\ufe02\n,\n[\ufe02 0 1\n\u22121 0\n]\ufe02}\ufe02\n= \ud835\udc402\u00d72(F).\nSince \u212c is a subset of \ud835\udc402\u00d72(F), it must be the case that any linear combination of the\nelements of \u212c is also in \ud835\udc402\u00d72(F) by the closure axioms for vector spaces.\nTherefore,\nSpan(\u212c) \u2286 \ud835\udc402\u00d72(F).\nIt remains to show that \ud835\udc402\u00d72(F) \u2286 Span(\u212c). Let \ud835\udc34 =\n[\ufe02\ud835\udc4e11 \ud835\udc4e12\n\ud835\udc4e21 \ud835\udc4e22\n]\ufe02\nbe a matrix in \ud835\udc402\u00d72(F).\nWe claim that there exist \ud835\udc501, \ud835\udc502, \ud835\udc503, \ud835\udc504 \u2208 F such that\n\ud835\udc501\n[\ufe021 0\n0 0\n]\ufe02\n+ \ud835\udc502\n[\ufe020 0\n0 1\n]\ufe02\n+ \ud835\udc503\n[\ufe020 1\n1 0\n]\ufe02\n+ \ud835\udc504\n[\ufe02 0 1\n\u22121 0\n]\ufe02\n=\n[\ufe02\ud835\udc4e11 \ud835\udc4e12\n\ud835\udc4e21 \ud835\udc4e22\n]\ufe02\n.\nTo see that this is the case, let us simplify the left-hand side of the above equality:\n[\ufe02\n\ud835\udc501\n\ud835\udc503 + \ud835\udc504\n\ud835\udc503 \u2212 \ud835\udc504\n\ud835\udc502\n]\ufe02\n=\n[\ufe02\ud835\udc4e11 \ud835\udc4e12\n\ud835\udc4e21 \ud835\udc4e22\n]\ufe02\n.\nEquating the entries of the matrices on both sides of the above equality, we obtain the\nfollowing system of four equations in four unknowns:\n\ud835\udc501\n= \ud835\udc4e11\n\ud835\udc503\n+\ud835\udc504\n= \ud835\udc4e12\n\ud835\udc503\n\u2212\ud835\udc504\n= \ud835\udc4e21\n\ud835\udc502\n= \ud835\udc4e22\n.\nSolving this system for \ud835\udc501, \ud835\udc502, \ud835\udc503, and \ud835\udc504, we find that\n\ud835\udc501 = \ud835\udc4e11,\n\ud835\udc502 = \ud835\udc4e22,\n\ud835\udc503 = \ud835\udc4e12 + \ud835\udc4e21\n2\n,\nand\n\ud835\udc504 = \ud835\udc4e12 \u2212 \ud835\udc4e21\n2\n.\nThus,\n\ud835\udc34 = \ud835\udc4e11\n[\ufe021 0\n0 0\n]\ufe02\n+ \ud835\udc4e22\n[\ufe020 0\n0 1\n]\ufe02\n+ \ud835\udc4e12 + \ud835\udc4e21\n2\n[\ufe020 1\n1 0\n]\ufe02\n+ \ud835\udc4e12 \u2212 \ud835\udc4e21\n2\n[\ufe02 0 1\n\u22121 0\n]\ufe02\n,\nso \ud835\udc34 \u2208 Span(\u212c). This means that \ud835\udc402\u00d72(F) \u2286 Span(\u212c), and since it is also the case that\nSpan(\u212c) \u2286 \ud835\udc402\u00d72(F), we conclude that \u212c is a spanning set for \ud835\udc402\u00d72(F).260\nChapter 10\nVector Spaces\nEXERCISE\nShow that the set\n\u212c =\n{\ufe02[\ufe021 0\n0 1\n]\ufe02\n,\n[\ufe020 1\n0 0\n]\ufe02\n,\n[\ufe020 0\n1 0\n]\ufe02\n,\n[\ufe021 0\n0 \u22121\n]\ufe02}\ufe02\nis a spanning set for \ud835\udc402\u00d72(F).\nExample 10.2.3\nShow that the set\n\u212c = {1 \u2212 \ud835\udc652, \u22121 + \ud835\udc56\ud835\udc65, \u22121 \u2212 \ud835\udc56\ud835\udc65}\nis a spanning set for \ud835\udc432(C).\nSolution: Our goal is to show that\nSpan\n{\ufe00\n1 \u2212 \ud835\udc652, \u22121 + \ud835\udc56\ud835\udc65, \u22121 \u2212 \ud835\udc56\ud835\udc65\n}\ufe00\n= \ud835\udc432(C).\nSince \u212c is a subset of \ud835\udc432(C), it must be the case that any linear combination of the elements\nof \u212c is also in \ud835\udc432(C). Therefore, Span(\u212c) \u2286 \ud835\udc432(C).\nIt remains to show that \ud835\udc432(C) \u2286 Span(\u212c). Let \ud835\udc5d(\ud835\udc65) = \ud835\udc4e0 + \ud835\udc4e1\ud835\udc65 + \ud835\udc4e2\ud835\udc652 be a polynomial in\n\ud835\udc432(C). We claim that there exist \ud835\udc501, \ud835\udc502, \ud835\udc503 \u2208 C such that\n\ud835\udc501(1 \u2212 \ud835\udc652) + \ud835\udc502(\u22121 + \ud835\udc56\ud835\udc65) + \ud835\udc503(\u22121 \u2212 \ud835\udc56\ud835\udc65) = \ud835\udc4e0 + \ud835\udc4e1\ud835\udc65 + \ud835\udc4e2\ud835\udc652.\nTo see that this is the case, let us simplify the left-hand side of the above equality:\n(\ud835\udc501 \u2212 \ud835\udc502 \u2212 \ud835\udc503) + (\ud835\udc56\ud835\udc502 \u2212 \ud835\udc56\ud835\udc503)\ud835\udc65 \u2212 \ud835\udc501\ud835\udc652 = \ud835\udc4e0 + \ud835\udc4e1\ud835\udc65 + \ud835\udc4e2\ud835\udc652.\nEquating the corresponding coefficients of the polynomials on both sides of the above equal-\nity, we obtain the following system of three equations in three unknowns:\n\ud835\udc501\n\u2212\ud835\udc502\n\u2212\ud835\udc503\n= \ud835\udc4e0\n\ud835\udc56\ud835\udc502\n\u2212\ud835\udc56\ud835\udc503\n= \ud835\udc4e1\n\u2212\ud835\udc501\n= \ud835\udc4e2\n.\nSolving this system for \ud835\udc501, \ud835\udc502, and \ud835\udc503, we find that\n\ud835\udc501 = \u2212\ud835\udc4e2,\n\ud835\udc502 = \u2212\ud835\udc4e0 \u2212 \ud835\udc56\ud835\udc4e1 \u2212 \ud835\udc4e2\n2\n, and\n\ud835\udc503 = \u2212\ud835\udc4e0 + \ud835\udc56\ud835\udc4e1 \u2212 \ud835\udc4e2\n2\n.\nThus,\n\ud835\udc5d(\ud835\udc65) = (\u2212\ud835\udc4e2)(1 \u2212 \ud835\udc652) + \u2212\ud835\udc4e0 \u2212 \ud835\udc56\ud835\udc4e1 \u2212 \ud835\udc4e2\n2\n(\u22121 + \ud835\udc56\ud835\udc65) + \u2212\ud835\udc4e0 + \ud835\udc56\ud835\udc4e1 \u2212 \ud835\udc4e2\n2\n(\u22121 \u2212 \ud835\udc56\ud835\udc65),\nso \ud835\udc5d(\ud835\udc65) \u2208 Span(\u212c). This means that \ud835\udc432(C) \u2286 Span(\u212c), and since it is also the case that\nSpan(\u212c) \u2286 \ud835\udc432(C), we conclude that \u212c is a spanning set for \ud835\udc432(C).\nEXERCISE\nLet \ud835\udc5b be a non-negative integer. Show that the set\n\u212c = {1, 2\ud835\udc65, 4\ud835\udc652, . . . , 2\ud835\udc5b\ud835\udc65\ud835\udc5b}Section 10.2\nSpan, Linear Independence and Basis\n261\nis a spanning set for \ud835\udc43\ud835\udc5b(F).\nAs with the definition of the span of a set, the definitions of linear dependence and linear\nindependence in the general vector space context will look nearly identical to what was used\nfor linear dependence and linear independence in F\ud835\udc5b in Definitions 8.2.3 and 8.2.4.\nDefinition 10.2.4\nLinear Dependence,\nLinear Independence\nWe say that the vectors #\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58 \u2208 F\ud835\udc5b are linearly dependent if there exist scalars\n\ud835\udc501, \ud835\udc502, . . . , \ud835\udc50\ud835\udc58 \u2208 F, not all zero, such that \ud835\udc501 #\u00bb\n\ud835\udc631 + \ud835\udc502 #\u00bb\n\ud835\udc632 + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc58 #\u00bb\n\ud835\udc63\ud835\udc58 = #\u00bb0 .\nWe say that #\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58 \u2208 V are linearly independent if the only solution to the equation\n\ud835\udc501 #\u00bb\n\ud835\udc631 + \ud835\udc502 #\u00bb\n\ud835\udc632 + . . . + \ud835\udc50\ud835\udc58 #\u00bb\n\ud835\udc63\ud835\udc58 = #\u00bb0\nis the trivial solution \ud835\udc501 = \ud835\udc502 = \u00b7 \u00b7 \u00b7 = \ud835\udc50\ud835\udc58 = 0.\nIf \ud835\udc48 = {#\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58}, then we say that the set \ud835\udc48 is linearly dependent (resp. linearly\nindependent) to mean that the vectors #\u00bb\n\ud835\udc631, #\u00bb\n\ud835\udc632, . . . , #\u00bb\n\ud835\udc63\ud835\udc58 are linearly dependent (resp. linearly\nindependent).\nSince we do not yet have an analogous result for Proposition 8.3.6 (Pivots and Linear\nIndependence) in the general vector space context, we will need to determine whether or\nnot a set \u212c is linearly independent directly from the definition above.\nExample 10.2.5\nDetermine whether the subset\n\u212c =\n{\ufe02[\ufe021 0\n0 0\n]\ufe02\n,\n[\ufe020 0\n0 1\n]\ufe02\n,\n[\ufe020 1\n1 0\n]\ufe02\n,\n[\ufe02 0 1\n\u22121 0\n]\ufe02}\ufe02\nof \ud835\udc402\u00d72(F) is linearly dependent or linearly independent.\nSolution: In order to determine whether the set \u212c is linearly dependent or linearly inde-\npendent, we examine the equation\n\ud835\udc501\n[\ufe021 0\n0 0\n]\ufe02\n+ \ud835\udc502\n[\ufe020 0\n0 1\n]\ufe02\n+ \ud835\udc503\n[\ufe020 1\n1 0\n]\ufe02\n+ \ud835\udc504\n[\ufe02 0 1\n\u22121 0\n]\ufe02\n=\n[\ufe020 0\n0 0\n]\ufe02\n.\nSimplifying the left-hand side of the above equality, we find that\n[\ufe02\n\ud835\udc501\n\ud835\udc503 + \ud835\udc504\n\ud835\udc503 \u2212 \ud835\udc504\n\ud835\udc502\n]\ufe02\n=\n[\ufe020 0\n0 0\n]\ufe02\n.\nEquating the entries of the matrices on both sides of the above equality, we obtain the\nfollowing system of four equations in four unknowns:\n\ud835\udc501\n= 0\n\ud835\udc503\n+\ud835\udc504\n= 0\n\ud835\udc503\n\u2212\ud835\udc504\n= 0\n\ud835\udc502\n= 0\n.\nSolving this system for \ud835\udc501, \ud835\udc502, \ud835\udc503 and \ud835\udc504, we find that \ud835\udc501 = \ud835\udc502 = \ud835\udc503 = \ud835\udc504 = 0. Therefore, \u212c\nis linearly independent.262\nChapter 10\nVector Spaces\nEXERCISE\nDetermine whether the subset\n\u212c =\n{\ufe02[\ufe021 0\n0 1\n]\ufe02\n,\n[\ufe020 1\n0 0\n]\ufe02\n,\n[\ufe020 0\n1 0\n]\ufe02\n,\n[\ufe021 0\n0 \u22121\n]\ufe02}\ufe02\nof \ud835\udc402\u00d72(F) is linearly dependent or linearly independent.\nExample 10.2.6\nDetermine whether the subset\n\u212c = {1 \u2212 \ud835\udc652, \u22121 + \ud835\udc56\ud835\udc65, \u22121 \u2212 \ud835\udc56\ud835\udc65}\nof \ud835\udc432(C) is linearly dependent or linearly independent.\nSolution: In order to determine whether the set \u212c is linearly dependent or linearly inde-\npendent, we examine the equation\n\ud835\udc501(1 \u2212 \ud835\udc652) + \ud835\udc502(\u22121 + \ud835\udc56\ud835\udc65) + \ud835\udc503(\u22121 \u2212 \ud835\udc56\ud835\udc65) = 0.\nSimplifying the left-hand side of the above equality, we find that\n(\ud835\udc501 \u2212 \ud835\udc502 \u2212 \ud835\udc503) + (\ud835\udc56\ud835\udc502 \u2212 \ud835\udc56\ud835\udc503)\ud835\udc65 \u2212 \ud835\udc501\ud835\udc652 = 0.\nEquating the corresponding coefficients of the polynomials on both sides of the above equal-\nity, we obtain the following system of three equations in three unknowns:\n\ud835\udc501\n\u2212\ud835\udc502\n\u2212\ud835\udc503\n= 0\n\ud835\udc56\ud835\udc502\n\u2212\ud835\udc56\ud835\udc503\n= 0\n\u2212\ud835\udc501\n= 0\n.\nSolving this system for \ud835\udc501, \ud835\udc502 and \ud835\udc503, we find that \ud835\udc501 = \ud835\udc502 = \ud835\udc503 = 0. Therefore, \u212c is linearly\nindependent.\nEXERCISE\nLet \ud835\udc5b be a non-negative integer. Determine whether the subset\n\u212c = {1, 2\ud835\udc65, 4\ud835\udc652, . . . , 2\ud835\udc5b\ud835\udc65\ud835\udc5b}\nof \ud835\udc43\ud835\udc5b(F) is linearly dependent or linearly independent.\nFinally, we extend the notion of basis to the general vector space context, with a definition\nthat is, yet again, nearly identical to what was used previously for a basis of a subspace of\nF\ud835\udc5b in Definition 8.2.6.\nDefinition 10.2.7\nBasis\nWe say that a subset \u212c of a nonzero vector space V is a basis for V if\n1. \u212c is linearly independent, andSection 10.2\nSpan, Linear Independence and Basis\n263\n2. V = Span(\u212c).\nREMARK\nYou should be cautioned that our definition requires a basis to have finitely many vectors in\nit. This may not always be possible. For example, the set of all polynomials with coefficients\nin F is a vector space over F with the usual operations of addition and scalar multiplication.\nHowever, this vector space does not admit a \u201cbasis\u201d according to our definition. The study\nof such \u201cinfinite-dimensional\u201d vector spaces has important applications in mathematics and\nphysics, and is taken up in more advanced courses.\nExample 10.2.8\nDetermine whether or not the set\n\u212c =\n{\ufe02[\ufe021 0\n0 0\n]\ufe02\n,\n[\ufe020 0\n0 1\n]\ufe02\n,\n[\ufe020 1\n1 0\n]\ufe02\n,\n[\ufe02 0 1\n\u22121 0\n]\ufe02}\ufe02\nis a basis for \ud835\udc402\u00d72(F).\nSolution:\nIt was demonstrated in Example 10.2.5 that \u212c is linearly independent.\nIt\nwas also demonstrated in Example 10.2.2 that \ud835\udc402\u00d72(F) = Span(\u212c). Since \u212c is a linearly\nindependent spanning set for \ud835\udc402\u00d72(F), it is a basis for \ud835\udc402\u00d72(F).\nEXERCISE\nShow that the set\n\u212c =\n{\ufe02[\ufe021 0\n0 1\n]\ufe02\n,\n[\ufe020 1\n0 0\n]\ufe02\n,\n[\ufe020 0\n1 0\n]\ufe02\n,\n[\ufe021 0\n0 \u22121\n]\ufe02}\ufe02\nis a basis for \ud835\udc402\u00d72(F).\nExample 10.2.9\nShow that the set\n\u212c = {1 \u2212 \ud835\udc652, \u22121 + \ud835\udc56\ud835\udc65, \u22121 \u2212 \ud835\udc56\ud835\udc65}\nis a basis for \ud835\udc432(C).\nSolution: It was demonstrated in Example 10.2.6 that \u212c is linearly independent. It was also\ndemonstrated in Example 10.2.3 that \ud835\udc432(C) = Span(\u212c). Since \u212c is a linearly independent\nspanning set for \ud835\udc432(C), it is a basis for \ud835\udc432(C).\nEXERCISE\nLet \ud835\udc5b be a non-negative integer. Determine whether or not the set\n\u212c = {1, 2\ud835\udc65, 4\ud835\udc652, . . . , 2\ud835\udc5b\ud835\udc65\ud835\udc5b}\nis a basis for \ud835\udc432(F).264\nChapter 10\nVector Spaces\nWith the definitions of the span of a set, linear independence, linear dependence, and basis\nbeing so similar to what were used previously in the context of F\ud835\udc5b, it should come as no\nsurprise that much of what we developed in that context holds for general vector spaces\nas well. In particular, analogous results to Theorem 8.7.2 (Dimension is Well-Defined) and\nTheorem 8.8.1 (Unique Representation Theorem) exist, allowing us to define the notions of\ndimension and coordinate vectors. With these tools, we can translate much of the work of\ngeneral vector spaces back to familiar territory in the context of F\ud835\udc5b!\n10.3", "Linear Operators\nJust like we were able to generalize the notions of a vector space, linear dependence, linear\nindependence, and basis, we can generalize the notion of a linear transformation.\nDefinition 10.3.1\nGeneric Linear\nTransformation\nLet (V, F, + , \u00b7 ) and (W, F, \u2295, \u2299) be vector spaces over the same field F. We say\nthat the function \ud835\udc47 : V \u2192 W is a linear transformation (or linear mapping) if, for any\n#\u00bb\ud835\udc65, #\u00bb\ud835\udc66 \u2208 V and any \ud835\udc50 \u2208 F, the following two properties hold:\n1. \ud835\udc47(#\u00bb\ud835\udc65 + #\u00bb\ud835\udc66 ) = \ud835\udc47(#\u00bb\ud835\udc65) \u2295 \ud835\udc47(#\u00bb\ud835\udc66 ) (called linearity over addition).\n2. \ud835\udc47(\ud835\udc50 \u00b7 #\u00bb\ud835\udc65) = \ud835\udc50 \u2299 \ud835\udc47(#\u00bb\ud835\udc65) (called linearity over scalar multiplication).\nWe refer to V here as the domain of \ud835\udc47 and W as the codomain of \ud835\udc47, as we would for any\nfunction.\nWhen studying functions between vector spaces, we will restrict our attention only to linear\ntransformations whose domains and codomains are F\ud835\udc5b, \ud835\udc43\ud835\udc5b(F) and \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F), equipped with\nthe standard operations of addition and scalar multiplication. In view of this, we will write\nV instead of (V, F, + , \u00b7 ) for brevity.\nExample 10.3.2\nFor a positive integer \ud835\udc5b, consider the function\n\ud835\udc37: \ud835\udc43\ud835\udc5b(F) \u2192 \ud835\udc43\ud835\udc5b(F)\ndefined by\n\ud835\udc37(\ud835\udc4e0 + \ud835\udc4e1\ud835\udc65 + \ud835\udc4e2\ud835\udc652 + \u00b7 \u00b7 \u00b7 + \ud835\udc4e\ud835\udc5b\ud835\udc65\ud835\udc5b) = \ud835\udc4e1 + (2\ud835\udc4e2)\ud835\udc65 + \u00b7 \u00b7 \u00b7 + (\ud835\udc5b\ud835\udc4e\ud835\udc5b)\ud835\udc65\ud835\udc5b\u22121.\nShow that \ud835\udc37 is a linear transformation.\nSolution: Notice that, for all polynomials\n\ud835\udc53(\ud835\udc65) = \ud835\udc4e0 + \ud835\udc4e1\ud835\udc65 + \ud835\udc4e2\ud835\udc652 + \u00b7 \u00b7 \u00b7 + \ud835\udc4e\ud835\udc5b\ud835\udc65\ud835\udc5b\nand\n\ud835\udc54(\ud835\udc65) = \ud835\udc4f0 + \ud835\udc4f1\ud835\udc65 + \ud835\udc4f2\ud835\udc652 + \u00b7 \u00b7 \u00b7 + \ud835\udc4f\ud835\udc5b\ud835\udc65\ud835\udc5b,\nwe have\n\ud835\udc37(\ud835\udc53(\ud835\udc65) + \ud835\udc54(\ud835\udc65)) = \ud835\udc37((\ud835\udc4e0 + \ud835\udc4f0) + (\ud835\udc4e1 + \ud835\udc4f1)\ud835\udc65 + (\ud835\udc4e2 + \ud835\udc4f2)\ud835\udc652 + \u00b7 \u00b7 \u00b7 + (\ud835\udc4e\ud835\udc5b + \ud835\udc4f\ud835\udc5b)\ud835\udc65\ud835\udc5b)\n= (\ud835\udc4e1 + \ud835\udc4f1) + 2(\ud835\udc4e2 + \ud835\udc4f2)\ud835\udc65 + \u00b7 \u00b7 \u00b7 + \ud835\udc5b(\ud835\udc4e\ud835\udc5b + \ud835\udc4f\ud835\udc5b)\ud835\udc65\ud835\udc5b\u22121\n= (\ud835\udc4e1 + 2\ud835\udc4e2\ud835\udc65 + \u00b7 \u00b7 \u00b7 + \ud835\udc5b\ud835\udc4e\ud835\udc5b\ud835\udc65\ud835\udc5b\u22121) + (\ud835\udc4f1 + 2\ud835\udc4f2\ud835\udc65 + \u00b7 \u00b7 \u00b7 + \ud835\udc5b\ud835\udc4f\ud835\udc5b\ud835\udc65\ud835\udc5b\u22121)\n= \ud835\udc37(\ud835\udc53(\ud835\udc65)) + \ud835\udc37(\ud835\udc54(\ud835\udc65)),Section 10.3\nLinear Operators\n265\nand for all \ud835\udc50 \u2208 F we have\n\ud835\udc37(\ud835\udc50\ud835\udc53(\ud835\udc65)) = \ud835\udc37(\ud835\udc50\ud835\udc4e0 + \ud835\udc50\ud835\udc4e1\ud835\udc65 + \ud835\udc50\ud835\udc4e2\ud835\udc652 + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc4e\ud835\udc5b\ud835\udc65\ud835\udc5b)\n= \ud835\udc50\ud835\udc4e1 + \ud835\udc50(2\ud835\udc4e2)\ud835\udc65 + \u00b7 \u00b7 \u00b7 + \ud835\udc50(\ud835\udc5b\ud835\udc4e\ud835\udc5b)\ud835\udc65\ud835\udc5b\u22121\n= \ud835\udc50(\ud835\udc4e1 + 2\ud835\udc4e2\ud835\udc65 + \u00b7 \u00b7 \u00b7 \ud835\udc5b\ud835\udc4e\ud835\udc5b\ud835\udc65\ud835\udc5b\u22121)\n= \ud835\udc50\ud835\udc37(\ud835\udc53(\ud835\udc65)).\nThus, \ud835\udc37 is a linear transformation. If you studied calculus, then you may recognize that \ud835\udc37\nis the differentiation operator; that is, for any polynomial \ud835\udc53(\ud835\udc65) \u2208 \ud835\udc43\ud835\udc5b(F), \ud835\udc37(\ud835\udc53(\ud835\udc65)) = \ud835\udc53\u2032(\ud835\udc65),\nwhere \ud835\udc53\u2032(\ud835\udc65) is the derivative of \ud835\udc53(\ud835\udc65).\nEXERCISE\nShow that the function \ud835\udc47 : \ud835\udc43\ud835\udc5b(F) \u2192 F defined by \ud835\udc47(\ud835\udc53(\ud835\udc65)) = \ud835\udc53(0) is a linear transformation.\nExample 10.3.3\nFor positive integers \ud835\udc5a and \ud835\udc5b, consider the function\n\ud835\udc46 : \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F) \u2192 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5a(F)\ndefined by\n\ud835\udc46(\ud835\udc34) = \ud835\udc34\ud835\udc47 .\nThat is, \ud835\udc46(\ud835\udc34) is equal to the transpose of the \ud835\udc5a \u00d7 \ud835\udc5b matrix \ud835\udc34. Show that \ud835\udc46 is a linear\ntransformation.\nSolution: In order to prove that \ud835\udc46 is a linear transformation we will use Proposition 4.3.\n13 (Properties of Matrix Transpose).\nNotice that, for all \ud835\udc34, \ud835\udc35 \u2208 \ud835\udc40\ud835\udc5a\u00d7\ud835\udc5b(F), we have\n\ud835\udc46(\ud835\udc34 + \ud835\udc35) = (\ud835\udc34 + \ud835\udc35)\ud835\udc47\n= \ud835\udc34\ud835\udc47 + \ud835\udc35\ud835\udc47\nby Proposition 4.3.13\n= \ud835\udc46(\ud835\udc34) + \ud835\udc46(\ud835\udc35).\nMoreover, for all \ud835\udc50 \u2208 F, we have\n\ud835\udc46(\ud835\udc50\ud835\udc34) = (\ud835\udc50\ud835\udc34)\ud835\udc47\n= \ud835\udc50\ud835\udc34\ud835\udc47\nby Proposition 4.3.13\n= \ud835\udc50\ud835\udc46(\ud835\udc34).\nThus, \ud835\udc46 is a linear transformation.\nEXERCISE\nRecall from Definition 7.3.2 that the trace tr(\ud835\udc34) of a square matrix \ud835\udc34 is defined as the sum\nof diagonal entries of \ud835\udc34. Show that the function tr: \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) \u2192 F is a linear transformation.266\nChapter 10\nVector Spaces\nAs in Chapter 9, the linear transformations \ud835\udc47 : V \u2192 V whose domain and codomain are the\nsame set are especially interesting to us.\nDefinition 10.3.4\nLinear Operator\nA linear transformation \ud835\udc47 : V \u2192 V is called a linear operator.\nJust like linear operators on F\ud835\udc5b that we studied in Chapter 9, linear operators \ud835\udc47 : V \u2192 V\nhave many nice properties, such as the property that the composition of \ud835\udc47 with itself, \ud835\udc47 \u2218\ud835\udc47,\nis well-defined, or that we can naturally introduce eigenvalues, eigenvectors, and eigenpairs\nfor \ud835\udc47. We will explore this second property in detail.\nDefinition 10.3.5\nEigenvector,\nEigenvalue and\nEigenpair of a\nLinear Operator\nLet \ud835\udc47 : V \u2192 V be a linear operator. We say that the nonzero vector #\u00bb\ud835\udc65 \u2208 V is an eigen-\nvector of \ud835\udc47 if there exists a scalar \ud835\udf06 \u2208 F such that\n\ud835\udc47(#\u00bb\ud835\udc65) = \ud835\udf06#\u00bb\ud835\udc65.\nThe scalar \ud835\udf06 is called an eigenvalue of \ud835\udc47 over F and the pair (\ud835\udf06, #\u00bb\ud835\udc65) is called an eigenpair\nof \ud835\udc47 over F.\nThus, if (\ud835\udf06, #\u00bb\ud835\udc65) is an eigenpair of \ud835\udc47 over F, then the action of \ud835\udc47 on #\u00bb\ud835\udc65 is especially simple,\ni.e., it is the result of scaling the vector #\u00bb\ud835\udc65 by a factor \ud835\udf06. In fact, this observation applies\nnot only to #\u00bb\ud835\udc65, but to any vector #\u00bb\ud835\udc66 = \ud835\udc50#\u00bb\ud835\udc65 with \ud835\udc50 \u2208 F that is a scalar multiple of #\u00bb\ud835\udc65, because\n\ud835\udc47(#\u00bb\ud835\udc66 ) = \ud835\udc47(\ud835\udc50#\u00bb\ud835\udc65) = \ud835\udc50\ud835\udc47(#\u00bb\ud835\udc65) = \ud835\udc50(\ud835\udf06#\u00bb\ud835\udc65) = \ud835\udf06(\ud835\udc50#\u00bb\ud835\udc65) = \ud835\udf06#\u00bb\ud835\udc66 .\nExample 10.3.6\nConsider the differentiation operator \ud835\udc37: \ud835\udc43\ud835\udc5b(F) \u2192 \ud835\udc43\ud835\udc5b(F) from Example 10.3.2. Then the\nconstant polynomial \ud835\udc5d(\ud835\udc65) = 1 satisfies\n\ud835\udc37(\ud835\udc5d(\ud835\udc65)) = \ud835\udc37(1) = 0 = 0 \u00b7 \ud835\udc5d(\ud835\udc65).\nSince \ud835\udc5d(\ud835\udc65) is not the zero polynomial, we see that, for \ud835\udf06 = 0, (\ud835\udf06, \ud835\udc5d(\ud835\udc65)) is an eigenpair of \ud835\udc37\nover F.\nExample 10.3.7\nIf in Example 10.3.3 we assume that \ud835\udc5a = \ud835\udc5b, then \ud835\udc46 : \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) \u2192 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) is a linear\noperator. Since the \ud835\udc5b\u00d7\ud835\udc5b identity matrix \ud835\udc3c\ud835\udc5b is diagonal, it remains fixed under the operation\nof matrix transpose, and so\n\ud835\udc46(\ud835\udc3c\ud835\udc5b) = \ud835\udc3c\ud835\udc47\n\ud835\udc5b = \ud835\udc3c\ud835\udc5b = 1 \u00b7 \ud835\udc3c\ud835\udc5b.\nSince \ud835\udc3c\ud835\udc5b is not the zero matrix, we see that, for \ud835\udf06 = 1, (\ud835\udf06, \ud835\udc3c\ud835\udc5b) is an eigenpair of \ud835\udc46 over F.\nAs we learned in Chapter 9, given an arbitrary linear operator \ud835\udc47 : F\ud835\udc5b \u2192 F\ud835\udc5b, it may be quite\ndifficult to understand the nature of its action. However, when \ud835\udc47 has a basis of eigenvec-\ntors {#\u00bb\ud835\udc63 1, . . . , #\u00bb\ud835\udc63 \ud835\udc5b}, then it follows from Proposition 9.2.6 (Eigenvector Basis Criterion for\nDiagonalizability) that \ud835\udc47 is diagonalizable, and so the action of \ud835\udc47 is well understood in\nthis case. We can use this criterion to introduce the notion of diagonalizability for linear\noperators V \u2192 V.Section 10.3\nLinear Operators\n267\nDefinition 10.3.8\nDiagonalizable\nLet \ud835\udc47 : V \u2192 V be a linear operator. We say that \ud835\udc47 is diagonalizable over F if there exists\na basis \u212c of V comprised of eigenvectors of \ud835\udc47.\nWhen \ud835\udc47 is diagonalizable, the action of \ud835\udc47 on an arbitrary vector #\u00bb\ud835\udc65 \u2208 V can be interpreted\nas scaling the vector #\u00bb\ud835\udc65 by a factor of \ud835\udf06\ud835\udc56 in the direction of an eigenvector #\u00bb\ud835\udc63 \ud835\udc56 of \ud835\udc47. We\nsummarize this observation in the following theorem, whose proof we leave as an exercise.\nTheorem 10.3.9\n(Diagonalizable Operators Viewed As Scalings)\nLet \ud835\udc47 : V \u2192 V be a diagonalizable linear operator. Let \u212c = {#\u00bb\ud835\udc63 1, . . . , #\u00bb\ud835\udc63 \ud835\udc5b} be a basis of\nV comprised of eigenvectors of \ud835\udc47 and, for \ud835\udc56 = 1, . . . , \ud835\udc5b, let \ud835\udf06\ud835\udc56 denote the eigenvalue of \ud835\udc47\ncorresponding to #\u00bb\ud835\udc63 \ud835\udc56. Then, for any #\u00bb\ud835\udc65 \u2208 V, if\n#\u00bb\ud835\udc65 = \ud835\udc501 #\u00bb\ud835\udc63 1 + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc5b #\u00bb\ud835\udc63 \ud835\udc5b,\n\ud835\udc501, . . . , \ud835\udc50\ud835\udc5b \u2208 F,\nwe have that\n\ud835\udc47(#\u00bb\ud835\udc65) = \ud835\udc47(\ud835\udc501 #\u00bb\ud835\udc63 1 + \u00b7 \u00b7 \u00b7 + \ud835\udc50\ud835\udc5b #\u00bb\ud835\udc63 \ud835\udc5b) = \ud835\udf061\ud835\udc501 #\u00bb\ud835\udc63 1 + \u00b7 \u00b7 \u00b7 + \ud835\udf06\ud835\udc5b\ud835\udc50\ud835\udc5b #\u00bb\ud835\udc63 \ud835\udc5b.\nThat is, the action of \ud835\udc47 on #\u00bb\ud835\udc65 can be viewed as the result of scaling #\u00bb\ud835\udc65 by a factor of \ud835\udf06\ud835\udc56 in\nthe direction of #\u00bb\ud835\udc63 \ud835\udc56 for each \ud835\udc56.\nExample 10.3.10\nShow that the linear operator \ud835\udc46 : \ud835\udc402\u00d72(F) \u2192 \ud835\udc402\u00d72(F) given by \ud835\udc46(\ud835\udc34) = \ud835\udc34\ud835\udc47 is diagonaliz-\nable.\nSolution: By observation, we find that\n\ud835\udc46\n(\ufe02[\ufe021 0\n0 0\n]\ufe02)\ufe02\n= 1 \u00b7\n[\ufe021 0\n0 0\n]\ufe02\n,\n\ud835\udc46\n(\ufe02[\ufe020 0\n0 1\n]\ufe02)\ufe02\n= 1 \u00b7\n[\ufe020 0\n0 1\n]\ufe02\n,\n\ud835\udc46\n(\ufe02[\ufe020 1\n1 0\n]\ufe02)\ufe02\n= 1 \u00b7\n[\ufe020 1\n1 0\n]\ufe02\n,\n\ud835\udc46\n(\ufe02[\ufe02 0 1\n\u22121 0\n]\ufe02)\ufe02\n= (\u22121) \u00b7\n[\ufe02 0 1\n\u22121 0\n]\ufe02\n.\nThus,\n(\ufe02\n1,\n[\ufe021 0\n0 0\n]\ufe02)\ufe02\n,\n(\ufe02\n1,\n[\ufe020 1\n1 0\n]\ufe02)\ufe02\n,\n(\ufe02\n1,\n[\ufe020 1\n1 0\n]\ufe02)\ufe02\nand\n(\ufe02\n\u22121,\n[\ufe02 0 1\n\u22121 0\n]\ufe02)\ufe02\nare the eigenpairs of \ud835\udc46. As we have seen in Example 10.2.8, the set\n\u212c =\n{\ufe02[\ufe021 0\n0 0\n]\ufe02\n,\n[\ufe020 0\n0 1\n]\ufe02\n,\n[\ufe020 1\n1 0\n]\ufe02\n,\n[\ufe02 0 1\n\u22121 0\n]\ufe02}\ufe02\nis a basis of V. Thus, \u212c is a basis of eigenvectors of \ud835\udc46, which means that \ud835\udc46 is diagonaliz-\nable. By Theorem 10.3.9 (Diagonalizable Operators Viewed As Scalings), for any matrix\n\ud835\udc34 \u2208 \ud835\udc402\u00d72(F) such that\n\ud835\udc34 = \ud835\udc501\n[\ufe021 0\n0 0\n]\ufe02\n+ \ud835\udc502\n[\ufe020 0\n0 1\n]\ufe02\n+ \ud835\udc503\n[\ufe020 1\n1 0\n]\ufe02\n+ \ud835\udc504\n[\ufe02 0 1\n\u22121 0\n]\ufe02\n=\n[\ufe02\n\ud835\udc501\n\ud835\udc503 + \ud835\udc504\n\ud835\udc503 \u2212 \ud835\udc504\n\ud835\udc502\n]\ufe02\n,268\nChapter 10\nVector Spaces\nwe have\n\ud835\udc46(\ud835\udc34) = \ud835\udc46\n(\ufe02[\ufe02\n\ud835\udc501\n\ud835\udc503 + \ud835\udc504\n\ud835\udc503 \u2212 \ud835\udc504\n\ud835\udc502\n]\ufe02)\ufe02\n= \ud835\udc46\n(\ufe02\n\ud835\udc501\n[\ufe021 0\n0 0\n]\ufe02\n+ \ud835\udc502\n[\ufe020 1\n1 0\n]\ufe02\n+ \ud835\udc503\n[\ufe020 1\n1 0\n]\ufe02\n+ \ud835\udc504\n[\ufe02 0 1\n\u22121 0\n]\ufe02)\ufe02\n= \ud835\udc501\n[\ufe021 0\n0 0\n]\ufe02\n+ \ud835\udc502\n[\ufe020 1\n1 0\n]\ufe02\n+ \ud835\udc503\n[\ufe020 1\n1 0\n]\ufe02\n\u2212 \ud835\udc504\n[\ufe02 0 1\n\u22121 0\n]\ufe02\n=\n[\ufe02\n\ud835\udc501\n\ud835\udc503 \u2212 \ud835\udc504\n\ud835\udc503 + \ud835\udc504\n\ud835\udc502\n]\ufe02\n.\nEXERCISE\nRecall Definition 6.4.2, where the adjugate of a square matrix was introduced. Show that\nthe linear operator adj: \ud835\udc402\u00d72(F) \u2192 \ud835\udc402\u00d72(F) given by\nadj\n(\ufe02[\ufe02\ud835\udc4e \ud835\udc4f\n\ud835\udc50 \ud835\udc51\n]\ufe02)\ufe02\n=\n[\ufe02 \ud835\udc51 \u2212\ud835\udc4f\n\u2212\ud835\udc50 \ud835\udc4e\n]\ufe02\nis diagonalizable over F.\nREMARK\nNotice that the function adj: \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) \u2192 \ud835\udc40\ud835\udc5b\u00d7\ud835\udc5b(F) is not linear when \ud835\udc5b \u2265 3.\nEXERCISE\nShow that, for any positive integer \ud835\udc5b, the linear operator \ud835\udc47 : \ud835\udc43\ud835\udc5b(F) \u2192 \ud835\udc43\ud835\udc5b(F) given by\n\ud835\udc47(\ud835\udc5d(\ud835\udc65)) = \ud835\udc5d(2\ud835\udc65) is diagonalizable over F.\nJust like Example 10.3.10, the exercises above can be solved by observation by finding the\nmost \u201cnatural\u201d basis of eigenvectors.\nHowever, in general, this method does not work,\nas sometimes a linear operator \ud835\udc47 : V \u2192 V may not be diagonalizable, and even if it is\ndiagonalizable the action of \ud835\udc47 may be so complicated that a basis of eigenvectors may not\nbe obvious.\nExample 10.3.11\nShow that the linear operator \ud835\udc47 : \ud835\udc432(C) \u2192 \ud835\udc432(C) given by\n\ud835\udc47(\ud835\udc4e0 + \ud835\udc4e1\ud835\udc65 + \ud835\udc4e2\ud835\udc652) = (\u2212\ud835\udc4e1 \u2212 \ud835\udc4e2) + (\ud835\udc4e0 + \ud835\udc4e2)\ud835\udc65 + \ud835\udc4e2\ud835\udc652\nis diagonalizable over C.\nSolution: As an exercise, show that\n\ud835\udc47(1 \u2212 \ud835\udc652) = 1 \u2212 \ud835\udc652,\n\ud835\udc47(\u22121 + \ud835\udc56\ud835\udc65) = \u22121 + \ud835\udc56\ud835\udc65,\nand \ud835\udc47(\u22121 \u2212 \ud835\udc56\ud835\udc65) = \ud835\udc56 \u2212 \ud835\udc65 = \u2212\ud835\udc56(\u22121 \u2212 \ud835\udc56\ud835\udc65),Section 10.3\nLinear Operators\n269\nso that we may conclude\n(1, 1 \u2212 \ud835\udc652), (\ud835\udc56, \u22121 + \ud835\udc56\ud835\udc65),\nand\n(\u2212\ud835\udc56, \u22121 \u2212 \ud835\udc56\ud835\udc65)\nare eigenpairs of \ud835\udc47. As we have seen in Example 10.2.9, the set\n\u212c = {1 \u2212 \ud835\udc652, \u22121 + \ud835\udc56\ud835\udc65, \u22121 \u2212 \ud835\udc56\ud835\udc65}\nis a basis of \ud835\udc432(C). Thus, \u212c is a basis of \ud835\udc432(C) comprised of eigenvectors of \ud835\udc47, which\nmeans that \ud835\udc47 is diagonalizable. By Theorem 10.3.9 (Diagonalizable Operators Viewed As\nScalings), for any polynomial \ud835\udc5d(\ud835\udc65) \u2208 \ud835\udc432(C) such that\n\ud835\udc5d(\ud835\udc65) = \ud835\udc501(1 \u2212 \ud835\udc652) + \ud835\udc502(\u22121 + \ud835\udc56\ud835\udc65) + \ud835\udc503(\u22121 \u2212 \ud835\udc56\ud835\udc65)\n= (\ud835\udc501 \u2212 \ud835\udc502 \u2212 \ud835\udc503) + (\ud835\udc56\ud835\udc502 \u2212 \ud835\udc56\ud835\udc503)\ud835\udc65 \u2212 \ud835\udc501\ud835\udc652\nwe have\n\ud835\udc47(\ud835\udc5d(\ud835\udc65)) = \ud835\udc47\n(\ufe00\n(\ud835\udc501 \u2212 \ud835\udc502 \u2212 \ud835\udc503) + (\ud835\udc56\ud835\udc502 \u2212 \ud835\udc56\ud835\udc503)\ud835\udc65 \u2212 \ud835\udc501\ud835\udc652)\ufe00\n= \ud835\udc47\n(\ufe00\n\ud835\udc501(1 \u2212 \ud835\udc652) + \ud835\udc502(\u22121 + \ud835\udc56\ud835\udc65) + \ud835\udc503(\u22121 \u2212 \ud835\udc56\ud835\udc65)\n)\ufe00\n= \ud835\udc501(1 \u2212 \ud835\udc652) + \ud835\udc56\ud835\udc502(\u22121 + \ud835\udc56\ud835\udc65) \u2212 \ud835\udc56\ud835\udc503(\u22121 \u2212 \ud835\udc56\ud835\udc65)\n= (\ud835\udc501 \u2212 \ud835\udc56\ud835\udc502 + \ud835\udc56\ud835\udc503) + (\u2212\ud835\udc502 \u2212 \ud835\udc503)\ud835\udc65 \u2212 \ud835\udc501\ud835\udc652.\nIn the solution to Example 10.3.11 a basis of eigenvectors \u212c was provided to you, but had\nwe have not provided it, finding \u212c would be a non-trivial task.\nFurthermore, with the\ntechniques that we currently have you would not be able to show that the linear operator\n\ud835\udc47 from Example 10.3.11 is not diagonalizable over R, or that the operator \ud835\udc37 from Example\n10.3.2 is not diagonalizable over F. This requires further generalizaton of the diagonalization\ntheory, which includes the introduction of notions such as the kernel of a linear operator,\n\u212c-matrix of a linear operator, geometric and algebraic multiplicities, etc.\nThis theory,\nalong with many other fascinating topics, is studied in detail in a subsequent linear algebra\ncourse."]